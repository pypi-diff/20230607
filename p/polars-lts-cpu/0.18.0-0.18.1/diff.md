# Comparing `tmp/polars_lts_cpu-0.18.0.tar.gz` & `tmp/polars_lts_cpu-0.18.1.tar.gz`

## Comparing `polars_lts_cpu-0.18.0.tar` & `polars_lts_cpu-0.18.1.tar`

### file list

```diff
@@ -1,1208 +1,1240 @@
--rw-r--r--   0        0        0     5256 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/LICENSE
--rw-r--r--   0     1001      123       45 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/constants.rs
--rw-r--r--   0     1001      123    17248 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dot.rs
--rw-r--r--   0     1001      123     4171 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/arithmetic.rs
--rw-r--r--   0     1001      123     3992 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/arity.rs
--rw-r--r--   0     1001      123      758 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/array.rs
--rw-r--r--   0     1001      123      935 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/binary.rs
--rw-r--r--   0     1001      123      650 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/cat.rs
--rw-r--r--   0     1001      123    10228 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/dt.rs
--rw-r--r--   0     1001      123    13410 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/expr.rs
--rw-r--r--   0     1001      123      753 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/from.rs
--rw-r--r--   0     1001      123       85 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/abs.rs
--rw-r--r--   0     1001      123     1431 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/arg_where.rs
--rw-r--r--   0     1001      123      780 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/array.rs
--rw-r--r--   0     1001      123     1327 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/binary.rs
--rw-r--r--   0     1001      123     4221 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/boolean.rs
--rw-r--r--   0     1001      123     1910 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/bounds.rs
--rw-r--r--   0     1001      123     1216 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/cat.rs
--rw-r--r--   0     1001      123      344 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/clip.rs
--rw-r--r--   0     1001      123     1593 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/cum.rs
--rw-r--r--   0     1001      123     9529 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/datetime.rs
--rw-r--r--   0     1001      123      673 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/dispatch.rs
--rw-r--r--   0     1001      123     2567 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/fill_null.rs
--rw-r--r--   0     1001      123      992 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/fused.rs
--rw-r--r--   0     1001      123     8119 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/list.rs
--rw-r--r--   0     1001      123      581 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/log.rs
--rw-r--r--   0     1001      123    20488 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/mod.rs
--rw-r--r--   0     1001      123      462 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/nan.rs
--rw-r--r--   0     1001      123     3132 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/pow.rs
--rw-r--r--   0     1001      123      152 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/rolling.rs
--rw-r--r--   0     1001      123      260 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/round.rs
--rw-r--r--   0     1001      123      200 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/row_hash.rs
--rw-r--r--   0     1001      123    13744 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/schema.rs
--rw-r--r--   0     1001      123      306 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/search_sorted.rs
--rw-r--r--   0     1001      123     3812 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/shift_and_fill.rs
--rw-r--r--   0     1001      123     1238 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/shrink_type.rs
--rw-r--r--   0     1001      123      972 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/sign.rs
--rw-r--r--   0     1001      123    21037 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/strings.rs
--rw-r--r--   0     1001      123     1017 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/struct_.rs
--rw-r--r--   0     1001      123     5406 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/temporal.rs
--rw-r--r--   0     1001      123     5122 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/trigonometry.rs
--rw-r--r--   0     1001      123      170 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/unique.rs
--rw-r--r--   0     1001      123    48049 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/functions.rs
--rw-r--r--   0     1001      123    10213 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/list.rs
--rw-r--r--   0     1001      123     2181 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/meta.rs
--rw-r--r--   0     1001      123    60990 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/mod.rs
--rw-r--r--   0     1001      123       40 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/names.rs
--rw-r--r--   0     1001      123     2786 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/options.rs
--rw-r--r--   0     1001      123    17095 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/string.rs
--rw-r--r--   0     1001      123     2715 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/struct_.rs
--rw-r--r--   0     1001      123       38 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/frame/mod.rs
--rw-r--r--   0     1001      123      933 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/frame/opt_state.rs
--rw-r--r--   0     1001      123      466 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/global.rs
--rw-r--r--   0     1001      123      175 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/lib.rs
--rw-r--r--   0     1001      123     8318 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/aexpr/mod.rs
--rw-r--r--   0     1001      123    11653 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/aexpr/schema.rs
--rw-r--r--   0     1001      123    25683 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/alp.rs
--rw-r--r--   0     1001      123     1622 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/anonymous_scan.rs
--rw-r--r--   0     1001      123     1428 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/apply.rs
--rw-r--r--   0     1001      123    24898 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/builder.rs
--rw-r--r--   0     1001      123    29916 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/conversion.rs
--rw-r--r--   0     1001      123      301 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/debug.rs
--rw-r--r--   0     1001      123    15415 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/format.rs
--rw-r--r--   0     1001      123      895 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/functions/drop.rs
--rw-r--r--   0     1001      123      137 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/functions/explode.rs
--rw-r--r--   0     1001      123     1169 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/functions/merge_sorted.rs
--rw-r--r--   0     1001      123    11905 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/functions/mod.rs
--rw-r--r--   0     1001      123     1330 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/functions/rename.rs
--rw-r--r--   0     1001      123     9849 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/iterator.rs
--rw-r--r--   0     1001      123    10559 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/lit.rs
--rw-r--r--   0     1001      123     8115 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/mod.rs
--rw-r--r--   0     1001      123     7416 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/cache_states.rs
--rw-r--r--   0     1001      123    15277 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/cse.rs
--rw-r--r--   0     1001      123     3250 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/delay_rechunk.rs
--rw-r--r--   0     1001      123     3236 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/drop_nulls.rs
--rw-r--r--   0     1001      123     3994 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/fast_projection.rs
--rw-r--r--   0     1001      123    14479 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/file_caching.rs
--rw-r--r--   0     1001      123     1556 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/flatten_union.rs
--rw-r--r--   0     1001      123     5827 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/fused.rs
--rw-r--r--   0     1001      123     6774 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/mod.rs
--rw-r--r--   0     1001      123     1222 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/keys.rs
--rw-r--r--   0     1001      123    28871 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/mod.rs
--rw-r--r--   0     1001      123     2571 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/rename.rs
--rw-r--r--   0     1001      123    15756 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/utils.rs
--rw-r--r--   0     1001      123     1755 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/melt.rs
--rw-r--r--   0     1001      123     3930 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/mod.rs
--rw-r--r--   0     1001      123     1799 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/generic.rs
--rw-r--r--   0     1001      123     3269 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/groupby.rs
--rw-r--r--   0     1001      123     2638 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/hstack.rs
--rw-r--r--   0     1001      123    15747 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/joins.rs
--rw-r--r--   0     1001      123    26502 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/mod.rs
--rw-r--r--   0     1001      123     3707 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/projection.rs
--rw-r--r--   0     1001      123     2639 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/rename.rs
--rw-r--r--   0     1001      123     3501 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/semi_anti_join.rs
--rw-r--r--   0     1001      123    27269 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/simplify_expr.rs
--rw-r--r--   0     1001      123     3492 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_expr.rs
--rw-r--r--   0     1001      123    13781 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_lp.rs
--rw-r--r--   0     1001      123     4181 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/stack_opt.rs
--rw-r--r--   0     1001      123     9725 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/binary.rs
--rw-r--r--   0     1001      123    20215 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/mod.rs
--rw-r--r--   0     1001      123     9838 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/options.rs
--rw-r--r--   0     1001      123    15313 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/projection.rs
--rw-r--r--   0     1001      123     5551 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/pyarrow.rs
--rw-r--r--   0     1001      123    13042 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/schema.rs
--rw-r--r--   0     1001      123      832 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/prelude.rs
--rw-r--r--   0     1001      123    11872 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/utils.rs
--rw-r--r--   0        0        0     4447 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/LICENSE
--rw-r--r--   0     1001      123      138 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/README.md
--rw-r--r--   0     1001      123     2383 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/avro/mod.rs
--rw-r--r--   0     1001      123     3608 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/avro/read.rs
--rw-r--r--   0     1001      123     2622 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/avro/write.rs
--rw-r--r--   0     1001      123     4505 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/cloud/adaptors.rs
--rw-r--r--   0     1001      123     9506 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/cloud/glob.rs
--rw-r--r--   0     1001      123     3089 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/cloud/mod.rs
--rw-r--r--   0     1001      123    28419 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/buffer.rs
--rw-r--r--   0     1001      123     1898 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/mod.rs
--rw-r--r--   0     1001      123    19446 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/parser.rs
--rw-r--r--   0     1001      123    21432 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/read.rs
--rw-r--r--   0     1001      123    10846 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/read_impl/batched_mmap.rs
--rw-r--r--   0     1001      123    13938 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/read_impl/batched_read.rs
--rw-r--r--   0     1001      123    30724 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/read_impl/mod.rs
--rw-r--r--   0     1001      123    11466 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/splitfields.rs
--rw-r--r--   0     1001      123    24531 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/utils.rs
--rw-r--r--   0     1001      123     2796 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/write.rs
--rw-r--r--   0     1001      123    14759 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/write_impl.rs
--rw-r--r--   0     1001      123      184 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/export.rs
--rw-r--r--   0     1001      123     7586 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/ipc/ipc_file.rs
--rw-r--r--   0     1001      123     9227 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/ipc/ipc_stream.rs
--rw-r--r--   0     1001      123     3253 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/ipc/mmap.rs
--rw-r--r--   0     1001      123      401 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/ipc/mod.rs
--rw-r--r--   0     1001      123     8287 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/ipc/write.rs
--rw-r--r--   0     1001      123     1471 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/ipc/write_async.rs
--rw-r--r--   0     1001      123    11044 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/json/mod.rs
--rw-r--r--   0     1001      123     4859 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/lib.rs
--rw-r--r--   0     1001      123     1969 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/mmap.rs
--rw-r--r--   0     1001      123     7155 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/ndjson/buffer.rs
--rw-r--r--   0     1001      123    12013 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/ndjson/core.rs
--rw-r--r--   0     1001      123       37 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/ndjson/mod.rs
--rw-r--r--   0     1001      123      273 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/options.rs
--rw-r--r--   0     1001      123     7360 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/parquet/async_impl.rs
--rw-r--r--   0     1001      123     3093 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/parquet/mmap.rs
--rw-r--r--   0     1001      123     3132 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/parquet/mod.rs
--rw-r--r--   0     1001      123     4784 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/parquet/predicates.rs
--rw-r--r--   0     1001      123     9623 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/parquet/read.rs
--rw-r--r--   0     1001      123    16886 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/parquet/read_impl.rs
--rw-r--r--   0     1001      123    10052 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/parquet/write.rs
--rw-r--r--   0     1001      123     5334 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/partition.rs
--rw-r--r--   0     1001      123     1455 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/predicates.rs
--rw-r--r--   0     1001      123      621 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/prelude.rs
--rw-r--r--   0     1001      123      417 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/tests.rs
--rw-r--r--   0     1001      123     4374 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/utils.rs
--rw-r--r--   0        0        0    10716 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/LICENSE
--rw-r--r--   0     1001      123     3590 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/Makefile
--rw-r--r--   0     1001      123      215 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/build.rs
--rw-r--r--   0     1001      123       78 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/clippy.toml
--rw-r--r--   0     1001      123    17602 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/src/docs/eager.rs
--rw-r--r--   0     1001      123     8794 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/src/docs/lazy.rs
--rw-r--r--   0     1001      123       50 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/src/docs/mod.rs
--rw-r--r--   0     1001      123     3797 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/src/docs/performance.rs
--rw-r--r--   0     1001      123       59 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/src/export.rs
--rw-r--r--   0     1001      123    20213 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/src/lib.rs
--rw-r--r--   0     1001      123      387 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/src/prelude.rs
--rw-r--r--   0     1001      123       44 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/src/sql.rs
--rw-r--r--   0     1001      123     4272 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/date_like.rs
--rw-r--r--   0     1001      123     2401 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/groupby.rs
--rw-r--r--   0     1001      123    17826 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/joins.rs
--rw-r--r--   0     1001      123      545 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/list.rs
--rw-r--r--   0     1001      123      198 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/mod.rs
--rw-r--r--   0     1001      123       24 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/ops/mod.rs
--rw-r--r--   0     1001      123      457 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/ops/take.rs
--rw-r--r--   0     1001      123     6259 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/pivot.rs
--rw-r--r--   0     1001      123     1102 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/random.rs
--rw-r--r--   0     1001      123    10844 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/rolling_window.rs
--rw-r--r--   0     1001      123     1093 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/series.rs
--rw-r--r--   0     1001      123      370 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/utils.rs
--rw-r--r--   0     1001      123    30423 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/io/csv.rs
--rw-r--r--   0     1001      123     4490 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/io/ipc_stream.rs
--rw-r--r--   0     1001      123     7043 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/io/json.rs
--rw-r--r--   0     1001      123      378 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/io/mod.rs
--rw-r--r--   0     1001      123      531 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/io/parquet.rs
--rw-r--r--   0     1001      123     1530 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/joins.rs
--rw-r--r--   0     1001      123     2452 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/aggregation.rs
--rw-r--r--   0     1001      123      702 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/cse.rs
--rw-r--r--   0     1001      123      500 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/explodes.rs
--rw-r--r--   0     1001      123     2279 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/expressions/apply.rs
--rw-r--r--   0     1001      123    10285 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/expressions/arity.rs
--rw-r--r--   0     1001      123     1065 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/expressions/expand.rs
--rw-r--r--   0     1001      123     1008 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/expressions/filter.rs
--rw-r--r--   0     1001      123      428 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/expressions/is_in.rs
--rw-r--r--   0     1001      123      121 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/expressions/mod.rs
--rw-r--r--   0     1001      123      659 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/expressions/slice.rs
--rw-r--r--   0     1001      123    10657 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/expressions/window.rs
--rw-r--r--   0     1001      123      579 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/folds.rs
--rw-r--r--   0     1001      123      557 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/functions.rs
--rw-r--r--   0     1001      123     4482 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/groupby.rs
--rw-r--r--   0     1001      123     1635 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/groupby_dynamic.rs
--rw-r--r--   0     1001      123      691 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/mod.rs
--rw-r--r--   0     1001      123     5614 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/predicate_queries.rs
--rw-r--r--   0     1001      123     4476 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/projection_queries.rs
--rw-r--r--   0     1001      123     6577 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/queries.rs
--rw-r--r--   0     1001      123      141 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/main.rs
--rw-r--r--   0     1001      123    12591 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/schema.rs
--rw-r--r--   0        0        0     1523 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/LICENSE
--rw-r--r--   0     1001      123      144 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/README.md
--rw-r--r--   0     1001      123     1975 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/array/default_arrays.rs
--rw-r--r--   0     1001      123     1791 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/array/fixed_size_list.rs
--rw-r--r--   0     1001      123     3773 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/array/get.rs
--rw-r--r--   0     1001      123     6664 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/array/list.rs
--rw-r--r--   0     1001      123     8165 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/array/mod.rs
--rw-r--r--   0     1001      123      878 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/array/null.rs
--rw-r--r--   0     1001      123     1125 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/array/slice.rs
--rw-r--r--   0     1001      123     2252 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/array/utf8.rs
--rw-r--r--   0     1001      123     2294 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/bit_util.rs
--rw-r--r--   0     1001      123       17 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/bitmap/mod.rs
--rw-r--r--   0     1001      123      819 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/bitmap/mutable.rs
--rw-r--r--   0     1001      123      727 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/compute/bitwise.rs
--rw-r--r--   0     1001      123     1159 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/compute/cast.rs
--rw-r--r--   0     1001      123     4163 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/compute/decimal.rs
--rw-r--r--   0     1001      123      138 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/compute/mod.rs
--rw-r--r--   0     1001      123      391 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/compute/take/bitmap.rs
--rw-r--r--   0     1001      123     2767 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/compute/take/boolean.rs
--rw-r--r--   0     1001      123     3487 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/compute/take/fixed_size_list.rs
--rw-r--r--   0     1001      123    25289 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/compute/take/mod.rs
--rw-r--r--   0     1001      123      797 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/compute/tile.rs
--rw-r--r--   0     1001      123     1042 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/conversion.rs
--rw-r--r--   0     1001      123     1609 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/data_types.rs
--rw-r--r--   0     1001      123       25 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/error.rs
--rw-r--r--   0     1001      123       28 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/export.rs
--rw-r--r--   0     1001      123       26 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/floats/mod.rs
--rw-r--r--   0     1001      123     2066 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/floats/ord.rs
--rw-r--r--   0     1001      123     1273 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/index.rs
--rw-r--r--   0     1001      123      984 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/is_valid.rs
--rw-r--r--   0     1001      123     4740 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/agg_mean.rs
--rw-r--r--   0     1001      123     1074 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/comparison.rs
--rw-r--r--   0     1001      123     1015 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/concatenate.rs
--rw-r--r--   0     1001      123     5161 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/ewm/average.rs
--rw-r--r--   0     1001      123     1808 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/ewm/mod.rs
--rw-r--r--   0     1001      123    25065 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/ewm/variance.rs
--rw-r--r--   0     1001      123     1406 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/float.rs
--rw-r--r--   0     1001      123     4907 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/list.rs
--rw-r--r--   0     1001      123     1885 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/list_bytes_iter.rs
--rw-r--r--   0     1001      123     9783 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/mod.rs
--rw-r--r--   0     1001      123     3703 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/mod.rs
--rw-r--r--   0     1001      123     2022 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mean.rs
--rw-r--r--   0     1001      123    18684 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/min_max.rs
--rw-r--r--   0     1001      123     3924 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mod.rs
--rw-r--r--   0     1001      123    11659 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/quantile.rs
--rw-r--r--   0     1001      123     5504 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/sum.rs
--rw-r--r--   0     1001      123     8683 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/variance.rs
--rw-r--r--   0     1001      123     1749 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mean.rs
--rw-r--r--   0     1001      123    14367 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/nulls/min_max.rs
--rw-r--r--   0     1001      123     9070 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mod.rs
--rw-r--r--   0     1001      123    11609 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/nulls/quantile.rs
--rw-r--r--   0     1001      123     4698 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/nulls/sum.rs
--rw-r--r--   0     1001      123     8335 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/nulls/variance.rs
--rw-r--r--   0     1001      123     8109 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/window.rs
--rw-r--r--   0     1001      123     4752 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/set.rs
--rw-r--r--   0     1001      123     4529 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/sort_partition.rs
--rw-r--r--   0     1001      123     2948 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/sorted_join/inner.rs
--rw-r--r--   0     1001      123     5974 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/sorted_join/left.rs
--rw-r--r--   0     1001      123      231 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/sorted_join/mod.rs
--rw-r--r--   0     1001      123      841 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/string.rs
--rw-r--r--   0     1001      123     2310 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/take_agg/boolean.rs
--rw-r--r--   0     1001      123     4344 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/take_agg/mod.rs
--rw-r--r--   0     1001      123     2606 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/take_agg/var.rs
--rw-r--r--   0     1001      123     3672 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/time.rs
--rw-r--r--   0     1001      123      341 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/lib.rs
--rw-r--r--   0     1001      123      434 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/prelude.rs
--rw-r--r--   0     1001      123      534 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/slice.rs
--rw-r--r--   0     1001      123      183 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/time_zone.rs
--rw-r--r--   0     1001      123      998 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/trusted_len/boolean.rs
--rw-r--r--   0     1001      123     2821 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/trusted_len/mod.rs
--rw-r--r--   0     1001      123     2052 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/trusted_len/push_unchecked.rs
--rw-r--r--   0     1001      123      158 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/trusted_len/rev.rs
--rw-r--r--   0     1001      123     5232 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/utils.rs
--rw-r--r--   0        0        0      943 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-row/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-row/LICENSE
--rw-r--r--   0     1001      123      137 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-row/README.md
--rw-r--r--   0     1001      123     8985 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-row/src/encode.rs
--rw-r--r--   0     1001      123     4591 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-row/src/encodings/fixed.rs
--rw-r--r--   0     1001      123       47 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-row/src/encodings/mod.rs
--rw-r--r--   0     1001      123     4508 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-row/src/encodings/variable.rs
--rw-r--r--   0     1001      123    13678 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-row/src/lib.rs
--rw-r--r--   0     1001      123     2079 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-row/src/row.rs
--rw-r--r--   0     1001      123      682 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-row/src/utils.rs
--rw-r--r--   0        0        0     1104 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/LICENSE
--rw-r--r--   0     1001      123      466 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/README.md
--rw-r--r--   0     1001      123    22886 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/src/context.rs
--rw-r--r--   0     1001      123    20710 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/src/functions.rs
--rw-r--r--   0     1001      123     2098 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/src/keywords.rs
--rw-r--r--   0     1001      123      211 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/src/lib.rs
--rw-r--r--   0     1001      123    18227 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/src/sql_expr.rs
--rw-r--r--   0     1001      123     4572 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/src/table_functions.rs
--rw-r--r--   0     1001      123     1682 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/functions_cumulative.rs
--rw-r--r--   0     1001      123     3063 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/functions_io.rs
--rw-r--r--   0     1001      123     1539 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/functions_math.rs
--rw-r--r--   0     1001      123      860 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/functions_meta.rs
--rw-r--r--   0     1001      123     2982 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/functions_string.rs
--rw-r--r--   0     1001      123     1056 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/iss_7436.rs
--rw-r--r--   0     1001      123      888 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/iss_7437.rs
--rw-r--r--   0     1001      123      652 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/iss_7440.rs
--rw-r--r--   0     1001      123      700 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/iss_8395.rs
--rw-r--r--   0     1001      123     1062 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/iss_8419.rs
--rw-r--r--   0     1001      123      982 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/ops_distinct_on.rs
--rw-r--r--   0     1001      123    15110 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/simple_exprs.rs
--rw-r--r--   0     1001      123     2985 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/statements.rs
--rw-r--r--   0        0        0     1948 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/LICENSE
--rw-r--r--   0     1001      123      165 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/README.md
--rw-r--r--   0     1001      123       98 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/mod.rs
--rw-r--r--   0     1001      123     1219 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/operators/filter.rs
--rw-r--r--   0     1001      123     4103 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/operators/function.rs
--rw-r--r--   0     1001      123      266 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/operators/mod.rs
--rw-r--r--   0     1001      123      682 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/operators/pass.rs
--rw-r--r--   0     1001      123      548 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/operators/placeholder.rs
--rw-r--r--   0     1001      123     3247 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/operators/projection.rs
--rw-r--r--   0     1001      123     2324 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/operators/reproject.rs
--rw-r--r--   0     1001      123     6479 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/file_sink.rs
--rw-r--r--   0     1001      123    11288 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/convert.rs
--rw-r--r--   0     1001      123     1207 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/count.rs
--rw-r--r--   0     1001      123     1888 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/first.rs
--rw-r--r--   0     1001      123     4554 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/interface.rs
--rw-r--r--   0     1001      123     1746 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/last.rs
--rw-r--r--   0     1001      123     5413 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mean.rs
--rw-r--r--   0     1001      123     4951 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/min_max.rs
--rw-r--r--   0     1001      123      211 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mod.rs
--rw-r--r--   0     1001      123      856 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/null.rs
--rw-r--r--   0     1001      123     4294 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/sum.rs
--rw-r--r--   0     1001      123     3030 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/eval.rs
--rw-r--r--   0     1001      123     7500 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/global.rs
--rw-r--r--   0     1001      123    13819 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/hash_table.rs
--rw-r--r--   0     1001      123     3243 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/mod.rs
--rw-r--r--   0     1001      123     2767 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/ooc_state.rs
--rw-r--r--   0     1001      123     6311 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/sink.rs
--rw-r--r--   0     1001      123     3116 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/source.rs
--rw-r--r--   0     1001      123    11009 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/thread_local.rs
--rw-r--r--   0     1001      123     2119 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/mod.rs
--rw-r--r--   0     1001      123     4695 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc.rs
--rw-r--r--   0     1001      123     1887 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc_state.rs
--rw-r--r--   0     1001      123    20800 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/primitive/mod.rs
--rw-r--r--   0     1001      123    23420 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/string.rs
--rw-r--r--   0     1001      123     2457 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/utils.rs
--rw-r--r--   0     1001      123     9239 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/io.rs
--rw-r--r--   0     1001      123     5485 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/joins/cross.rs
--rw-r--r--   0     1001      123    14279 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/joins/generic_build.rs
--rw-r--r--   0     1001      123    11824 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/joins/inner_left.rs
--rw-r--r--   0     1001      123      178 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/joins/mod.rs
--rw-r--r--   0     1001      123     2241 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/memory.rs
--rw-r--r--   0     1001      123      589 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/mod.rs
--rw-r--r--   0     1001      123     1492 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/ordered.rs
--rw-r--r--   0     1001      123     1824 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/reproject.rs
--rw-r--r--   0     1001      123     3108 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/slice.rs
--rw-r--r--   0     1001      123      130 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/sort/mod.rs
--rw-r--r--   0     1001      123     6787 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/sort/ooc.rs
--rw-r--r--   0     1001      123     7279 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/sort/sink.rs
--rw-r--r--   0     1001      123     5953 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/sort/sink_multiple.rs
--rw-r--r--   0     1001      123     3908 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/sort/source.rs
--rw-r--r--   0     1001      123      635 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/utils.rs
--rw-r--r--   0     1001      123     5076 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sources/csv.rs
--rw-r--r--   0     1001      123     1231 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sources/frame.rs
--rw-r--r--   0     1001      123      987 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sources/ipc_one_shot.rs
--rw-r--r--   0     1001      123      366 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sources/mod.rs
--rw-r--r--   0     1001      123     3387 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sources/parquet.rs
--rw-r--r--   0     1001      123     1146 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sources/reproject.rs
--rw-r--r--   0     1001      123     1022 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sources/union.rs
--rw-r--r--   0     1001      123      448 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/expressions.rs
--rw-r--r--   0     1001      123      272 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/lib.rs
--rw-r--r--   0     1001      123      719 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/operators/chunks.rs
--rw-r--r--   0     1001      123      474 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/operators/context.rs
--rw-r--r--   0     1001      123      223 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/operators/mod.rs
--rw-r--r--   0     1001      123      514 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/operators/operator.rs
--rw-r--r--   0     1001      123      626 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/operators/sink.rs
--rw-r--r--   0     1001      123      241 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/operators/source.rs
--rw-r--r--   0     1001      123        1 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/pipeline/config.rs
--rw-r--r--   0     1001      123    21311 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/pipeline/convert.rs
--rw-r--r--   0     1001      123    18204 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/pipeline/dispatcher.rs
--rw-r--r--   0     1001      123     1155 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/pipeline/mod.rs
--rw-r--r--   0        0        0      554 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/LICENSE
--rw-r--r--   0     1001      123      141 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/README.md
--rw-r--r--   0     1001      123      151 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/aliases.rs
--rw-r--r--   0     1001      123     2862 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/arena.rs
--rw-r--r--   0     1001      123     1373 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/atomic.rs
--rw-r--r--   0     1001      123     2659 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/cell.rs
--rw-r--r--   0     1001      123     1015 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/contention_pool.rs
--rw-r--r--   0     1001      123      509 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/error.rs
--rw-r--r--   0     1001      123      271 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/fmt.rs
--rw-r--r--   0     1001      123      763 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/functions.rs
--rw-r--r--   0     1001      123      514 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/hash.rs
--rw-r--r--   0     1001      123     2709 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/iter/enumerate_idx.rs
--rw-r--r--   0     1001      123       61 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/iter/mod.rs
--rw-r--r--   0     1001      123      600 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/lib.rs
--rw-r--r--   0     1001      123      573 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/macros.rs
--rw-r--r--   0     1001      123      282 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/mem.rs
--rw-r--r--   0     1001      123     2336 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/slice.rs
--rw-r--r--   0     1001      123     2467 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/sort.rs
--rw-r--r--   0     1001      123     1115 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/sync.rs
--rw-r--r--   0     1001      123      504 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/sys.rs
--rw-r--r--   0     1001      123      697 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/unwrap.rs
--rw-r--r--   0     1001      123      616 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/wasm.rs
--rw-r--r--   0        0        0     6173 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/LICENSE
--rw-r--r--   0     1001      123      358 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/README.md
--rw-r--r--   0     1001      123     1796 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/dot.rs
--rw-r--r--   0     1001      123     4479 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/dsl/eval.rs
--rw-r--r--   0     1001      123     4505 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/dsl/functions.rs
--rw-r--r--   0     1001      123      164 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/dsl/into.rs
--rw-r--r--   0     1001      123     6754 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/dsl/list.rs
--rw-r--r--   0     1001      123     2899 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/dsl/mod.rs
--rw-r--r--   0     1001      123     1182 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/frame/anonymous_scan.rs
--rw-r--r--   0     1001      123     9278 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/frame/csv.rs
--rw-r--r--   0     1001      123     4309 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/frame/file_list_reader.rs
--rw-r--r--   0     1001      123     2261 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/frame/ipc.rs
--rw-r--r--   0     1001      123    48361 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/frame/mod.rs
--rw-r--r--   0     1001      123     3414 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/frame/ndjson.rs
--rw-r--r--   0     1001      123     2734 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/frame/parquet.rs
--rw-r--r--   0     1001      123     2892 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/frame/pivot.rs
--rw-r--r--   0     1001      123      416 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/frame/python.rs
--rw-r--r--   0     1001      123     6376 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/lib.rs
--rw-r--r--   0     1001      123     1049 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/cache.rs
--rw-r--r--   0     1001      123      776 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/executor.rs
--rw-r--r--   0     1001      123      670 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/ext_context.rs
--rw-r--r--   0     1001      123     1555 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/filter.rs
--rw-r--r--   0     1001      123     3986 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/groupby.rs
--rw-r--r--   0     1001      123     4125 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_dynamic.rs
--rw-r--r--   0     1001      123    13503 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_partitioned.rs
--rw-r--r--   0     1001      123     4883 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_rolling.rs
--rw-r--r--   0     1001      123     6058 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/join.rs
--rw-r--r--   0     1001      123     6753 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/mod.rs
--rw-r--r--   0     1001      123     2045 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/projection.rs
--rw-r--r--   0     1001      123     1677 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/python_scan.rs
--rw-r--r--   0     1001      123     2854 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/scan/csv.rs
--rw-r--r--   0     1001      123     1963 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ipc.rs
--rw-r--r--   0     1001      123     4303 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/scan/mod.rs
--rw-r--r--   0     1001      123     1209 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ndjson.rs
--rw-r--r--   0     1001      123     2421 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/scan/parquet.rs
--rw-r--r--   0     1001      123      548 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/slice.rs
--rw-r--r--   0     1001      123     2197 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/sort.rs
--rw-r--r--   0     1001      123     2015 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/stack.rs
--rw-r--r--   0     1001      123      663 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/udf.rs
--rw-r--r--   0     1001      123     3897 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/union.rs
--rw-r--r--   0     1001      123      838 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/unique.rs
--rw-r--r--   0     1001      123     1309 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/exotic.rs
--rw-r--r--   0     1001      123    21959 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/aggregation.rs
--rw-r--r--   0     1001      123     2689 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/alias.rs
--rw-r--r--   0     1001      123    18036 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/apply.rs
--rw-r--r--   0     1001      123    17104 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/binary.rs
--rw-r--r--   0     1001      123     2583 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/cache.rs
--rw-r--r--   0     1001      123     3153 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/cast.rs
--rw-r--r--   0     1001      123     6326 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/column.rs
--rw-r--r--   0     1001      123     1996 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/count.rs
--rw-r--r--   0     1001      123     5809 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/filter.rs
--rw-r--r--   0     1001      123     4131 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/group_iter.rs
--rw-r--r--   0     1001      123     5304 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/literal.rs
--rw-r--r--   0     1001      123    23159 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/mod.rs
--rw-r--r--   0     1001      123    10091 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/slice.rs
--rw-r--r--   0     1001      123     4332 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/sort.rs
--rw-r--r--   0     1001      123    13127 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/sortby.rs
--rw-r--r--   0     1001      123     8331 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/take.rs
--rw-r--r--   0     1001      123    14360 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/ternary.rs
--rw-r--r--   0     1001      123    31384 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/window.rs
--rw-r--r--   0     1001      123     2039 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/file_cache.rs
--rw-r--r--   0     1001      123      414 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/mod.rs
--rw-r--r--   0     1001      123     2005 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/node_timer.rs
--rw-r--r--   0     1001      123    23938 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/planner/expr.rs
--rw-r--r--   0     1001      123    20614 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/planner/lp.rs
--rw-r--r--   0     1001      123       87 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/planner/mod.rs
--rw-r--r--   0     1001      123     9637 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/state.rs
--rw-r--r--   0     1001      123     2463 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/streaming/checks.rs
--rw-r--r--   0     1001      123     9100 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/streaming/construct_pipeline.rs
--rw-r--r--   0     1001      123    15834 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/streaming/convert_alp.rs
--rw-r--r--   0     1001      123      116 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/streaming/mod.rs
--rw-r--r--   0     1001      123     5754 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/streaming/tree.rs
--rw-r--r--   0     1001      123      722 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/prelude.rs
--rw-r--r--   0     1001      123    14990 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/aggregations.rs
--rw-r--r--   0     1001      123     2339 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/arity.rs
--rw-r--r--   0     1001      123     7031 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/cse.rs
--rw-r--r--   0     1001      123    12759 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/io.rs
--rw-r--r--   0     1001      123     4166 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/logical.rs
--rw-r--r--   0     1001      123     4273 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/mod.rs
--rw-r--r--   0     1001      123    15543 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/optimization_checks.rs
--rw-r--r--   0     1001      123     6758 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/predicate_queries.rs
--rw-r--r--   0     1001      123     3158 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/projection_queries.rs
--rw-r--r--   0     1001      123    47673 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/queries.rs
--rw-r--r--   0     1001      123     9513 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/streaming.rs
--rw-r--r--   0     1001      123     2886 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/tpch.rs
--rw-r--r--   0     1001      123     1028 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/utils.rs
--rw-r--r--   0        0        0     5546 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/LICENSE
--rw-r--r--   0     1001      123      144 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/README.md
--rw-r--r--   0     1001      123    18769 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/arithmetic.rs
--rw-r--r--   0     1001      123     2496 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/array/iterator.rs
--rw-r--r--   0     1001      123     2551 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/array/mod.rs
--rw-r--r--   0     1001      123     6448 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/bitwise.rs
--rw-r--r--   0     1001      123     2298 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/builder/binary.rs
--rw-r--r--   0     1001      123     1207 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/builder/boolean.rs
--rw-r--r--   0     1001      123     4311 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/builder/fixed_size_list.rs
--rw-r--r--   0     1001      123     1556 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/builder/from.rs
--rw-r--r--   0     1001      123    20366 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/builder/list.rs
--rw-r--r--   0     1001      123     8969 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/builder/mod.rs
--rw-r--r--   0     1001      123     1410 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/builder/primitive.rs
--rw-r--r--   0     1001      123     2291 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/builder/utf8.rs
--rw-r--r--   0     1001      123    16487 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/cast.rs
--rw-r--r--   0     1001      123    48418 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/comparison/mod.rs
--rw-r--r--   0     1001      123    10060 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/comparison/scalar.rs
--rw-r--r--   0     1001      123      551 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/drop.rs
--rw-r--r--   0     1001      123      963 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/float.rs
--rw-r--r--   0     1001      123     6859 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/from.rs
--rw-r--r--   0     1001      123    42339 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/iterator/mod.rs
--rw-r--r--   0     1001      123     1453 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/iterator/par/list.rs
--rw-r--r--   0     1001      123       28 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/iterator/par/mod.rs
--rw-r--r--   0     1001      123     1129 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/iterator/par/utf8.rs
--rw-r--r--   0     1001      123       21 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/kernels/mod.rs
--rw-r--r--   0     1001      123     2347 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/kernels/take.rs
--rw-r--r--   0     1001      123     8111 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/list/iterator.rs
--rw-r--r--   0     1001      123     3274 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/list/mod.rs
--rw-r--r--   0     1001      123    19866 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/builder.rs
--rw-r--r--   0     1001      123     3688 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/from.rs
--rw-r--r--   0     1001      123     4270 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/merge.rs
--rw-r--r--   0     1001      123    10219 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/mod.rs
--rw-r--r--   0     1001      123     1400 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/append.rs
--rw-r--r--   0     1001      123      358 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/full.rs
--rw-r--r--   0     1001      123      192 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/mod.rs
--rw-r--r--   0     1001      123     2731 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/take_random.rs
--rw-r--r--   0     1001      123     2172 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/unique.rs
--rw-r--r--   0     1001      123      925 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/zip.rs
--rw-r--r--   0     1001      123     6453 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/stringcache.rs
--rw-r--r--   0     1001      123     1604 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/date.rs
--rw-r--r--   0     1001      123     4105 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/datetime.rs
--rw-r--r--   0     1001      123     4443 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/decimal.rs
--rw-r--r--   0     1001      123     2434 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/duration.rs
--rw-r--r--   0     1001      123     2549 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/mod.rs
--rw-r--r--   0     1001      123      476 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/struct_/from.rs
--rw-r--r--   0     1001      123    15081 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/struct_/mod.rs
--rw-r--r--   0     1001      123     1182 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/time.rs
--rw-r--r--   0     1001      123    23385 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/mod.rs
--rw-r--r--   0     1001      123     7200 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ndarray.rs
--rw-r--r--   0     1001      123     4484 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/builder.rs
--rw-r--r--   0     1001      123     1547 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/extension/drop.rs
--rw-r--r--   0     1001      123     3124 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/extension/list.rs
--rw-r--r--   0     1001      123     7054 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/extension/mod.rs
--rw-r--r--   0     1001      123     3410 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/extension/polars_extension.rs
--rw-r--r--   0     1001      123      137 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/is_valid.rs
--rw-r--r--   0     1001      123     4419 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/iterator.rs
--rw-r--r--   0     1001      123     4826 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/mod.rs
--rw-r--r--   0     1001      123     2853 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/registry.rs
--rw-r--r--   0     1001      123      272 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/abs.rs
--rw-r--r--   0     1001      123    32691 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/aggregate/mod.rs
--rw-r--r--   0     1001      123    10025 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/aggregate/quantile.rs
--rw-r--r--   0     1001      123     2880 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/aggregate/var.rs
--rw-r--r--   0     1001      123    10551 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/any_value.rs
--rw-r--r--   0     1001      123     2820 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/append.rs
--rw-r--r--   0     1001      123    28256 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/apply.rs
--rw-r--r--   0     1001      123    12799 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/bit_repr.rs
--rw-r--r--   0     1001      123     6214 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/chunkops.rs
--rw-r--r--   0     1001      123    11537 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/compare_inner.rs
--rw-r--r--   0     1001      123     1737 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/concat_str.rs
--rw-r--r--   0     1001      123     4801 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/cum_agg.rs
--rw-r--r--   0     1001      123     1127 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/decimal.rs
--rw-r--r--   0     1001      123     7056 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/downcast.rs
--rw-r--r--   0     1001      123    27356 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/explode.rs
--rw-r--r--   0     1001      123     8866 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/extend.rs
--rw-r--r--   0     1001      123    13777 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/fill_null.rs
--rw-r--r--   0     1001      123     6323 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/filter.rs
--rw-r--r--   0     1001      123     5876 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/full.rs
--rw-r--r--   0     1001      123        1 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/interpolate.rs
--rw-r--r--   0     1001      123    15385 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/is_in.rs
--rw-r--r--   0     1001      123        1 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/len.rs
--rw-r--r--   0     1001      123     2658 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/min_max_binary.rs
--rw-r--r--   0     1001      123    23220 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/mod.rs
--rw-r--r--   0     1001      123     2403 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/nulls.rs
--rw-r--r--   0     1001      123      593 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/peaks.rs
--rw-r--r--   0     1001      123     4375 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/repeat_by.rs
--rw-r--r--   0     1001      123     2771 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/reverse.rs
--rw-r--r--   0     1001      123    10234 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/rolling_window.rs
--rw-r--r--   0     1001      123    12518 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/set.rs
--rw-r--r--   0     1001      123     7391 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/shift.rs
--rw-r--r--   0     1001      123     2299 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort.rs
--rw-r--r--   0     1001      123     5528 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort_multiple.rs
--rw-r--r--   0     1001      123     7543 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/sort/categorical.rs
--rw-r--r--   0     1001      123    31192 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/sort/mod.rs
--rw-r--r--   0     1001      123      380 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/sort/slice.rs
--rw-r--r--   0     1001      123    22078 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/take/mod.rs
--rw-r--r--   0     1001      123     7848 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/take/take_chunked.rs
--rw-r--r--   0     1001      123      301 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/take/take_every.rs
--rw-r--r--   0     1001      123    16256 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/take/take_random.rs
--rw-r--r--   0     1001      123     5810 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/take/take_single.rs
--rw-r--r--   0     1001      123     6064 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/take/traits.rs
--rw-r--r--   0     1001      123      459 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/tile.rs
--rw-r--r--   0     1001      123    11241 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/unique/mod.rs
--rw-r--r--   0     1001      123    14620 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/unique/rank.rs
--rw-r--r--   0     1001      123     8427 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/zip.rs
--rw-r--r--   0     1001      123     9093 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/random.rs
--rw-r--r--   0     1001      123     1959 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/temporal/conversion.rs
--rw-r--r--   0     1001      123     2826 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/temporal/date.rs
--rw-r--r--   0     1001      123    10497 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/temporal/datetime.rs
--rw-r--r--   0     1001      123     3201 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/temporal/duration.rs
--rw-r--r--   0     1001      123      595 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/temporal/mod.rs
--rw-r--r--   0     1001      123     3042 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/temporal/time.rs
--rw-r--r--   0     1001      123      872 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/to_vec.rs
--rw-r--r--   0     1001      123     8113 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/trusted_len.rs
--rw-r--r--   0     1001      123    25931 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/upstream_traits.rs
--rw-r--r--   0     1001      123     7689 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/cloud.rs
--rw-r--r--   0     1001      123     1549 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/config.rs
--rw-r--r--   0     1001      123     3946 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/datatypes/_serde.rs
--rw-r--r--   0     1001      123     2509 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/datatypes/aliases.rs
--rw-r--r--   0     1001      123    42690 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/datatypes/any_value.rs
--rw-r--r--   0     1001      123    13256 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/datatypes/dtype.rs
--rw-r--r--   0     1001      123     5609 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/datatypes/field.rs
--rw-r--r--   0     1001      123     8059 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/datatypes/mod.rs
--rw-r--r--   0     1001      123     2016 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/datatypes/time_unit.rs
--rw-r--r--   0     1001      123      118 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/doc/changelog/mod.rs
--rw-r--r--   0     1001      123      898 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/doc/changelog/v0_10_0_11.rs
--rw-r--r--   0     1001      123      481 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/doc/changelog/v0_3.rs
--rw-r--r--   0     1001      123      293 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/doc/changelog/v0_4.rs
--rw-r--r--   0     1001      123      499 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/doc/changelog/v0_5.rs
--rw-r--r--   0     1001      123      288 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/doc/changelog/v0_6.rs
--rw-r--r--   0     1001      123     1071 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/doc/changelog/v0_7.rs
--rw-r--r--   0     1001      123      819 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/doc/changelog/v0_8.rs
--rw-r--r--   0     1001      123      596 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/doc/changelog/v0_9.rs
--rw-r--r--   0     1001      123       43 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/doc/mod.rs
--rw-r--r--   0     1001      123       25 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/error.rs
--rw-r--r--   0     1001      123      433 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/export.rs
--rw-r--r--   0     1001      123    36432 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/fmt.rs
--rw-r--r--   0     1001      123     5177 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/arithmetic.rs
--rw-r--r--   0     1001      123     9916 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/asof_join/asof.rs
--rw-r--r--   0     1001      123    35761 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/asof_join/groups.rs
--rw-r--r--   0     1001      123     6973 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/asof_join/mod.rs
--rw-r--r--   0     1001      123      559 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/chunks.rs
--rw-r--r--   0     1001      123     5181 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/cross_join.rs
--rw-r--r--   0     1001      123    16609 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/explode.rs
--rw-r--r--   0     1001      123     1019 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/from.rs
--rw-r--r--   0     1001      123    19219 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/aggregations/agg_list.rs
--rw-r--r--   0     1001      123     4113 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/aggregations/boolean.rs
--rw-r--r--   0     1001      123     7749 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/aggregations/dispatch.rs
--rw-r--r--   0     1001      123    39253 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/aggregations/mod.rs
--rw-r--r--   0     1001      123     5634 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/aggregations/utf8.rs
--rw-r--r--   0     1001      123      218 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/expr.rs
--rw-r--r--   0     1001      123    22943 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/hashing.rs
--rw-r--r--   0     1001      123    14419 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/into_groups.rs
--rw-r--r--   0     1001      123    39508 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/mod.rs
--rw-r--r--   0     1001      123    10608 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/perfect.rs
--rw-r--r--   0     1001      123    19876 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/proxy.rs
--rw-r--r--   0     1001      123    14800 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/mod.rs
--rw-r--r--   0     1001      123    22392 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/multiple_keys.rs
--rw-r--r--   0     1001      123     2413 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/single_keys.rs
--rw-r--r--   0     1001      123    16352 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/single_keys_dispatch.rs
--rw-r--r--   0     1001      123     4295 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/single_keys_inner.rs
--rw-r--r--   0     1001      123     6076 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/single_keys_left.rs
--rw-r--r--   0     1001      123     4247 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/single_keys_outer.rs
--rw-r--r--   0     1001      123     3913 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/single_keys_semi_anti.rs
--rw-r--r--   0     1001      123    11884 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/sort_merge.rs
--rw-r--r--   0     1001      123     3865 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/zip_outer.rs
--rw-r--r--   0     1001      123   124502 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/mod.rs
--rw-r--r--   0     1001      123    27652 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/row/av_buffer.rs
--rw-r--r--   0     1001      123     3732 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/row/dataframe.rs
--rw-r--r--   0     1001      123     5976 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/row/mod.rs
--rw-r--r--   0     1001      123     9875 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/row/transpose.rs
--rw-r--r--   0     1001      123     2811 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/top_k.rs
--rw-r--r--   0     1001      123     1388 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/upstream_traits.rs
--rw-r--r--   0     1001      123    10198 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/functions.rs
--rw-r--r--   0     1001      123     2149 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/hashing/fx.rs
--rw-r--r--   0     1001      123     1503 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/hashing/identity.rs
--rw-r--r--   0     1001      123      457 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/hashing/mod.rs
--rw-r--r--   0     1001      123     2684 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/hashing/partition.rs
--rw-r--r--   0     1001      123    17653 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/hashing/vector_hasher.rs
--rw-r--r--   0     1001      123     1896 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/lib.rs
--rw-r--r--   0     1001      123    15733 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/named_from.rs
--rw-r--r--   0     1001      123     2411 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/prelude.rs
--rw-r--r--   0     1001      123    17015 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/schema.rs
--rw-r--r--   0     1001      123     4218 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/serde/chunked_array.rs
--rw-r--r--   0     1001      123     1094 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/serde/df.rs
--rw-r--r--   0     1001      123     6559 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/serde/mod.rs
--rw-r--r--   0     1001      123     9929 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/serde/series.rs
--rw-r--r--   0     1001      123    18526 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/any_value.rs
--rw-r--r--   0     1001      123    28755 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/arithmetic/borrowed.rs
--rw-r--r--   0     1001      123      222 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/arithmetic/mod.rs
--rw-r--r--   0     1001      123     3546 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/arithmetic/owned.rs
--rw-r--r--   0     1001      123    19293 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/comparison.rs
--rw-r--r--   0     1001      123    26164 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/from.rs
--rw-r--r--   0     1001      123     6112 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/array.rs
--rw-r--r--   0     1001      123     9121 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/binary.rs
--rw-r--r--   0     1001      123    10867 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/boolean.rs
--rw-r--r--   0     1001      123    12832 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/categorical.rs
--rw-r--r--   0     1001      123    18254 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/dates_time.rs
--rw-r--r--   0     1001      123    15066 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/datetime.rs
--rw-r--r--   0     1001      123     5656 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/decimal.rs
--rw-r--r--   0     1001      123    14766 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/duration.rs
--rw-r--r--   0     1001      123    14103 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/floats.rs
--rw-r--r--   0     1001      123     6110 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/list.rs
--rw-r--r--   0     1001      123    18436 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/mod.rs
--rw-r--r--   0     1001      123     5208 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/null.rs
--rw-r--r--   0     1001      123     7907 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/object.rs
--rw-r--r--   0     1001      123    11788 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/struct_.rs
--rw-r--r--   0     1001      123     9639 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/utf8.rs
--rw-r--r--   0     1001      123     4471 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/into.rs
--rw-r--r--   0     1001      123     6297 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/iterator.rs
--rw-r--r--   0     1001      123    38157 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/mod.rs
--rw-r--r--   0     1001      123      853 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/diff.rs
--rw-r--r--   0     1001      123     5814 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/downcast.rs
--rw-r--r--   0     1001      123     3601 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/ewm.rs
--rw-r--r--   0     1001      123      413 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/extend.rs
--rw-r--r--   0     1001      123      562 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/mod.rs
--rw-r--r--   0     1001      123     5974 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/moment.rs
--rw-r--r--   0     1001      123     2908 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/null.rs
--rw-r--r--   0     1001      123     1347 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/pct_change.rs
--rw-r--r--   0     1001      123     4620 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/round.rs
--rw-r--r--   0     1001      123     5073 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/to_list.rs
--rw-r--r--   0     1001      123     1476 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/unique.rs
--rw-r--r--   0     1001      123    18440 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/series_trait.rs
--rw-r--r--   0     1001      123     2940 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/unstable.rs
--rw-r--r--   0     1001      123     7077 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/testing.rs
--rw-r--r--   0     1001      123      508 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/tests.rs
--rw-r--r--   0     1001      123     2492 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/utils/flatten.rs
--rw-r--r--   0     1001      123    30764 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/utils/mod.rs
--rw-r--r--   0     1001      123     1600 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/utils/series.rs
--rw-r--r--   0     1001      123    13257 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/utils/supertype.rs
--rw-r--r--   0        0        0      823 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-algo/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-algo/LICENSE
--rw-r--r--   0     1001      123      142 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-algo/README.md
--rw-r--r--   0     1001      123     7548 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-algo/src/algo.rs
--rw-r--r--   0     1001      123       88 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-algo/src/lib.rs
--rw-r--r--   0     1001      123       28 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-algo/src/prelude.rs
--rw-r--r--   0        0        0     3437 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/LICENSE
--rw-r--r--   0     1001      123      132 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/README.md
--rw-r--r--   0     1001      123     2382 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/array/min_max.rs
--rw-r--r--   0     1001      123      267 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/array/mod.rs
--rw-r--r--   0     1001      123     1188 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/array/namespace.rs
--rw-r--r--   0     1001      123     4108 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/array/sum_mean.rs
--rw-r--r--   0     1001      123      234 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/binary/mod.rs
--rw-r--r--   0     1001      123     3549 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/binary/namespace.rs
--rw-r--r--   0     1001      123    11023 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/interpolate.rs
--rw-r--r--   0     1001      123     1679 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/list/count.rs
--rw-r--r--   0     1001      123     2452 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/list/hash.rs
--rw-r--r--   0     1001      123     7861 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/list/min_max.rs
--rw-r--r--   0     1001      123      511 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/list/mod.rs
--rw-r--r--   0     1001      123    19010 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/list/namespace.rs
--rw-r--r--   0     1001      123     7633 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/list/sum_mean.rs
--rw-r--r--   0     1001      123     2435 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/list/to_struct.rs
--rw-r--r--   0     1001      123      545 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/mod.rs
--rw-r--r--   0     1001      123     9380 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/nan_propagating_aggregate.rs
--rw-r--r--   0     1001      123     6795 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/set.rs
--rw-r--r--   0     1001      123     7490 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/strings/case.rs
--rw-r--r--   0     1001      123     8409 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/strings/json_path.rs
--rw-r--r--   0     1001      123     2345 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/strings/justify.rs
--rw-r--r--   0     1001      123      514 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/strings/mod.rs
--rw-r--r--   0     1001      123    14731 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/strings/namespace.rs
--rw-r--r--   0     1001      123     4053 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/strings/replace.rs
--rw-r--r--   0     1001      123      439 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/sum.rs
--rw-r--r--   0     1001      123     2486 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/top_k.rs
--rw-r--r--   0     1001      123     7727 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/frame/join/merge_sorted.rs
--rw-r--r--   0     1001      123    18435 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/frame/join/mod.rs
--rw-r--r--   0     1001      123     4174 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/frame/mod.rs
--rw-r--r--   0     1001      123    10257 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/frame/pivot/mod.rs
--rw-r--r--   0     1001      123    13486 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/frame/pivot/positioning.rs
--rw-r--r--   0     1001      123      237 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/lib.rs
--rw-r--r--   0     1001      123      290 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/prelude.rs
--rw-r--r--   0     1001      123       25 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/mod.rs
--rw-r--r--   0     1001      123     9623 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/approx_algo/hyperloglogplus.rs
--rw-r--r--   0     1001      123      118 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/approx_algo/mod.rs
--rw-r--r--   0     1001      123     2016 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/approx_unique.rs
--rw-r--r--   0     1001      123    11866 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/arg_min_max.rs
--rw-r--r--   0     1001      123     3688 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/floor_divide.rs
--rw-r--r--   0     1001      123     5245 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/fused.rs
--rw-r--r--   0     1001      123     3423 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/is_first.rs
--rw-r--r--   0     1001      123     2975 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/is_unique.rs
--rw-r--r--   0     1001      123     3626 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/log.rs
--rw-r--r--   0     1001      123     1187 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/mod.rs
--rw-r--r--   0     1001      123     1769 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/rolling.rs
--rw-r--r--   0     1001      123     7642 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/search_sorted.rs
--rw-r--r--   0     1001      123     2500 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/to_dummies.rs
--rw-r--r--   0     1001      123     2067 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/various.rs
--rw-r--r--   0        0        0     1342 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-json/Cargo.toml
--rw-r--r--   0     1001      123    16716 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-json/src/json/deserialize.rs
--rw-r--r--   0     1001      123     6468 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-json/src/json/infer_schema.rs
--rw-r--r--   0     1001      123      189 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-json/src/json/mod.rs
--rw-r--r--   0     1001      123       30 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-json/src/lib.rs
--rw-r--r--   0     1001      123     1117 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-json/src/ndjson/deserialize.rs
--rw-r--r--   0     1001      123     4808 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-json/src/ndjson/file.rs
--rw-r--r--   0     1001      123      143 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-json/src/ndjson/mod.rs
--rw-r--r--   0        0        0     2059 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/LICENSE
--rw-r--r--   0     1001      123      143 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/README.md
--rw-r--r--   0     1001      123     3565 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/date.rs
--rw-r--r--   0     1001      123     6465 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/datetime.rs
--rw-r--r--   0     1001      123     3305 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/duration.rs
--rw-r--r--   0     1001      123     5607 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/kernels.rs
--rw-r--r--   0     1001      123     1062 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/mod.rs
--rw-r--r--   0     1001      123     7302 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/rolling_window/floats.rs
--rw-r--r--   0     1001      123     2582 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/rolling_window/ints.rs
--rw-r--r--   0     1001      123    10495 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/rolling_window/mod.rs
--rw-r--r--   0     1001      123      428 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/mod.rs
--rw-r--r--   0     1001      123     5987 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/no_nulls.rs
--rw-r--r--   0     1001      123     2372 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/time.rs
--rw-r--r--   0     1001      123    18180 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/utf8/infer.rs
--rw-r--r--   0     1001      123    18638 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/utf8/mod.rs
--rw-r--r--   0     1001      123     4115 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/utf8/patterns.rs
--rw-r--r--   0     1001      123    10548 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/utf8/strptime.rs
--rw-r--r--   0     1001      123     3498 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/date_range.rs
--rw-r--r--   0     1001      123    34303 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/groupby/dynamic.rs
--rw-r--r--   0     1001      123       88 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/groupby/mod.rs
--rw-r--r--   0     1001      123      621 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/lib.rs
--rw-r--r--   0     1001      123     2976 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/month_end.rs
--rw-r--r--   0     1001      123     3365 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/month_start.rs
--rw-r--r--   0     1001      123      274 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/prelude.rs
--rw-r--r--   0     1001      123     1381 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/round.rs
--rw-r--r--   0     1001      123     4028 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/_trait.rs
--rw-r--r--   0     1001      123      136 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/implementations/boolean.rs
--rw-r--r--   0     1001      123      140 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/implementations/categoricals.rs
--rw-r--r--   0     1001      123      133 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/implementations/date.rs
--rw-r--r--   0     1001      123      137 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/implementations/datetime.rs
--rw-r--r--   0     1001      123      137 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/implementations/duration.rs
--rw-r--r--   0     1001      123     1863 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/implementations/floats.rs
--rw-r--r--   0     1001      123     1792 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/implementations/integers.rs
--rw-r--r--   0     1001      123      133 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/implementations/list.rs
--rw-r--r--   0     1001      123      486 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/implementations/mod.rs
--rw-r--r--   0     1001      123      155 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/implementations/object.rs
--rw-r--r--   0     1001      123      135 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/implementations/struct_.rs
--rw-r--r--   0     1001      123      133 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/implementations/time.rs
--rw-r--r--   0     1001      123      133 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/implementations/utf8.rs
--rw-r--r--   0     1001      123    12787 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/mod.rs
--rw-r--r--   0     1001      123     1443 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/truncate.rs
--rw-r--r--   0     1001      123     6815 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/upsample.rs
--rw-r--r--   0     1001      123     2511 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/utils.rs
--rw-r--r--   0     1001      123     1524 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/windows/bounds.rs
--rw-r--r--   0     1001      123     2672 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/windows/calendar.rs
--rw-r--r--   0     1001      123    25094 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/windows/duration.rs
--rw-r--r--   0     1001      123    21244 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/windows/groupby.rs
--rw-r--r--   0     1001      123      503 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/windows/mod.rs
--rw-r--r--   0     1001      123    23652 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/windows/test.rs
--rw-r--r--   0     1001      123    11666 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/windows/window.rs
--rw-r--r--   0        0        0      883 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-error/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-error/LICENSE
--rw-r--r--   0     1001      123      145 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-error/README.md
--rw-r--r--   0     1001      123     6297 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/local_dependencies/polars-error/src/lib.rs
--rw-r--r--   0        0        0     4408 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/Cargo.toml
--rw-r--r--   0     1001      123       76 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/.gitignore
--rw-r--r--   0     1001      123     1055 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/LICENSE
--rw-r--r--   0     1001      123     2414 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/Makefile
--rw-r--r--   0     1001      123    11998 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/README.md
--rw-r--r--   0     1001      123      651 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/build.rs
--rw-r--r--   0     1001      123       32 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/.gitignore
--rw-r--r--   0     1001      123      679 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/Makefile
--rw-r--r--   0     1001      123      318 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/_templates/api_redirect.html
--rw-r--r--   0     1001      123      151 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/_templates/autosummary/accessor.rst
--rw-r--r--   0     1001      123      160 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/_templates/autosummary/accessor_attribute.rst
--rw-r--r--   0     1001      123      168 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/_templates/autosummary/accessor_callable.rst
--rw-r--r--   0     1001      123      157 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/_templates/autosummary/accessor_method.rst
--rw-r--r--   0     1001      123      836 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/_templates/autosummary/class.rst
--rw-r--r--   0     1001      123       94 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/_templates/autosummary/class_without_autosummary.rst
--rw-r--r--   0     1001      123      406 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/_templates/sidebar-nav-bs.html
--rw-r--r--   0     1001      123      491 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/requirements-docs.txt
--rw-r--r--   0     1001      123     1164 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/run_live_docs_server.py
--rw-r--r--   0     1001      123     1567 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/_static/css/custom.css
--rw-r--r--   0     1001      123     7297 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/conf.py
--rw-r--r--   0     1001      123       51 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/index.rst
--rw-r--r--   0     1001      123     6767 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/api.rst
--rw-r--r--   0     1001      123     1694 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/config.rst
--rw-r--r--   0     1001      123      274 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/dataframe/aggregation.rst
--rw-r--r--   0     1001      123      221 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/dataframe/attributes.rst
--rw-r--r--   0     1001      123      142 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/dataframe/computation.rst
--rw-r--r--   0     1001      123      319 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/dataframe/descriptive.rst
--rw-r--r--   0     1001      123      319 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/dataframe/export.rst
--rw-r--r--   0     1001      123      464 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/dataframe/groupby.rst
--rw-r--r--   0     1001      123      379 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/dataframe/index.rst
--rw-r--r--   0     1001      123      189 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/dataframe/miscellaneous.rst
--rw-r--r--   0     1001      123     1538 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/dataframe/modify_select.rst
--rw-r--r--   0     1001      123      673 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/datatypes.rst
--rw-r--r--   0     1001      123      421 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/exceptions.rst
--rw-r--r--   0     1001      123      391 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/aggregation.rst
--rw-r--r--   0     1001      123      247 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/array.rst
--rw-r--r--   0     1001      123      309 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/binary.rst
--rw-r--r--   0     1001      123      338 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/boolean.rst
--rw-r--r--   0     1001      123      237 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/categories.rst
--rw-r--r--   0     1001      123      221 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/columns.rst
--rw-r--r--   0     1001      123     1061 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/computation.rst
--rw-r--r--   0     1001      123     1118 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/functions.rst
--rw-r--r--   0     1001      123      470 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/index.rst
--rw-r--r--   0     1001      123      722 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/list.rst
--rw-r--r--   0     1001      123      407 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/meta.rst
--rw-r--r--   0     1001      123      140 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/miscellaneous.rst
--rw-r--r--   0     1001      123      977 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/modify_select.rst
--rw-r--r--   0     1001      123      639 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/operators.rst
--rw-r--r--   0     1001      123      951 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/string.rst
--rw-r--r--   0     1001      123      254 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/struct.rst
--rw-r--r--   0     1001      123     1036 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/temporal.rst
--rw-r--r--   0     1001      123       98 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/expressions/window.rst
--rw-r--r--   0     1001      123      683 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/functions.rst
--rw-r--r--   0     1001      123      392 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/index.rst
--rw-r--r--   0     1001      123     1294 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/io.rst
--rw-r--r--   0     1001      123      277 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/lazyframe/aggregation.rst
--rw-r--r--   0     1001      123      179 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/lazyframe/attributes.rst
--rw-r--r--   0     1001      123      146 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/lazyframe/descriptive.rst
--rw-r--r--   0     1001      123      497 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/lazyframe/groupby.rst
--rw-r--r--   0     1001      123      354 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/lazyframe/index.rst
--rw-r--r--   0     1001      123      455 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/lazyframe/miscellaneous.rst
--rw-r--r--   0     1001      123     1013 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/lazyframe/modify_select.rst
--rw-r--r--   0     1001      123      358 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/series/aggregation.rst
--rw-r--r--   0     1001      123      255 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/series/array.rst
--rw-r--r--   0     1001      123      257 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/series/attributes.rst
--rw-r--r--   0     1001      123      321 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/series/binary.rst
--rw-r--r--   0     1001      123      117 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/series/boolean.rst
--rw-r--r--   0     1001      123      241 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/series/categories.rst
--rw-r--r--   0     1001      123     1103 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/series/computation.rst
--rw-r--r--   0     1001      123      744 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/series/descriptive.rst
--rw-r--r--   0     1001      123      240 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/series/export.rst
--rw-r--r--   0     1001      123      437 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/series/index.rst
--rw-r--r--   0     1001      123      776 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/series/list.rst
--rw-r--r--   0     1001      123      236 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/series/miscellaneous.rst
--rw-r--r--   0     1001      123     1077 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/series/modify_select.rst
--rw-r--r--   0     1001      123     1021 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/series/string.rst
--rw-r--r--   0     1001      123      421 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/series/struct.rst
--rw-r--r--   0     1001      123     1192 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/series/temporal.rst
--rw-r--r--   0     1001      123      503 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/sql.rst
--rw-r--r--   0     1001      123     8067 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/testing.rst
--rw-r--r--   0     1001      123      168 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/docs/source/reference/utils.rst
--rw-r--r--   0     1001      123     6098 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/__init__.py
--rw-r--r--   0     1001      123      280 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/_reexport.py
--rw-r--r--   0     1001      123    13229 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/api.py
--rw-r--r--   0     1001      123    28746 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/config.py
--rw-r--r--   0     1001      123    28105 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/convert.py
--rw-r--r--   0     1001      123       77 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/dataframe/__init__.py
--rw-r--r--   0     1001      123     5227 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/dataframe/_html.py
--rw-r--r--   0     1001      123   314170 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/dataframe/frame.py
--rw-r--r--   0     1001      123    40842 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/dataframe/groupby.py
--rw-r--r--   0     1001      123     2692 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/datatypes/__init__.py
--rw-r--r--   0     1001      123    16192 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/datatypes/classes.py
--rw-r--r--   0     1001      123     1603 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/datatypes/constants.py
--rw-r--r--   0     1001      123     4701 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/datatypes/constructor.py
--rw-r--r--   0     1001      123    15739 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/datatypes/convert.py
--rw-r--r--   0     1001      123     7338 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/dependencies.py
--rw-r--r--   0     1001      123     3573 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/exceptions.py
--rw-r--r--   0     1001      123       61 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/expr/__init__.py
--rw-r--r--   0     1001      123     2139 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/expr/array.py
--rw-r--r--   0     1001      123     2704 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/expr/binary.py
--rw-r--r--   0     1001      123     1698 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/expr/categorical.py
--rw-r--r--   0     1001      123    77496 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/expr/datetime.py
--rw-r--r--   0     1001      123   256586 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/expr/expr.py
--rw-r--r--   0     1001      123    23961 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/expr/list.py
--rw-r--r--   0     1001      123     2403 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/expr/meta.py
--rw-r--r--   0     1001      123    57885 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/expr/string.py
--rw-r--r--   0     1001      123     5426 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/expr/struct.py
--rw-r--r--   0     1001      123     2038 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/functions/__init__.py
--rw-r--r--   0     1001      123    16399 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/functions/as_datatype.py
--rw-r--r--   0     1001      123    18348 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/functions/eager.py
--rw-r--r--   0     1001      123    71716 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/functions/lazy.py
--rw-r--r--   0     1001      123    16085 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/functions/range.py
--rw-r--r--   0     1001      123     6027 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/functions/repeat.py
--rw-r--r--   0     1001      123     6195 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/functions/whenthen.py
--rw-r--r--   0     1001      123      952 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/__init__.py
--rw-r--r--   0     1001      123     6264 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/_utils.py
--rw-r--r--   0     1001      123      861 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/avro.py
--rw-r--r--   0     1001      123      144 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/csv/__init__.py
--rw-r--r--   0     1001      123     1072 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/csv/_utils.py
--rw-r--r--   0     1001      123     4681 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/csv/batched_reader.py
--rw-r--r--   0     1001      123    35482 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/csv/functions.py
--rw-r--r--   0     1001      123     5627 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/database.py
--rw-r--r--   0     1001      123    11047 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/delta.py
--rw-r--r--   0     1001      123       75 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/excel/__init__.py
--rw-r--r--   0     1001      123    18449 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/excel/_write_utils.py
--rw-r--r--   0     1001      123     6466 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/excel/functions.py
--rw-r--r--   0     1001      123      142 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/ipc/__init__.py
--rw-r--r--   0     1001      123     1227 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/ipc/anonymous_scan.py
--rw-r--r--   0     1001      123     5804 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/ipc/functions.py
--rw-r--r--   0     1001      123      502 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/json.py
--rw-r--r--   0     1001      123     2207 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/ndjson.py
--rw-r--r--   0     1001      123      170 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/parquet/__init__.py
--rw-r--r--   0     1001      123     1259 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/parquet/anonymous_scan.py
--rw-r--r--   0     1001      123     7177 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/parquet/functions.py
--rw-r--r--   0     1001      123      136 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/pyarrow_dataset/__init__.py
--rw-r--r--   0     1001      123     2291 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/pyarrow_dataset/anonymous_scan.py
--rw-r--r--   0     1001      123     3601 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/io/pyarrow_dataset/functions.py
--rw-r--r--   0     1001      123       77 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/lazyframe/__init__.py
--rw-r--r--   0     1001      123   166400 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/lazyframe/frame.py
--rw-r--r--   0     1001      123    23676 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/lazyframe/groupby.py
--rw-r--r--   0     1001      123        0 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/py.typed
--rw-r--r--   0     1001      123       69 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/series/__init__.py
--rw-r--r--   0     1001      123     1572 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/series/_numpy.py
--rw-r--r--   0     1001      123     1700 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/series/array.py
--rw-r--r--   0     1001      123     1913 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/series/binary.py
--rw-r--r--   0     1001      123     1692 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/series/categorical.py
--rw-r--r--   0     1001      123    51602 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/series/datetime.py
--rw-r--r--   0     1001      123    13196 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/series/list.py
--rw-r--r--   0     1001      123   167955 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/series/series.py
--rw-r--r--   0     1001      123    37216 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/series/string.py
--rw-r--r--   0     1001      123     2542 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/series/struct.py
--rw-r--r--   0     1001      123     5361 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/series/utils.py
--rw-r--r--   0     1001      123     7559 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/slice.py
--rw-r--r--   0     1001      123       75 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/sql/__init__.py
--rw-r--r--   0     1001      123    17409 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/sql/context.py
--rw-r--r--   0     1001      123     4764 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/string_cache.py
--rw-r--r--   0     1001      123      362 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/testing/__init__.py
--rw-r--r--   0     1001      123     1060 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/testing/_private.py
--rw-r--r--   0     1001      123     3689 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/testing/_tempdir.py
--rw-r--r--   0     1001      123    16425 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/testing/asserts.py
--rw-r--r--   0     1001      123      898 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/testing/parametric/__init__.py
--rw-r--r--   0     1001      123    26833 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/testing/parametric/primitives.py
--rw-r--r--   0     1001      123     3409 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/testing/parametric/profiles.py
--rw-r--r--   0     1001      123    12132 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/testing/parametric/strategies.py
--rw-r--r--   0     1001      123     6214 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/type_aliases.py
--rw-r--r--   0     1001      123     1169 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/utils/__init__.py
--rw-r--r--   0     1001      123    54272 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/utils/_construction.py
--rw-r--r--   0     1001      123     3891 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/utils/_parse_expr_input.py
--rw-r--r--   0     1001      123      711 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/utils/_scan.py
--rw-r--r--   0     1001      123      579 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/utils/_wrap.py
--rw-r--r--   0     1001      123      683 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/utils/build_info.py
--rw-r--r--   0     1001      123     8609 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/utils/convert.py
--rw-r--r--   0     1001      123     6132 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/utils/decorators.py
--rw-r--r--   0     1001      123     1660 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/utils/meta.py
--rw-r--r--   0     1001      123      514 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/utils/polars_version.py
--rw-r--r--   0     1001      123     2673 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/utils/show_versions.py
--rw-r--r--   0     1001      123    12905 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/polars/utils/various.py
--rw-r--r--   0     1001      123     5377 2023-05-29 20:01:51.000000 polars_lts_cpu-0.18.0/pyproject.toml
--rw-r--r--   0     1001      123      699 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/requirements-dev.txt
--rw-r--r--   0     1001      123       70 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/requirements-lint.txt
--rw-r--r--   0     1001      123     1640 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/scripts/check_stacklevels.py
--rw-r--r--   0     1001      123    11023 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/apply/dataframe.rs
--rw-r--r--   0     1001      123     7448 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/apply/lazy.rs
--rw-r--r--   0     1001      123     8402 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/apply/mod.rs
--rw-r--r--   0     1001      123    90063 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/apply/series.rs
--rw-r--r--   0     1001      123       32 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/arrow_interop/mod.rs
--rw-r--r--   0     1001      123     1306 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/arrow_interop/to_py.rs
--rw-r--r--   0     1001      123     3902 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/arrow_interop/to_rust.rs
--rw-r--r--   0     1001      123     5250 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/batched_csv.rs
--rw-r--r--   0     1001      123    47907 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/conversion.rs
--rw-r--r--   0     1001      123    45844 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/dataframe.rs
--rw-r--r--   0     1001      123     3950 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/datatypes.rs
--rw-r--r--   0     1001      123     3288 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/error.rs
--rw-r--r--   0     1001      123      337 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/expr/array.rs
--rw-r--r--   0     1001      123     2080 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/expr/binary.rs
--rw-r--r--   0     1001      123      274 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/expr/categorical.rs
--rw-r--r--   0     1001      123     5935 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/expr/datetime.rs
--rw-r--r--   0     1001      123    34212 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/expr/general.rs
--rw-r--r--   0     1001      123     3937 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/expr/list.rs
--rw-r--r--   0     1001      123     1096 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/expr/meta.rs
--rw-r--r--   0     1001      123      870 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/expr/mod.rs
--rw-r--r--   0     1001      123     8677 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/expr/string.rs
--rw-r--r--   0     1001      123      467 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/expr/struct.rs
--rw-r--r--   0     1001      123     9482 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/file.rs
--rw-r--r--   0     1001      123     3307 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/functions/eager.rs
--rw-r--r--   0     1001      123     1657 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/functions/io.rs
--rw-r--r--   0     1001      123    11456 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/functions/lazy.rs
--rw-r--r--   0     1001      123     1312 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/functions/meta.rs
--rw-r--r--   0     1001      123      217 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/functions/misc.rs
--rw-r--r--   0     1001      123       87 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/functions/mod.rs
--rw-r--r--   0     1001      123     1474 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/functions/whenthen.rs
--rw-r--r--   0     1001      123    30642 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/lazyframe.rs
--rw-r--r--   0     1001      123     2670 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/lazygroupby.rs
--rw-r--r--   0     1001      123     8072 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/lib.rs
--rw-r--r--   0     1001      123     1029 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/object.rs
--rw-r--r--   0     1001      123      122 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/prelude.rs
--rw-r--r--   0     1001      123      435 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/py_modules.rs
--rw-r--r--   0     1001      123     1964 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/series/aggregation.rs
--rw-r--r--   0     1001      123     5406 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/series/arithmetic.rs
--rw-r--r--   0     1001      123     5138 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/series/comparison.rs
--rw-r--r--   0     1001      123     9077 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/series/construction.rs
--rw-r--r--   0     1001      123     8971 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/series/export.rs
--rw-r--r--   0     1001      123    26521 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/series/mod.rs
--rw-r--r--   0     1001      123     4569 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/series/numpy_ufunc.rs
--rw-r--r--   0     1001      123     4046 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/series/set_at_idx.rs
--rw-r--r--   0     1001      123     1036 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/sql.rs
--rw-r--r--   0     1001      123     2335 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/src/utils.rs
--rw-r--r--   0     1001      123     6165 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/README.md
--rw-r--r--   0     1001      123     2189 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/benchmark/groupby-datagen.R
--rw-r--r--   0     1001      123     7963 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/benchmark/run_h2oai_benchmark.py
--rw-r--r--   0     1001      123     6530 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/benchmark/test_release.py
--rw-r--r--   0     1001      123     4589 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/docs/run_doctest.py
--rw-r--r--   0     1001      123      179 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/parametric/conftest.py
--rw-r--r--   0     1001      123     3856 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/parametric/test_dataframe.py
--rw-r--r--   0     1001      123     1692 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/parametric/test_lazyframe.py
--rw-r--r--   0     1001      123     6897 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/parametric/test_series.py
--rw-r--r--   0     1001      123     8299 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/parametric/test_testing.py
--rw-r--r--   0     1001      123        0 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/__init__.py
--rw-r--r--   0     1001      123     3382 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/conftest.py
--rw-r--r--   0     1001      123       86 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/datatypes/__init__.py
--rw-r--r--   0     1001      123      973 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/datatypes/test_array.py
--rw-r--r--   0     1001      123      351 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/datatypes/test_binary.py
--rw-r--r--   0     1001      123     1420 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/datatypes/test_bool.py
--rw-r--r--   0     1001      123    13226 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/datatypes/test_categorical.py
--rw-r--r--   0     1001      123     3289 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/datatypes/test_decimal.py
--rw-r--r--   0     1001      123      549 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/datatypes/test_duration.py
--rw-r--r--   0     1001      123    12837 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/datatypes/test_list.py
--rw-r--r--   0     1001      123      284 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/datatypes/test_null.py
--rw-r--r--   0     1001      123     2801 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/datatypes/test_object.py
--rw-r--r--   0     1001      123    27425 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/datatypes/test_struct.py
--rw-r--r--   0     1001      123    86309 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/datatypes/test_temporal.py
--rw-r--r--   0     1001      123      418 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/datatypes/test_time.py
--rw-r--r--   0     1001      123        0 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/functions/__init__.py
--rw-r--r--   0     1001      123    13649 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/functions/test_as_datatype.py
--rw-r--r--   0     1001      123    15610 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/functions/test_functions.py
--rw-r--r--   0     1001      123    17732 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/functions/test_range.py
--rw-r--r--   0     1001      123     3002 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/functions/test_repeat.py
--rw-r--r--   0     1001      123      218 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/conftest.py
--rw-r--r--   0     1001      123       16 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/delta-table/.part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet.crc
--rw-r--r--   0     1001      123       16 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/delta-table/.part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet.crc
--rw-r--r--   0     1001      123       16 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/delta-table/_delta_log/.00000000000000000000.json.crc
--rw-r--r--   0     1001      123       16 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/delta-table/_delta_log/.00000000000000000001.json.crc
--rw-r--r--   0     1001      123      905 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/delta-table/_delta_log/00000000000000000000.json
--rw-r--r--   0     1001      123      936 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/delta-table/_delta_log/00000000000000000001.json
--rw-r--r--   0     1001      123      972 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/delta-table/part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet
--rw-r--r--   0     1001      123      690 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/delta-table/part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet
--rw-r--r--   0     1001      123        0 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/empty.csv
--rw-r--r--   0     1001      123     5959 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/example.xlsx
--rw-r--r--   0     1001      123      457 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/foods1.csv
--rw-r--r--   0     1001      123     2351 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/foods1.ipc
--rw-r--r--   0     1001      123     1713 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/foods1.ndjson
--rw-r--r--   0     1001      123     1427 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/foods1.parquet
--rw-r--r--   0     1001      123      455 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/foods2.csv
--rw-r--r--   0     1001      123     2351 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/foods2.ipc
--rw-r--r--   0     1001      123     1711 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/foods2.ndjson
--rw-r--r--   0     1001      123     1916 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/foods2.parquet
--rw-r--r--   0     1001      123      455 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/foods3.csv
--rw-r--r--   0     1001      123      457 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/foods4.csv
--rw-r--r--   0     1001      123      452 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/foods5.csv
--rw-r--r--   0     1001      123       49 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/gzipped.csv
--rw-r--r--   0     1001      123       57 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/small.csv
--rw-r--r--   0     1001      123      756 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/files/small.parquet
--rw-r--r--   0     1001      123     1937 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/test_avro.py
--rw-r--r--   0     1001      123    39389 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/test_csv.py
--rw-r--r--   0     1001      123     6650 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/test_database.py
--rw-r--r--   0     1001      123     6172 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/test_delta.py
--rw-r--r--   0     1001      123    11169 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/test_excel.py
--rw-r--r--   0     1001      123     5919 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/test_ipc.py
--rw-r--r--   0     1001      123     3995 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/test_json.py
--rw-r--r--   0     1001      123     7456 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/test_lazy_csv.py
--rw-r--r--   0     1001      123     2060 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/test_lazy_ipc.py
--rw-r--r--   0     1001      123     2881 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/test_lazy_json.py
--rw-r--r--   0     1001      123    11849 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/test_lazy_parquet.py
--rw-r--r--   0     1001      123     2012 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/test_other.py
--rw-r--r--   0     1001      123    14077 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/test_parquet.py
--rw-r--r--   0     1001      123      612 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/test_pickle.py
--rw-r--r--   0     1001      123     3886 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/io/test_pyarrow_dataset.py
--rw-r--r--   0     1001      123      509 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/namespaces/__init__.py
--rw-r--r--   0     1001      123      377 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/namespaces/test_array.py
--rw-r--r--   0     1001      123     3218 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/namespaces/test_binary.py
--rw-r--r--   0     1001      123     2489 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/namespaces/test_categorical.py
--rw-r--r--   0     1001      123    19210 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/namespaces/test_datetime.py
--rw-r--r--   0     1001      123    13879 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/namespaces/test_list.py
--rw-r--r--   0     1001      123     1829 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/namespaces/test_meta.py
--rw-r--r--   0     1001      123    23349 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/namespaces/test_string.py
--rw-r--r--   0     1001      123    16029 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/namespaces/test_strptime.py
--rw-r--r--   0     1001      123      982 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/namespaces/test_struct.py
--rw-r--r--   0     1001      123       85 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/__init__.py
--rw-r--r--   0     1001      123     7475 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_aggregations.py
--rw-r--r--   0     1001      123     9922 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_apply.py
--rw-r--r--   0     1001      123     6932 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_arithmetic.py
--rw-r--r--   0     1001      123     4631 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_comparison.py
--rw-r--r--   0     1001      123     3275 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_drop.py
--rw-r--r--   0     1001      123     8519 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_explode.py
--rw-r--r--   0     1001      123     3664 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_filter.py
--rw-r--r--   0     1001      123     1801 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_folds.py
--rw-r--r--   0     1001      123    24317 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_groupby.py
--rw-r--r--   0     1001      123     7649 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_groupby_rolling.py
--rw-r--r--   0     1001      123     2983 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_is_in.py
--rw-r--r--   0     1001      123    17498 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_join.py
--rw-r--r--   0     1001      123    14612 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_join_asof.py
--rw-r--r--   0     1001      123      643 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_melt.py
--rw-r--r--   0     1001      123    10253 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_pivot.py
--rw-r--r--   0     1001      123    19405 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_rolling.py
--rw-r--r--   0     1001      123    20578 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_sort.py
--rw-r--r--   0     1001      123     4038 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_statistics.py
--rw-r--r--   0     1001      123     4130 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_transpose.py
--rw-r--r--   0     1001      123      771 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_unique.py
--rw-r--r--   0     1001      123    11694 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/operations/test_window.py
--rw-r--r--   0     1001      123        0 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/streaming/__init__.py
--rw-r--r--   0     1001      123      196 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/streaming/conftest.py
--rw-r--r--   0     1001      123      839 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/streaming/test_ooc.py
--rw-r--r--   0     1001      123    16053 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/streaming/test_streaming.py
--rw-r--r--   0     1001      123     4775 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_api.py
--rw-r--r--   0     1001      123     1077 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_arity.py
--rw-r--r--   0     1001      123    19865 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_cfg.py
--rw-r--r--   0     1001      123    41153 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_constructors.py
--rw-r--r--   0     1001      123      454 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_context.py
--rw-r--r--   0     1001      123     1628 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_cse.py
--rw-r--r--   0     1001      123     3817 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_datatypes.py
--rw-r--r--   0     1001      123   124160 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_df.py
--rw-r--r--   0     1001      123     1906 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_empty.py
--rw-r--r--   0     1001      123    18539 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_errors.py
--rw-r--r--   0     1001      123     2387 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_expr_multi_cols.py
--rw-r--r--   0     1001      123    34736 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_exprs.py
--rw-r--r--   0     1001      123     3516 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_fmt.py
--rw-r--r--   0     1001      123     3763 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_interchange.py
--rw-r--r--   0     1001      123    37738 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_interop.py
--rw-r--r--   0     1001      123    49117 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_lazy.py
--rw-r--r--   0     1001      123     2369 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_polars_import.py
--rw-r--r--   0     1001      123     4610 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_predicates.py
--rw-r--r--   0     1001      123     7073 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_projections.py
--rw-r--r--   0     1001      123    11551 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_queries.py
--rw-r--r--   0     1001      123     4743 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_rows.py
--rw-r--r--   0     1001      123    13203 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_schema.py
--rw-r--r--   0     1001      123     2634 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_serde.py
--rw-r--r--   0     1001      123    83565 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_series.py
--rw-r--r--   0     1001      123      657 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_single.py
--rw-r--r--   0     1001      123     6527 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_sql.py
--rw-r--r--   0     1001      123    12957 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/test_testing.py
--rw-r--r--   0     1001      123       41 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/utils/__init__.py
--rw-r--r--   0     1001      123      306 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/utils/test_build_info.py
--rw-r--r--   0     1001      123     2631 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/utils/test_parse_expr_input.py
--rw-r--r--   0     1001      123      247 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/utils/test_show_versions.py
--rw-r--r--   0     1001      123     5026 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/tests/unit/utils/test_utils.py
--rw-r--r--   0     1001      123    63477 2023-05-29 20:01:50.000000 polars_lts_cpu-0.18.0/Cargo.lock
--rw-r--r--   0        0        0    14535 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.0/PKG-INFO
+-rw-r--r--   0        0        0      827 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-algo/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-algo/LICENSE
+-rw-r--r--   0     1001      123      142 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-algo/README.md
+-rw-r--r--   0     1001      123     7548 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-algo/src/algo.rs
+-rw-r--r--   0     1001      123       88 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-algo/src/lib.rs
+-rw-r--r--   0     1001      123       28 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-algo/src/prelude.rs
+-rw-r--r--   0        0        0     3439 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/LICENSE
+-rw-r--r--   0     1001      123      132 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/README.md
+-rw-r--r--   0     1001      123     2382 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/array/min_max.rs
+-rw-r--r--   0     1001      123      267 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/array/mod.rs
+-rw-r--r--   0     1001      123     1512 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/array/namespace.rs
+-rw-r--r--   0     1001      123     4108 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/array/sum_mean.rs
+-rw-r--r--   0     1001      123      234 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/binary/mod.rs
+-rw-r--r--   0     1001      123     3549 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/binary/namespace.rs
+-rw-r--r--   0     1001      123    11023 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/interpolate.rs
+-rw-r--r--   0     1001      123     1687 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/list/count.rs
+-rw-r--r--   0     1001      123     2419 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/list/hash.rs
+-rw-r--r--   0     1001      123     7861 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/list/min_max.rs
+-rw-r--r--   0     1001      123      511 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/list/mod.rs
+-rw-r--r--   0     1001      123    19010 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/list/namespace.rs
+-rw-r--r--   0     1001      123     7633 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/list/sum_mean.rs
+-rw-r--r--   0     1001      123     2435 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/list/to_struct.rs
+-rw-r--r--   0     1001      123      545 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/mod.rs
+-rw-r--r--   0     1001      123     9452 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/nan_propagating_aggregate.rs
+-rw-r--r--   0     1001      123     6795 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/set.rs
+-rw-r--r--   0     1001      123     7490 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/strings/case.rs
+-rw-r--r--   0     1001      123     8409 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/strings/json_path.rs
+-rw-r--r--   0     1001      123     2345 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/strings/justify.rs
+-rw-r--r--   0     1001      123      514 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/strings/mod.rs
+-rw-r--r--   0     1001      123    14731 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/strings/namespace.rs
+-rw-r--r--   0     1001      123     4053 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/strings/replace.rs
+-rw-r--r--   0     1001      123      439 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/sum.rs
+-rw-r--r--   0     1001      123     2486 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/top_k.rs
+-rw-r--r--   0     1001      123     7727 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/frame/join/merge_sorted.rs
+-rw-r--r--   0     1001      123    18232 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/frame/join/mod.rs
+-rw-r--r--   0     1001      123     4174 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/frame/mod.rs
+-rw-r--r--   0     1001      123    10257 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/frame/pivot/mod.rs
+-rw-r--r--   0     1001      123    13486 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/frame/pivot/positioning.rs
+-rw-r--r--   0     1001      123      237 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/lib.rs
+-rw-r--r--   0     1001      123      290 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/prelude.rs
+-rw-r--r--   0     1001      123       25 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/mod.rs
+-rw-r--r--   0     1001      123     9623 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/approx_algo/hyperloglogplus.rs
+-rw-r--r--   0     1001      123      118 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/approx_algo/mod.rs
+-rw-r--r--   0     1001      123     2016 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/approx_unique.rs
+-rw-r--r--   0     1001      123    11866 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/arg_min_max.rs
+-rw-r--r--   0     1001      123     3688 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/floor_divide.rs
+-rw-r--r--   0     1001      123     5245 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/fused.rs
+-rw-r--r--   0     1001      123     3423 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/is_first.rs
+-rw-r--r--   0     1001      123     2975 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/is_unique.rs
+-rw-r--r--   0     1001      123     3626 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/log.rs
+-rw-r--r--   0     1001      123     1187 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/mod.rs
+-rw-r--r--   0     1001      123     1769 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/rolling.rs
+-rw-r--r--   0     1001      123     7642 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/search_sorted.rs
+-rw-r--r--   0     1001      123     2500 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/to_dummies.rs
+-rw-r--r--   0     1001      123     2067 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/various.rs
+-rw-r--r--   0        0        0     1353 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-json/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-json/LICENSE
+-rw-r--r--   0     1001      123    16770 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-json/src/json/deserialize.rs
+-rw-r--r--   0     1001      123     6564 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-json/src/json/infer_schema.rs
+-rw-r--r--   0     1001      123      189 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-json/src/json/mod.rs
+-rw-r--r--   0     1001      123       30 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-json/src/lib.rs
+-rw-r--r--   0     1001      123     1198 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-json/src/ndjson/deserialize.rs
+-rw-r--r--   0     1001      123     4808 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-json/src/ndjson/file.rs
+-rw-r--r--   0     1001      123      143 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-json/src/ndjson/mod.rs
+-rw-r--r--   0        0        0     1592 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/LICENSE
+-rw-r--r--   0     1001      123      144 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/README.md
+-rw-r--r--   0     1001      123     1975 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/array/default_arrays.rs
+-rw-r--r--   0     1001      123     1791 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/array/fixed_size_list.rs
+-rw-r--r--   0     1001      123     3773 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/array/get.rs
+-rw-r--r--   0     1001      123     6664 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/array/list.rs
+-rw-r--r--   0     1001      123     8165 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/array/mod.rs
+-rw-r--r--   0     1001      123      878 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/array/null.rs
+-rw-r--r--   0     1001      123     1125 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/array/slice.rs
+-rw-r--r--   0     1001      123     2252 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/array/utf8.rs
+-rw-r--r--   0     1001      123     2294 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/bit_util.rs
+-rw-r--r--   0     1001      123       17 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/bitmap/mod.rs
+-rw-r--r--   0     1001      123      819 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/bitmap/mutable.rs
+-rw-r--r--   0     1001      123      370 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/add.rs
+-rw-r--r--   0     1001      123     2181 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/commutative.rs
+-rw-r--r--   0     1001      123     1482 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/div.rs
+-rw-r--r--   0     1001      123     1028 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/mod.rs
+-rw-r--r--   0     1001      123     1177 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/mul.rs
+-rw-r--r--   0     1001      123      508 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/sub.rs
+-rw-r--r--   0     1001      123       51 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/arithmetics/mod.rs
+-rw-r--r--   0     1001      123        1 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/arity.rs
+-rw-r--r--   0     1001      123      727 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/bitwise.rs
+-rw-r--r--   0     1001      123     1206 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/cast.rs
+-rw-r--r--   0     1001      123     3964 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/decimal.rs
+-rw-r--r--   0     1001      123     1250 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/mod.rs
+-rw-r--r--   0     1001      123      391 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/take/bitmap.rs
+-rw-r--r--   0     1001      123     2767 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/take/boolean.rs
+-rw-r--r--   0     1001      123     3487 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/take/fixed_size_list.rs
+-rw-r--r--   0     1001      123    25289 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/take/mod.rs
+-rw-r--r--   0     1001      123      797 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/tile.rs
+-rw-r--r--   0     1001      123     1102 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/conversion.rs
+-rw-r--r--   0     1001      123     1609 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/data_types.rs
+-rw-r--r--   0     1001      123       25 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/error.rs
+-rw-r--r--   0     1001      123       28 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/export.rs
+-rw-r--r--   0     1001      123       26 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/floats/mod.rs
+-rw-r--r--   0     1001      123     2066 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/floats/ord.rs
+-rw-r--r--   0     1001      123     1273 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/index.rs
+-rw-r--r--   0     1001      123      984 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/is_valid.rs
+-rw-r--r--   0     1001      123     4783 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/agg_mean.rs
+-rw-r--r--   0     1001      123     1074 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/comparison.rs
+-rw-r--r--   0     1001      123     1068 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/concatenate.rs
+-rw-r--r--   0     1001      123     5161 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/ewm/average.rs
+-rw-r--r--   0     1001      123     1808 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/ewm/mod.rs
+-rw-r--r--   0     1001      123    25065 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/ewm/variance.rs
+-rw-r--r--   0     1001      123     1406 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/float.rs
+-rw-r--r--   0     1001      123     4907 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/list.rs
+-rw-r--r--   0     1001      123     1885 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/list_bytes_iter.rs
+-rw-r--r--   0     1001      123     9783 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/mod.rs
+-rw-r--r--   0     1001      123     3923 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/mod.rs
+-rw-r--r--   0     1001      123     2105 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mean.rs
+-rw-r--r--   0     1001      123    19032 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/min_max.rs
+-rw-r--r--   0     1001      123     3970 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mod.rs
+-rw-r--r--   0     1001      123    11693 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/quantile.rs
+-rw-r--r--   0     1001      123     5616 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/sum.rs
+-rw-r--r--   0     1001      123     9545 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/variance.rs
+-rw-r--r--   0     1001      123     1879 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mean.rs
+-rw-r--r--   0     1001      123    14722 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/nulls/min_max.rs
+-rw-r--r--   0     1001      123    10034 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mod.rs
+-rw-r--r--   0     1001      123    11643 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/nulls/quantile.rs
+-rw-r--r--   0     1001      123     4821 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/nulls/sum.rs
+-rw-r--r--   0     1001      123     8687 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/nulls/variance.rs
+-rw-r--r--   0     1001      123     8109 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/window.rs
+-rw-r--r--   0     1001      123     4752 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/set.rs
+-rw-r--r--   0     1001      123     4529 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/sort_partition.rs
+-rw-r--r--   0     1001      123     2948 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/sorted_join/inner.rs
+-rw-r--r--   0     1001      123     5974 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/sorted_join/left.rs
+-rw-r--r--   0     1001      123      231 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/sorted_join/mod.rs
+-rw-r--r--   0     1001      123      841 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/string.rs
+-rw-r--r--   0     1001      123     2310 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/take_agg/boolean.rs
+-rw-r--r--   0     1001      123     4344 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/take_agg/mod.rs
+-rw-r--r--   0     1001      123     2606 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/take_agg/var.rs
+-rw-r--r--   0     1001      123     3672 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/time.rs
+-rw-r--r--   0     1001      123      341 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/lib.rs
+-rw-r--r--   0     1001      123      496 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/prelude.rs
+-rw-r--r--   0     1001      123      534 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/slice.rs
+-rw-r--r--   0     1001      123      183 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/time_zone.rs
+-rw-r--r--   0     1001      123      998 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/trusted_len/boolean.rs
+-rw-r--r--   0     1001      123     2821 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/trusted_len/mod.rs
+-rw-r--r--   0     1001      123     2052 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/trusted_len/push_unchecked.rs
+-rw-r--r--   0     1001      123      158 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/trusted_len/rev.rs
+-rw-r--r--   0     1001      123     5232 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/utils.rs
+-rw-r--r--   0        0        0     4397 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/LICENSE
+-rw-r--r--   0     1001      123      138 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/README.md
+-rw-r--r--   0     1001      123     2383 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/avro/mod.rs
+-rw-r--r--   0     1001      123     3608 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/avro/read.rs
+-rw-r--r--   0     1001      123     2622 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/avro/write.rs
+-rw-r--r--   0     1001      123     4505 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/cloud/adaptors.rs
+-rw-r--r--   0     1001      123     9506 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/cloud/glob.rs
+-rw-r--r--   0     1001      123     3089 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/cloud/mod.rs
+-rw-r--r--   0     1001      123    28133 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/buffer.rs
+-rw-r--r--   0     1001      123     1815 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/mod.rs
+-rw-r--r--   0     1001      123    19446 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/parser.rs
+-rw-r--r--   0     1001      123    22226 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/read.rs
+-rw-r--r--   0     1001      123    10846 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/read_impl/batched_mmap.rs
+-rw-r--r--   0     1001      123    13938 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/read_impl/batched_read.rs
+-rw-r--r--   0     1001      123    30724 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/read_impl/mod.rs
+-rw-r--r--   0     1001      123    11466 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/splitfields.rs
+-rw-r--r--   0     1001      123    24531 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/utils.rs
+-rw-r--r--   0     1001      123     2796 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/write.rs
+-rw-r--r--   0     1001      123    14759 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/write_impl.rs
+-rw-r--r--   0     1001      123      184 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/export.rs
+-rw-r--r--   0     1001      123     7586 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/ipc/ipc_file.rs
+-rw-r--r--   0     1001      123     9227 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/ipc/ipc_stream.rs
+-rw-r--r--   0     1001      123     3253 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/ipc/mmap.rs
+-rw-r--r--   0     1001      123      401 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/ipc/mod.rs
+-rw-r--r--   0     1001      123     8287 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/ipc/write.rs
+-rw-r--r--   0     1001      123     1471 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/ipc/write_async.rs
+-rw-r--r--   0     1001      123    11044 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/json/mod.rs
+-rw-r--r--   0     1001      123     4771 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/lib.rs
+-rw-r--r--   0     1001      123     1969 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/mmap.rs
+-rw-r--r--   0     1001      123     7155 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/ndjson/buffer.rs
+-rw-r--r--   0     1001      123    11979 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/ndjson/core.rs
+-rw-r--r--   0     1001      123       37 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/ndjson/mod.rs
+-rw-r--r--   0     1001      123      273 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/options.rs
+-rw-r--r--   0     1001      123     7360 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/parquet/async_impl.rs
+-rw-r--r--   0     1001      123     3093 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/parquet/mmap.rs
+-rw-r--r--   0     1001      123     3132 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/parquet/mod.rs
+-rw-r--r--   0     1001      123     4784 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/parquet/predicates.rs
+-rw-r--r--   0     1001      123     9623 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/parquet/read.rs
+-rw-r--r--   0     1001      123    16886 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/parquet/read_impl.rs
+-rw-r--r--   0     1001      123    10052 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/parquet/write.rs
+-rw-r--r--   0     1001      123     5334 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/partition.rs
+-rw-r--r--   0     1001      123     1455 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/predicates.rs
+-rw-r--r--   0     1001      123      621 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/prelude.rs
+-rw-r--r--   0     1001      123      417 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/tests.rs
+-rw-r--r--   0     1001      123     4374 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/utils.rs
+-rw-r--r--   0        0        0     5152 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/LICENSE
+-rw-r--r--   0     1001      123       45 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/constants.rs
+-rw-r--r--   0     1001      123    17253 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dot.rs
+-rw-r--r--   0     1001      123     4171 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/arithmetic.rs
+-rw-r--r--   0     1001      123     3992 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/arity.rs
+-rw-r--r--   0     1001      123     1278 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/array.rs
+-rw-r--r--   0     1001      123      935 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/binary.rs
+-rw-r--r--   0     1001      123      650 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/cat.rs
+-rw-r--r--   0     1001      123    10228 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/dt.rs
+-rw-r--r--   0     1001      123     9538 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/expr.rs
+-rw-r--r--   0     1001      123     6441 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/expr_dyn_fn.rs
+-rw-r--r--   0     1001      123      753 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/from.rs
+-rw-r--r--   0     1001      123       85 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/abs.rs
+-rw-r--r--   0     1001      123     1431 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/arg_where.rs
+-rw-r--r--   0     1001      123     1074 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/array.rs
+-rw-r--r--   0     1001      123     1327 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/binary.rs
+-rw-r--r--   0     1001      123     4221 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/boolean.rs
+-rw-r--r--   0     1001      123     1910 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/bounds.rs
+-rw-r--r--   0     1001      123     1216 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/cat.rs
+-rw-r--r--   0     1001      123      344 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/clip.rs
+-rw-r--r--   0     1001      123      257 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/concat.rs
+-rw-r--r--   0     1001      123     6261 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/correlation.rs
+-rw-r--r--   0     1001      123     1593 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/cum.rs
+-rw-r--r--   0     1001      123     9597 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/datetime.rs
+-rw-r--r--   0     1001      123      673 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/dispatch.rs
+-rw-r--r--   0     1001      123     2567 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/fill_null.rs
+-rw-r--r--   0     1001      123      992 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/fused.rs
+-rw-r--r--   0     1001      123     8119 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/list.rs
+-rw-r--r--   0     1001      123      581 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/log.rs
+-rw-r--r--   0     1001      123    21034 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/mod.rs
+-rw-r--r--   0     1001      123      462 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/nan.rs
+-rw-r--r--   0     1001      123     3132 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/pow.rs
+-rw-r--r--   0     1001      123      152 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/rolling.rs
+-rw-r--r--   0     1001      123      260 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/round.rs
+-rw-r--r--   0     1001      123      200 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/row_hash.rs
+-rw-r--r--   0     1001      123    14242 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/schema.rs
+-rw-r--r--   0     1001      123      306 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/search_sorted.rs
+-rw-r--r--   0     1001      123     3812 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/shift_and_fill.rs
+-rw-r--r--   0     1001      123     1238 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/shrink_type.rs
+-rw-r--r--   0     1001      123      972 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/sign.rs
+-rw-r--r--   0     1001      123    21047 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/strings.rs
+-rw-r--r--   0     1001      123     1017 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/struct_.rs
+-rw-r--r--   0     1001      123     5509 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/temporal.rs
+-rw-r--r--   0     1001      123     5122 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/trigonometry.rs
+-rw-r--r--   0     1001      123      170 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/unique.rs
+-rw-r--r--   0     1001      123     1155 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/functions/arity.rs
+-rw-r--r--   0     1001      123      611 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/functions/coerce.rs
+-rw-r--r--   0     1001      123     2717 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/functions/concat.rs
+-rw-r--r--   0     1001      123     4525 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/functions/correlation.rs
+-rw-r--r--   0     1001      123     8736 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/functions/horizontal.rs
+-rw-r--r--   0     1001      123     1044 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/functions/index.rs
+-rw-r--r--   0     1001      123      968 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/functions/mod.rs
+-rw-r--r--   0     1001      123     9827 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/functions/range.rs
+-rw-r--r--   0     1001      123     1308 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/functions/selectors.rs
+-rw-r--r--   0     1001      123     1973 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/functions/syntactic_sugar.rs
+-rw-r--r--   0     1001      123    11328 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/functions/temporal.rs
+-rw-r--r--   0     1001      123    10213 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/list.rs
+-rw-r--r--   0     1001      123     3772 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/meta.rs
+-rw-r--r--   0     1001      123    61334 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/mod.rs
+-rw-r--r--   0     1001      123       40 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/names.rs
+-rw-r--r--   0     1001      123     2658 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/options.rs
+-rw-r--r--   0     1001      123     1068 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/selector.rs
+-rw-r--r--   0     1001      123    17095 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/string.rs
+-rw-r--r--   0     1001      123     2715 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/struct_.rs
+-rw-r--r--   0     1001      123       38 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/frame/mod.rs
+-rw-r--r--   0     1001      123      933 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/frame/opt_state.rs
+-rw-r--r--   0     1001      123      466 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/global.rs
+-rw-r--r--   0     1001      123      175 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/lib.rs
+-rw-r--r--   0     1001      123     8318 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/aexpr/mod.rs
+-rw-r--r--   0     1001      123    11742 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/aexpr/schema.rs
+-rw-r--r--   0     1001      123    25683 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/alp.rs
+-rw-r--r--   0     1001      123     1622 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/anonymous_scan.rs
+-rw-r--r--   0     1001      123     1428 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/apply.rs
+-rw-r--r--   0     1001      123    24898 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/builder.rs
+-rw-r--r--   0     1001      123    29993 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/conversion.rs
+-rw-r--r--   0     1001      123      301 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/debug.rs
+-rw-r--r--   0     1001      123    15470 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/format.rs
+-rw-r--r--   0     1001      123      895 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/functions/drop.rs
+-rw-r--r--   0     1001      123      137 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/functions/explode.rs
+-rw-r--r--   0     1001      123     1169 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/functions/merge_sorted.rs
+-rw-r--r--   0     1001      123    11905 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/functions/mod.rs
+-rw-r--r--   0     1001      123     1330 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/functions/rename.rs
+-rw-r--r--   0     1001      123    10140 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/iterator.rs
+-rw-r--r--   0     1001      123    10559 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/lit.rs
+-rw-r--r--   0     1001      123     8072 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/mod.rs
+-rw-r--r--   0     1001      123     7416 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/cache_states.rs
+-rw-r--r--   0     1001      123    15277 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/cse.rs
+-rw-r--r--   0     1001      123     2889 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/delay_rechunk.rs
+-rw-r--r--   0     1001      123     3236 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/drop_nulls.rs
+-rw-r--r--   0     1001      123     3994 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/fast_projection.rs
+-rw-r--r--   0     1001      123    14479 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/file_caching.rs
+-rw-r--r--   0     1001      123     1556 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/flatten_union.rs
+-rw-r--r--   0     1001      123     6017 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/fused.rs
+-rw-r--r--   0     1001      123     6774 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/mod.rs
+-rw-r--r--   0     1001      123     1222 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/keys.rs
+-rw-r--r--   0     1001      123    28901 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/mod.rs
+-rw-r--r--   0     1001      123     2571 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/rename.rs
+-rw-r--r--   0     1001      123    15756 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/utils.rs
+-rw-r--r--   0     1001      123     1755 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/melt.rs
+-rw-r--r--   0     1001      123     3930 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/mod.rs
+-rw-r--r--   0     1001      123     1799 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/generic.rs
+-rw-r--r--   0     1001      123     3269 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/groupby.rs
+-rw-r--r--   0     1001      123     2638 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/hstack.rs
+-rw-r--r--   0     1001      123    15752 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/joins.rs
+-rw-r--r--   0     1001      123    26507 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/mod.rs
+-rw-r--r--   0     1001      123     3707 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/projection.rs
+-rw-r--r--   0     1001      123     2639 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/rename.rs
+-rw-r--r--   0     1001      123     3501 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/semi_anti_join.rs
+-rw-r--r--   0     1001      123    27269 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/simplify_expr.rs
+-rw-r--r--   0     1001      123     3492 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_expr.rs
+-rw-r--r--   0     1001      123    13786 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_lp.rs
+-rw-r--r--   0     1001      123     4181 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/stack_opt.rs
+-rw-r--r--   0     1001      123     9725 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/binary.rs
+-rw-r--r--   0     1001      123    20215 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/mod.rs
+-rw-r--r--   0     1001      123    10545 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/options.rs
+-rw-r--r--   0     1001      123    18601 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/projection.rs
+-rw-r--r--   0     1001      123     6144 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/pyarrow.rs
+-rw-r--r--   0     1001      123    13026 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/schema.rs
+-rw-r--r--   0     1001      123      832 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/prelude.rs
+-rw-r--r--   0     1001      123    11871 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/utils.rs
+-rw-r--r--   0        0        0     5971 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/LICENSE
+-rw-r--r--   0     1001      123      358 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/README.md
+-rw-r--r--   0     1001      123     1796 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/dot.rs
+-rw-r--r--   0     1001      123     4479 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/dsl/eval.rs
+-rw-r--r--   0     1001      123     5127 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/dsl/functions.rs
+-rw-r--r--   0     1001      123      164 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/dsl/into.rs
+-rw-r--r--   0     1001      123     6754 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/dsl/list.rs
+-rw-r--r--   0     1001      123     2899 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/dsl/mod.rs
+-rw-r--r--   0     1001      123     1182 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/anonymous_scan.rs
+-rw-r--r--   0     1001      123     9278 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/csv.rs
+-rw-r--r--   0     1001      123     4309 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/file_list_reader.rs
+-rw-r--r--   0     1001      123     2261 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/ipc.rs
+-rw-r--r--   0     1001      123    48867 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/mod.rs
+-rw-r--r--   0     1001      123     3414 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/ndjson.rs
+-rw-r--r--   0     1001      123     2734 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/parquet.rs
+-rw-r--r--   0     1001      123     2892 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/pivot.rs
+-rw-r--r--   0     1001      123      416 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/python.rs
+-rw-r--r--   0     1001      123     6376 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/lib.rs
+-rw-r--r--   0     1001      123     1049 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/cache.rs
+-rw-r--r--   0     1001      123      776 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/executor.rs
+-rw-r--r--   0     1001      123      670 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/ext_context.rs
+-rw-r--r--   0     1001      123     1555 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/filter.rs
+-rw-r--r--   0     1001      123     3986 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/groupby.rs
+-rw-r--r--   0     1001      123     4125 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_dynamic.rs
+-rw-r--r--   0     1001      123    13580 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_partitioned.rs
+-rw-r--r--   0     1001      123     4883 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_rolling.rs
+-rw-r--r--   0     1001      123     5859 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/join.rs
+-rw-r--r--   0     1001      123     6753 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/mod.rs
+-rw-r--r--   0     1001      123     2045 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/projection.rs
+-rw-r--r--   0     1001      123     1677 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/python_scan.rs
+-rw-r--r--   0     1001      123     2854 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/scan/csv.rs
+-rw-r--r--   0     1001      123     1963 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ipc.rs
+-rw-r--r--   0     1001      123     4303 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/scan/mod.rs
+-rw-r--r--   0     1001      123     1209 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ndjson.rs
+-rw-r--r--   0     1001      123     2421 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/scan/parquet.rs
+-rw-r--r--   0     1001      123      548 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/slice.rs
+-rw-r--r--   0     1001      123     2197 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/sort.rs
+-rw-r--r--   0     1001      123     2015 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/stack.rs
+-rw-r--r--   0     1001      123      663 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/udf.rs
+-rw-r--r--   0     1001      123     4041 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/union.rs
+-rw-r--r--   0     1001      123      838 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/unique.rs
+-rw-r--r--   0     1001      123     1335 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/exotic.rs
+-rw-r--r--   0     1001      123    21959 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/aggregation.rs
+-rw-r--r--   0     1001      123     2689 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/alias.rs
+-rw-r--r--   0     1001      123    18331 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/apply.rs
+-rw-r--r--   0     1001      123    17197 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/binary.rs
+-rw-r--r--   0     1001      123     2583 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/cache.rs
+-rw-r--r--   0     1001      123     3153 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/cast.rs
+-rw-r--r--   0     1001      123     6326 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/column.rs
+-rw-r--r--   0     1001      123     1996 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/count.rs
+-rw-r--r--   0     1001      123     5809 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/filter.rs
+-rw-r--r--   0     1001      123     4131 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/group_iter.rs
+-rw-r--r--   0     1001      123     5304 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/literal.rs
+-rw-r--r--   0     1001      123    23566 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/mod.rs
+-rw-r--r--   0     1001      123    10091 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/slice.rs
+-rw-r--r--   0     1001      123     4332 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/sort.rs
+-rw-r--r--   0     1001      123    13549 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/sortby.rs
+-rw-r--r--   0     1001      123     8331 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/take.rs
+-rw-r--r--   0     1001      123    14360 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/ternary.rs
+-rw-r--r--   0     1001      123    31558 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/window.rs
+-rw-r--r--   0     1001      123     2039 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/file_cache.rs
+-rw-r--r--   0     1001      123      414 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/mod.rs
+-rw-r--r--   0     1001      123     2005 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/node_timer.rs
+-rw-r--r--   0     1001      123    24050 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/planner/expr.rs
+-rw-r--r--   0     1001      123    20552 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/planner/lp.rs
+-rw-r--r--   0     1001      123       87 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/planner/mod.rs
+-rw-r--r--   0     1001      123     9647 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/state.rs
+-rw-r--r--   0     1001      123     2535 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/streaming/checks.rs
+-rw-r--r--   0     1001      123     9227 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/streaming/construct_pipeline.rs
+-rw-r--r--   0     1001      123    15835 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/streaming/convert_alp.rs
+-rw-r--r--   0     1001      123      116 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/streaming/mod.rs
+-rw-r--r--   0     1001      123     5827 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/streaming/tree.rs
+-rw-r--r--   0     1001      123      722 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/prelude.rs
+-rw-r--r--   0     1001      123    14990 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/aggregations.rs
+-rw-r--r--   0     1001      123     2339 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/arity.rs
+-rw-r--r--   0     1001      123     7066 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/cse.rs
+-rw-r--r--   0     1001      123    12759 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/io.rs
+-rw-r--r--   0     1001      123     4166 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/logical.rs
+-rw-r--r--   0     1001      123     4273 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/mod.rs
+-rw-r--r--   0     1001      123    15680 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/optimization_checks.rs
+-rw-r--r--   0     1001      123     6772 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/predicate_queries.rs
+-rw-r--r--   0     1001      123     3165 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/projection_queries.rs
+-rw-r--r--   0     1001      123    47687 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/queries.rs
+-rw-r--r--   0     1001      123     9513 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/streaming.rs
+-rw-r--r--   0     1001      123     2893 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/tpch.rs
+-rw-r--r--   0     1001      123     1028 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/utils.rs
+-rw-r--r--   0        0        0     1998 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/LICENSE
+-rw-r--r--   0     1001      123      165 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/README.md
+-rw-r--r--   0     1001      123       98 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/mod.rs
+-rw-r--r--   0     1001      123     1219 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/operators/filter.rs
+-rw-r--r--   0     1001      123     4103 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/operators/function.rs
+-rw-r--r--   0     1001      123      266 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/operators/mod.rs
+-rw-r--r--   0     1001      123      682 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/operators/pass.rs
+-rw-r--r--   0     1001      123      548 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/operators/placeholder.rs
+-rw-r--r--   0     1001      123     3553 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/operators/projection.rs
+-rw-r--r--   0     1001      123     3559 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/operators/reproject.rs
+-rw-r--r--   0     1001      123     6479 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/file_sink.rs
+-rw-r--r--   0     1001      123    11288 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/convert.rs
+-rw-r--r--   0     1001      123     1207 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/count.rs
+-rw-r--r--   0     1001      123     1888 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/first.rs
+-rw-r--r--   0     1001      123     4554 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/interface.rs
+-rw-r--r--   0     1001      123     1746 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/last.rs
+-rw-r--r--   0     1001      123     5413 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mean.rs
+-rw-r--r--   0     1001      123     4951 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/min_max.rs
+-rw-r--r--   0     1001      123      211 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mod.rs
+-rw-r--r--   0     1001      123      856 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/null.rs
+-rw-r--r--   0     1001      123     4294 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/sum.rs
+-rw-r--r--   0     1001      123     3030 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/eval.rs
+-rw-r--r--   0     1001      123     7500 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/global.rs
+-rw-r--r--   0     1001      123    13819 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/hash_table.rs
+-rw-r--r--   0     1001      123     3243 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/mod.rs
+-rw-r--r--   0     1001      123     2767 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/ooc_state.rs
+-rw-r--r--   0     1001      123     6311 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/sink.rs
+-rw-r--r--   0     1001      123     3116 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/source.rs
+-rw-r--r--   0     1001      123    11009 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/thread_local.rs
+-rw-r--r--   0     1001      123     2119 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/mod.rs
+-rw-r--r--   0     1001      123     4695 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc.rs
+-rw-r--r--   0     1001      123     1887 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc_state.rs
+-rw-r--r--   0     1001      123    20783 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/primitive/mod.rs
+-rw-r--r--   0     1001      123    23420 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/string.rs
+-rw-r--r--   0     1001      123     2457 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/utils.rs
+-rw-r--r--   0     1001      123     9239 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/io.rs
+-rw-r--r--   0     1001      123     5451 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/joins/cross.rs
+-rw-r--r--   0     1001      123    14279 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/joins/generic_build.rs
+-rw-r--r--   0     1001      123    11824 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/joins/inner_left.rs
+-rw-r--r--   0     1001      123      178 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/joins/mod.rs
+-rw-r--r--   0     1001      123     2241 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/memory.rs
+-rw-r--r--   0     1001      123      589 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/mod.rs
+-rw-r--r--   0     1001      123     1492 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/ordered.rs
+-rw-r--r--   0     1001      123     1824 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/reproject.rs
+-rw-r--r--   0     1001      123     3108 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/slice.rs
+-rw-r--r--   0     1001      123      130 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/sort/mod.rs
+-rw-r--r--   0     1001      123     6787 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/sort/ooc.rs
+-rw-r--r--   0     1001      123     7279 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/sort/sink.rs
+-rw-r--r--   0     1001      123     5953 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/sort/sink_multiple.rs
+-rw-r--r--   0     1001      123     3908 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/sort/source.rs
+-rw-r--r--   0     1001      123      635 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/utils.rs
+-rw-r--r--   0     1001      123     5984 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sources/csv.rs
+-rw-r--r--   0     1001      123     1231 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sources/frame.rs
+-rw-r--r--   0     1001      123      987 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sources/ipc_one_shot.rs
+-rw-r--r--   0     1001      123      366 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sources/mod.rs
+-rw-r--r--   0     1001      123     4335 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sources/parquet.rs
+-rw-r--r--   0     1001      123     1146 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sources/reproject.rs
+-rw-r--r--   0     1001      123     1022 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sources/union.rs
+-rw-r--r--   0     1001      123      448 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/expressions.rs
+-rw-r--r--   0     1001      123      272 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/lib.rs
+-rw-r--r--   0     1001      123      719 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/operators/chunks.rs
+-rw-r--r--   0     1001      123      474 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/operators/context.rs
+-rw-r--r--   0     1001      123      223 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/operators/mod.rs
+-rw-r--r--   0     1001      123      514 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/operators/operator.rs
+-rw-r--r--   0     1001      123      626 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/operators/sink.rs
+-rw-r--r--   0     1001      123      241 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/operators/source.rs
+-rw-r--r--   0     1001      123        1 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/pipeline/config.rs
+-rw-r--r--   0     1001      123    21304 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/pipeline/convert.rs
+-rw-r--r--   0     1001      123    18204 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/pipeline/dispatcher.rs
+-rw-r--r--   0     1001      123     1155 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/pipeline/mod.rs
+-rw-r--r--   0        0        0      954 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-row/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-row/LICENSE
+-rw-r--r--   0     1001      123      137 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-row/README.md
+-rw-r--r--   0     1001      123     8985 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-row/src/encode.rs
+-rw-r--r--   0     1001      123     4591 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-row/src/encodings/fixed.rs
+-rw-r--r--   0     1001      123       47 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-row/src/encodings/mod.rs
+-rw-r--r--   0     1001      123     4508 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-row/src/encodings/variable.rs
+-rw-r--r--   0     1001      123    13676 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-row/src/lib.rs
+-rw-r--r--   0     1001      123     2079 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-row/src/row.rs
+-rw-r--r--   0     1001      123      682 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-row/src/utils.rs
+-rw-r--r--   0        0        0     2037 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/LICENSE
+-rw-r--r--   0     1001      123      143 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/README.md
+-rw-r--r--   0     1001      123     3565 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/date.rs
+-rw-r--r--   0     1001      123     6465 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/datetime.rs
+-rw-r--r--   0     1001      123     3305 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/duration.rs
+-rw-r--r--   0     1001      123     5607 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/kernels.rs
+-rw-r--r--   0     1001      123     1062 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/mod.rs
+-rw-r--r--   0     1001      123     7302 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/rolling_window/floats.rs
+-rw-r--r--   0     1001      123     2582 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/rolling_window/ints.rs
+-rw-r--r--   0     1001      123    11031 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/rolling_window/mod.rs
+-rw-r--r--   0     1001      123      428 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/mod.rs
+-rw-r--r--   0     1001      123     6408 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/no_nulls.rs
+-rw-r--r--   0     1001      123     2372 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/time.rs
+-rw-r--r--   0     1001      123    18180 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/utf8/infer.rs
+-rw-r--r--   0     1001      123    18997 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/utf8/mod.rs
+-rw-r--r--   0     1001      123     3975 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/utf8/patterns.rs
+-rw-r--r--   0     1001      123    10548 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/utf8/strptime.rs
+-rw-r--r--   0     1001      123     3442 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/date_range.rs
+-rw-r--r--   0     1001      123    34469 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/groupby/dynamic.rs
+-rw-r--r--   0     1001      123       88 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/groupby/mod.rs
+-rw-r--r--   0     1001      123      621 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/lib.rs
+-rw-r--r--   0     1001      123     2976 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/month_end.rs
+-rw-r--r--   0     1001      123     3365 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/month_start.rs
+-rw-r--r--   0     1001      123      274 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/prelude.rs
+-rw-r--r--   0     1001      123     1381 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/round.rs
+-rw-r--r--   0     1001      123     3992 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/_trait.rs
+-rw-r--r--   0     1001      123      136 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/implementations/boolean.rs
+-rw-r--r--   0     1001      123      140 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/implementations/categoricals.rs
+-rw-r--r--   0     1001      123      133 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/implementations/date.rs
+-rw-r--r--   0     1001      123      137 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/implementations/datetime.rs
+-rw-r--r--   0     1001      123      137 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/implementations/duration.rs
+-rw-r--r--   0     1001      123     1863 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/implementations/floats.rs
+-rw-r--r--   0     1001      123     1792 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/implementations/integers.rs
+-rw-r--r--   0     1001      123      133 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/implementations/list.rs
+-rw-r--r--   0     1001      123      486 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/implementations/mod.rs
+-rw-r--r--   0     1001      123      155 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/implementations/object.rs
+-rw-r--r--   0     1001      123      135 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/implementations/struct_.rs
+-rw-r--r--   0     1001      123      133 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/implementations/time.rs
+-rw-r--r--   0     1001      123      133 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/implementations/utf8.rs
+-rw-r--r--   0     1001      123    12787 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/mod.rs
+-rw-r--r--   0     1001      123     1443 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/truncate.rs
+-rw-r--r--   0     1001      123     6845 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/upsample.rs
+-rw-r--r--   0     1001      123     2511 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/utils.rs
+-rw-r--r--   0     1001      123     1524 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/windows/bounds.rs
+-rw-r--r--   0     1001      123     2672 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/windows/calendar.rs
+-rw-r--r--   0     1001      123    25015 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/windows/duration.rs
+-rw-r--r--   0     1001      123    21244 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/windows/groupby.rs
+-rw-r--r--   0     1001      123      503 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/windows/mod.rs
+-rw-r--r--   0     1001      123    23652 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/windows/test.rs
+-rw-r--r--   0     1001      123    11666 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/windows/window.rs
+-rw-r--r--   0        0        0     5484 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/LICENSE
+-rw-r--r--   0     1001      123      144 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/README.md
+-rw-r--r--   0     1001      123     5125 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/arithmetic/decimal.rs
+-rw-r--r--   0     1001      123     8275 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/arithmetic/mod.rs
+-rw-r--r--   0     1001      123     9406 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/arithmetic/numeric.rs
+-rw-r--r--   0     1001      123     3588 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/array/iterator.rs
+-rw-r--r--   0     1001      123     2551 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/array/mod.rs
+-rw-r--r--   0     1001      123     6448 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/bitwise.rs
+-rw-r--r--   0     1001      123     2298 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/builder/binary.rs
+-rw-r--r--   0     1001      123     1207 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/builder/boolean.rs
+-rw-r--r--   0     1001      123     4311 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/builder/fixed_size_list.rs
+-rw-r--r--   0     1001      123     1556 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/builder/from.rs
+-rw-r--r--   0     1001      123    20366 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/builder/list.rs
+-rw-r--r--   0     1001      123     8969 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/builder/mod.rs
+-rw-r--r--   0     1001      123     1410 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/builder/primitive.rs
+-rw-r--r--   0     1001      123     2291 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/builder/utf8.rs
+-rw-r--r--   0     1001      123    16475 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/cast.rs
+-rw-r--r--   0     1001      123    49461 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/comparison/mod.rs
+-rw-r--r--   0     1001      123    10060 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/comparison/scalar.rs
+-rw-r--r--   0     1001      123      551 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/drop.rs
+-rw-r--r--   0     1001      123      963 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/float.rs
+-rw-r--r--   0     1001      123     7175 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/from.rs
+-rw-r--r--   0     1001      123    42339 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/iterator/mod.rs
+-rw-r--r--   0     1001      123     1453 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/iterator/par/list.rs
+-rw-r--r--   0     1001      123       28 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/iterator/par/mod.rs
+-rw-r--r--   0     1001      123     1129 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/iterator/par/utf8.rs
+-rw-r--r--   0     1001      123       21 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/kernels/mod.rs
+-rw-r--r--   0     1001      123     2347 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/kernels/take.rs
+-rw-r--r--   0     1001      123     7963 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/list/iterator.rs
+-rw-r--r--   0     1001      123     3242 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/list/mod.rs
+-rw-r--r--   0     1001      123    19830 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/builder.rs
+-rw-r--r--   0     1001      123     3688 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/from.rs
+-rw-r--r--   0     1001      123     4270 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/merge.rs
+-rw-r--r--   0     1001      123    10219 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/mod.rs
+-rw-r--r--   0     1001      123     1400 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/append.rs
+-rw-r--r--   0     1001      123      358 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/full.rs
+-rw-r--r--   0     1001      123      192 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/mod.rs
+-rw-r--r--   0     1001      123     2731 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/take_random.rs
+-rw-r--r--   0     1001      123     2172 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/unique.rs
+-rw-r--r--   0     1001      123      925 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/zip.rs
+-rw-r--r--   0     1001      123     6417 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/stringcache.rs
+-rw-r--r--   0     1001      123     1604 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/date.rs
+-rw-r--r--   0     1001      123     4105 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/datetime.rs
+-rw-r--r--   0     1001      123     4443 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/decimal.rs
+-rw-r--r--   0     1001      123     2434 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/duration.rs
+-rw-r--r--   0     1001      123     2556 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/mod.rs
+-rw-r--r--   0     1001      123      476 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/struct_/from.rs
+-rw-r--r--   0     1001      123    15982 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/struct_/mod.rs
+-rw-r--r--   0     1001      123     1182 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/time.rs
+-rw-r--r--   0     1001      123    23389 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/mod.rs
+-rw-r--r--   0     1001      123     7200 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ndarray.rs
+-rw-r--r--   0     1001      123     4484 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/builder.rs
+-rw-r--r--   0     1001      123     1547 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/extension/drop.rs
+-rw-r--r--   0     1001      123     3124 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/extension/list.rs
+-rw-r--r--   0     1001      123     7054 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/extension/mod.rs
+-rw-r--r--   0     1001      123     3410 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/extension/polars_extension.rs
+-rw-r--r--   0     1001      123      137 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/is_valid.rs
+-rw-r--r--   0     1001      123     4419 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/iterator.rs
+-rw-r--r--   0     1001      123     4806 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/mod.rs
+-rw-r--r--   0     1001      123     2956 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/registry.rs
+-rw-r--r--   0     1001      123      272 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/abs.rs
+-rw-r--r--   0     1001      123    32691 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/aggregate/mod.rs
+-rw-r--r--   0     1001      123    10025 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/aggregate/quantile.rs
+-rw-r--r--   0     1001      123     2880 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/aggregate/var.rs
+-rw-r--r--   0     1001      123    10551 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/any_value.rs
+-rw-r--r--   0     1001      123     2820 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/append.rs
+-rw-r--r--   0     1001      123    28256 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/apply.rs
+-rw-r--r--   0     1001      123    12799 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/bit_repr.rs
+-rw-r--r--   0     1001      123     6214 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/chunkops.rs
+-rw-r--r--   0     1001      123    11537 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/compare_inner.rs
+-rw-r--r--   0     1001      123     1737 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/concat_str.rs
+-rw-r--r--   0     1001      123     4801 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/cum_agg.rs
+-rw-r--r--   0     1001      123      908 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/decimal.rs
+-rw-r--r--   0     1001      123     7056 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/downcast.rs
+-rw-r--r--   0     1001      123    19463 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/explode.rs
+-rw-r--r--   0     1001      123     8691 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/explode_and_offsets.rs
+-rw-r--r--   0     1001      123     8866 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/extend.rs
+-rw-r--r--   0     1001      123    13777 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/fill_null.rs
+-rw-r--r--   0     1001      123     6323 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/filter.rs
+-rw-r--r--   0     1001      123     5876 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/full.rs
+-rw-r--r--   0     1001      123        1 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/interpolate.rs
+-rw-r--r--   0     1001      123    16797 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/is_in.rs
+-rw-r--r--   0     1001      123        1 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/len.rs
+-rw-r--r--   0     1001      123     2658 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/min_max_binary.rs
+-rw-r--r--   0     1001      123    23276 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/mod.rs
+-rw-r--r--   0     1001      123     2403 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/nulls.rs
+-rw-r--r--   0     1001      123      593 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/peaks.rs
+-rw-r--r--   0     1001      123     4375 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/repeat_by.rs
+-rw-r--r--   0     1001      123     2771 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/reverse.rs
+-rw-r--r--   0     1001      123    10266 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/rolling_window.rs
+-rw-r--r--   0     1001      123    12518 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/set.rs
+-rw-r--r--   0     1001      123     7391 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/shift.rs
+-rw-r--r--   0     1001      123     2299 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort.rs
+-rw-r--r--   0     1001      123     5528 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort_multiple.rs
+-rw-r--r--   0     1001      123     7543 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/sort/categorical.rs
+-rw-r--r--   0     1001      123    31164 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/sort/mod.rs
+-rw-r--r--   0     1001      123      380 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/sort/slice.rs
+-rw-r--r--   0     1001      123    22078 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/take/mod.rs
+-rw-r--r--   0     1001      123     7848 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/take/take_chunked.rs
+-rw-r--r--   0     1001      123      301 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/take/take_every.rs
+-rw-r--r--   0     1001      123    16256 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/take/take_random.rs
+-rw-r--r--   0     1001      123     5810 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/take/take_single.rs
+-rw-r--r--   0     1001      123     6072 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/take/traits.rs
+-rw-r--r--   0     1001      123      459 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/tile.rs
+-rw-r--r--   0     1001      123    11626 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/unique/mod.rs
+-rw-r--r--   0     1001      123    14620 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/unique/rank.rs
+-rw-r--r--   0     1001      123     8427 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/zip.rs
+-rw-r--r--   0     1001      123     9093 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/random.rs
+-rw-r--r--   0     1001      123     1875 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/temporal/conversion.rs
+-rw-r--r--   0     1001      123     2826 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/temporal/date.rs
+-rw-r--r--   0     1001      123    10497 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/temporal/datetime.rs
+-rw-r--r--   0     1001      123     3201 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/temporal/duration.rs
+-rw-r--r--   0     1001      123      595 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/temporal/mod.rs
+-rw-r--r--   0     1001      123     3042 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/temporal/time.rs
+-rw-r--r--   0     1001      123      872 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/to_vec.rs
+-rw-r--r--   0     1001      123     8113 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/trusted_len.rs
+-rw-r--r--   0     1001      123    25939 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/upstream_traits.rs
+-rw-r--r--   0     1001      123     7944 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/cloud.rs
+-rw-r--r--   0     1001      123     1549 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/config.rs
+-rw-r--r--   0     1001      123     3946 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/datatypes/_serde.rs
+-rw-r--r--   0     1001      123     2509 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/datatypes/aliases.rs
+-rw-r--r--   0     1001      123    42658 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/datatypes/any_value.rs
+-rw-r--r--   0     1001      123    13349 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/datatypes/dtype.rs
+-rw-r--r--   0     1001      123     5609 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/datatypes/field.rs
+-rw-r--r--   0     1001      123     8059 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/datatypes/mod.rs
+-rw-r--r--   0     1001      123     2016 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/datatypes/time_unit.rs
+-rw-r--r--   0     1001      123      118 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/doc/changelog/mod.rs
+-rw-r--r--   0     1001      123      898 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/doc/changelog/v0_10_0_11.rs
+-rw-r--r--   0     1001      123      481 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/doc/changelog/v0_3.rs
+-rw-r--r--   0     1001      123      293 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/doc/changelog/v0_4.rs
+-rw-r--r--   0     1001      123      499 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/doc/changelog/v0_5.rs
+-rw-r--r--   0     1001      123      288 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/doc/changelog/v0_6.rs
+-rw-r--r--   0     1001      123     1071 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/doc/changelog/v0_7.rs
+-rw-r--r--   0     1001      123      819 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/doc/changelog/v0_8.rs
+-rw-r--r--   0     1001      123      596 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/doc/changelog/v0_9.rs
+-rw-r--r--   0     1001      123       43 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/doc/mod.rs
+-rw-r--r--   0     1001      123       25 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/error.rs
+-rw-r--r--   0     1001      123      263 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/export.rs
+-rw-r--r--   0     1001      123    36432 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/fmt.rs
+-rw-r--r--   0     1001      123     5177 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/arithmetic.rs
+-rw-r--r--   0     1001      123     9916 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/asof_join/asof.rs
+-rw-r--r--   0     1001      123    35761 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/asof_join/groups.rs
+-rw-r--r--   0     1001      123     6973 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/asof_join/mod.rs
+-rw-r--r--   0     1001      123      559 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/chunks.rs
+-rw-r--r--   0     1001      123     5181 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/cross_join.rs
+-rw-r--r--   0     1001      123    16760 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/explode.rs
+-rw-r--r--   0     1001      123     1019 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/from.rs
+-rw-r--r--   0     1001      123    19219 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/aggregations/agg_list.rs
+-rw-r--r--   0     1001      123     4113 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/aggregations/boolean.rs
+-rw-r--r--   0     1001      123     7749 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/aggregations/dispatch.rs
+-rw-r--r--   0     1001      123    40369 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/aggregations/mod.rs
+-rw-r--r--   0     1001      123     5634 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/aggregations/utf8.rs
+-rw-r--r--   0     1001      123      218 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/expr.rs
+-rw-r--r--   0     1001      123    22901 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/hashing.rs
+-rw-r--r--   0     1001      123    14380 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/into_groups.rs
+-rw-r--r--   0     1001      123    39516 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/mod.rs
+-rw-r--r--   0     1001      123    10637 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/perfect.rs
+-rw-r--r--   0     1001      123    19780 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/proxy.rs
+-rw-r--r--   0     1001      123     5406 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/args.rs
+-rw-r--r--   0     1001      123    13329 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/mod.rs
+-rw-r--r--   0     1001      123    22364 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/multiple_keys.rs
+-rw-r--r--   0     1001      123     2413 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/single_keys.rs
+-rw-r--r--   0     1001      123    17372 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/single_keys_dispatch.rs
+-rw-r--r--   0     1001      123     4608 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/single_keys_inner.rs
+-rw-r--r--   0     1001      123     6434 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/single_keys_left.rs
+-rw-r--r--   0     1001      123     4564 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/single_keys_outer.rs
+-rw-r--r--   0     1001      123     3913 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/single_keys_semi_anti.rs
+-rw-r--r--   0     1001      123    12313 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/sort_merge.rs
+-rw-r--r--   0     1001      123     3865 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/zip_outer.rs
+-rw-r--r--   0     1001      123   126128 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/mod.rs
+-rw-r--r--   0     1001      123    27652 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/row/av_buffer.rs
+-rw-r--r--   0     1001      123     5183 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/row/dataframe.rs
+-rw-r--r--   0     1001      123     5976 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/row/mod.rs
+-rw-r--r--   0     1001      123     9875 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/row/transpose.rs
+-rw-r--r--   0     1001      123     2811 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/top_k.rs
+-rw-r--r--   0     1001      123     1388 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/upstream_traits.rs
+-rw-r--r--   0     1001      123    10198 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/functions.rs
+-rw-r--r--   0     1001      123     2149 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/hashing/fx.rs
+-rw-r--r--   0     1001      123     1503 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/hashing/identity.rs
+-rw-r--r--   0     1001      123      457 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/hashing/mod.rs
+-rw-r--r--   0     1001      123     2684 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/hashing/partition.rs
+-rw-r--r--   0     1001      123    17611 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/hashing/vector_hasher.rs
+-rw-r--r--   0     1001      123     1896 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/lib.rs
+-rw-r--r--   0     1001      123    15733 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/named_from.rs
+-rw-r--r--   0     1001      123     2423 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/prelude.rs
+-rw-r--r--   0     1001      123    17006 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/schema.rs
+-rw-r--r--   0     1001      123     4218 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/serde/chunked_array.rs
+-rw-r--r--   0     1001      123     1094 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/serde/df.rs
+-rw-r--r--   0     1001      123     6559 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/serde/mod.rs
+-rw-r--r--   0     1001      123     9929 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/serde/series.rs
+-rw-r--r--   0     1001      123    18543 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/any_value.rs
+-rw-r--r--   0     1001      123    28755 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/arithmetic/borrowed.rs
+-rw-r--r--   0     1001      123      222 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/arithmetic/mod.rs
+-rw-r--r--   0     1001      123     3546 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/arithmetic/owned.rs
+-rw-r--r--   0     1001      123    19293 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/comparison.rs
+-rw-r--r--   0     1001      123    29575 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/from.rs
+-rw-r--r--   0     1001      123     6080 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/array.rs
+-rw-r--r--   0     1001      123     9089 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/binary.rs
+-rw-r--r--   0     1001      123    10835 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/boolean.rs
+-rw-r--r--   0     1001      123    12800 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/categorical.rs
+-rw-r--r--   0     1001      123    18214 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/dates_time.rs
+-rw-r--r--   0     1001      123    15034 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/datetime.rs
+-rw-r--r--   0     1001      123     7981 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/decimal.rs
+-rw-r--r--   0     1001      123    14734 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/duration.rs
+-rw-r--r--   0     1001      123    14063 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/floats.rs
+-rw-r--r--   0     1001      123     6078 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/list.rs
+-rw-r--r--   0     1001      123    18396 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/mod.rs
+-rw-r--r--   0     1001      123     5522 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/null.rs
+-rw-r--r--   0     1001      123     7939 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/object.rs
+-rw-r--r--   0     1001      123    11788 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/struct_.rs
+-rw-r--r--   0     1001      123     9607 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/utf8.rs
+-rw-r--r--   0     1001      123     4471 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/into.rs
+-rw-r--r--   0     1001      123     6241 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/iterator.rs
+-rw-r--r--   0     1001      123    38559 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/mod.rs
+-rw-r--r--   0     1001      123      853 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/diff.rs
+-rw-r--r--   0     1001      123     5814 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/downcast.rs
+-rw-r--r--   0     1001      123     3601 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/ewm.rs
+-rw-r--r--   0     1001      123      413 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/extend.rs
+-rw-r--r--   0     1001      123      562 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/mod.rs
+-rw-r--r--   0     1001      123     5974 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/moment.rs
+-rw-r--r--   0     1001      123     2908 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/null.rs
+-rw-r--r--   0     1001      123     1347 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/pct_change.rs
+-rw-r--r--   0     1001      123     4620 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/round.rs
+-rw-r--r--   0     1001      123     5073 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/to_list.rs
+-rw-r--r--   0     1001      123     1476 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/unique.rs
+-rw-r--r--   0     1001      123    18408 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/series_trait.rs
+-rw-r--r--   0     1001      123     2912 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/unstable.rs
+-rw-r--r--   0     1001      123     7077 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/testing.rs
+-rw-r--r--   0     1001      123      508 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/tests.rs
+-rw-r--r--   0     1001      123     2492 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/utils/flatten.rs
+-rw-r--r--   0     1001      123    30596 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/utils/mod.rs
+-rw-r--r--   0     1001      123     1600 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/utils/series.rs
+-rw-r--r--   0     1001      123    13201 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/utils/supertype.rs
+-rw-r--r--   0        0        0      569 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/LICENSE
+-rw-r--r--   0     1001      123      141 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/README.md
+-rw-r--r--   0     1001      123      151 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/aliases.rs
+-rw-r--r--   0     1001      123     2862 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/arena.rs
+-rw-r--r--   0     1001      123     1373 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/atomic.rs
+-rw-r--r--   0     1001      123     2659 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/cell.rs
+-rw-r--r--   0     1001      123     1015 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/contention_pool.rs
+-rw-r--r--   0     1001      123      509 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/error.rs
+-rw-r--r--   0     1001      123      271 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/fmt.rs
+-rw-r--r--   0     1001      123      763 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/functions.rs
+-rw-r--r--   0     1001      123     2709 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/iter/enumerate_idx.rs
+-rw-r--r--   0     1001      123       61 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/iter/mod.rs
+-rw-r--r--   0     1001      123      490 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/lib.rs
+-rw-r--r--   0     1001      123      573 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/macros.rs
+-rw-r--r--   0     1001      123      282 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/mem.rs
+-rw-r--r--   0     1001      123     2336 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/slice.rs
+-rw-r--r--   0     1001      123     2467 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/sort.rs
+-rw-r--r--   0     1001      123     1115 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/sync.rs
+-rw-r--r--   0     1001      123      504 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/sys.rs
+-rw-r--r--   0     1001      123      697 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/unwrap.rs
+-rw-r--r--   0     1001      123      616 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/wasm.rs
+-rw-r--r--   0        0        0     1106 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/LICENSE
+-rw-r--r--   0     1001      123      466 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/README.md
+-rw-r--r--   0     1001      123    22794 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/src/context.rs
+-rw-r--r--   0     1001      123    20710 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/src/functions.rs
+-rw-r--r--   0     1001      123     2098 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/src/keywords.rs
+-rw-r--r--   0     1001      123      239 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/src/lib.rs
+-rw-r--r--   0     1001      123    19192 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/src/sql_expr.rs
+-rw-r--r--   0     1001      123     4572 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/src/table_functions.rs
+-rw-r--r--   0     1001      123     1682 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/functions_cumulative.rs
+-rw-r--r--   0     1001      123     3063 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/functions_io.rs
+-rw-r--r--   0     1001      123     1539 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/functions_math.rs
+-rw-r--r--   0     1001      123      860 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/functions_meta.rs
+-rw-r--r--   0     1001      123     2982 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/functions_string.rs
+-rw-r--r--   0     1001      123     1056 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/iss_7436.rs
+-rw-r--r--   0     1001      123      888 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/iss_7437.rs
+-rw-r--r--   0     1001      123      652 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/iss_7440.rs
+-rw-r--r--   0     1001      123      700 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/iss_8395.rs
+-rw-r--r--   0     1001      123     1062 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/iss_8419.rs
+-rw-r--r--   0     1001      123      982 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/ops_distinct_on.rs
+-rw-r--r--   0     1001      123    15418 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/simple_exprs.rs
+-rw-r--r--   0     1001      123     2985 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/statements.rs
+-rw-r--r--   0        0        0      894 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-error/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-error/LICENSE
+-rw-r--r--   0     1001      123      145 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-error/README.md
+-rw-r--r--   0     1001      123     6584 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars-error/src/lib.rs
+-rw-r--r--   0        0        0    10560 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/LICENSE
+-rw-r--r--   0     1001      123     3570 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/Makefile
+-rw-r--r--   0     1001      123      215 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/build.rs
+-rw-r--r--   0     1001      123       78 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/clippy.toml
+-rw-r--r--   0     1001      123    17602 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/src/docs/eager.rs
+-rw-r--r--   0     1001      123     8794 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/src/docs/lazy.rs
+-rw-r--r--   0     1001      123       50 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/src/docs/mod.rs
+-rw-r--r--   0     1001      123     3797 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/src/docs/performance.rs
+-rw-r--r--   0     1001      123       59 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/src/export.rs
+-rw-r--r--   0     1001      123    20213 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/src/lib.rs
+-rw-r--r--   0     1001      123      387 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/src/prelude.rs
+-rw-r--r--   0     1001      123       54 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/src/sql.rs
+-rw-r--r--   0     1001      123     4272 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/date_like.rs
+-rw-r--r--   0     1001      123     2401 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/groupby.rs
+-rw-r--r--   0     1001      123    17836 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/joins.rs
+-rw-r--r--   0     1001      123      545 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/list.rs
+-rw-r--r--   0     1001      123      198 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/mod.rs
+-rw-r--r--   0     1001      123       24 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/ops/mod.rs
+-rw-r--r--   0     1001      123      457 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/ops/take.rs
+-rw-r--r--   0     1001      123     6259 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/pivot.rs
+-rw-r--r--   0     1001      123     1102 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/random.rs
+-rw-r--r--   0     1001      123    11091 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/rolling_window.rs
+-rw-r--r--   0     1001      123     1093 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/series.rs
+-rw-r--r--   0     1001      123      370 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/utils.rs
+-rw-r--r--   0     1001      123    30423 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/io/csv.rs
+-rw-r--r--   0     1001      123     4490 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/io/ipc_stream.rs
+-rw-r--r--   0     1001      123     7043 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/io/json.rs
+-rw-r--r--   0     1001      123      378 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/io/mod.rs
+-rw-r--r--   0     1001      123      531 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/io/parquet.rs
+-rw-r--r--   0     1001      123     1530 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/joins.rs
+-rw-r--r--   0     1001      123     2452 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/aggregation.rs
+-rw-r--r--   0     1001      123      709 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/cse.rs
+-rw-r--r--   0     1001      123      500 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/explodes.rs
+-rw-r--r--   0     1001      123     2279 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/expressions/apply.rs
+-rw-r--r--   0     1001      123    10285 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/expressions/arity.rs
+-rw-r--r--   0     1001      123     1065 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/expressions/expand.rs
+-rw-r--r--   0     1001      123     1008 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/expressions/filter.rs
+-rw-r--r--   0     1001      123      428 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/expressions/is_in.rs
+-rw-r--r--   0     1001      123      121 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/expressions/mod.rs
+-rw-r--r--   0     1001      123      659 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/expressions/slice.rs
+-rw-r--r--   0     1001      123    10657 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/expressions/window.rs
+-rw-r--r--   0     1001      123      579 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/folds.rs
+-rw-r--r--   0     1001      123      557 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/functions.rs
+-rw-r--r--   0     1001      123     4482 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/groupby.rs
+-rw-r--r--   0     1001      123     1635 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/groupby_dynamic.rs
+-rw-r--r--   0     1001      123      691 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/mod.rs
+-rw-r--r--   0     1001      123     5614 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/predicate_queries.rs
+-rw-r--r--   0     1001      123     4483 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/projection_queries.rs
+-rw-r--r--   0     1001      123     6584 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/queries.rs
+-rw-r--r--   0     1001      123      141 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/main.rs
+-rw-r--r--   0     1001      123    12591 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/schema.rs
+-rw-r--r--   0        0        0     4393 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/Cargo.toml
+-rw-r--r--   0     1001      123       76 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/.gitignore
+-rw-r--r--   0     1001      123     1055 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/LICENSE
+-rw-r--r--   0     1001      123     2414 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/Makefile
+-rw-r--r--   0     1001      123    11998 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/README.md
+-rw-r--r--   0     1001      123      651 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/build.rs
+-rw-r--r--   0     1001      123       32 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/.gitignore
+-rw-r--r--   0     1001      123      679 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/Makefile
+-rw-r--r--   0     1001      123      318 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/_templates/api_redirect.html
+-rw-r--r--   0     1001      123      151 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/_templates/autosummary/accessor.rst
+-rw-r--r--   0     1001      123      160 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/_templates/autosummary/accessor_attribute.rst
+-rw-r--r--   0     1001      123      168 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/_templates/autosummary/accessor_callable.rst
+-rw-r--r--   0     1001      123      157 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/_templates/autosummary/accessor_method.rst
+-rw-r--r--   0     1001      123      836 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/_templates/autosummary/class.rst
+-rw-r--r--   0     1001      123       94 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/_templates/autosummary/class_without_autosummary.rst
+-rw-r--r--   0     1001      123      406 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/_templates/sidebar-nav-bs.html
+-rw-r--r--   0     1001      123      491 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/requirements-docs.txt
+-rw-r--r--   0     1001      123     1164 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/run_live_docs_server.py
+-rw-r--r--   0     1001      123     1567 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/_static/css/custom.css
+-rw-r--r--   0     1001      123     7297 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/conf.py
+-rw-r--r--   0     1001      123       51 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/index.rst
+-rw-r--r--   0     1001      123     6767 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/api.rst
+-rw-r--r--   0     1001      123     1694 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/config.rst
+-rw-r--r--   0     1001      123      274 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/dataframe/aggregation.rst
+-rw-r--r--   0     1001      123      221 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/dataframe/attributes.rst
+-rw-r--r--   0     1001      123      142 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/dataframe/computation.rst
+-rw-r--r--   0     1001      123      319 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/dataframe/descriptive.rst
+-rw-r--r--   0     1001      123      319 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/dataframe/export.rst
+-rw-r--r--   0     1001      123      464 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/dataframe/groupby.rst
+-rw-r--r--   0     1001      123      379 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/dataframe/index.rst
+-rw-r--r--   0     1001      123      189 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/dataframe/miscellaneous.rst
+-rw-r--r--   0     1001      123     1538 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/dataframe/modify_select.rst
+-rw-r--r--   0     1001      123      673 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/datatypes.rst
+-rw-r--r--   0     1001      123      421 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/exceptions.rst
+-rw-r--r--   0     1001      123      391 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/aggregation.rst
+-rw-r--r--   0     1001      123      267 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/array.rst
+-rw-r--r--   0     1001      123      309 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/binary.rst
+-rw-r--r--   0     1001      123      338 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/boolean.rst
+-rw-r--r--   0     1001      123      237 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/categories.rst
+-rw-r--r--   0     1001      123      221 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/columns.rst
+-rw-r--r--   0     1001      123     1061 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/computation.rst
+-rw-r--r--   0     1001      123     1130 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/functions.rst
+-rw-r--r--   0     1001      123      470 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/index.rst
+-rw-r--r--   0     1001      123      722 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/list.rst
+-rw-r--r--   0     1001      123      432 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/meta.rst
+-rw-r--r--   0     1001      123      159 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/miscellaneous.rst
+-rw-r--r--   0     1001      123      977 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/modify_select.rst
+-rw-r--r--   0     1001      123      639 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/operators.rst
+-rw-r--r--   0     1001      123      951 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/string.rst
+-rw-r--r--   0     1001      123      254 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/struct.rst
+-rw-r--r--   0     1001      123     1036 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/temporal.rst
+-rw-r--r--   0     1001      123       98 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/expressions/window.rst
+-rw-r--r--   0     1001      123      683 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/functions.rst
+-rw-r--r--   0     1001      123      405 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/index.rst
+-rw-r--r--   0     1001      123     1294 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/io.rst
+-rw-r--r--   0     1001      123      277 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/lazyframe/aggregation.rst
+-rw-r--r--   0     1001      123      179 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/lazyframe/attributes.rst
+-rw-r--r--   0     1001      123      146 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/lazyframe/descriptive.rst
+-rw-r--r--   0     1001      123      497 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/lazyframe/groupby.rst
+-rw-r--r--   0     1001      123      354 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/lazyframe/index.rst
+-rw-r--r--   0     1001      123      455 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/lazyframe/miscellaneous.rst
+-rw-r--r--   0     1001      123     1013 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/lazyframe/modify_select.rst
+-rw-r--r--   0     1001      123     3316 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/selectors.rst
+-rw-r--r--   0     1001      123      358 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/series/aggregation.rst
+-rw-r--r--   0     1001      123      277 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/series/array.rst
+-rw-r--r--   0     1001      123      257 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/series/attributes.rst
+-rw-r--r--   0     1001      123      321 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/series/binary.rst
+-rw-r--r--   0     1001      123      117 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/series/boolean.rst
+-rw-r--r--   0     1001      123      241 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/series/categories.rst
+-rw-r--r--   0     1001      123     1103 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/series/computation.rst
+-rw-r--r--   0     1001      123      744 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/series/descriptive.rst
+-rw-r--r--   0     1001      123      240 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/series/export.rst
+-rw-r--r--   0     1001      123      437 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/series/index.rst
+-rw-r--r--   0     1001      123      776 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/series/list.rst
+-rw-r--r--   0     1001      123      236 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/series/miscellaneous.rst
+-rw-r--r--   0     1001      123     1077 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/series/modify_select.rst
+-rw-r--r--   0     1001      123     1021 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/series/string.rst
+-rw-r--r--   0     1001      123      421 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/series/struct.rst
+-rw-r--r--   0     1001      123     1192 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/series/temporal.rst
+-rw-r--r--   0     1001      123      503 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/sql.rst
+-rw-r--r--   0     1001      123     8067 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/testing.rst
+-rw-r--r--   0     1001      123      168 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/docs/source/reference/utils.rst
+-rw-r--r--   0     1001      123     6161 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/__init__.py
+-rw-r--r--   0     1001      123      280 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/_reexport.py
+-rw-r--r--   0     1001      123    13229 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/api.py
+-rw-r--r--   0     1001      123    28746 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/config.py
+-rw-r--r--   0     1001      123    28105 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/convert.py
+-rw-r--r--   0     1001      123       77 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/dataframe/__init__.py
+-rw-r--r--   0     1001      123     5227 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/dataframe/_html.py
+-rw-r--r--   0     1001      123   315508 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/dataframe/frame.py
+-rw-r--r--   0     1001      123    40637 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/dataframe/groupby.py
+-rw-r--r--   0     1001      123     2692 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/datatypes/__init__.py
+-rw-r--r--   0     1001      123    16199 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/datatypes/classes.py
+-rw-r--r--   0     1001      123     1603 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/datatypes/constants.py
+-rw-r--r--   0     1001      123     4701 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/datatypes/constructor.py
+-rw-r--r--   0     1001      123    15739 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/datatypes/convert.py
+-rw-r--r--   0     1001      123     7338 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/dependencies.py
+-rw-r--r--   0     1001      123     3573 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/exceptions.py
+-rw-r--r--   0     1001      123       61 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/expr/__init__.py
+-rw-r--r--   0     1001      123     3020 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/expr/array.py
+-rw-r--r--   0     1001      123     2704 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/expr/binary.py
+-rw-r--r--   0     1001      123     1698 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/expr/categorical.py
+-rw-r--r--   0     1001      123    77598 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/expr/datetime.py
+-rw-r--r--   0     1001      123   261537 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/expr/expr.py
+-rw-r--r--   0     1001      123    23905 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/expr/list.py
+-rw-r--r--   0     1001      123     4050 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/expr/meta.py
+-rw-r--r--   0     1001      123    58339 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/expr/string.py
+-rw-r--r--   0     1001      123     5426 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/expr/struct.py
+-rw-r--r--   0     1001      123     2068 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/functions/__init__.py
+-rw-r--r--   0     1001      123    16541 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/functions/as_datatype.py
+-rw-r--r--   0     1001      123    18358 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/functions/eager.py
+-rw-r--r--   0     1001      123    72401 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/functions/lazy.py
+-rw-r--r--   0     1001      123    16227 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/functions/range.py
+-rw-r--r--   0     1001      123     6027 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/functions/repeat.py
+-rw-r--r--   0     1001      123     6139 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/functions/whenthen.py
+-rw-r--r--   0     1001      123      952 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/__init__.py
+-rw-r--r--   0     1001      123     6264 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/_utils.py
+-rw-r--r--   0     1001      123      861 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/avro.py
+-rw-r--r--   0     1001      123      144 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/csv/__init__.py
+-rw-r--r--   0     1001      123     1072 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/csv/_utils.py
+-rw-r--r--   0     1001      123     4681 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/csv/batched_reader.py
+-rw-r--r--   0     1001      123    35482 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/csv/functions.py
+-rw-r--r--   0     1001      123     5627 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/database.py
+-rw-r--r--   0     1001      123    11047 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/delta.py
+-rw-r--r--   0     1001      123       75 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/excel/__init__.py
+-rw-r--r--   0     1001      123    18449 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/excel/_write_utils.py
+-rw-r--r--   0     1001      123     6466 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/excel/functions.py
+-rw-r--r--   0     1001      123      142 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/ipc/__init__.py
+-rw-r--r--   0     1001      123     1227 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/ipc/anonymous_scan.py
+-rw-r--r--   0     1001      123     5804 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/ipc/functions.py
+-rw-r--r--   0     1001      123      502 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/json.py
+-rw-r--r--   0     1001      123     2207 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/ndjson.py
+-rw-r--r--   0     1001      123      170 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/parquet/__init__.py
+-rw-r--r--   0     1001      123     1259 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/parquet/anonymous_scan.py
+-rw-r--r--   0     1001      123     7177 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/parquet/functions.py
+-rw-r--r--   0     1001      123      136 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/pyarrow_dataset/__init__.py
+-rw-r--r--   0     1001      123     2291 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/pyarrow_dataset/anonymous_scan.py
+-rw-r--r--   0     1001      123     3601 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/io/pyarrow_dataset/functions.py
+-rw-r--r--   0     1001      123       77 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/lazyframe/__init__.py
+-rw-r--r--   0     1001      123   168214 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/lazyframe/frame.py
+-rw-r--r--   0     1001      123    24078 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/lazyframe/groupby.py
+-rw-r--r--   0     1001      123        0 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/py.typed
+-rw-r--r--   0     1001      123    32340 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/selectors.py
+-rw-r--r--   0     1001      123       69 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/series/__init__.py
+-rw-r--r--   0     1001      123     1572 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/series/_numpy.py
+-rw-r--r--   0     1001      123     2515 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/series/array.py
+-rw-r--r--   0     1001      123     1913 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/series/binary.py
+-rw-r--r--   0     1001      123     1692 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/series/categorical.py
+-rw-r--r--   0     1001      123    51711 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/series/datetime.py
+-rw-r--r--   0     1001      123    13196 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/series/list.py
+-rw-r--r--   0     1001      123   170010 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/series/series.py
+-rw-r--r--   0     1001      123    37766 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/series/string.py
+-rw-r--r--   0     1001      123     2542 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/series/struct.py
+-rw-r--r--   0     1001      123     5361 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/series/utils.py
+-rw-r--r--   0     1001      123     7559 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/slice.py
+-rw-r--r--   0     1001      123       75 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/sql/__init__.py
+-rw-r--r--   0     1001      123    17409 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/sql/context.py
+-rw-r--r--   0     1001      123     4764 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/string_cache.py
+-rw-r--r--   0     1001      123      362 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/testing/__init__.py
+-rw-r--r--   0     1001      123     1060 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/testing/_private.py
+-rw-r--r--   0     1001      123    16425 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/testing/asserts.py
+-rw-r--r--   0     1001      123      898 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/testing/parametric/__init__.py
+-rw-r--r--   0     1001      123    26833 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/testing/parametric/primitives.py
+-rw-r--r--   0     1001      123     3409 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/testing/parametric/profiles.py
+-rw-r--r--   0     1001      123    12132 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/testing/parametric/strategies.py
+-rw-r--r--   0     1001      123     6214 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/type_aliases.py
+-rw-r--r--   0     1001      123     1169 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/utils/__init__.py
+-rw-r--r--   0     1001      123    54269 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/utils/_construction.py
+-rw-r--r--   0     1001      123     3902 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/utils/_parse_expr_input.py
+-rw-r--r--   0     1001      123      711 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/utils/_scan.py
+-rw-r--r--   0     1001      123      579 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/utils/_wrap.py
+-rw-r--r--   0     1001      123      683 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/utils/build_info.py
+-rw-r--r--   0     1001      123     8609 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/utils/convert.py
+-rw-r--r--   0     1001      123     6132 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/utils/decorators.py
+-rw-r--r--   0     1001      123     1660 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/utils/meta.py
+-rw-r--r--   0     1001      123      514 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/utils/polars_version.py
+-rw-r--r--   0     1001      123     2673 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/utils/show_versions.py
+-rw-r--r--   0     1001      123    12905 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/polars/utils/various.py
+-rw-r--r--   0     1001      123     5375 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/pyproject.toml
+-rw-r--r--   0     1001      123      697 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/requirements-dev.txt
+-rw-r--r--   0     1001      123       71 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/requirements-lint.txt
+-rw-r--r--   0     1001      123     1640 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/scripts/check_stacklevels.py
+-rw-r--r--   0     1001      123    10980 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/apply/dataframe.rs
+-rw-r--r--   0     1001      123     7448 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/apply/lazy.rs
+-rw-r--r--   0     1001      123     8402 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/apply/mod.rs
+-rw-r--r--   0     1001      123    90009 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/apply/series.rs
+-rw-r--r--   0     1001      123       32 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/arrow_interop/mod.rs
+-rw-r--r--   0     1001      123     1306 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/arrow_interop/to_py.rs
+-rw-r--r--   0     1001      123     3902 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/arrow_interop/to_rust.rs
+-rw-r--r--   0     1001      123     5250 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/batched_csv.rs
+-rw-r--r--   0     1001      123    48675 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/conversion.rs
+-rw-r--r--   0     1001      123    45928 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/dataframe.rs
+-rw-r--r--   0     1001      123     3950 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/datatypes.rs
+-rw-r--r--   0     1001      123     3288 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/error.rs
+-rw-r--r--   0     1001      123      570 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/expr/array.rs
+-rw-r--r--   0     1001      123     2080 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/expr/binary.rs
+-rw-r--r--   0     1001      123      274 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/expr/categorical.rs
+-rw-r--r--   0     1001      123     5935 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/expr/datetime.rs
+-rw-r--r--   0     1001      123    34247 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/expr/general.rs
+-rw-r--r--   0     1001      123     3937 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/expr/list.rs
+-rw-r--r--   0     1001      123     2907 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/expr/meta.rs
+-rw-r--r--   0     1001      123      870 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/expr/mod.rs
+-rw-r--r--   0     1001      123     8677 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/expr/string.rs
+-rw-r--r--   0     1001      123      467 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/expr/struct.rs
+-rw-r--r--   0     1001      123     9482 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/file.rs
+-rw-r--r--   0     1001      123     3307 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/functions/eager.rs
+-rw-r--r--   0     1001      123     1657 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/functions/io.rs
+-rw-r--r--   0     1001      123    11835 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/functions/lazy.rs
+-rw-r--r--   0     1001      123     1312 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/functions/meta.rs
+-rw-r--r--   0     1001      123      217 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/functions/misc.rs
+-rw-r--r--   0     1001      123       87 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/functions/mod.rs
+-rw-r--r--   0     1001      123     1474 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/functions/whenthen.rs
+-rw-r--r--   0     1001      123    30767 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/lazyframe.rs
+-rw-r--r--   0     1001      123     2670 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/lazygroupby.rs
+-rw-r--r--   0     1001      123     8268 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/lib.rs
+-rw-r--r--   0     1001      123     1029 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/object.rs
+-rw-r--r--   0     1001      123      122 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/prelude.rs
+-rw-r--r--   0     1001      123      435 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/py_modules.rs
+-rw-r--r--   0     1001      123     1964 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/series/aggregation.rs
+-rw-r--r--   0     1001      123     5406 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/series/arithmetic.rs
+-rw-r--r--   0     1001      123     5138 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/series/comparison.rs
+-rw-r--r--   0     1001      123     9077 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/series/construction.rs
+-rw-r--r--   0     1001      123     8971 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/series/export.rs
+-rw-r--r--   0     1001      123    26521 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/series/mod.rs
+-rw-r--r--   0     1001      123     4569 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/series/numpy_ufunc.rs
+-rw-r--r--   0     1001      123     4046 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/series/set_at_idx.rs
+-rw-r--r--   0     1001      123     1036 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/sql.rs
+-rw-r--r--   0     1001      123     2335 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/src/utils.rs
+-rw-r--r--   0     1001      123     6165 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/README.md
+-rw-r--r--   0     1001      123     2189 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/benchmark/groupby-datagen.R
+-rw-r--r--   0     1001      123     7963 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/benchmark/run_h2oai_benchmark.py
+-rw-r--r--   0     1001      123     6530 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/benchmark/test_release.py
+-rw-r--r--   0     1001      123     4589 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/docs/run_doctest.py
+-rw-r--r--   0     1001      123      179 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/parametric/conftest.py
+-rw-r--r--   0     1001      123     3856 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/parametric/test_dataframe.py
+-rw-r--r--   0     1001      123     1692 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/parametric/test_lazyframe.py
+-rw-r--r--   0     1001      123     6897 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/parametric/test_series.py
+-rw-r--r--   0     1001      123     8299 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/parametric/test_testing.py
+-rw-r--r--   0     1001      123        0 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/__init__.py
+-rw-r--r--   0     1001      123     3382 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/conftest.py
+-rw-r--r--   0     1001      123       86 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/datatypes/__init__.py
+-rw-r--r--   0     1001      123      973 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/datatypes/test_array.py
+-rw-r--r--   0     1001      123      847 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/datatypes/test_binary.py
+-rw-r--r--   0     1001      123     1420 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/datatypes/test_bool.py
+-rw-r--r--   0     1001      123    13603 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/datatypes/test_categorical.py
+-rw-r--r--   0     1001      123     5222 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/datatypes/test_decimal.py
+-rw-r--r--   0     1001      123      549 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/datatypes/test_duration.py
+-rw-r--r--   0     1001      123      423 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/datatypes/test_integer.py
+-rw-r--r--   0     1001      123    13216 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/datatypes/test_list.py
+-rw-r--r--   0     1001      123      284 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/datatypes/test_null.py
+-rw-r--r--   0     1001      123     2801 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/datatypes/test_object.py
+-rw-r--r--   0     1001      123    27749 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/datatypes/test_struct.py
+-rw-r--r--   0     1001      123    87542 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/datatypes/test_temporal.py
+-rw-r--r--   0     1001      123      418 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/datatypes/test_time.py
+-rw-r--r--   0     1001      123        0 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/functions/__init__.py
+-rw-r--r--   0     1001      123    13970 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/functions/test_as_datatype.py
+-rw-r--r--   0     1001      123      480 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/functions/test_concat.py
+-rw-r--r--   0     1001      123    15610 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/functions/test_functions.py
+-rw-r--r--   0     1001      123    18470 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/functions/test_range.py
+-rw-r--r--   0     1001      123     3724 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/functions/test_repeat.py
+-rw-r--r--   0     1001      123      218 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/conftest.py
+-rw-r--r--   0     1001      123       16 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/delta-table/.part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet.crc
+-rw-r--r--   0     1001      123       16 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/delta-table/.part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet.crc
+-rw-r--r--   0     1001      123       16 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/delta-table/_delta_log/.00000000000000000000.json.crc
+-rw-r--r--   0     1001      123       16 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/delta-table/_delta_log/.00000000000000000001.json.crc
+-rw-r--r--   0     1001      123      905 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/delta-table/_delta_log/00000000000000000000.json
+-rw-r--r--   0     1001      123      936 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/delta-table/_delta_log/00000000000000000001.json
+-rw-r--r--   0     1001      123      972 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/delta-table/part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet
+-rw-r--r--   0     1001      123      690 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/delta-table/part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet
+-rw-r--r--   0     1001      123        0 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/empty.csv
+-rw-r--r--   0     1001      123     5959 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/example.xlsx
+-rw-r--r--   0     1001      123      457 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/foods1.csv
+-rw-r--r--   0     1001      123     2351 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/foods1.ipc
+-rw-r--r--   0     1001      123     1713 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/foods1.ndjson
+-rw-r--r--   0     1001      123     1427 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/foods1.parquet
+-rw-r--r--   0     1001      123      455 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/foods2.csv
+-rw-r--r--   0     1001      123     2351 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/foods2.ipc
+-rw-r--r--   0     1001      123     1711 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/foods2.ndjson
+-rw-r--r--   0     1001      123     1916 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/foods2.parquet
+-rw-r--r--   0     1001      123      455 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/foods3.csv
+-rw-r--r--   0     1001      123      457 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/foods4.csv
+-rw-r--r--   0     1001      123      452 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/foods5.csv
+-rw-r--r--   0     1001      123       49 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/gzipped.csv
+-rw-r--r--   0     1001      123       57 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/small.csv
+-rw-r--r--   0     1001      123      756 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/files/small.parquet
+-rw-r--r--   0     1001      123     1884 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/test_avro.py
+-rw-r--r--   0     1001      123    39230 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/test_csv.py
+-rw-r--r--   0     1001      123     6336 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/test_database.py
+-rw-r--r--   0     1001      123     6172 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/test_delta.py
+-rw-r--r--   0     1001      123    11169 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/test_excel.py
+-rw-r--r--   0     1001      123     5483 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/test_ipc.py
+-rw-r--r--   0     1001      123     3986 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/test_json.py
+-rw-r--r--   0     1001      123     7379 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/test_lazy_csv.py
+-rw-r--r--   0     1001      123     2060 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/test_lazy_ipc.py
+-rw-r--r--   0     1001      123     2867 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/test_lazy_json.py
+-rw-r--r--   0     1001      123    11145 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/test_lazy_parquet.py
+-rw-r--r--   0     1001      123     2012 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/test_other.py
+-rw-r--r--   0     1001      123    13739 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/test_parquet.py
+-rw-r--r--   0     1001      123      612 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/test_pickle.py
+-rw-r--r--   0     1001      123     3686 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/io/test_pyarrow_dataset.py
+-rw-r--r--   0     1001      123      509 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/namespaces/__init__.py
+-rw-r--r--   0     1001      123      589 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/namespaces/test_array.py
+-rw-r--r--   0     1001      123     3218 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/namespaces/test_binary.py
+-rw-r--r--   0     1001      123     2489 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/namespaces/test_categorical.py
+-rw-r--r--   0     1001      123    19585 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/namespaces/test_datetime.py
+-rw-r--r--   0     1001      123    14067 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/namespaces/test_list.py
+-rw-r--r--   0     1001      123     1829 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/namespaces/test_meta.py
+-rw-r--r--   0     1001      123    23544 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/namespaces/test_string.py
+-rw-r--r--   0     1001      123    17964 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/namespaces/test_strptime.py
+-rw-r--r--   0     1001      123      982 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/namespaces/test_struct.py
+-rw-r--r--   0     1001      123       85 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/__init__.py
+-rw-r--r--   0     1001      123     7755 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_aggregations.py
+-rw-r--r--   0     1001      123    10643 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_apply.py
+-rw-r--r--   0     1001      123     6932 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_arithmetic.py
+-rw-r--r--   0     1001      123     4631 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_comparison.py
+-rw-r--r--   0     1001      123     3275 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_drop.py
+-rw-r--r--   0     1001      123     8813 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_explode.py
+-rw-r--r--   0     1001      123     3664 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_filter.py
+-rw-r--r--   0     1001      123     1801 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_folds.py
+-rw-r--r--   0     1001      123    24998 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_groupby.py
+-rw-r--r--   0     1001      123     7649 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_groupby_rolling.py
+-rw-r--r--   0     1001      123     2983 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_is_in.py
+-rw-r--r--   0     1001      123    18169 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_join.py
+-rw-r--r--   0     1001      123    14612 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_join_asof.py
+-rw-r--r--   0     1001      123      643 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_melt.py
+-rw-r--r--   0     1001      123    10253 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_pivot.py
+-rw-r--r--   0     1001      123    19818 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_rolling.py
+-rw-r--r--   0     1001      123     1917 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_select.py
+-rw-r--r--   0     1001      123    20578 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_sort.py
+-rw-r--r--   0     1001      123     4273 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_statistics.py
+-rw-r--r--   0     1001      123     4130 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_transpose.py
+-rw-r--r--   0     1001      123      771 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_unique.py
+-rw-r--r--   0     1001      123    11694 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_window.py
+-rw-r--r--   0     1001      123     5401 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/operations/test_with_columns.py
+-rw-r--r--   0     1001      123        0 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/streaming/__init__.py
+-rw-r--r--   0     1001      123      196 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/streaming/conftest.py
+-rw-r--r--   0     1001      123      839 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/streaming/test_ooc.py
+-rw-r--r--   0     1001      123    16053 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/streaming/test_streaming.py
+-rw-r--r--   0     1001      123     4775 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_api.py
+-rw-r--r--   0     1001      123     1077 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_arity.py
+-rw-r--r--   0     1001      123    19865 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_cfg.py
+-rw-r--r--   0     1001      123    41129 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_constructors.py
+-rw-r--r--   0     1001      123      454 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_context.py
+-rw-r--r--   0     1001      123     1628 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_cse.py
+-rw-r--r--   0     1001      123     5198 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_datatypes.py
+-rw-r--r--   0     1001      123   119415 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_df.py
+-rw-r--r--   0     1001      123     2151 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_empty.py
+-rw-r--r--   0     1001      123    18790 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_errors.py
+-rw-r--r--   0     1001      123     2741 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_expr_multi_cols.py
+-rw-r--r--   0     1001      123    34736 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_exprs.py
+-rw-r--r--   0     1001      123     3516 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_fmt.py
+-rw-r--r--   0     1001      123     3763 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_interchange.py
+-rw-r--r--   0     1001      123    38286 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_interop.py
+-rw-r--r--   0     1001      123    47730 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_lazy.py
+-rw-r--r--   0     1001      123     2463 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_polars_import.py
+-rw-r--r--   0     1001      123     4610 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_predicates.py
+-rw-r--r--   0     1001      123     7073 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_projections.py
+-rw-r--r--   0     1001      123    11551 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_queries.py
+-rw-r--r--   0     1001      123     4743 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_rows.py
+-rw-r--r--   0     1001      123    13394 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_schema.py
+-rw-r--r--   0     1001      123     7231 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_selectors.py
+-rw-r--r--   0     1001      123     2823 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_serde.py
+-rw-r--r--   0     1001      123    83729 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_series.py
+-rw-r--r--   0     1001      123      657 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_single.py
+-rw-r--r--   0     1001      123     6747 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_sql.py
+-rw-r--r--   0     1001      123    12957 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/test_testing.py
+-rw-r--r--   0     1001      123       41 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/utils/__init__.py
+-rw-r--r--   0     1001      123      306 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/utils/test_build_info.py
+-rw-r--r--   0     1001      123     2784 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/utils/test_parse_expr_input.py
+-rw-r--r--   0     1001      123      247 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/utils/test_show_versions.py
+-rw-r--r--   0     1001      123     5026 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/tests/unit/utils/test_utils.py
+-rw-r--r--   0     1001      123    63894 2023-06-07 16:53:55.000000 polars_lts_cpu-0.18.1/Cargo.lock
+-rw-r--r--   0        0        0    14545 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.1/PKG-INFO
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/Cargo.toml` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/Cargo.toml`

 * *Files 14% similar despite different names*

```diff
@@ -1,43 +1,44 @@
 [package]
 name = "polars-plan"
 version= "0.30.0"
 edition = "2021"
 license = "MIT"
 repository = "https://github.com/pola-rs/polars"
 description = "Lazy query engine for the Polars DataFrame library"
+resolver = "2"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
 ahash= "0.8"
 chrono = { version = "0.4", optional = true }
 chrono-tz = { version = "0.8", optional = true }
 futures = { version = "0.3.25", optional = true }
 once_cell= "1"
 polars-arrow = { version = "0.30.0", path = "../polars-arrow" }
-polars-core = { version = "0.30.0", path = "../polars-core", features = ["lazy", "private", "zip_with", "random"], default-features = false }
-polars-io = { version = "0.30.0", path = "../polars-io", features = ["lazy", "csv", "private"], default-features = false }
+polars-core = { version = "0.30.0", path = "../polars-core", features = ["lazy", "zip_with", "random"], default-features = false }
+polars-io = { version = "0.30.0", path = "../polars-io", features = ["lazy", "csv"], default-features = false }
 polars-ops = { version = "0.30.0", path = "../polars-ops", default-features = false }
 polars-time = { version = "0.30.0", path = "../polars-time", optional = true }
 polars-utils = { version = "0.30.0", path = "../polars-utils" }
-pyo3 = { version = "0.18", optional = true }
+pyo3 = { version = "0.19", optional = true }
 rayon= "1.6"
 regex = { version = "1.6", optional = true }
 serde = { version = "1", features = ["derive", "rc"], optional = true }
 smartstring= { version = "1" }
 
 [features]
 # debugging utility
 debugging = []
 python = ["pyo3"]
 # make sure we don't compile unneeded things even though
 # this dependency gets activated
 compile = []
-default = ["compile", "private"]
+default = ["compile"]
 streaming = []
 parquet = ["polars-core/parquet", "polars-io/parquet"]
 async = []
 ipc = ["polars-io/ipc"]
 json = ["polars-io/json"]
 csv = ["polars-io/csv"]
 temporal = ["polars-core/temporal", "dtype-date", "dtype-datetime", "dtype-time"]
@@ -96,15 +97,14 @@
 dynamic_groupby = ["polars-core/dynamic_groupby"]
 ewma = ["polars-core/ewma"]
 dot_diagram = []
 unique_counts = ["polars-core/unique_counts"]
 log = ["polars-ops/log"]
 chunked_ids = ["polars-core/chunked_ids"]
 list_to_struct = ["polars-ops/list_to_struct"]
-# python = ["pyo3"]
 row_hash = ["polars-core/row_hash", "polars-ops/hash"]
 string_justify = ["polars-ops/string_justify"]
 string_from_radix = ["polars-ops/string_from_radix"]
 arg_where = []
 search_sorted = ["polars-ops/search_sorted"]
 merge_sorted = ["polars-ops/merge_sorted"]
 meta = []
@@ -112,31 +112,28 @@
 top_k = ["polars-ops/top_k"]
 semi_anti_join = ["polars-core/semi_anti_join", "polars-ops/semi_anti_join"]
 cse = []
 propagate_nans = ["polars-ops/propagate_nans"]
 coalesce = []
 fused = []
 
-# no guarantees whatsoever
-private = ["polars-time/private"]
-
 bigidx = ["polars-arrow/bigidx", "polars-core/bigidx", "polars-utils/bigidx"]
 
 panic_on_schema = []
 
 [package.metadata.docs.rs]
 all-features = true
 # defines the configuration attribute `docsrs`
 rustdoc-args = ["--cfg", "docsrs"]
 
 [dependencies.arrow]
 package = "arrow2"
-# git = "https://github.com/jorgecarleitao/arrow2"
+git = "https://github.com/jorgecarleitao/arrow2"
 # git = "https://github.com/ritchie46/arrow2"
-# rev = "1491c6e8f4fd100f53c358e4f3ef1536d9e75090"
+rev = "fb5e4d591c7149df590a330365fae55d2370962f"
 # path = "../arrow2"
 # branch = "polars_2023-05-25"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/LICENSE` & `polars_lts_cpu-0.18.1/local_dependencies/polars-algo/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dot.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dot.rs`

 * *Files 1% similar despite different names*

```diff
@@ -405,15 +405,15 @@
                 options,
                 ..
             } => {
                 let fmt = format!(
                     r#"JOIN {}
                     left {:?};
                     right: {:?}"#,
-                    options.how, left_on, right_on
+                    options.args.how, left_on, right_on
                 );
                 let current_node = DotNode {
                     branch,
                     id,
                     fmt: &fmt,
                 };
                 self.write_dot(acc_str, prev_node, current_node, id_map)?;
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/arithmetic.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/arithmetic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/arity.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/arity.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/binary.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/cat.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/cat.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/dt.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/dt.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/from.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/from.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/arg_where.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/arg_where.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/array.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/array.rs`

 * *Files 10% similar despite different names*

```diff
@@ -4,23 +4,25 @@
 
 #[derive(Clone, Copy, Eq, PartialEq, Hash, Debug)]
 #[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
 pub enum ArrayFunction {
     Min,
     Max,
     Sum,
+    Unique(bool),
 }
 
 impl Display for ArrayFunction {
     fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
         use ArrayFunction::*;
         let name = match self {
             Min => "min",
             Max => "max",
             Sum => "sum",
+            Unique(_) => "unique",
         };
 
         write!(f, "arr.{name}")
     }
 }
 
 pub(super) fn max(s: &Series) -> PolarsResult<Series> {
@@ -30,7 +32,17 @@
 pub(super) fn min(s: &Series) -> PolarsResult<Series> {
     Ok(s.array()?.array_min())
 }
 
 pub(super) fn sum(s: &Series) -> PolarsResult<Series> {
     s.array()?.array_sum()
 }
+
+pub(super) fn unique(s: &Series, stable: bool) -> PolarsResult<Series> {
+    let ca = s.array()?;
+    let out = if stable {
+        ca.array_unique_stable()
+    } else {
+        ca.array_unique()
+    };
+    out.map(|ca| ca.into_series())
+}
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/binary.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/boolean.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/boolean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/bounds.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/bounds.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/cat.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/cat.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/cum.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/cum.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/datetime.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/datetime.rs`

 * *Files 2% similar despite different names*

```diff
@@ -177,15 +177,15 @@
 pub(super) fn timestamp(s: &Series, tu: TimeUnit) -> PolarsResult<Series> {
     s.timestamp(tu).map(|ca| ca.into_series())
 }
 
 pub(super) fn truncate(s: &Series, every: &str, offset: &str) -> PolarsResult<Series> {
     let every = Duration::parse(every);
     let offset = Duration::parse(offset);
-    Ok(match s.dtype() {
+    let mut out = match s.dtype() {
         DataType::Datetime(_, tz) => match tz {
             #[cfg(feature = "timezones")]
             Some(tz) => s
                 .datetime()
                 .unwrap()
                 .truncate(every, offset, tz.parse::<Tz>().ok().as_ref())?
                 .into_series(),
@@ -197,15 +197,17 @@
         },
         DataType::Date => s
             .date()
             .unwrap()
             .truncate(every, offset, None)?
             .into_series(),
         dt => polars_bail!(opq = round, got = dt, expected = "date/datetime"),
-    })
+    };
+    out.set_sorted_flag(s.is_sorted_flag());
+    Ok(out)
 }
 
 #[cfg(feature = "date_offset")]
 pub(super) fn month_start(s: &Series) -> PolarsResult<Series> {
     Ok(match s.dtype() {
         DataType::Datetime(_, tz) => match tz {
             #[cfg(feature = "timezones")]
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/dispatch.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/dispatch.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/fill_null.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/fill_null.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/fused.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/fused.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/list.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/log.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/log.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 mod binary;
 mod boolean;
 mod bounds;
 #[cfg(feature = "dtype-categorical")]
 mod cat;
 #[cfg(feature = "round_series")]
 mod clip;
+mod concat;
+mod correlation;
 mod cum;
 #[cfg(feature = "temporal")]
 mod datetime;
 mod dispatch;
 mod fill_null;
 #[cfg(feature = "fused")]
 mod fused;
@@ -46,14 +48,15 @@
 mod trigonometry;
 mod unique;
 
 use std::fmt::{Display, Formatter};
 
 #[cfg(feature = "dtype-array")]
 pub(super) use array::ArrayFunction;
+pub(crate) use correlation::CorrelationMethod;
 #[cfg(feature = "fused")]
 pub(crate) use fused::FusedOperator;
 pub(super) use list::ListFunction;
 use polars_core::prelude::*;
 use schema::FieldsMapper;
 #[cfg(feature = "serde")]
 use serde::{Deserialize, Serialize};
@@ -174,14 +177,19 @@
     Floor,
     #[cfg(feature = "round_series")]
     Ceil,
     UpperBound,
     LowerBound,
     #[cfg(feature = "fused")]
     Fused(fused::FusedOperator),
+    ConcatExpr(bool),
+    Correlation {
+        method: correlation::CorrelationMethod,
+        ddof: u8,
+    },
 }
 
 impl Display for FunctionExpr {
     fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
         use FunctionExpr::*;
 
         let s = match self {
@@ -264,14 +272,16 @@
             Ceil => "ceil",
             UpperBound => "upper_bound",
             LowerBound => "lower_bound",
             #[cfg(feature = "fused")]
             Fused(fused) => return Display::fmt(fused, f),
             #[cfg(feature = "dtype-array")]
             ArrayExpr(af) => return Display::fmt(af, f),
+            ConcatExpr(_) => "concat_expr",
+            Correlation { method, .. } => return Display::fmt(method, f),
         };
         write!(f, "{s}")
     }
 }
 
 #[macro_export]
 macro_rules! wrap {
@@ -426,14 +436,15 @@
             #[cfg(feature = "dtype-array")]
             ArrayExpr(lf) => {
                 use ArrayFunction::*;
                 match lf {
                     Min => map!(array::min),
                     Max => map!(array::max),
                     Sum => map!(array::sum),
+                    Unique(stable) => map!(array::unique, stable),
                 }
             }
             #[cfg(feature = "dtype-struct")]
             StructExpr(sf) => {
                 use StructFunction::*;
                 match sf {
                     FieldByIndex(index) => map!(struct_::get_by_index, index),
@@ -479,14 +490,16 @@
             Floor => map!(round::floor),
             #[cfg(feature = "round_series")]
             Ceil => map!(round::ceil),
             UpperBound => map!(bounds::upper_bound),
             LowerBound => map!(bounds::lower_bound),
             #[cfg(feature = "fused")]
             Fused(op) => map_as_slice!(fused::fused, op),
+            ConcatExpr(rechunk) => map_as_slice!(concat::concat_expr, rechunk),
+            Correlation { method, ddof } => map_as_slice!(correlation::corr, ddof, method),
         }
     }
 }
 
 #[cfg(feature = "strings")]
 impl From<StringFunction> for SpecialEq<Arc<dyn SeriesUdf>> {
     fn from(func: StringFunction) -> Self {
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/pow.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/pow.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/schema.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/schema.rs`

 * *Files 1% similar despite different names*

```diff
@@ -102,14 +102,21 @@
             }
             #[cfg(feature = "dtype-array")]
             ArrayExpr(af) => {
                 use ArrayFunction::*;
                 match af {
                     Min | Max => mapper.with_same_dtype(),
                     Sum => mapper.nested_sum_type(),
+                    Unique(_) => mapper.try_map_dtype(|dt| {
+                        if let DataType::Array(inner, _) = dt {
+                            Ok(DataType::List(inner.clone()))
+                        } else {
+                            polars_bail!(ComputeError: "expected array dtype")
+                        }
+                    }),
                 }
             }
             #[cfg(feature = "dtype-struct")]
             StructExpr(s) => {
                 use polars_core::utils::slice_offsets;
                 use StructFunction::*;
                 match s {
@@ -189,14 +196,16 @@
             Entropy { .. } | Log { .. } | Log1p | Exp => mapper.map_to_float_dtype(),
             Unique(_) => mapper.with_same_dtype(),
             #[cfg(feature = "round_series")]
             Round { .. } | Floor | Ceil => mapper.with_same_dtype(),
             UpperBound | LowerBound => mapper.with_same_dtype(),
             #[cfg(feature = "fused")]
             Fused(_) => mapper.map_to_supertype(),
+            ConcatExpr(_) => mapper.map_to_supertype(),
+            Correlation { .. } => mapper.map_to_float_dtype(),
         }
     }
 }
 
 pub(super) struct FieldsMapper<'a> {
     fields: &'a [Field],
 }
@@ -223,15 +232,15 @@
         self.map_dtype(|dtype| match dtype {
             DataType::Float32 => DataType::Float32,
             _ => DataType::Float64,
         })
     }
 
     /// Map a single dtype with a potentially failing mapper function.
-    #[cfg(feature = "timezones")]
+    #[cfg(any(feature = "timezones", feature = "dtype-array"))]
     pub(super) fn try_map_dtype(
         &self,
         func: impl Fn(&DataType) -> PolarsResult<DataType>,
     ) -> PolarsResult<Field> {
         let dtype = func(self.fields[0].data_type())?;
         Ok(Field::new(self.fields[0].name(), dtype))
     }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/shift_and_fill.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/shift_and_fill.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/shrink_type.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/shrink_type.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/sign.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/sign.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/strings.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/strings.rs`

 * *Files 0% similar despite different names*

```diff
@@ -421,15 +421,15 @@
             *time_unit,
             options.cache,
             tz_aware,
             time_zone,
         )?
         .into_series()
     } else {
-        ca.as_datetime_not_exact(options.format.as_deref(), *time_unit, time_zone)?
+        ca.as_datetime_not_exact(options.format.as_deref(), *time_unit, tz_aware, time_zone)?
             .into_series()
     };
 
     if options.strict {
         polars_ensure!(
             out.null_count() == ca.null_count(),
             ComputeError:
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/struct_.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/struct_.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/temporal.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/temporal.rs`

 * *Files 8% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 #[cfg(feature = "date_offset")]
 use polars_time::prelude::*;
 
 use super::*;
 
 #[cfg(feature = "date_offset")]
 pub(super) fn date_offset(s: Series, offset: Duration) -> PolarsResult<Series> {
-    match s.dtype().clone() {
+    let out = match s.dtype().clone() {
         DataType::Date => {
             let s = s
                 .cast(&DataType::Datetime(TimeUnit::Milliseconds, None))
                 .unwrap();
             date_offset(s, offset).and_then(|s| s.cast(&DataType::Date))
         }
         DataType::Datetime(tu, tz) => {
@@ -38,15 +38,19 @@
                 }
             }?;
             out.cast(&DataType::Datetime(tu, tz))
         }
         dt => polars_bail!(
             ComputeError: "cannot use 'date_offset' on Series of datatype {}", dt,
         ),
-    }
+    };
+    out.map(|mut out| {
+        out.set_sorted_flag(s.is_sorted_flag());
+        out
+    })
 }
 
 pub(super) fn combine(s: &[Series], tu: TimeUnit) -> PolarsResult<Series> {
     let date = &s[0];
     let time = &s[1];
 
     let tz = match date.dtype() {
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/function_expr/trigonometry.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/function_expr/trigonometry.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/functions.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/mod.rs`

 * *Files 21% similar despite different names*

```diff
@@ -1,1453 +1,1498 @@
-//! # Functions
-//!
-//! Functions on expressions that might be useful.
-//!
-use std::ops::{BitAnd, BitOr};
-
-#[cfg(feature = "temporal")]
-use polars_core::export::arrow::temporal_conversions::NANOSECONDS;
-#[cfg(feature = "temporal")]
-use polars_core::utils::arrow::temporal_conversions::SECONDS_IN_DAY;
-#[cfg(feature = "dtype-struct")]
-use polars_core::utils::get_supertype;
-
-#[cfg(feature = "arg_where")]
-use crate::dsl::function_expr::FunctionExpr;
-use crate::dsl::function_expr::ListFunction;
-#[cfg(all(feature = "concat_str", feature = "strings"))]
-use crate::dsl::function_expr::StringFunction;
-use crate::dsl::*;
+//! Lazy variant of a [DataFrame](polars_core::frame::DataFrame).
+#[cfg(feature = "csv")]
+mod csv;
+#[cfg(feature = "ipc")]
+mod ipc;
+#[cfg(feature = "json")]
+mod ndjson;
+#[cfg(feature = "parquet")]
+mod parquet;
+#[cfg(feature = "python")]
+mod python;
+
+mod anonymous_scan;
+mod file_list_reader;
+#[cfg(feature = "pivot")]
+pub mod pivot;
+
+use std::borrow::Cow;
+#[cfg(any(feature = "parquet", feature = "ipc"))]
+use std::path::PathBuf;
+use std::sync::Arc;
+
+pub use anonymous_scan::*;
+#[cfg(feature = "csv")]
+pub use csv::*;
+pub use file_list_reader::*;
+#[cfg(feature = "ipc")]
+pub use ipc::*;
+#[cfg(feature = "json")]
+pub use ndjson::*;
+#[cfg(feature = "parquet")]
+pub use parquet::*;
+use polars_arrow::prelude::QuantileInterpolOptions;
+use polars_core::frame::explode::MeltArgs;
+use polars_core::frame::hash_join::{JoinType, JoinValidation};
+use polars_core::prelude::*;
+use polars_io::RowCount;
+pub use polars_plan::frame::{AllowedOptimizations, OptState};
+use polars_plan::global::FETCH_ROWS;
+#[cfg(any(feature = "ipc", feature = "parquet", feature = "csv"))]
+use polars_plan::logical_plan::collect_fingerprints;
+use polars_plan::logical_plan::optimize;
+use polars_plan::utils::expr_to_leaf_column_names;
+use smartstring::alias::String as SmartString;
+
+use crate::physical_plan::executors::Executor;
+use crate::physical_plan::planner::create_physical_plan;
+use crate::physical_plan::state::ExecutionState;
+#[cfg(feature = "streaming")]
+use crate::physical_plan::streaming::insert_streaming_nodes;
 use crate::prelude::*;
 
-/// Compute the covariance between two columns.
-pub fn cov(a: Expr, b: Expr) -> Expr {
-    let name = "cov";
-    let function = move |a: Series, b: Series| {
-        let s = match a.dtype() {
-            DataType::Float32 => {
-                let ca_a = a.f32().unwrap();
-                let ca_b = b.f32().unwrap();
-                Series::new(name, &[polars_core::functions::cov_f(ca_a, ca_b)])
-            }
-            DataType::Float64 => {
-                let ca_a = a.f64().unwrap();
-                let ca_b = b.f64().unwrap();
-                Series::new(name, &[polars_core::functions::cov_f(ca_a, ca_b)])
-            }
-            DataType::Int32 => {
-                let ca_a = a.i32().unwrap();
-                let ca_b = b.i32().unwrap();
-                Series::new(name, &[polars_core::functions::cov_i(ca_a, ca_b)])
-            }
-            DataType::Int64 => {
-                let ca_a = a.i64().unwrap();
-                let ca_b = b.i64().unwrap();
-                Series::new(name, &[polars_core::functions::cov_i(ca_a, ca_b)])
-            }
-            DataType::UInt32 => {
-                let ca_a = a.u32().unwrap();
-                let ca_b = b.u32().unwrap();
-                Series::new(name, &[polars_core::functions::cov_i(ca_a, ca_b)])
-            }
-            DataType::UInt64 => {
-                let ca_a = a.u64().unwrap();
-                let ca_b = b.u64().unwrap();
-                Series::new(name, &[polars_core::functions::cov_i(ca_a, ca_b)])
-            }
-            _ => {
-                let a = a.cast(&DataType::Float64)?;
-                let b = b.cast(&DataType::Float64)?;
-                let ca_a = a.f64().unwrap();
-                let ca_b = b.f64().unwrap();
-                Series::new(name, &[polars_core::functions::cov_f(ca_a, ca_b)])
-            }
-        };
-        Ok(Some(s))
-    };
-    apply_binary(
-        a,
-        b,
-        function,
-        GetOutput::map_dtype(|dt| {
-            if matches!(dt, DataType::Float32) {
-                DataType::Float32
-            } else {
-                DataType::Float64
-            }
-        }),
-    )
-    .with_function_options(|mut options| {
-        options.auto_explode = true;
-        options.fmt_str = "cov";
-        options
-    })
+pub trait IntoLazy {
+    fn lazy(self) -> LazyFrame;
 }
 
-/// Compute the pearson correlation between two columns.
-pub fn pearson_corr(a: Expr, b: Expr, ddof: u8) -> Expr {
-    let name = "pearson_corr";
-    let function = move |a: Series, b: Series| {
-        let s = match a.dtype() {
-            DataType::Float32 => {
-                let ca_a = a.f32().unwrap();
-                let ca_b = b.f32().unwrap();
-                Series::new(
-                    name,
-                    &[polars_core::functions::pearson_corr_f(ca_a, ca_b, ddof)],
-                )
-            }
-            DataType::Float64 => {
-                let ca_a = a.f64().unwrap();
-                let ca_b = b.f64().unwrap();
-                Series::new(
-                    name,
-                    &[polars_core::functions::pearson_corr_f(ca_a, ca_b, ddof)],
-                )
-            }
-            DataType::Int32 => {
-                let ca_a = a.i32().unwrap();
-                let ca_b = b.i32().unwrap();
-                Series::new(
-                    name,
-                    &[polars_core::functions::pearson_corr_i(ca_a, ca_b, ddof)],
-                )
-            }
-            DataType::Int64 => {
-                let ca_a = a.i64().unwrap();
-                let ca_b = b.i64().unwrap();
-                Series::new(
-                    name,
-                    &[polars_core::functions::pearson_corr_i(ca_a, ca_b, ddof)],
-                )
-            }
-            DataType::UInt32 => {
-                let ca_a = a.u32().unwrap();
-                let ca_b = b.u32().unwrap();
-                Series::new(
-                    name,
-                    &[polars_core::functions::pearson_corr_i(ca_a, ca_b, ddof)],
-                )
-            }
-            DataType::UInt64 => {
-                let ca_a = a.u64().unwrap();
-                let ca_b = b.u64().unwrap();
-                Series::new(
-                    name,
-                    &[polars_core::functions::pearson_corr_i(ca_a, ca_b, ddof)],
-                )
-            }
-            _ => {
-                let a = a.cast(&DataType::Float64)?;
-                let b = b.cast(&DataType::Float64)?;
-                let ca_a = a.f64().unwrap();
-                let ca_b = b.f64().unwrap();
-                Series::new(
-                    name,
-                    &[polars_core::functions::pearson_corr_f(ca_a, ca_b, ddof)],
-                )
-            }
-        };
-        Ok(Some(s))
-    };
-    apply_binary(
-        a,
-        b,
-        function,
-        GetOutput::map_dtype(|dt| {
-            if matches!(dt, DataType::Float32) {
-                DataType::Float32
-            } else {
-                DataType::Float64
-            }
-        }),
-    )
-    .with_function_options(|mut options| {
-        options.auto_explode = true;
-        options.fmt_str = "pearson_corr";
-        options
-    })
+impl IntoLazy for DataFrame {
+    /// Convert the `DataFrame` into a lazy `DataFrame`
+    fn lazy(self) -> LazyFrame {
+        let lp = LogicalPlanBuilder::from_existing_df(self).build();
+        LazyFrame {
+            logical_plan: lp,
+            opt_state: Default::default(),
+        }
+    }
 }
 
-/// Compute the spearman rank correlation between two columns.
-/// Missing data will be excluded from the computation.
-/// # Arguments
-/// * ddof
-///     Delta degrees of freedom
-/// * propagate_nans
-///     If `true` any `NaN` encountered will lead to `NaN` in the output.
-///     If to `false` then `NaN` are regarded as larger than any finite number
-///     and thus lead to the highest rank.
-#[cfg(all(feature = "rank", feature = "propagate_nans"))]
-pub fn spearman_rank_corr(a: Expr, b: Expr, ddof: u8, propagate_nans: bool) -> Expr {
-    use polars_core::utils::coalesce_nulls_series;
-    use polars_ops::prelude::nan_propagating_aggregate::nan_max_s;
-
-    let function = move |a: Series, b: Series| {
-        let (a, b) = coalesce_nulls_series(&a, &b);
-
-        let name = "spearman_rank_correlation";
-        if propagate_nans && a.dtype().is_float() {
-            for s in [&a, &b] {
-                if nan_max_s(s, "")
-                    .get(0)
-                    .unwrap()
-                    .extract::<f64>()
-                    .unwrap()
-                    .is_nan()
-                {
-                    return Ok(Some(Series::new(name, &[f64::NAN])));
-                }
-            }
-        }
+/// Lazy abstraction over an eager `DataFrame`.
+/// It really is an abstraction over a logical plan. The methods of this struct will incrementally
+/// modify a logical plan until output is requested (via [collect](crate::frame::LazyFrame::collect))
+#[derive(Clone, Default)]
+#[must_use]
+pub struct LazyFrame {
+    pub logical_plan: LogicalPlan,
+    pub(crate) opt_state: OptState,
+}
 
-        // drop nulls so that they are excluded
-        let a = a.drop_nulls();
-        let b = b.drop_nulls();
-
-        let a_idx = a.rank(
-            RankOptions {
-                method: RankMethod::Min,
-                ..Default::default()
-            },
-            None,
-        );
-        let b_idx = b.rank(
-            RankOptions {
-                method: RankMethod::Min,
+impl From<LogicalPlan> for LazyFrame {
+    fn from(plan: LogicalPlan) -> Self {
+        Self {
+            logical_plan: plan,
+            opt_state: OptState {
+                file_caching: true,
                 ..Default::default()
             },
-            None,
-        );
-        let a_idx = a_idx.idx().unwrap();
-        let b_idx = b_idx.idx().unwrap();
-
-        Ok(Some(Series::new(
-            name,
-            &[polars_core::functions::pearson_corr_i(a_idx, b_idx, ddof)],
-        )))
-    };
-
-    apply_binary(a, b, function, GetOutput::from_type(DataType::Float64)).with_function_options(
-        |mut options| {
-            options.auto_explode = true;
-            options.fmt_str = "spearman_rank_correlation";
-            options
-        },
-    )
+        }
+    }
 }
 
-/// Find the indexes that would sort these series in order of appearance.
-/// That means that the first `Series` will be used to determine the ordering
-/// until duplicates are found. Once duplicates are found, the next `Series` will
-/// be used and so on.
-#[cfg(feature = "arange")]
-pub fn arg_sort_by<E: AsRef<[Expr]>>(by: E, descending: &[bool]) -> Expr {
-    let e = &by.as_ref()[0];
-    let name = expr_output_name(e).unwrap();
-    arange(lit(0 as IdxSize), count().cast(IDX_DTYPE), 1)
-        .sort_by(by, descending)
-        .alias(name.as_ref())
-}
+impl LazyFrame {
+    /// Get a hold on the schema of the current LazyFrame computation.
+    pub fn schema(&self) -> PolarsResult<SchemaRef> {
+        self.logical_plan.schema().map(|schema| schema.into_owned())
+    }
 
-#[cfg(all(feature = "concat_str", feature = "strings"))]
-/// Horizontally concat string columns in linear time
-pub fn concat_str<E: AsRef<[Expr]>>(s: E, separator: &str) -> Expr {
-    let input = s.as_ref().to_vec();
-    let separator = separator.to_string();
-
-    Expr::Function {
-        input,
-        function: StringFunction::ConcatHorizontal(separator).into(),
-        options: FunctionOptions {
-            collect_groups: ApplyOptions::ApplyFlat,
-            input_wildcard_expansion: true,
-            auto_explode: true,
-            ..Default::default()
-        },
+    pub(crate) fn get_plan_builder(self) -> LogicalPlanBuilder {
+        LogicalPlanBuilder::from(self.logical_plan)
     }
-}
 
-#[cfg(all(feature = "concat_str", feature = "strings"))]
-/// Format the results of an array of expressions using a format string
-pub fn format_str<E: AsRef<[Expr]>>(format: &str, args: E) -> PolarsResult<Expr> {
-    let mut args: std::collections::VecDeque<Expr> = args.as_ref().to_vec().into();
-
-    // Parse the format string, and separate substrings between placeholders
-    let segments: Vec<&str> = format.split("{}").collect();
-
-    polars_ensure!(
-        segments.len() - 1 == args.len(),
-        ShapeMismatch: "number of placeholders should equal the number of arguments"
-    );
-
-    let mut exprs: Vec<Expr> = Vec::new();
-
-    for (i, s) in segments.iter().enumerate() {
-        if i > 0 {
-            if let Some(arg) = args.pop_front() {
-                exprs.push(arg);
-            }
-        }
+    fn get_opt_state(&self) -> OptState {
+        self.opt_state
+    }
 
-        if !s.is_empty() {
-            exprs.push(lit(s.to_string()))
+    fn from_logical_plan(logical_plan: LogicalPlan, opt_state: OptState) -> Self {
+        LazyFrame {
+            logical_plan,
+            opt_state,
         }
     }
 
-    Ok(concat_str(exprs, ""))
-}
+    /// Set allowed optimizations
+    pub fn with_optimizations(mut self, opt_state: OptState) -> Self {
+        self.opt_state = opt_state;
+        self
+    }
 
-/// Concat lists entries.
-pub fn concat_list<E: AsRef<[IE]>, IE: Into<Expr> + Clone>(s: E) -> PolarsResult<Expr> {
-    let s: Vec<_> = s.as_ref().iter().map(|e| e.clone().into()).collect();
-
-    polars_ensure!(!s.is_empty(), ComputeError: "`concat_list` needs one or more expressions");
-
-    Ok(Expr::Function {
-        input: s,
-        function: FunctionExpr::ListExpr(ListFunction::Concat),
-        options: FunctionOptions {
-            collect_groups: ApplyOptions::ApplyGroups,
-            input_wildcard_expansion: true,
-            fmt_str: "concat_list",
-            ..Default::default()
-        },
-    })
-}
+    /// Turn off all optimizations
+    pub fn without_optimizations(self) -> Self {
+        self.with_optimizations(OptState {
+            projection_pushdown: false,
+            predicate_pushdown: false,
+            type_coercion: true,
+            simplify_expr: false,
+            slice_pushdown: false,
+            // will be toggled by a scan operation such as csv scan or parquet scan
+            file_caching: false,
+            #[cfg(feature = "cse")]
+            common_subplan_elimination: false,
+            streaming: false,
+        })
+    }
 
-#[cfg(feature = "arange")]
-fn arange_impl<T>(start: T::Native, end: T::Native, step: i64) -> PolarsResult<Option<Series>>
-where
-    T: PolarsNumericType,
-    ChunkedArray<T>: IntoSeries,
-    std::ops::Range<T::Native>: Iterator<Item = T::Native>,
-    std::ops::RangeInclusive<T::Native>: DoubleEndedIterator<Item = T::Native>,
-{
-    let mut ca = match step {
-        1 => ChunkedArray::<T>::from_iter_values("arange", start..end),
-        2.. => ChunkedArray::<T>::from_iter_values("arange", (start..end).step_by(step as usize)),
-        _ => {
-            polars_ensure!(start > end, InvalidOperation: "range must be decreasing if 'step' is negative");
-            ChunkedArray::<T>::from_iter_values(
-                "arange",
-                (end..=start).rev().step_by(step.unsigned_abs() as usize),
-            )
-        }
-    };
-    let is_sorted = if end < start {
-        IsSorted::Descending
-    } else {
-        IsSorted::Ascending
-    };
-    ca.set_sorted_flag(is_sorted);
-    Ok(Some(ca.into_series()))
-}
+    /// Toggle projection pushdown optimization.
+    pub fn with_projection_pushdown(mut self, toggle: bool) -> Self {
+        self.opt_state.projection_pushdown = toggle;
+        self
+    }
 
-// TODO! rewrite this with the apply_private architecture
-/// Create list entries that are range arrays
-/// - if `start` and `end` are a column, every element will expand into an array in a list column.
-/// - if `start` and `end` are literals the output will be of `Int64`.
-#[cfg(feature = "arange")]
-pub fn arange(start: Expr, end: Expr, step: i64) -> Expr {
-    let output_name = "arange";
-
-    let has_col_without_agg = |e: &Expr| {
-        has_expr(e, |ae| matches!(ae, Expr::Column(_)))
-            &&
-            // check if there is no aggregation
-            !has_expr(e, |ae| {
-                matches!(
-                    ae,
-                    Expr::Agg(_)
-                        | Expr::Count
-                        | Expr::AnonymousFunction {
-                            options: FunctionOptions {
-                                collect_groups: ApplyOptions::ApplyGroups,
-                                ..
-                            },
-                            ..
-                        }
-                        | Expr::Function {
-                            options: FunctionOptions {
-                                collect_groups: ApplyOptions::ApplyGroups,
-                                ..
-                            },
-                            ..
-                        },
-                )
-            })
-    };
-    let has_lit = |e: &Expr| {
-        (matches!(e, Expr::Literal(_)) && !matches!(e, Expr::Literal(LiteralValue::Series(_))))
-    };
-
-    let any_column_no_agg = has_col_without_agg(&start) || has_col_without_agg(&end);
-    let literal_start = has_lit(&start);
-    let literal_end = has_lit(&end);
-
-    if (literal_start || literal_end) && !any_column_no_agg {
-        let f = move |sa: Series, sb: Series| {
-            polars_ensure!(step != 0, InvalidOperation: "step must not be zero");
-
-            match sa.dtype() {
-                dt if dt == &IDX_DTYPE => {
-                    let start = sa
-                        .idx()?
-                        .get(0)
-                        .ok_or_else(|| polars_err!(NoData: "no data in `start` evaluation"))?;
-                    let sb = sb.cast(&IDX_DTYPE)?;
-                    let end = sb
-                        .idx()?
-                        .get(0)
-                        .ok_or_else(|| polars_err!(NoData: "no data in `end` evaluation"))?;
-                    #[cfg(feature = "bigidx")]
-                    {
-                        arange_impl::<UInt64Type>(start, end, step)
-                    }
-                    #[cfg(not(feature = "bigidx"))]
-                    {
-                        arange_impl::<UInt32Type>(start, end, step)
-                    }
-                }
-                _ => {
-                    let sa = sa.cast(&DataType::Int64)?;
-                    let sb = sb.cast(&DataType::Int64)?;
-                    let start = sa
-                        .i64()?
-                        .get(0)
-                        .ok_or_else(|| polars_err!(NoData: "no data in `start` evaluation"))?;
-                    let end = sb
-                        .i64()?
-                        .get(0)
-                        .ok_or_else(|| polars_err!(NoData: "no data in `end` evaluation"))?;
-                    arange_impl::<Int64Type>(start, end, step)
-                }
-            }
-        };
-        apply_binary(
-            start,
-            end,
-            f,
-            GetOutput::map_field(|input| {
-                let dtype = if input.data_type() == &IDX_DTYPE {
-                    IDX_DTYPE
-                } else {
-                    DataType::Int64
-                };
-                Field::new(output_name, dtype)
-            }),
-        )
-        .alias(output_name)
-    } else {
-        let f = move |sa: Series, sb: Series| {
-            polars_ensure!(step != 0, InvalidOperation: "step must not be zero");
-            let mut sa = sa.cast(&DataType::Int64)?;
-            let mut sb = sb.cast(&DataType::Int64)?;
-
-            if sa.len() != sb.len() {
-                if sa.len() == 1 {
-                    sa = sa.new_from_index(0, sb.len())
-                } else if sb.len() == 1 {
-                    sb = sb.new_from_index(0, sa.len())
-                } else {
-                    polars_bail!(
-                        ComputeError:
-                        "lengths of `start`: {} and `end`: {} arguments `\
-                        cannot be matched in the `arange` expression",
-                        sa.len(), sb.len()
-                    );
-                }
-            }
+    /// Toggle predicate pushdown optimization.
+    pub fn with_predicate_pushdown(mut self, toggle: bool) -> Self {
+        self.opt_state.predicate_pushdown = toggle;
+        self
+    }
 
-            let start = sa.i64()?;
-            let end = sb.i64()?;
-            let mut builder = ListPrimitiveChunkedBuilder::<Int64Type>::new(
-                output_name,
-                start.len(),
-                start.len() * 3,
-                DataType::Int64,
-            );
-
-            for (opt_start, opt_end) in start.into_iter().zip(end.into_iter()) {
-                match (opt_start, opt_end) {
-                    (Some(start_v), Some(end_v)) => match step {
-                        1 => {
-                            builder.append_iter_values(start_v..end_v);
-                        }
-                        2.. => {
-                            builder.append_iter_values((start_v..end_v).step_by(step as usize));
-                        }
-                        _ => {
-                            polars_ensure!(start_v > end_v, InvalidOperation: "range must be decreasing if 'step' is negative");
-                            builder.append_iter_values(
-                                (end_v..=start_v)
-                                    .rev()
-                                    .step_by(step.unsigned_abs() as usize),
-                            )
-                        }
-                    },
-                    _ => builder.append_null(),
-                }
-            }
+    /// Toggle type coercion optimization.
+    pub fn with_type_coercion(mut self, toggle: bool) -> Self {
+        self.opt_state.type_coercion = toggle;
+        self
+    }
 
-            Ok(Some(builder.finish().into_series()))
-        };
-        apply_binary(
-            start,
-            end,
-            f,
-            GetOutput::map_field(|_| {
-                Field::new(output_name, DataType::List(DataType::Int64.into()))
-            }),
-        )
-        .alias(output_name)
+    /// Toggle expression simplification optimization on or off
+    pub fn with_simplify_expr(mut self, toggle: bool) -> Self {
+        self.opt_state.simplify_expr = toggle;
+        self
     }
-}
 
-macro_rules! impl_unit_setter {
-    ($fn_name:ident($field:ident)) => {
-        #[doc = concat!("Set the ", stringify!($field))]
-        pub fn $fn_name(mut self, n: Expr) -> Self {
-            self.$field = n.into();
-            self
+    /// Toggle common subplan elimination optimization on or off
+    #[cfg(feature = "cse")]
+    pub fn with_common_subplan_elimination(mut self, toggle: bool) -> Self {
+        self.opt_state.common_subplan_elimination = toggle;
+        self
+    }
+
+    /// Toggle slice pushdown optimization
+    pub fn with_slice_pushdown(mut self, toggle: bool) -> Self {
+        self.opt_state.slice_pushdown = toggle;
+        self
+    }
+
+    /// Allow (partial) streaming engine
+    pub fn with_streaming(mut self, toggle: bool) -> Self {
+        self.opt_state.streaming = toggle;
+        self
+    }
+
+    /// Explain the naive logical plan.
+    pub fn describe_plan(&self) -> String {
+        self.logical_plan.describe()
+    }
+
+    /// Explain the optimized logical plan.
+    pub fn describe_optimized_plan(&self) -> PolarsResult<String> {
+        let mut expr_arena = Arena::with_capacity(64);
+        let mut lp_arena = Arena::with_capacity(64);
+        let lp_top = self.clone().optimize_with_scratch(
+            &mut lp_arena,
+            &mut expr_arena,
+            &mut vec![],
+            true,
+        )?;
+        let logical_plan = node_to_lp(lp_top, &expr_arena, &mut lp_arena);
+        Ok(logical_plan.describe())
+    }
+
+    /// Explain the logical plan.
+    pub fn explain(&self, optimized: bool) -> PolarsResult<String> {
+        if optimized {
+            self.describe_optimized_plan()
+        } else {
+            Ok(self.describe_plan())
         }
-    };
-}
+    }
 
-/// Arguments used by [`datetime`] in order to produce an `Expr` of `Datetime`
-///
-/// Construct a `DatetimeArgs` with `DatetimeArgs::new(y, m, d)`. This will set the other time units to `lit(0)`. You
-/// can then set the other fields with the `with_*` methods, or use `with_hms` to set `hour`, `minute`, and `second` all
-/// at once.
-///
-/// # Examples
-/// ```
-/// // construct a DatetimeArgs set to July 20, 1969 at 20:17
-/// let args = DatetimeArgs::new(lit(1969), lit(7), lit(20)).with_hms(lit(20), lit(17), lit(0));
-/// // or
-/// let args = DatetimeArgs::new(lit(1969), lit(7), lit(20)).with_hour(lit(20)).with_minute(lit(17));
-///
-/// // construct a DatetimeArgs using existing columns
-/// let args = DatetimeArgs::new(lit(2023), col("month"), col("day"));
-/// ```
-#[derive(Debug, Clone)]
-pub struct DatetimeArgs {
-    pub year: Expr,
-    pub month: Expr,
-    pub day: Expr,
-    pub hour: Expr,
-    pub minute: Expr,
-    pub second: Expr,
-    pub microsecond: Expr,
-}
+    /// Add a sort operation to the logical plan.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use polars_core::prelude::*;
+    /// use polars_lazy::prelude::*;
+    ///
+    /// /// Sort DataFrame by 'sepal.width' column
+    /// fn example(df: DataFrame) -> LazyFrame {
+    ///       df.lazy()
+    ///         .sort("sepal.width", Default::default())
+    /// }
+    /// ```
+    pub fn sort(self, by_column: &str, options: SortOptions) -> Self {
+        let descending = options.descending;
+        let nulls_last = options.nulls_last;
+
+        let opt_state = self.get_opt_state();
+        let lp = self
+            .get_plan_builder()
+            .sort(vec![col(by_column)], vec![descending], nulls_last)
+            .build();
+        Self::from_logical_plan(lp, opt_state)
+    }
 
-impl DatetimeArgs {
-    /// Construct a new `DatetimeArgs` set to `year`, `month`, `day`
+    /// Add a sort operation to the logical plan.
     ///
-    /// Other fields default to `lit(0)`. Use the `with_*` methods to set them.
-    pub fn new(year: Expr, month: Expr, day: Expr) -> Self {
-        Self {
-            year,
-            month,
-            day,
-            hour: lit(0),
-            minute: lit(0),
-            second: lit(0),
-            microsecond: lit(0),
+    /// # Example
+    ///
+    /// ```rust
+    /// use polars_core::prelude::*;
+    /// use polars_lazy::prelude::*;
+    ///
+    /// /// Sort DataFrame by 'sepal.width' column
+    /// fn example(df: DataFrame) -> LazyFrame {
+    ///       df.lazy()
+    ///         .sort_by_exprs(vec![col("sepal.width")], vec![false], false)
+    /// }
+    /// ```
+    pub fn sort_by_exprs<E: AsRef<[Expr]>, B: AsRef<[bool]>>(
+        self,
+        by_exprs: E,
+        descending: B,
+        nulls_last: bool,
+    ) -> Self {
+        let by_exprs = by_exprs.as_ref().to_vec();
+        let descending = descending.as_ref().to_vec();
+        if by_exprs.is_empty() {
+            self
+        } else {
+            let opt_state = self.get_opt_state();
+            let lp = self
+                .get_plan_builder()
+                .sort(by_exprs, descending, nulls_last)
+                .build();
+            Self::from_logical_plan(lp, opt_state)
         }
     }
 
-    /// Set `hour`, `minute`, and `second`
-    ///
-    /// Equivalent to
-    /// ```ignore
-    /// self.with_hour(hour)
-    ///     .with_minute(minute)
-    ///     .with_second(second)
-    /// ```
-    pub fn with_hms(self, hour: Expr, minute: Expr, second: Expr) -> Self {
-        Self {
-            hour,
-            minute,
-            second,
-            ..self
+    pub fn top_k<E: AsRef<[Expr]>, B: AsRef<[bool]>>(
+        self,
+        k: IdxSize,
+        by_exprs: E,
+        descending: B,
+        nulls_last: bool,
+    ) -> Self {
+        let mut descending = descending.as_ref().to_vec();
+        // top-k is reverse from sort
+        for v in &mut descending {
+            *v = !*v;
         }
+        // this will optimize to top-k
+        self.sort_by_exprs(by_exprs, descending, nulls_last)
+            .slice(0, k)
     }
 
-    impl_unit_setter!(with_year(year));
-    impl_unit_setter!(with_month(month));
-    impl_unit_setter!(with_day(day));
-    impl_unit_setter!(with_hour(hour));
-    impl_unit_setter!(with_minute(minute));
-    impl_unit_setter!(with_second(second));
-    impl_unit_setter!(with_microsecond(microsecond));
-}
+    pub fn bottom_k<E: AsRef<[Expr]>, B: AsRef<[bool]>>(
+        self,
+        k: IdxSize,
+        by_exprs: E,
+        descending: B,
+        nulls_last: bool,
+    ) -> Self {
+        let descending = descending.as_ref().to_vec();
+        // this will optimize to bottom-k
+        self.sort_by_exprs(by_exprs, descending, nulls_last)
+            .slice(0, k)
+    }
 
-/// Construct a column of `Datetime` from the provided [`DatetimeArgs`].
-#[cfg(feature = "temporal")]
-pub fn datetime(args: DatetimeArgs) -> Expr {
-    use polars_core::export::chrono::NaiveDate;
-    use polars_core::utils::CustomIterTools;
-
-    let year = args.year;
-    let month = args.month;
-    let day = args.day;
-    let hour = args.hour;
-    let minute = args.minute;
-    let second = args.second;
-    let microsecond = args.microsecond;
-
-    let function = SpecialEq::new(Arc::new(move |s: &mut [Series]| {
-        assert_eq!(s.len(), 7);
-        let max_len = s.iter().map(|s| s.len()).max().unwrap();
-        let mut year = s[0].cast(&DataType::Int32)?;
-        if year.len() < max_len {
-            year = year.new_from_index(0, max_len)
-        }
-        let year = year.i32()?;
-        let mut month = s[1].cast(&DataType::UInt32)?;
-        if month.len() < max_len {
-            month = month.new_from_index(0, max_len);
-        }
-        let month = month.u32()?;
-        let mut day = s[2].cast(&DataType::UInt32)?;
-        if day.len() < max_len {
-            day = day.new_from_index(0, max_len);
-        }
-        let day = day.u32()?;
-        let mut hour = s[3].cast(&DataType::UInt32)?;
-        if hour.len() < max_len {
-            hour = hour.new_from_index(0, max_len);
-        }
-        let hour = hour.u32()?;
-
-        let mut minute = s[4].cast(&DataType::UInt32)?;
-        if minute.len() < max_len {
-            minute = minute.new_from_index(0, max_len);
-        }
-        let minute = minute.u32()?;
-
-        let mut second = s[5].cast(&DataType::UInt32)?;
-        if second.len() < max_len {
-            second = second.new_from_index(0, max_len);
-        }
-        let second = second.u32()?;
-
-        let mut microsecond = s[6].cast(&DataType::UInt32)?;
-        if microsecond.len() < max_len {
-            microsecond = microsecond.new_from_index(0, max_len);
+    /// Reverse the DataFrame
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use polars_core::prelude::*;
+    /// use polars_lazy::prelude::*;
+    ///
+    /// fn example(df: DataFrame) -> LazyFrame {
+    ///       df.lazy()
+    ///         .reverse()
+    /// }
+    /// ```
+    pub fn reverse(self) -> Self {
+        self.select_local(vec![col("*").reverse()])
+    }
+
+    /// Check the if the `names` are available in the `schema`, if not
+    /// return a `LogicalPlan` that raises an `Error`.
+    fn check_names(&self, names: &[SmartString], schema: Option<&SchemaRef>) -> Option<Self> {
+        let schema = schema
+            .map(Cow::Borrowed)
+            .unwrap_or_else(|| Cow::Owned(self.schema().unwrap()));
+
+        let mut opt_not_found = None;
+        names.iter().for_each(|name| {
+            let invalid = schema.get(name).is_none();
+
+            if invalid && opt_not_found.is_none() {
+                opt_not_found = Some(name)
+            }
+        });
+
+        if let Some(name) = opt_not_found {
+            let lp = self
+                .clone()
+                .get_plan_builder()
+                .add_err(polars_err!(SchemaFieldNotFound: "{}", name))
+                .build();
+            Some(Self::from_logical_plan(lp, self.opt_state))
+        } else {
+            None
+        }
+    }
+
+    /// Rename columns in the DataFrame.
+    pub fn rename<I, J, T, S>(self, existing: I, new: J) -> Self
+    where
+        I: IntoIterator<Item = T>,
+        J: IntoIterator<Item = S>,
+        T: AsRef<str>,
+        S: AsRef<str>,
+    {
+        let iter = existing.into_iter();
+        let cap = iter.size_hint().0;
+        let mut existing_vec: Vec<SmartString> = Vec::with_capacity(cap);
+        let mut new_vec: Vec<SmartString> = Vec::with_capacity(cap);
+
+        for (existing, new) in iter.zip(new.into_iter()) {
+            let existing = existing.as_ref();
+            let new = new.as_ref();
+
+            if new != existing {
+                existing_vec.push(existing.into());
+                new_vec.push(new.into());
+            }
+        }
+
+        // a column gets swapped
+        let schema = &self.schema().unwrap();
+        let swapping = new_vec.iter().any(|name| schema.get(name).is_some());
+
+        if let Some(lp) = self.check_names(&existing_vec, Some(schema)) {
+            lp
+        } else {
+            self.map_private(FunctionNode::Rename {
+                existing: existing_vec.into(),
+                new: new_vec.into(),
+                swapping,
+            })
         }
-        let microsecond = microsecond.u32()?;
+    }
 
-        let ca: Int64Chunked = year
+    /// Removes columns from the DataFrame.
+    /// Note that its better to only select the columns you need
+    /// and let the projection pushdown optimize away the unneeded columns.
+    pub fn drop_columns<I, T>(self, columns: I) -> Self
+    where
+        I: IntoIterator<Item = T>,
+        T: AsRef<str>,
+    {
+        let columns: Vec<SmartString> = columns
             .into_iter()
-            .zip(month.into_iter())
-            .zip(day.into_iter())
-            .zip(hour.into_iter())
-            .zip(minute.into_iter())
-            .zip(second.into_iter())
-            .zip(microsecond.into_iter())
-            .map(|((((((y, m), d), h), mnt), s), us)| {
-                if let (Some(y), Some(m), Some(d), Some(h), Some(mnt), Some(s), Some(us)) =
-                    (y, m, d, h, mnt, s, us)
-                {
-                    NaiveDate::from_ymd_opt(y, m, d)
-                        .and_then(|nd| nd.and_hms_micro_opt(h, mnt, s, us))
-                        .map(|ndt| ndt.timestamp_micros())
-                } else {
-                    None
-                }
+            .map(|name| name.as_ref().into())
+            .collect();
+        self.drop_columns_impl(columns)
+    }
+
+    #[allow(clippy::ptr_arg)]
+    fn drop_columns_impl(self, columns: Vec<SmartString>) -> Self {
+        if let Some(lp) = self.check_names(&columns, None) {
+            lp
+        } else {
+            self.map_private(FunctionNode::Drop {
+                names: columns.into(),
             })
-            .collect_trusted();
+        }
+    }
 
-        Ok(Some(
-            ca.into_datetime(TimeUnit::Microseconds, None).into_series(),
-        ))
-    }) as Arc<dyn SeriesUdf>);
-
-    Expr::AnonymousFunction {
-        input: vec![year, month, day, hour, minute, second, microsecond],
-        function,
-        output_type: GetOutput::from_type(DataType::Datetime(TimeUnit::Microseconds, None)),
-        options: FunctionOptions {
-            collect_groups: ApplyOptions::ApplyFlat,
-            input_wildcard_expansion: true,
-            fmt_str: "datetime",
-            ..Default::default()
-        },
+    /// Shift the values by a given period and fill the parts that will be empty due to this operation
+    /// with `Nones`.
+    ///
+    /// See the method on [Series](polars_core::series::SeriesTrait::shift) for more info on the `shift` operation.
+    pub fn shift(self, periods: i64) -> Self {
+        self.select_local(vec![col("*").shift(periods)])
     }
-    .alias("datetime")
-}
 
-/// Arguments used by [`duration`] in order to produce an `Expr` of `Duration`
-///
-/// To construct a `DurationArgs`, use struct literal syntax with `..Default::default()` to leave unspecified fields at
-/// their default value of `lit(0)`, as demonstrated below.
-///
-/// ```
-/// let args = DurationArgs {
-///     days: lit(5),
-///     hours: col("num_hours"),
-///     minutes: col("num_minutes"),
-///     ..Default::default()  // other fields are lit(0)
-/// };
-/// ```
-/// If you prefer builder syntax, `with_*` methods are also available.
-/// ```
-/// let args = DurationArgs::new().with_weeks(lit(42)).with_hours(lit(84));
-/// ```
-#[derive(Debug, Clone)]
-pub struct DurationArgs {
-    pub weeks: Expr,
-    pub days: Expr,
-    pub hours: Expr,
-    pub minutes: Expr,
-    pub seconds: Expr,
-    pub milliseconds: Expr,
-    pub microseconds: Expr,
-    pub nanoseconds: Expr,
-}
+    /// Shift the values by a given period and fill the parts that will be empty due to this operation
+    /// with the result of the `fill_value` expression.
+    ///
+    /// See the method on [Series](polars_core::series::SeriesTrait::shift) for more info on the `shift` operation.
+    pub fn shift_and_fill<E: Into<Expr>>(self, periods: i64, fill_value: E) -> Self {
+        self.select_local(vec![col("*").shift_and_fill(periods, fill_value.into())])
+    }
 
-impl Default for DurationArgs {
-    fn default() -> Self {
-        Self {
-            weeks: lit(0),
-            days: lit(0),
-            hours: lit(0),
-            minutes: lit(0),
-            seconds: lit(0),
-            milliseconds: lit(0),
-            microseconds: lit(0),
-            nanoseconds: lit(0),
-        }
+    /// Fill none values in the DataFrame
+    pub fn fill_null<E: Into<Expr>>(self, fill_value: E) -> LazyFrame {
+        let opt_state = self.get_opt_state();
+        let lp = self.get_plan_builder().fill_null(fill_value.into()).build();
+        Self::from_logical_plan(lp, opt_state)
     }
-}
 
-impl DurationArgs {
-    /// Create a new `DurationArgs` with all fields set to `lit(0)`. Use the `with_*` methods to set the fields.
-    pub fn new() -> Self {
-        Self::default()
+    /// Fill NaN values in the DataFrame
+    pub fn fill_nan<E: Into<Expr>>(self, fill_value: E) -> LazyFrame {
+        let opt_state = self.get_opt_state();
+        let lp = self.get_plan_builder().fill_nan(fill_value.into()).build();
+        Self::from_logical_plan(lp, opt_state)
     }
 
-    /// Set `hours`, `minutes`, and `seconds`
-    ///
-    /// Equivalent to
-    /// ```ignore
-    /// self.with_hours(hours)
-    ///     .with_minutes(minutes)
-    ///     .with_seconds(seconds)
-    /// ```.
-    pub fn with_hms(self, hours: Expr, minutes: Expr, seconds: Expr) -> Self {
-        Self {
-            hours,
-            minutes,
-            seconds,
-            ..self
-        }
+    /// Caches the result into a new LazyFrame. This should be used to prevent computations
+    /// running multiple times
+    pub fn cache(self) -> Self {
+        let opt_state = self.get_opt_state();
+        let lp = self.get_plan_builder().cache().build();
+        Self::from_logical_plan(lp, opt_state)
     }
 
-    /// Set `milliseconds`, `microseconds`, and `nanoseconds`
+    /// Fetch is like a collect operation, but it overwrites the number of rows read by every scan
+    /// operation. This is a utility that helps debug a query on a smaller number of rows.
     ///
-    /// Equivalent to
-    /// ```ignore
-    /// self.with_milliseconds(milliseconds)
-    ///     .with_microseconds(microseconds)
-    ///     .with_nanoseconds(nanoseconds)
-    /// ```
-    pub fn with_fractional_seconds(
+    /// Note that the fetch does not guarantee the final number of rows in the DataFrame.
+    /// Filter, join operations and a lower number of rows available in the scanned file influence
+    /// the final number of rows.
+    pub fn fetch(self, n_rows: usize) -> PolarsResult<DataFrame> {
+        FETCH_ROWS.with(|fetch_rows| fetch_rows.set(Some(n_rows)));
+        let res = self.collect();
+        FETCH_ROWS.with(|fetch_rows| fetch_rows.set(None));
+        res
+    }
+
+    pub fn optimize(
         self,
-        milliseconds: Expr,
-        microseconds: Expr,
-        nanoseconds: Expr,
-    ) -> Self {
-        Self {
-            milliseconds,
-            microseconds,
-            nanoseconds,
-            ..self
+        lp_arena: &mut Arena<ALogicalPlan>,
+        expr_arena: &mut Arena<AExpr>,
+    ) -> PolarsResult<Node> {
+        self.optimize_with_scratch(lp_arena, expr_arena, &mut vec![], false)
+    }
+
+    pub(crate) fn optimize_with_scratch(
+        self,
+        lp_arena: &mut Arena<ALogicalPlan>,
+        expr_arena: &mut Arena<AExpr>,
+        scratch: &mut Vec<Node>,
+        _fmt: bool,
+    ) -> PolarsResult<Node> {
+        #[allow(unused_mut)]
+        let mut opt_state = self.opt_state;
+        let streaming = self.opt_state.streaming;
+        #[cfg(feature = "cse")]
+        if streaming && self.opt_state.common_subplan_elimination {
+            eprintln!("Cannot combine 'streaming' with 'common_subplan_elimination'. CSE will be turned off.");
+            opt_state.common_subplan_elimination = false;
+        }
+        let lp_top = optimize(self.logical_plan, opt_state, lp_arena, expr_arena, scratch)?;
+
+        if streaming {
+            #[cfg(feature = "streaming")]
+            {
+                insert_streaming_nodes(lp_top, lp_arena, expr_arena, scratch, _fmt)?;
+            }
+            #[cfg(not(feature = "streaming"))]
+            {
+                panic!("activate feature 'streaming'")
+            }
+        }
+        Ok(lp_top)
+    }
+
+    #[allow(unused_mut)]
+    fn prepare_collect(
+        mut self,
+        check_sink: bool,
+    ) -> PolarsResult<(ExecutionState, Box<dyn Executor>, bool)> {
+        let file_caching = self.opt_state.file_caching;
+        let mut expr_arena = Arena::with_capacity(256);
+        let mut lp_arena = Arena::with_capacity(128);
+        let mut scratch = vec![];
+        let lp_top =
+            self.optimize_with_scratch(&mut lp_arena, &mut expr_arena, &mut scratch, false)?;
+
+        let finger_prints = if file_caching {
+            #[cfg(any(feature = "ipc", feature = "parquet", feature = "csv"))]
+            {
+                let mut fps = Vec::with_capacity(8);
+                collect_fingerprints(lp_top, &mut fps, &lp_arena, &expr_arena);
+                Some(fps)
+            }
+            #[cfg(not(any(feature = "ipc", feature = "parquet", feature = "csv")))]
+            {
+                None
+            }
+        } else {
+            None
+        };
+
+        // file sink should be replaced
+        let no_file_sink = if check_sink {
+            !matches!(lp_arena.get(lp_top), ALogicalPlan::FileSink { .. })
+        } else {
+            true
+        };
+        let physical_plan = create_physical_plan(lp_top, &mut lp_arena, &mut expr_arena)?;
+
+        let state = ExecutionState::with_finger_prints(finger_prints);
+        Ok((state, physical_plan, no_file_sink))
+    }
+
+    /// Execute all the lazy operations and collect them into a [`DataFrame`].
+    /// Before execution the query is being optimized.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use polars_core::prelude::*;
+    /// use polars_lazy::prelude::*;
+    ///
+    /// fn example(df: DataFrame) -> PolarsResult<DataFrame> {
+    ///     df.lazy()
+    ///       .groupby([col("foo")])
+    ///       .agg([col("bar").sum(), col("ham").mean().alias("avg_ham")])
+    ///       .collect()
+    /// }
+    /// ```
+    pub fn collect(self) -> PolarsResult<DataFrame> {
+        let (mut state, mut physical_plan, _) = self.prepare_collect(false)?;
+        let out = physical_plan.execute(&mut state);
+        #[cfg(debug_assertions)]
+        {
+            #[cfg(any(feature = "ipc", feature = "parquet", feature = "csv"))]
+            state.file_cache.assert_empty();
         }
+        out
     }
 
-    impl_unit_setter!(with_weeks(weeks));
-    impl_unit_setter!(with_days(days));
-    impl_unit_setter!(with_hours(hours));
-    impl_unit_setter!(with_minutes(minutes));
-    impl_unit_setter!(with_seconds(seconds));
-    impl_unit_setter!(with_milliseconds(milliseconds));
-    impl_unit_setter!(with_microseconds(microseconds));
-    impl_unit_setter!(with_nanoseconds(nanoseconds));
-}
+    /// Profile a LazyFrame.
+    ///
+    /// This will run the query and return a tuple
+    /// containing the materialized DataFrame and a DataFrame that contains profiling information
+    /// of each node that is executed.
+    ///
+    /// The units of the timings are microseconds.
+    pub fn profile(self) -> PolarsResult<(DataFrame, DataFrame)> {
+        let (mut state, mut physical_plan, _) = self.prepare_collect(false)?;
+        state.time_nodes();
+        let out = physical_plan.execute(&mut state)?;
+        let timer_df = state.finish_timer()?;
+        Ok((out, timer_df))
+    }
+
+    /// Stream a query result into a parquet file. This is useful if the final result doesn't fit
+    /// into memory. This methods will return an error if the query cannot be completely done in a
+    /// streaming fashion.
+    #[cfg(feature = "parquet")]
+    pub fn sink_parquet(mut self, path: PathBuf, options: ParquetWriteOptions) -> PolarsResult<()> {
+        self.opt_state.streaming = true;
+        self.logical_plan = LogicalPlan::FileSink {
+            input: Box::new(self.logical_plan),
+            payload: FileSinkOptions {
+                path: Arc::new(path),
+                file_type: FileType::Parquet(options),
+            },
+        };
+        let (mut state, mut physical_plan, is_streaming) = self.prepare_collect(true)?;
+        polars_ensure!(
+            is_streaming,
+            ComputeError: "cannot run the whole query in a streaming order; \
+            use `collect().write_parquet()` instead"
+        );
+        let _ = physical_plan.execute(&mut state)?;
+        Ok(())
+    }
 
-/// Construct a column of `Duration` from the provided [`DurationArgs`]
-#[cfg(feature = "temporal")]
-pub fn duration(args: DurationArgs) -> Expr {
-    let function = SpecialEq::new(Arc::new(move |s: &mut [Series]| {
-        assert_eq!(s.len(), 8);
-        if s.iter().any(|s| s.is_empty()) {
-            return Ok(Some(Series::new_empty(
-                s[0].name(),
-                &DataType::Duration(TimeUnit::Nanoseconds),
-            )));
-        }
-
-        let days = s[0].cast(&DataType::Int64).unwrap();
-        let seconds = s[1].cast(&DataType::Int64).unwrap();
-        let mut nanoseconds = s[2].cast(&DataType::Int64).unwrap();
-        let microseconds = s[3].cast(&DataType::Int64).unwrap();
-        let milliseconds = s[4].cast(&DataType::Int64).unwrap();
-        let minutes = s[5].cast(&DataType::Int64).unwrap();
-        let hours = s[6].cast(&DataType::Int64).unwrap();
-        let weeks = s[7].cast(&DataType::Int64).unwrap();
-
-        let max_len = s.iter().map(|s| s.len()).max().unwrap();
-
-        let condition = |s: &Series| {
-            // check if not literal 0 || full column
-            (s.len() != max_len && s.get(0).unwrap() != AnyValue::Int64(0)) || s.len() == max_len
+    /// Stream a query result into an ipc/arrow file. This is useful if the final result doesn't fit
+    /// into memory. This methods will return an error if the query cannot be completely done in a
+    /// streaming fashion.
+    #[cfg(feature = "ipc")]
+    pub fn sink_ipc(mut self, path: PathBuf, options: IpcWriterOptions) -> PolarsResult<()> {
+        self.opt_state.streaming = true;
+        self.logical_plan = LogicalPlan::FileSink {
+            input: Box::new(self.logical_plan),
+            payload: FileSinkOptions {
+                path: Arc::new(path),
+                file_type: FileType::Ipc(options),
+            },
         };
+        let (mut state, mut physical_plan, is_streaming) = self.prepare_collect(true)?;
+        polars_ensure!(
+            is_streaming,
+            ComputeError: "cannot run the whole query in a streaming order; \
+            use `collect().write_ipc()` instead"
+        );
+        let _ = physical_plan.execute(&mut state)?;
+        Ok(())
+    }
 
-        if nanoseconds.len() != max_len {
-            nanoseconds = nanoseconds.new_from_index(0, max_len);
+    /// Filter by some predicate expression.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use polars_core::prelude::*;
+    /// use polars_lazy::prelude::*;
+    ///
+    /// fn example(df: DataFrame) -> LazyFrame {
+    ///       df.lazy()
+    ///         .filter(col("sepal.width").is_not_null())
+    ///         .select(&[col("sepal.width"), col("sepal.length")])
+    /// }
+    /// ```
+    pub fn filter(self, predicate: Expr) -> Self {
+        let opt_state = self.get_opt_state();
+        let lp = self.get_plan_builder().filter(predicate).build();
+        Self::from_logical_plan(lp, opt_state)
+    }
+
+    /// Select (and rename) columns from the query.
+    ///
+    /// Columns can be selected with [col](crate::dsl::col);
+    /// If you want to select all columns use `col("*")`.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use polars_core::prelude::*;
+    /// use polars_lazy::prelude::*;
+    ///
+    /// /// This function selects column "foo" and column "bar".
+    /// /// Column "bar" is renamed to "ham".
+    /// fn example(df: DataFrame) -> LazyFrame {
+    ///       df.lazy()
+    ///         .select(&[col("foo"),
+    ///                   col("bar").alias("ham")])
+    /// }
+    ///
+    /// /// This function selects all columns except "foo"
+    /// fn exclude_a_column(df: DataFrame) -> LazyFrame {
+    ///       df.lazy()
+    ///         .select(&[col("*").exclude(["foo"])])
+    /// }
+    /// ```
+    pub fn select<E: AsRef<[Expr]>>(self, exprs: E) -> Self {
+        let opt_state = self.get_opt_state();
+        let lp = self
+            .get_plan_builder()
+            .project(exprs.as_ref().to_vec())
+            .build();
+        Self::from_logical_plan(lp, opt_state)
+    }
+
+    /// A projection that doesn't get optimized and may drop projections if they are not in
+    /// schema after optimization
+    fn select_local(self, exprs: Vec<Expr>) -> Self {
+        let opt_state = self.get_opt_state();
+        let lp = self.get_plan_builder().project_local(exprs).build();
+        Self::from_logical_plan(lp, opt_state)
+    }
+
+    /// Group by and aggregate.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use polars_core::prelude::*;
+    /// use polars_lazy::prelude::*;
+    /// use polars_arrow::prelude::QuantileInterpolOptions;
+    ///
+    /// fn example(df: DataFrame) -> LazyFrame {
+    ///       df.lazy()
+    ///        .groupby([col("date")])
+    ///        .agg([
+    ///            col("rain").min(),
+    ///            col("rain").sum(),
+    ///            col("rain").quantile(lit(0.5), QuantileInterpolOptions::Nearest).alias("median_rain"),
+    ///        ])
+    /// }
+    /// ```
+    pub fn groupby<E: AsRef<[IE]>, IE: Into<Expr> + Clone>(self, by: E) -> LazyGroupBy {
+        let keys = by
+            .as_ref()
+            .iter()
+            .map(|e| e.clone().into())
+            .collect::<Vec<_>>();
+        let opt_state = self.get_opt_state();
+
+        #[cfg(feature = "dynamic_groupby")]
+        {
+            LazyGroupBy {
+                logical_plan: self.logical_plan,
+                opt_state,
+                keys,
+                maintain_order: false,
+                dynamic_options: None,
+                rolling_options: None,
+            }
         }
-        if condition(&microseconds) {
-            nanoseconds = nanoseconds + (microseconds * 1_000);
+
+        #[cfg(not(feature = "dynamic_groupby"))]
+        {
+            LazyGroupBy {
+                logical_plan: self.logical_plan,
+                opt_state,
+                keys,
+                maintain_order: false,
+            }
         }
-        if condition(&milliseconds) {
-            nanoseconds = nanoseconds + (milliseconds * 1_000_000);
+    }
+
+    /// Create rolling groups based on a time column.
+    ///
+    /// Also works for index values of type Int32 or Int64.
+    ///
+    /// Different from a [`groupby_dynamic`][`Self::groupby_dynamic`], the windows are now determined by the
+    /// individual values and are not of constant intervals. For constant intervals use
+    /// *groupby_dynamic*
+    #[cfg(feature = "dynamic_groupby")]
+    pub fn groupby_rolling<E: AsRef<[Expr]>>(
+        self,
+        index_column: Expr,
+        by: E,
+        mut options: RollingGroupOptions,
+    ) -> LazyGroupBy {
+        if let Expr::Column(name) = index_column {
+            options.index_column = name.as_ref().into();
+        } else {
+            let name = expr_output_name(&index_column).unwrap();
+            return self
+                .with_column(index_column)
+                .groupby_rolling(Expr::Column(name), by, options);
+        }
+        let opt_state = self.get_opt_state();
+        LazyGroupBy {
+            logical_plan: self.logical_plan,
+            opt_state,
+            keys: by.as_ref().to_vec(),
+            maintain_order: true,
+            dynamic_options: None,
+            rolling_options: Some(options),
         }
-        if condition(&seconds) {
-            nanoseconds = nanoseconds + (seconds * NANOSECONDS);
-        }
-        if condition(&days) {
-            nanoseconds = nanoseconds + (days * NANOSECONDS * SECONDS_IN_DAY);
-        }
-        if condition(&minutes) {
-            nanoseconds = nanoseconds + minutes * NANOSECONDS * 60;
-        }
-        if condition(&hours) {
-            nanoseconds = nanoseconds + hours * NANOSECONDS * 60 * 60;
-        }
-        if condition(&weeks) {
-            nanoseconds = nanoseconds + weeks * NANOSECONDS * SECONDS_IN_DAY * 7;
-        }
-
-        nanoseconds
-            .cast(&DataType::Duration(TimeUnit::Nanoseconds))
-            .map(Some)
-    }) as Arc<dyn SeriesUdf>);
-
-    Expr::AnonymousFunction {
-        input: vec![
-            args.days,
-            args.seconds,
-            args.nanoseconds,
-            args.microseconds,
-            args.milliseconds,
-            args.minutes,
-            args.hours,
-            args.weeks,
-        ],
-        function,
-        output_type: GetOutput::from_type(DataType::Duration(TimeUnit::Nanoseconds)),
-        options: FunctionOptions {
-            collect_groups: ApplyOptions::ApplyFlat,
-            input_wildcard_expansion: true,
-            fmt_str: "duration",
-            ..Default::default()
-        },
     }
-    .alias("duration")
-}
 
-/// Create a Column Expression based on a column name.
-///
-/// # Arguments
-///
-/// * `name` - A string slice that holds the name of the column. If a column with this name does not exist when the
-///   LazyFrame is collected, an error is returned.
-///
-/// # Examples
-///
-/// ```ignore
-/// // select a column name
-/// col("foo")
-/// ```
-///
-/// ```ignore
-/// // select all columns by using a wildcard
-/// col("*")
-/// ```
-///
-/// ```ignore
-/// // select specific column by writing a regular expression that starts with `^` and ends with `$`
-/// // only if regex features is activated
-/// col("^foo.*$")
-/// ```
-pub fn col(name: &str) -> Expr {
-    match name {
-        "*" => Expr::Wildcard,
-        _ => Expr::Column(Arc::from(name)),
+    /// Group based on a time value (or index value of type Int32, Int64).
+    ///
+    /// Time windows are calculated and rows are assigned to windows. Different from a
+    /// normal groupby is that a row can be member of multiple groups. The time/index
+    /// window could be seen as a rolling window, with a window size determined by
+    /// dates/times/values instead of slots in the DataFrame.
+    ///
+    /// A window is defined by:
+    ///
+    /// - every: interval of the window
+    /// - period: length of the window
+    /// - offset: offset of the window
+    ///
+    /// The `by` argument should be empty `[]` if you don't want to combine this
+    /// with a ordinary groupby on these keys.
+    #[cfg(feature = "dynamic_groupby")]
+    pub fn groupby_dynamic<E: AsRef<[Expr]>>(
+        self,
+        index_column: Expr,
+        by: E,
+        mut options: DynamicGroupOptions,
+    ) -> LazyGroupBy {
+        if let Expr::Column(name) = index_column {
+            options.index_column = name.as_ref().into();
+        } else {
+            let name = expr_output_name(&index_column).unwrap();
+            return self
+                .with_column(index_column)
+                .groupby_dynamic(Expr::Column(name), by, options);
+        }
+        let opt_state = self.get_opt_state();
+        LazyGroupBy {
+            logical_plan: self.logical_plan,
+            opt_state,
+            keys: by.as_ref().to_vec(),
+            maintain_order: true,
+            dynamic_options: Some(options),
+            rolling_options: None,
+        }
     }
-}
 
-/// Selects all columns. Shorthand for `col("*")`.
-pub fn all() -> Expr {
-    Expr::Wildcard
-}
+    /// Similar to [`groupby`][`Self::groupby`], but order of the DataFrame is maintained.
+    pub fn groupby_stable<E: AsRef<[IE]>, IE: Into<Expr> + Clone>(self, by: E) -> LazyGroupBy {
+        let keys = by
+            .as_ref()
+            .iter()
+            .map(|e| e.clone().into())
+            .collect::<Vec<_>>();
+        let opt_state = self.get_opt_state();
+
+        #[cfg(feature = "dynamic_groupby")]
+        {
+            LazyGroupBy {
+                logical_plan: self.logical_plan,
+                opt_state,
+                keys,
+                maintain_order: true,
+                dynamic_options: None,
+                rolling_options: None,
+            }
+        }
 
-/// Select multiple columns by name.
-pub fn cols<I: IntoVec<String>>(names: I) -> Expr {
-    let names = names.into_vec();
-    Expr::Columns(names)
-}
+        #[cfg(not(feature = "dynamic_groupby"))]
+        {
+            LazyGroupBy {
+                logical_plan: self.logical_plan,
+                opt_state,
+                keys,
+                maintain_order: true,
+            }
+        }
+    }
 
-/// Select multiple columns by dtype.
-pub fn dtype_col(dtype: &DataType) -> Expr {
-    Expr::DtypeColumn(vec![dtype.clone()])
-}
+    /// Join query with other lazy query.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use polars_core::prelude::*;
+    /// use polars_lazy::prelude::*;
+    /// fn join_dataframes(ldf: LazyFrame, other: LazyFrame) -> LazyFrame {
+    ///         ldf
+    ///         .left_join(other, col("foo"), col("bar"))
+    /// }
+    /// ```
+    pub fn left_join<E: Into<Expr>>(self, other: LazyFrame, left_on: E, right_on: E) -> LazyFrame {
+        self.join(
+            other,
+            [left_on.into()],
+            [right_on.into()],
+            JoinArgs::new(JoinType::Left),
+        )
+    }
 
-/// Select multiple columns by dtype.
-pub fn dtype_cols<DT: AsRef<[DataType]>>(dtype: DT) -> Expr {
-    let dtypes = dtype.as_ref().to_vec();
-    Expr::DtypeColumn(dtypes)
-}
+    /// Join query with other lazy query.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use polars_core::prelude::*;
+    /// use polars_lazy::prelude::*;
+    /// fn join_dataframes(ldf: LazyFrame, other: LazyFrame) -> LazyFrame {
+    ///         ldf
+    ///         .outer_join(other, col("foo"), col("bar"))
+    /// }
+    /// ```
+    pub fn outer_join<E: Into<Expr>>(self, other: LazyFrame, left_on: E, right_on: E) -> LazyFrame {
+        self.join(
+            other,
+            [left_on.into()],
+            [right_on.into()],
+            JoinArgs::new(JoinType::Outer),
+        )
+    }
 
-/// Sum all the values in the column named `name`. Shorthand for `col(name).sum()`.
-pub fn sum(name: &str) -> Expr {
-    col(name).sum()
-}
+    /// Join query with other lazy query.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use polars_core::prelude::*;
+    /// use polars_lazy::prelude::*;
+    /// fn join_dataframes(ldf: LazyFrame, other: LazyFrame) -> LazyFrame {
+    ///         ldf
+    ///         .inner_join(other, col("foo"), col("bar").cast(DataType::Utf8))
+    /// }
+    /// ```
+    pub fn inner_join<E: Into<Expr>>(self, other: LazyFrame, left_on: E, right_on: E) -> LazyFrame {
+        self.join(
+            other,
+            [left_on.into()],
+            [right_on.into()],
+            JoinArgs::new(JoinType::Inner),
+        )
+    }
 
-/// Find the minimum of all the values in the column named `name`. Shorthand for `col(name).min()`.
-pub fn min(name: &str) -> Expr {
-    col(name).min()
-}
+    /// Creates the cartesian product from both frames, preserves the order of the left keys.
+    #[cfg(feature = "cross_join")]
+    pub fn cross_join(self, other: LazyFrame) -> LazyFrame {
+        self.join(other, vec![], vec![], JoinArgs::new(JoinType::Cross))
+    }
 
-/// Find the maximum of all the values in the column named `name`. Shorthand for `col(name).max()`.
-pub fn max(name: &str) -> Expr {
-    col(name).max()
-}
+    /// Generic join function that can join on multiple columns.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use polars_core::prelude::*;
+    /// use polars_lazy::prelude::*;
+    ///
+    /// fn example(ldf: LazyFrame, other: LazyFrame) -> LazyFrame {
+    ///         ldf
+    ///         .join(other, [col("foo"), col("bar")], [col("foo"), col("bar")], JoinArgs::new(JoinType::Inner))
+    /// }
+    /// ```
+    pub fn join<E: AsRef<[Expr]>>(
+        mut self,
+        other: LazyFrame,
+        left_on: E,
+        right_on: E,
+        args: JoinArgs,
+    ) -> LazyFrame {
+        // if any of the nodes reads from files we must activate this this plan as well.
+        self.opt_state.file_caching |= other.opt_state.file_caching;
+
+        let left_on = left_on.as_ref().to_vec();
+        let right_on = right_on.as_ref().to_vec();
+        self.join_builder()
+            .with(other)
+            .left_on(left_on)
+            .right_on(right_on)
+            .how(args.how)
+            .finish()
+    }
+
+    /// Control more join options with the join builder.
+    pub fn join_builder(self) -> JoinBuilder {
+        JoinBuilder::new(self)
+    }
 
-/// Find the mean of all the values in the column named `name`. Shorthand for `col(name).mean()`.
-pub fn mean(name: &str) -> Expr {
-    col(name).mean()
-}
+    /// Add a column to a DataFrame
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use polars_core::prelude::*;
+    /// use polars_lazy::prelude::*;
+    /// fn add_column(df: DataFrame) -> LazyFrame {
+    ///     df.lazy()
+    ///         .with_column(
+    ///             when(col("sepal.length").lt(lit(5.0)))
+    ///             .then(lit(10))
+    ///             .otherwise(lit(1))
+    ///             .alias("new_column_name"),
+    ///             )
+    /// }
+    /// ```
+    pub fn with_column(self, expr: Expr) -> LazyFrame {
+        let opt_state = self.get_opt_state();
+        let lp = self.get_plan_builder().with_columns(vec![expr]).build();
+        Self::from_logical_plan(lp, opt_state)
+    }
 
-/// Find the mean of all the values in the column named `name`. Alias for [`mean`].
-pub fn avg(name: &str) -> Expr {
-    col(name).mean()
-}
+    /// Add multiple columns to a DataFrame.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use polars_core::prelude::*;
+    /// use polars_lazy::prelude::*;
+    /// fn add_columns(df: DataFrame) -> LazyFrame {
+    ///     df.lazy()
+    ///         .with_columns(
+    ///             vec![lit(10).alias("foo"), lit(100).alias("bar")]
+    ///          )
+    /// }
+    /// ```
+    pub fn with_columns<E: AsRef<[Expr]>>(self, exprs: E) -> LazyFrame {
+        let exprs = exprs.as_ref().to_vec();
+        let opt_state = self.get_opt_state();
+        let lp = self.get_plan_builder().with_columns(exprs).build();
+        Self::from_logical_plan(lp, opt_state)
+    }
 
-/// Find the median of all the values in the column named `name`. Shorthand for `col(name).median()`.
-pub fn median(name: &str) -> Expr {
-    col(name).median()
-}
+    pub fn with_context<C: AsRef<[LazyFrame]>>(self, contexts: C) -> LazyFrame {
+        let contexts = contexts
+            .as_ref()
+            .iter()
+            .map(|lf| lf.logical_plan.clone())
+            .collect();
+        let opt_state = self.get_opt_state();
+        let lp = self.get_plan_builder().with_context(contexts).build();
+        Self::from_logical_plan(lp, opt_state)
+    }
 
-/// Find a specific quantile of all the values in the column named `name`.
-pub fn quantile(name: &str, quantile: Expr, interpol: QuantileInterpolOptions) -> Expr {
-    col(name).quantile(quantile, interpol)
-}
+    /// Aggregate all the columns as their maximum values.
+    pub fn max(self) -> LazyFrame {
+        self.select_local(vec![col("*").max()])
+    }
 
-macro_rules! prepare_binary_function {
-    ($f:ident) => {
-        move |s: &mut [Series]| {
-            let s0 = std::mem::take(&mut s[0]);
-            let s1 = std::mem::take(&mut s[1]);
+    /// Aggregate all the columns as their minimum values.
+    pub fn min(self) -> LazyFrame {
+        self.select_local(vec![col("*").min()])
+    }
 
-            $f(s0, s1)
-        }
-    };
-}
+    /// Aggregate all the columns as their sum values.
+    pub fn sum(self) -> LazyFrame {
+        self.select_local(vec![col("*").sum()])
+    }
 
-/// Apply a closure on the two columns that are evaluated from `Expr` a and `Expr` b.
-///
-/// The closure takes two arguments, each a `Series`. `output_type` must be the output dtype of the resulting `Series`.
-pub fn map_binary<F: 'static>(a: Expr, b: Expr, f: F, output_type: GetOutput) -> Expr
-where
-    F: Fn(Series, Series) -> PolarsResult<Option<Series>> + Send + Sync,
-{
-    let function = prepare_binary_function!(f);
-    a.map_many(function, &[b], output_type)
-}
+    /// Aggregate all the columns as their mean values.
+    pub fn mean(self) -> LazyFrame {
+        self.select_local(vec![col("*").mean()])
+    }
 
-/// Like [`map_binary`], but used in a groupby-aggregation context.
-///
-/// See [`Expr::apply`] for the difference between [`map`](Expr::map) and [`apply`](Expr::apply).
-pub fn apply_binary<F: 'static>(a: Expr, b: Expr, f: F, output_type: GetOutput) -> Expr
-where
-    F: Fn(Series, Series) -> PolarsResult<Option<Series>> + Send + Sync,
-{
-    let function = prepare_binary_function!(f);
-    a.apply_many(function, &[b], output_type)
-}
+    /// Aggregate all the columns as their median values.
+    pub fn median(self) -> LazyFrame {
+        self.select_local(vec![col("*").median()])
+    }
 
-#[cfg(feature = "dtype-struct")]
-fn cumfold_dtype() -> GetOutput {
-    GetOutput::map_fields(|fields| {
-        let mut st = fields[0].dtype.clone();
-        for fld in &fields[1..] {
-            st = get_supertype(&st, &fld.dtype).unwrap();
-        }
-        Field::new(
-            &fields[0].name,
-            DataType::Struct(
-                fields
-                    .iter()
-                    .map(|fld| Field::new(fld.name(), st.clone()))
-                    .collect(),
-            ),
-        )
-    })
-}
+    /// Aggregate all the columns as their quantile values.
+    pub fn quantile(self, quantile: Expr, interpol: QuantileInterpolOptions) -> LazyFrame {
+        self.select_local(vec![col("*").quantile(quantile, interpol)])
+    }
 
-/// Accumulate over multiple columns horizontally / row wise.
-pub fn fold_exprs<F: 'static, E: AsRef<[Expr]>>(acc: Expr, f: F, exprs: E) -> Expr
-where
-    F: Fn(Series, Series) -> PolarsResult<Option<Series>> + Send + Sync + Clone,
-{
-    let mut exprs = exprs.as_ref().to_vec();
-    exprs.push(acc);
-
-    let function = SpecialEq::new(Arc::new(move |series: &mut [Series]| {
-        let mut series = series.to_vec();
-        let mut acc = series.pop().unwrap();
-
-        for s in series {
-            if let Some(a) = f(acc.clone(), s)? {
-                acc = a
-            }
-        }
-        Ok(Some(acc))
-    }) as Arc<dyn SeriesUdf>);
+    /// Aggregate all the columns as their standard deviation values.
+    pub fn std(self, ddof: u8) -> LazyFrame {
+        self.select_local(vec![col("*").std(ddof)])
+    }
 
-    Expr::AnonymousFunction {
-        input: exprs,
-        function,
-        output_type: GetOutput::super_type(),
-        options: FunctionOptions {
-            collect_groups: ApplyOptions::ApplyGroups,
-            input_wildcard_expansion: true,
-            auto_explode: true,
-            fmt_str: "fold",
-            ..Default::default()
-        },
+    /// Aggregate all the columns as their variance values.
+    pub fn var(self, ddof: u8) -> LazyFrame {
+        self.select_local(vec![col("*").var(ddof)])
     }
-}
 
-/// Analogous to [`Iterator::reduce`](std::iter::Iterator::reduce).
-///
-/// An accumulator is initialized to the series given by the first expression in `exprs`, and then each subsequent value
-/// of the accumulator is computed from `f(acc, next_expr_series)`. If `exprs` is empty, an error is returned when
-/// `collect` is called.
-pub fn reduce_exprs<F: 'static, E: AsRef<[Expr]>>(f: F, exprs: E) -> Expr
-where
-    F: Fn(Series, Series) -> PolarsResult<Option<Series>> + Send + Sync + Clone,
-{
-    let exprs = exprs.as_ref().to_vec();
-
-    let function = SpecialEq::new(Arc::new(move |series: &mut [Series]| {
-        let mut s_iter = series.iter();
-
-        match s_iter.next() {
-            Some(acc) => {
-                let mut acc = acc.clone();
-
-                for s in s_iter {
-                    if let Some(a) = f(acc.clone(), s.clone())? {
-                        acc = a
-                    }
-                }
-                Ok(Some(acc))
-            }
-            None => Err(polars_err!(ComputeError: "`reduce` did not have any expressions to fold")),
-        }
-    }) as Arc<dyn SeriesUdf>);
+    /// Apply explode operation. [See eager explode](polars_core::frame::DataFrame::explode).
+    pub fn explode<E: AsRef<[IE]>, IE: Into<Expr> + Clone>(self, columns: E) -> LazyFrame {
+        let columns = columns
+            .as_ref()
+            .iter()
+            .map(|e| e.clone().into())
+            .collect::<Vec<_>>();
+        let opt_state = self.get_opt_state();
+        let lp = self.get_plan_builder().explode(columns).build();
+        Self::from_logical_plan(lp, opt_state)
+    }
+
+    /// Aggregate all the columns as the sum of their null value count.
+    pub fn null_count(self) -> LazyFrame {
+        self.select_local(vec![col("*").null_count()])
+    }
 
-    Expr::AnonymousFunction {
-        input: exprs,
-        function,
-        output_type: GetOutput::super_type(),
-        options: FunctionOptions {
-            collect_groups: ApplyOptions::ApplyGroups,
-            input_wildcard_expansion: true,
-            auto_explode: true,
-            fmt_str: "reduce",
+    /// Keep unique rows and maintain order
+    pub fn unique_stable(
+        self,
+        subset: Option<Vec<String>>,
+        keep_strategy: UniqueKeepStrategy,
+    ) -> LazyFrame {
+        let opt_state = self.get_opt_state();
+        let options = DistinctOptions {
+            subset: subset.map(Arc::new),
+            maintain_order: true,
+            keep_strategy,
             ..Default::default()
-        },
+        };
+        let lp = self.get_plan_builder().distinct(options).build();
+        Self::from_logical_plan(lp, opt_state)
     }
-}
 
-/// Accumulate over multiple columns horizontally / row wise.
-#[cfg(feature = "dtype-struct")]
-pub fn cumreduce_exprs<F: 'static, E: AsRef<[Expr]>>(f: F, exprs: E) -> Expr
-where
-    F: Fn(Series, Series) -> PolarsResult<Option<Series>> + Send + Sync + Clone,
-{
-    let exprs = exprs.as_ref().to_vec();
-
-    let function = SpecialEq::new(Arc::new(move |series: &mut [Series]| {
-        let mut s_iter = series.iter();
-
-        match s_iter.next() {
-            Some(acc) => {
-                let mut acc = acc.clone();
-                let mut result = vec![acc.clone()];
-
-                for s in s_iter {
-                    let name = s.name().to_string();
-                    if let Some(a) = f(acc.clone(), s.clone())? {
-                        acc = a;
-                    }
-                    acc.rename(&name);
-                    result.push(acc.clone());
-                }
+    /// Keep unique rows, do not maintain order
+    pub fn unique(
+        self,
+        subset: Option<Vec<String>>,
+        keep_strategy: UniqueKeepStrategy,
+    ) -> LazyFrame {
+        let opt_state = self.get_opt_state();
+        let options = DistinctOptions {
+            subset: subset.map(Arc::new),
+            maintain_order: false,
+            keep_strategy,
+            ..Default::default()
+        };
+        let lp = self.get_plan_builder().distinct(options).build();
+        Self::from_logical_plan(lp, opt_state)
+    }
 
-                StructChunked::new(acc.name(), &result).map(|ca| Some(ca.into_series()))
+    /// Drop null rows.
+    ///
+    /// Equal to `LazyFrame::filter(col("*").is_not_null())`
+    pub fn drop_nulls(self, subset: Option<Vec<Expr>>) -> LazyFrame {
+        match subset {
+            None => self.filter(all_exprs([col("*").is_not_null()])),
+            Some(subset) => {
+                let predicate = all_exprs(
+                    subset
+                        .into_iter()
+                        .map(|e| e.is_not_null())
+                        .collect::<Vec<_>>(),
+                );
+                self.filter(predicate)
             }
-            None => Err(polars_err!(ComputeError: "`reduce` did not have any expressions to fold")),
         }
-    }) as Arc<dyn SeriesUdf>);
+    }
 
-    Expr::AnonymousFunction {
-        input: exprs,
-        function,
-        output_type: cumfold_dtype(),
-        options: FunctionOptions {
-            collect_groups: ApplyOptions::ApplyGroups,
-            input_wildcard_expansion: true,
-            auto_explode: true,
-            fmt_str: "cumreduce",
-            ..Default::default()
-        },
+    /// Slice the DataFrame.
+    pub fn slice(self, offset: i64, len: IdxSize) -> LazyFrame {
+        let opt_state = self.get_opt_state();
+        let lp = self.get_plan_builder().slice(offset, len).build();
+        Self::from_logical_plan(lp, opt_state)
     }
-}
 
-/// Accumulate over multiple columns horizontally / row wise.
-#[cfg(feature = "dtype-struct")]
-pub fn cumfold_exprs<F: 'static, E: AsRef<[Expr]>>(
-    acc: Expr,
-    f: F,
-    exprs: E,
-    include_init: bool,
-) -> Expr
-where
-    F: Fn(Series, Series) -> PolarsResult<Option<Series>> + Send + Sync + Clone,
-{
-    let mut exprs = exprs.as_ref().to_vec();
-    exprs.push(acc);
-
-    let function = SpecialEq::new(Arc::new(move |series: &mut [Series]| {
-        let mut series = series.to_vec();
-        let mut acc = series.pop().unwrap();
-
-        let mut result = vec![];
-        if include_init {
-            result.push(acc.clone())
-        }
-
-        for s in series {
-            let name = s.name().to_string();
-            if let Some(a) = f(acc.clone(), s)? {
-                acc = a;
-                acc.rename(&name);
-                result.push(acc.clone());
-            }
-        }
+    /// Get the first row.
+    pub fn first(self) -> LazyFrame {
+        self.slice(0, 1)
+    }
 
-        StructChunked::new(acc.name(), &result).map(|ca| Some(ca.into_series()))
-    }) as Arc<dyn SeriesUdf>);
+    /// Get the last row
+    pub fn last(self) -> LazyFrame {
+        self.slice(-1, 1)
+    }
 
-    Expr::AnonymousFunction {
-        input: exprs,
-        function,
-        output_type: cumfold_dtype(),
-        options: FunctionOptions {
-            collect_groups: ApplyOptions::ApplyGroups,
-            input_wildcard_expansion: true,
-            auto_explode: true,
-            fmt_str: "cumfold",
-            ..Default::default()
-        },
+    /// Get the last `n` rows
+    pub fn tail(self, n: IdxSize) -> LazyFrame {
+        let neg_tail = -(n as i64);
+        self.slice(neg_tail, n)
     }
-}
 
-/// Create a new column with the the sum of the values in each row.
-///
-/// The name of the resulting column will be `"sum"`; use [`alias`](Expr::alias) to choose a different name.
-pub fn sum_exprs<E: AsRef<[Expr]>>(exprs: E) -> Expr {
-    let mut exprs = exprs.as_ref().to_vec();
-    let func = |s1, s2| Ok(Some(&s1 + &s2));
-    let init = match exprs.pop() {
-        Some(e) => e,
-        // use u32 as that is not cast to float as eagerly
-        _ => lit(0u32),
-    };
-    fold_exprs(init, func, exprs).alias("sum")
-}
+    /// Melt the DataFrame from wide to long format
+    pub fn melt(self, args: MeltArgs) -> LazyFrame {
+        let opt_state = self.get_opt_state();
+        let lp = self.get_plan_builder().melt(Arc::new(args)).build();
+        Self::from_logical_plan(lp, opt_state)
+    }
 
-/// Create a new column with the the maximum value per row.
-///
-/// The name of the resulting column will be `"max"`; use [`alias`](Expr::alias) to choose a different name.
-pub fn max_exprs<E: AsRef<[Expr]>>(exprs: E) -> Expr {
-    let exprs = exprs.as_ref().to_vec();
-    if exprs.is_empty() {
-        return Expr::Columns(Vec::new());
-    }
-    let func = |s1, s2| {
-        let df = DataFrame::new_no_checks(vec![s1, s2]);
-        df.hmax()
-    };
-    reduce_exprs(func, exprs).alias("max")
-}
+    /// Limit the DataFrame to the first `n` rows. Note if you don't want the rows to be scanned,
+    /// use [fetch](LazyFrame::fetch).
+    pub fn limit(self, n: IdxSize) -> LazyFrame {
+        self.slice(0, n)
+    }
 
-/// Create a new column with the the minimum value per row.
-///
-/// The name of the resulting column will be `"min"`; use [`alias`](Expr::alias) to choose a different name.
-pub fn min_exprs<E: AsRef<[Expr]>>(exprs: E) -> Expr {
-    let exprs = exprs.as_ref().to_vec();
-    if exprs.is_empty() {
-        return Expr::Columns(Vec::new());
-    }
-    let func = |s1, s2| {
-        let df = DataFrame::new_no_checks(vec![s1, s2]);
-        df.hmin()
-    };
-    reduce_exprs(func, exprs).alias("min")
-}
+    /// Apply a function/closure once the logical plan get executed.
+    ///
+    /// ## Warning
+    /// This can blow up in your face if the schema is changed due to the operation. The optimizer
+    /// relies on a correct schema.
+    ///
+    /// You can toggle certain optimizations off.
+    pub fn map<F>(
+        self,
+        function: F,
+        optimizations: AllowedOptimizations,
+        schema: Option<Arc<dyn UdfSchema>>,
+        name: Option<&'static str>,
+    ) -> LazyFrame
+    where
+        F: 'static + Fn(DataFrame) -> PolarsResult<DataFrame> + Send + Sync,
+    {
+        let opt_state = self.get_opt_state();
+        let lp = self
+            .get_plan_builder()
+            .map(
+                function,
+                optimizations,
+                schema,
+                name.unwrap_or("ANONYMOUS UDF"),
+            )
+            .build();
+        Self::from_logical_plan(lp, opt_state)
+    }
 
-/// Create a new column with the the bitwise-or of the elements in each row.
-///
-/// The name of the resulting column is arbitrary; use [`alias`](Expr::alias) to choose a different name.
-pub fn any_exprs<E: AsRef<[Expr]>>(exprs: E) -> Expr {
-    let exprs = exprs.as_ref().to_vec();
-    let func = |s1: Series, s2: Series| Ok(Some(s1.bool()?.bitor(s2.bool()?).into_series()));
-    fold_exprs(lit(false), func, exprs)
-}
+    pub(crate) fn map_private(self, function: FunctionNode) -> LazyFrame {
+        let opt_state = self.get_opt_state();
+        let lp = self.get_plan_builder().map_private(function).build();
+        Self::from_logical_plan(lp, opt_state)
+    }
 
-/// Create a new column with the the bitwise-and of the elements in each row.
-///
-/// The name of the resulting column is arbitrary; use [`alias`](Expr::alias) to choose a different name.
-pub fn all_exprs<E: AsRef<[Expr]>>(exprs: E) -> Expr {
-    let exprs = exprs.as_ref().to_vec();
-    let func = |s1: Series, s2: Series| Ok(Some(s1.bool()?.bitand(s2.bool()?).into_series()));
-    fold_exprs(lit(true), func, exprs)
-}
+    /// Add a new column at index 0 that counts the rows.
+    ///
+    /// # Warning
+    /// This can have a negative effect on query performance.
+    /// This may for instance block predicate pushdown optimization.
+    pub fn with_row_count(mut self, name: &str, offset: Option<IdxSize>) -> LazyFrame {
+        let add_row_count_in_map = match &mut self.logical_plan {
+            // Do the row count at scan
+            #[cfg(feature = "csv")]
+            LogicalPlan::CsvScan { options, .. } => {
+                options.row_count = Some(RowCount {
+                    name: name.to_string(),
+                    offset: offset.unwrap_or(0),
+                });
+                false
+            }
+            #[cfg(feature = "ipc")]
+            LogicalPlan::IpcScan { options, .. } => {
+                options.row_count = Some(RowCount {
+                    name: name.to_string(),
+                    offset: offset.unwrap_or(0),
+                });
+                false
+            }
+            #[cfg(feature = "parquet")]
+            LogicalPlan::ParquetScan { options, .. } => {
+                options.row_count = Some(RowCount {
+                    name: name.to_string(),
+                    offset: offset.unwrap_or(0),
+                });
+                false
+            }
+            _ => true,
+        };
 
-/// Negates a boolean column.
-pub fn not(expr: Expr) -> Expr {
-    expr.not()
-}
+        let name2: SmartString = name.into();
+        let udf_schema = move |s: &Schema| {
+            // Can't error, index 0 is always in bounds
+            let new = s
+                .new_inserting_at_index(0, name2.clone(), IDX_DTYPE)
+                .unwrap();
+            Ok(Arc::new(new))
+        };
 
-/// A column which is `true` wherever `expr` is null, `false` elsewhere.
-pub fn is_null(expr: Expr) -> Expr {
-    expr.is_null()
-}
+        let name = name.to_owned();
 
-/// A column which is `false` wherever `expr` is null, `true` elsewhere.
-pub fn is_not_null(expr: Expr) -> Expr {
-    expr.is_not_null()
-}
+        // if we do the row count at scan we add a dummy map, to update the schema
+        let opt = if add_row_count_in_map {
+            AllowedOptimizations {
+                slice_pushdown: false,
+                predicate_pushdown: false,
+                streaming: false,
+                ..Default::default()
+            }
+        } else {
+            AllowedOptimizations::default()
+        };
 
-/// Casts the column given by `Expr` to a different type.
-///
-/// Follows the rules of Rust casting, with the exception that integers and floats can be cast to `DataType::Date` and
-/// `DataType::DateTime(_, _)`. A column consisting entirely of of `Null` can be cast to any type, regardless of the
-/// nominal type of the column.
-pub fn cast(expr: Expr, data_type: DataType) -> Expr {
-    Expr::Cast {
-        expr: Box::new(expr),
-        data_type,
-        strict: false,
+        self.map(
+            move |df: DataFrame| {
+                if add_row_count_in_map {
+                    df.with_row_count(&name, offset)
+                } else {
+                    Ok(df)
+                }
+            },
+            opt,
+            Some(Arc::new(udf_schema)),
+            Some("WITH ROW COUNT"),
+        )
     }
-}
 
-pub trait Range<T> {
-    fn into_range(self, high: T) -> Expr;
+    /// Unnest the given `Struct` columns. This means that the fields of the `Struct` type will be
+    /// inserted as columns.
+    #[cfg(feature = "dtype-struct")]
+    pub fn unnest<I: IntoIterator<Item = S>, S: AsRef<str>>(self, cols: I) -> Self {
+        self.map_private(FunctionNode::Unnest {
+            columns: cols.into_iter().map(|s| Arc::from(s.as_ref())).collect(),
+        })
+    }
+
+    #[cfg(feature = "merge_sorted")]
+    pub fn merge_sorted(self, other: LazyFrame, key: &str) -> PolarsResult<LazyFrame> {
+        // The two DataFrames are temporary concatenated
+        // this indicates until which chunk the data is from the left df
+        // this trick allows us to reuse the `Union` architecture to get map over
+        // two DataFrames
+        let left = self.map_private(FunctionNode::Rechunk);
+        let q = concat(&[left, other], false, true)?;
+        Ok(q.map_private(FunctionNode::MergeSorted {
+            column: Arc::from(key),
+        }))
+    }
 }
 
-macro_rules! impl_into_range {
-    ($dt: ty) => {
-        impl Range<$dt> for $dt {
-            fn into_range(self, high: $dt) -> Expr {
-                Expr::Literal(LiteralValue::Range {
-                    low: self as i64,
-                    high: high as i64,
-                    data_type: DataType::Int32,
-                })
-            }
-        }
-    };
+/// Utility struct for lazy groupby operation.
+#[derive(Clone)]
+pub struct LazyGroupBy {
+    pub logical_plan: LogicalPlan,
+    opt_state: OptState,
+    keys: Vec<Expr>,
+    maintain_order: bool,
+    #[cfg(feature = "dynamic_groupby")]
+    dynamic_options: Option<DynamicGroupOptions>,
+    #[cfg(feature = "dynamic_groupby")]
+    rolling_options: Option<RollingGroupOptions>,
 }
 
-impl_into_range!(i32);
-impl_into_range!(i64);
-impl_into_range!(u32);
-
-/// Create a range literal.
-pub fn range<T: Range<T>>(low: T, high: T) -> Expr {
-    low.into_range(high)
-}
+impl LazyGroupBy {
+    /// Group by and aggregate.
+    ///
+    /// Select a column with [col](crate::dsl::col) and choose an aggregation.
+    /// If you want to aggregate all columns use `col("*")`.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use polars_core::prelude::*;
+    /// use polars_lazy::prelude::*;
+    /// use polars_arrow::prelude::QuantileInterpolOptions;
+    ///
+    /// fn example(df: DataFrame) -> LazyFrame {
+    ///       df.lazy()
+    ///        .groupby_stable([col("date")])
+    ///        .agg([
+    ///            col("rain").min(),
+    ///            col("rain").sum(),
+    ///            col("rain").quantile(lit(0.5), QuantileInterpolOptions::Nearest).alias("median_rain"),
+    ///        ])
+    /// }
+    /// ```
+    pub fn agg<E: AsRef<[Expr]>>(self, aggs: E) -> LazyFrame {
+        #[cfg(feature = "dynamic_groupby")]
+        let lp = LogicalPlanBuilder::from(self.logical_plan)
+            .groupby(
+                self.keys,
+                aggs,
+                None,
+                self.maintain_order,
+                self.dynamic_options,
+                self.rolling_options,
+            )
+            .build();
+
+        #[cfg(not(feature = "dynamic_groupby"))]
+        let lp = LogicalPlanBuilder::from(self.logical_plan)
+            .groupby(self.keys, aggs, None, self.maintain_order)
+            .build();
+        LazyFrame::from_logical_plan(lp, self.opt_state)
+    }
+
+    /// Return first n rows of each group
+    pub fn head(self, n: Option<usize>) -> LazyFrame {
+        let keys = self
+            .keys
+            .iter()
+            .flat_map(|k| expr_to_leaf_column_names(k).into_iter())
+            .collect::<Vec<_>>();
+
+        self.agg([col("*").exclude(&keys).head(n).keep_name()])
+            .explode([col("*").exclude(&keys)])
+    }
+
+    /// Return last n rows of each group
+    pub fn tail(self, n: Option<usize>) -> LazyFrame {
+        let keys = self
+            .keys
+            .iter()
+            .flat_map(|k| expr_to_leaf_column_names(k).into_iter())
+            .collect::<Vec<_>>();
+
+        self.agg([col("*").exclude(&keys).tail(n).keep_name()])
+            .explode([col("*").exclude(&keys)])
+    }
+
+    /// Apply a function over the groups as a new `DataFrame`. It is not recommended that you use
+    /// this as materializing the `DataFrame` is very expensive.
+    pub fn apply<F>(self, f: F, schema: SchemaRef) -> LazyFrame
+    where
+        F: 'static + Fn(DataFrame) -> PolarsResult<DataFrame> + Send + Sync,
+    {
+        #[cfg(feature = "dynamic_groupby")]
+        let options = GroupbyOptions {
+            dynamic: self.dynamic_options,
+            rolling: self.rolling_options,
+            slice: None,
+        };
 
-/// Take several expressions and collect them into a [`StructChunked`].
-#[cfg(feature = "dtype-struct")]
-pub fn as_struct(exprs: &[Expr]) -> Expr {
-    map_multiple(
-        |s| StructChunked::new(s[0].name(), s).map(|ca| Some(ca.into_series())),
-        exprs,
-        GetOutput::map_fields(|fld| Field::new(fld[0].name(), DataType::Struct(fld.to_vec()))),
-    )
-    .with_function_options(|mut options| {
-        options.input_wildcard_expansion = true;
-        options.fmt_str = "as_struct";
-        options.pass_name_to_apply = true;
-        options
-    })
+        #[cfg(not(feature = "dynamic_groupby"))]
+        let options = GroupbyOptions { slice: None };
+
+        let lp = LogicalPlan::Aggregate {
+            input: Box::new(self.logical_plan),
+            keys: Arc::new(self.keys),
+            aggs: vec![],
+            schema,
+            apply: Some(Arc::new(f)),
+            maintain_order: self.maintain_order,
+            options,
+        };
+        LazyFrame::from_logical_plan(lp, self.opt_state)
+    }
 }
 
-/// Create a column of length `n` containing `n` copies of the literal `value`. Generally you won't need this function,
-/// as `lit(value)` already represents a column containing only `value` whose length is automatically set to the correct
-/// number of rows.
-pub fn repeat<L: Literal>(value: L, n: Expr) -> Expr {
-    let function = |s: Series, n: Series| {
-        let n =
-            n.get(0).unwrap().extract::<usize>().ok_or_else(
-                || polars_err!(ComputeError: "could not extract a size from {:?}", n),
-            )?;
-        Ok(Some(s.new_from_index(0, n)))
-    };
-    apply_binary(lit(value), n, function, GetOutput::same_type()).alias("repeat")
+#[must_use]
+pub struct JoinBuilder {
+    lf: LazyFrame,
+    how: JoinType,
+    other: Option<LazyFrame>,
+    left_on: Vec<Expr>,
+    right_on: Vec<Expr>,
+    allow_parallel: bool,
+    force_parallel: bool,
+    suffix: Option<String>,
+    validation: JoinValidation,
 }
+impl JoinBuilder {
+    pub fn new(lf: LazyFrame) -> Self {
+        Self {
+            lf,
+            other: None,
+            how: JoinType::Inner,
+            left_on: vec![],
+            right_on: vec![],
+            allow_parallel: true,
+            force_parallel: false,
+            suffix: None,
+            validation: Default::default(),
+        }
+    }
 
-#[cfg(feature = "arg_where")]
-/// Get the indices where `condition` evaluates `true`.
-pub fn arg_where<E: Into<Expr>>(condition: E) -> Expr {
-    let condition = condition.into();
-    Expr::Function {
-        input: vec![condition],
-        function: FunctionExpr::ArgWhere,
-        options: FunctionOptions {
-            collect_groups: ApplyOptions::ApplyGroups,
-            ..Default::default()
-        },
+    /// The table to join with.
+    pub fn with(mut self, other: LazyFrame) -> Self {
+        self.other = Some(other);
+        self
     }
-}
 
-/// Folds the expressions from left to right keeping the first non-null values.
-///
-/// It is an error to provide an empty `exprs`.
-pub fn coalesce(exprs: &[Expr]) -> Expr {
-    let input = exprs.to_vec();
-    Expr::Function {
-        input,
-        function: FunctionExpr::Coalesce,
-        options: FunctionOptions {
-            collect_groups: ApplyOptions::ApplyGroups,
-            cast_to_supertypes: true,
-            input_wildcard_expansion: true,
-            ..Default::default()
-        },
+    /// Select the join type.
+    pub fn how(mut self, how: JoinType) -> Self {
+        self.how = how;
+        self
     }
-}
 
-/// Create a date range from a `start` and `stop` expression.
-#[cfg(feature = "temporal")]
-pub fn date_range(
-    start: Expr,
-    end: Expr,
-    every: Duration,
-    closed: ClosedWindow,
-    tz: Option<TimeZone>,
-) -> Expr {
-    let input = vec![start, end];
-
-    Expr::Function {
-        input,
-        function: FunctionExpr::TemporalExpr(TemporalFunction::DateRange { every, closed, tz }),
-        options: FunctionOptions {
-            collect_groups: ApplyOptions::ApplyGroups,
-            cast_to_supertypes: true,
-            allow_rename: true,
-            ..Default::default()
-        },
+    pub fn validate(mut self, validation: JoinValidation) -> Self {
+        self.validation = validation;
+        self
     }
-}
 
-/// Create a time range from a `start` and `stop` expression.
-#[cfg(feature = "temporal")]
-pub fn time_range(start: Expr, end: Expr, every: Duration, closed: ClosedWindow) -> Expr {
-    let input = vec![start, end];
-
-    Expr::Function {
-        input,
-        function: FunctionExpr::TemporalExpr(TemporalFunction::TimeRange { every, closed }),
-        options: FunctionOptions {
-            collect_groups: ApplyOptions::ApplyGroups,
-            cast_to_supertypes: false,
-            allow_rename: true,
-            ..Default::default()
-        },
+    /// The columns you want to join both tables on.
+    pub fn on<E: AsRef<[Expr]>>(mut self, on: E) -> Self {
+        let on = on.as_ref().to_vec();
+        self.left_on = on.clone();
+        self.right_on = on;
+        self
     }
-}
 
-#[cfg(feature = "rolling_window")]
-pub fn rolling_corr(x: Expr, y: Expr, options: RollingCovOptions) -> Expr {
-    let x = x.cache();
-    let y = y.cache();
-    // see: https://github.com/pandas-dev/pandas/blob/v1.5.1/pandas/core/window/rolling.py#L1780-L1804
-    let rolling_options = RollingOptions {
-        window_size: Duration::new(options.window_size as i64),
-        min_periods: options.min_periods as usize,
-        ..Default::default()
-    };
-
-    let mean_x_y = (x.clone() * y.clone()).rolling_mean(rolling_options.clone());
-    let mean_x = x.clone().rolling_mean(rolling_options.clone());
-    let mean_y = y.clone().rolling_mean(rolling_options.clone());
-    let var_x = x.clone().rolling_var(rolling_options.clone());
-    let var_y = y.clone().rolling_var(rolling_options);
-
-    let rolling_options_count = RollingOptions {
-        window_size: Duration::new(options.window_size as i64),
-        min_periods: 0,
-        ..Default::default()
-    };
-    let ddof = options.ddof as f64;
-    let count_x_y = (x + y)
-        .is_not_null()
-        .cast(DataType::Float64)
-        .rolling_sum(rolling_options_count)
-        .cache();
-    let numerator = (mean_x_y - mean_x * mean_y) * (count_x_y.clone() / (count_x_y - lit(ddof)));
-    let denominator = (var_x * var_y).pow(lit(0.5));
+    /// The columns you want to join the left table on.
+    pub fn left_on<E: AsRef<[Expr]>>(mut self, on: E) -> Self {
+        self.left_on = on.as_ref().to_vec();
+        self
+    }
 
-    numerator / denominator
-}
+    /// The columns you want to join the right table on.
+    pub fn right_on<E: AsRef<[Expr]>>(mut self, on: E) -> Self {
+        self.right_on = on.as_ref().to_vec();
+        self
+    }
+    /// Allow parallel table evaluation.
+    pub fn allow_parallel(mut self, allow: bool) -> Self {
+        self.allow_parallel = allow;
+        self
+    }
+
+    /// Force parallel table evaluation.
+    pub fn force_parallel(mut self, force: bool) -> Self {
+        self.force_parallel = force;
+        self
+    }
+
+    /// Suffix to add duplicate column names in join.
+    /// Defaults to `"_right"`.
+    pub fn suffix<S: AsRef<str>>(mut self, suffix: S) -> Self {
+        self.suffix = Some(suffix.as_ref().to_string());
+        self
+    }
+
+    /// Finish builder
+    pub fn finish(self) -> LazyFrame {
+        let mut opt_state = self.lf.opt_state;
+        let other = self.other.expect("with not set");
 
-#[cfg(feature = "rolling_window")]
-pub fn rolling_cov(x: Expr, y: Expr, options: RollingCovOptions) -> Expr {
-    let x = x.cache();
-    let y = y.cache();
-    // see: https://github.com/pandas-dev/pandas/blob/91111fd99898d9dcaa6bf6bedb662db4108da6e6/pandas/core/window/rolling.py#L1700
-    let rolling_options = RollingOptions {
-        window_size: Duration::new(options.window_size as i64),
-        min_periods: options.min_periods as usize,
-        ..Default::default()
-    };
-
-    let mean_x_y = (x.clone() * y.clone()).rolling_mean(rolling_options.clone());
-    let mean_x = x.clone().rolling_mean(rolling_options.clone());
-    let mean_y = y.clone().rolling_mean(rolling_options);
-    let rolling_options_count = RollingOptions {
-        window_size: Duration::new(options.window_size as i64),
-        min_periods: 0,
-        ..Default::default()
-    };
-    let count_x_y = (x + y)
-        .is_not_null()
-        .cast(DataType::Float64)
-        .rolling_sum(rolling_options_count)
-        .cache();
+        // if any of the nodes reads from files we must activate this this plan as well.
+        opt_state.file_caching |= other.opt_state.file_caching;
 
-    let ddof = options.ddof as f64;
+        let args = JoinArgs {
+            how: self.how,
+            validation: self.validation,
+            suffix: self.suffix,
+            slice: None,
+        };
 
-    (mean_x_y - mean_x * mean_y) * (count_x_y.clone() / (count_x_y - lit(ddof)))
+        let lp = self
+            .lf
+            .get_plan_builder()
+            .join(
+                other.logical_plan,
+                self.left_on,
+                self.right_on,
+                JoinOptions {
+                    allow_parallel: self.allow_parallel,
+                    force_parallel: self.force_parallel,
+                    args,
+                    ..Default::default()
+                },
+            )
+            .build();
+        LazyFrame::from_logical_plan(lp, opt_state)
+    }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/list.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/meta.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/alias.rs`

 * *Files 24% similar despite different names*

```diff
@@ -1,70 +1,102 @@
-use super::*;
-use crate::logical_plan::projection::is_regex_projection;
+use std::sync::Arc;
 
-/// Specialized expressions for Categorical dtypes.
-pub struct MetaNameSpace(pub(crate) Expr);
+use polars_core::frame::groupby::GroupsProxy;
+use polars_core::prelude::*;
 
-impl MetaNameSpace {
-    /// Pop latest expression and return the input(s) of the popped expression.
-    pub fn pop(self) -> Vec<Expr> {
-        let mut arena = Arena::with_capacity(8);
-        let node = to_aexpr(self.0, &mut arena);
-        let ae = arena.get(node);
-        let mut inputs = Vec::with_capacity(2);
-        ae.nodes(&mut inputs);
-        inputs
-            .iter()
-            .map(|node| node_to_expr(*node, &arena))
-            .collect()
-    }
-
-    /// Get the root column names.
-    pub fn root_names(&self) -> Vec<Arc<str>> {
-        expr_to_leaf_column_names(&self.0)
-    }
-    /// A projection that only takes a column or a column + alias.
-    pub fn is_simple_projection(&self) -> bool {
-        let mut arena = Arena::with_capacity(8);
-        let node = to_aexpr(self.0.clone(), &mut arena);
-        aexpr_is_simple_projection(node, &arena)
-    }
-
-    /// Get the output name of this expression.
-    pub fn output_name(&self) -> PolarsResult<Arc<str>> {
-        expr_output_name(&self.0)
-    }
-
-    /// Undo any renaming operation like `alias`, `keep_name`.
-    pub fn undo_aliases(mut self) -> Expr {
-        self.0.mutate().apply(|e| match e {
-            Expr::Alias(input, _)
-            | Expr::KeepName(input)
-            | Expr::RenameAlias { expr: input, .. } => {
-                // remove this node
-                *e = *input.clone();
-
-                // continue iteration
-                true
-            }
-            // continue iteration
-            _ => true,
-        });
-
-        self.0
-    }
-
-    pub fn has_multiple_outputs(&self) -> bool {
-        self.0.into_iter().any(|e| match e {
-            Expr::Wildcard | Expr::Columns(_) | Expr::DtypeColumn(_) => true,
-            Expr::Column(name) => is_regex_projection(name),
-            _ => false,
+use crate::physical_plan::state::ExecutionState;
+use crate::prelude::*;
+
+pub struct AliasExpr {
+    pub(crate) physical_expr: Arc<dyn PhysicalExpr>,
+    pub(crate) name: Arc<str>,
+    expr: Expr,
+}
+
+impl AliasExpr {
+    pub fn new(physical_expr: Arc<dyn PhysicalExpr>, name: Arc<str>, expr: Expr) -> Self {
+        Self {
+            physical_expr,
+            name,
+            expr,
+        }
+    }
+    fn finish(&self, mut input: Series) -> Series {
+        input.rename(&self.name);
+        input
+    }
+}
+
+impl PhysicalExpr for AliasExpr {
+    fn as_expression(&self) -> Option<&Expr> {
+        Some(&self.expr)
+    }
+
+    fn evaluate(&self, df: &DataFrame, state: &ExecutionState) -> PolarsResult<Series> {
+        let series = self.physical_expr.evaluate(df, state)?;
+        Ok(self.finish(series))
+    }
+
+    #[allow(clippy::ptr_arg)]
+    fn evaluate_on_groups<'a>(
+        &self,
+        df: &DataFrame,
+        groups: &'a GroupsProxy,
+        state: &ExecutionState,
+    ) -> PolarsResult<AggregationContext<'a>> {
+        let mut ac = self.physical_expr.evaluate_on_groups(df, groups, state)?;
+        let s = ac.take();
+        let s = self.finish(s);
+
+        if ac.is_literal() {
+            ac.with_literal(s);
+        } else {
+            ac.with_series(s, ac.is_aggregated(), Some(&self.expr))?;
+        }
+        Ok(ac)
+    }
+
+    fn to_field(&self, input_schema: &Schema) -> PolarsResult<Field> {
+        Ok(Field::new(
+            &self.name,
+            self.physical_expr
+                .to_field(input_schema)?
+                .data_type()
+                .clone(),
+        ))
+    }
+
+    fn as_partitioned_aggregator(&self) -> Option<&dyn PartitionedAggregation> {
+        Some(self)
+    }
+    fn is_valid_aggregation(&self) -> bool {
+        self.physical_expr.is_valid_aggregation()
+    }
+}
+
+impl PartitionedAggregation for AliasExpr {
+    fn evaluate_partitioned(
+        &self,
+        df: &DataFrame,
+        groups: &GroupsProxy,
+        state: &ExecutionState,
+    ) -> PolarsResult<Series> {
+        let agg = self.physical_expr.as_partitioned_aggregator().unwrap();
+        agg.evaluate_partitioned(df, groups, state).map(|mut s| {
+            s.rename(&self.name);
+            s
         })
     }
 
-    pub fn is_regex_projection(&self) -> bool {
-        self.0.into_iter().any(|e| match e {
-            Expr::Column(name) => is_regex_projection(name),
-            _ => false,
+    fn finalize(
+        &self,
+        partitioned: Series,
+        groups: &GroupsProxy,
+        state: &ExecutionState,
+    ) -> PolarsResult<Series> {
+        let agg = self.physical_expr.as_partitioned_aggregator().unwrap();
+        agg.finalize(partitioned, groups, state).map(|mut s| {
+            s.rename(&self.name);
+            s
         })
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -8,45 +8,54 @@
 mod arity;
 #[cfg(feature = "dtype-array")]
 mod array;
 pub mod binary;
 #[cfg(feature = "temporal")]
 pub mod dt;
 mod expr;
+mod expr_dyn_fn;
 mod from;
 pub(crate) mod function_expr;
 #[cfg(feature = "compile")]
 pub mod functions;
 mod list;
 #[cfg(feature = "meta")]
 mod meta;
 pub(crate) mod names;
 mod options;
+mod selector;
 #[cfg(feature = "strings")]
 pub mod string;
 #[cfg(feature = "dtype-struct")]
 mod struct_;
 
 use std::fmt::Debug;
 use std::sync::Arc;
 
 pub use arity::*;
+#[cfg(feature = "dtype-array")]
+pub use array::*;
 pub use expr::*;
 pub use function_expr::*;
 pub use functions::*;
 pub use list::*;
+#[cfg(feature = "meta")]
+pub use meta::*;
 pub use options::*;
 use polars_arrow::prelude::QuantileInterpolOptions;
 use polars_core::prelude::*;
 #[cfg(feature = "diff")]
 use polars_core::series::ops::NullBehavior;
 use polars_core::series::IsSorted;
 use polars_core::utils::{try_get_supertype, NoNull};
 #[cfg(feature = "rolling_window")]
 use polars_time::series::SeriesOpsTime;
+pub(crate) use selector::Selector;
+#[cfg(feature = "dtype-struct")]
+pub use struct_::*;
 
 use crate::constants::MAP_LIST_NAME;
 pub use crate::logical_plan::lit;
 use crate::prelude::*;
 use crate::utils::has_expr;
 #[cfg(feature = "is_in")]
 use crate::utils::has_root_literal_expr;
@@ -1003,17 +1012,18 @@
     }
 
     /// or operation
     pub fn or<E: Into<Expr>>(self, expr: E) -> Self {
         binary_expr(self, Operator::Or, expr.into())
     }
 
-    /// Filter a single column
-    /// Should be used in aggregation context. If you want to filter on a DataFrame level, use
-    /// [LazyFrame::filter](LazyFrame::filter)
+    /// Filter a single column.
+    ///
+    /// Should be used in aggregation context. If you want to filter on a
+    /// DataFrame level, use `LazyFrame::filter`.
     pub fn filter<E: Into<Expr>>(self, predicate: E) -> Self {
         if has_expr(&self, |e| matches!(e, Expr::Wildcard)) {
             panic!("filter '*' not allowed, use LazyFrame::filter")
         };
         Expr::Filter {
             input: Box::new(self),
             by: Box::new(predicate.into()),
@@ -1238,14 +1248,15 @@
                         min_periods: options.min_periods,
                         weights: None,
                         center: options.center,
                         by: Some(by_values),
                         tu: Some(tu),
                         tz: tz.as_ref(),
                         closed_window: options.closed_window,
+                        fn_params: options.fn_params.clone(),
                     };
 
                     rolling_fn(s, options).map(Some)
                 },
                 &[col(by)],
                 output_type,
             )
@@ -1259,81 +1270,87 @@
                 move |s| rolling_fn(&s, options.clone().into()).map(Some),
                 output_type,
             )
             .with_fmt(expr_name)
         }
     }
 
-    /// Apply a rolling min See:
-    /// [ChunkedArray::rolling_min]
+    /// Apply a rolling minimum.
+    ///
+    /// See: [`RollingAgg::rolling_min`]
     #[cfg(feature = "rolling_window")]
     pub fn rolling_min(self, options: RollingOptions) -> Expr {
         self.finish_rolling(
             options,
             "rolling_min",
             "rolling_min_by",
             Arc::new(|s, options| s.rolling_min(options)),
             GetOutput::same_type(),
         )
     }
 
-    /// Apply a rolling max See:
-    /// [ChunkedArray::rolling_max]
+    /// Apply a rolling maximum.
+    ///
+    /// See: [`RollingAgg::rolling_max`]
     #[cfg(feature = "rolling_window")]
     pub fn rolling_max(self, options: RollingOptions) -> Expr {
         self.finish_rolling(
             options,
             "rolling_max",
             "rolling_max_by",
             Arc::new(|s, options| s.rolling_max(options)),
             GetOutput::same_type(),
         )
     }
 
-    /// Apply a rolling mean See:
-    /// [ChunkedArray::rolling_mean]
+    /// Apply a rolling mean.
+    ///
+    /// See: [`RollingAgg::rolling_mean`]
     #[cfg(feature = "rolling_window")]
     pub fn rolling_mean(self, options: RollingOptions) -> Expr {
         self.finish_rolling(
             options,
             "rolling_mean",
             "rolling_mean_by",
             Arc::new(|s, options| s.rolling_mean(options)),
             GetOutput::float_type(),
         )
     }
 
-    /// Apply a rolling sum See:
-    /// [ChunkedArray::rolling_sum]
+    /// Apply a rolling sum.
+    ///
+    /// See: [`RollingAgg::rolling_sum`]
     #[cfg(feature = "rolling_window")]
     pub fn rolling_sum(self, options: RollingOptions) -> Expr {
         self.finish_rolling(
             options,
             "rolling_sum",
             "rolling_sum_by",
             Arc::new(|s, options| s.rolling_sum(options)),
             GetOutput::same_type(),
         )
     }
 
-    /// Apply a rolling median See:
-    /// [`ChunkedArray::rolling_median`]
+    /// Apply a rolling median.
+    ///
+    /// See: [`RollingAgg::rolling_median`]
     #[cfg(feature = "rolling_window")]
     pub fn rolling_median(self, options: RollingOptions) -> Expr {
         self.finish_rolling(
             options,
             "rolling_median",
             "rolling_median_by",
             Arc::new(|s, options| s.rolling_median(options)),
             GetOutput::same_type(),
         )
     }
 
-    /// Apply a rolling quantile See:
-    /// [`ChunkedArray::rolling_quantile`]
+    /// Apply a rolling quantile.
+    ///
+    /// See: [`RollingAgg::rolling_quantile`]
     #[cfg(feature = "rolling_window")]
     pub fn rolling_quantile(
         self,
         quantile: f64,
         interpolation: QuantileInterpolOptions,
         options: RollingOptions,
     ) -> Expr {
@@ -1764,33 +1781,33 @@
         dt::DateLikeNameSpace(self)
     }
 
     pub fn list(self) -> list::ListNameSpace {
         list::ListNameSpace(self)
     }
 
-    /// Get the [`ArrayNameSpace`]
+    /// Get the [`array::ArrayNameSpace`]
     #[cfg(feature = "dtype-array")]
     pub fn arr(self) -> array::ArrayNameSpace {
         array::ArrayNameSpace(self)
     }
 
     /// Get the [`CategoricalNameSpace`]
     #[cfg(feature = "dtype-categorical")]
     pub fn cat(self) -> cat::CategoricalNameSpace {
         cat::CategoricalNameSpace(self)
     }
 
-    /// Get the [`StructNameSpace`]
+    /// Get the [`struct_::StructNameSpace`]
     #[cfg(feature = "dtype-struct")]
     pub fn struct_(self) -> struct_::StructNameSpace {
         struct_::StructNameSpace(self)
     }
 
-    /// Get the [`MetaNameSpace`]
+    /// Get the [`meta::MetaNameSpace`]
     #[cfg(feature = "meta")]
     pub fn meta(self) -> meta::MetaNameSpace {
         meta::MetaNameSpace(self)
     }
 }
 
 /// Apply a function/closure over multiple columns once the logical plan get executed.
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/options.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/options.rs`

 * *Files 9% similar despite different names*

```diff
@@ -1,10 +1,8 @@
-use std::borrow::Cow;
-
-use polars_core::prelude::JoinType;
+use polars_core::prelude::{JoinArgs, JoinType};
 use polars_utils::IdxSize;
 #[cfg(feature = "serde")]
 use serde::{Deserialize, Serialize};
 
 #[derive(Copy, Clone, PartialEq, Debug, Eq, Hash)]
 #[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
 pub struct RollingCovOptions {
@@ -39,31 +37,27 @@
 }
 
 #[derive(Clone, Debug, PartialEq, Eq)]
 #[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
 pub struct JoinOptions {
     pub allow_parallel: bool,
     pub force_parallel: bool,
-    pub how: JoinType,
-    pub suffix: Cow<'static, str>,
-    pub slice: Option<(i64, usize)>,
+    pub args: JoinArgs,
     /// Proxy of the number of rows in both sides of the joins
     /// Holds `(Option<known_size>, estimated_size)`
     pub rows_left: (Option<usize>, usize),
     pub rows_right: (Option<usize>, usize),
 }
 
 impl Default for JoinOptions {
     fn default() -> Self {
         JoinOptions {
             allow_parallel: true,
             force_parallel: false,
-            how: JoinType::Left,
-            suffix: "_right".into(),
-            slice: None,
+            args: JoinArgs::new(JoinType::Left),
             rows_left: (None, usize::MAX),
             rows_right: (None, usize::MAX),
         }
     }
 }
 
 #[derive(Copy, Clone, Debug, PartialEq, Eq, Default)]
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/string.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/string.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/dsl/struct_.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/dsl/struct_.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/frame/opt_state.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/frame/opt_state.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/aexpr/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/aexpr/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/aexpr/schema.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/aexpr/schema.rs`

 * *Files 1% similar despite different names*

```diff
@@ -60,14 +60,16 @@
                     Operator::Lt
                     | Operator::Gt
                     | Operator::Eq
                     | Operator::NotEq
                     | Operator::And
                     | Operator::LtEq
                     | Operator::GtEq
+                    | Operator::NotEqValidity
+                    | Operator::EqValidity
                     | Operator::Or => {
                         let out_field;
                         let out_name = {
                             out_field = arena.get(*left).to_field(schema, ctxt, arena)?;
                             out_field.name().as_str()
                         };
                         Field::new(out_name, Boolean)
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/alp.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/alp.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/anonymous_scan.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/anonymous_scan.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/apply.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/apply.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/builder.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/builder.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/conversion.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/conversion.rs`

 * *Files 1% similar despite different names*

```diff
@@ -153,14 +153,15 @@
         Expr::Count => AExpr::Count,
         Expr::Nth(i) => AExpr::Nth(i),
         Expr::KeepName(_) => panic!("no keep_name expected at this point"),
         Expr::Exclude(_, _) => panic!("no exclude expected at this point"),
         Expr::RenameAlias { .. } => panic!("no `rename_alias` expected at this point"),
         Expr::Columns { .. } => panic!("no `columns` expected at this point"),
         Expr::DtypeColumn { .. } => panic!("no `dtype-columns` expected at this point"),
+        Expr::Selector(_) => panic!("no `selector` expected at this point"),
     };
     arena.add(v)
 }
 
 /// converts LogicalPlan to ALogicalPlan
 /// it adds expressions & lps to the respective arenas as it traverses the plan
 /// finally it returns the top node of the logical plan
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/format.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/format.rs`

 * *Files 0% similar despite different names*

```diff
@@ -233,15 +233,15 @@
                 input_left,
                 input_right,
                 left_on,
                 right_on,
                 options,
                 ..
             } => {
-                let how = &options.how;
+                let how = &options.args.how;
                 write!(f, "{:indent$}{how} JOIN:", "")?;
                 write!(f, "\n{:indent$}LEFT PLAN ON: {left_on:?}", "")?;
                 input_left._format(f, sub_indent)?;
                 write!(f, "\n{:indent$}RIGHT PLAN ON: {right_on:?}", "")?;
                 input_right._format(f, sub_indent)?;
                 write!(f, "\n{:indent$}END {} JOIN", "", how)
             }
@@ -413,14 +413,15 @@
             Wildcard => write!(f, "*"),
             Exclude(column, names) => write!(f, "{column:?}, EXCEPT {names:?}"),
             KeepName(e) => write!(f, "KEEP NAME {e:?}"),
             RenameAlias { expr, .. } => write!(f, "RENAME_ALIAS {expr:?}"),
             Columns(names) => write!(f, "COLUMNS({names:?})"),
             DtypeColumn(dt) => write!(f, "COLUMN OF DTYPE: {dt:?}"),
             Cache { input, .. } => write!(f, "CACHE {input:?}"),
+            Selector(_) => write!(f, "SELECTOR"),
         }
     }
 }
 
 impl Debug for Operator {
     fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
         Display::fmt(self, f)
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/functions/drop.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/functions/drop.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/functions/merge_sorted.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/functions/merge_sorted.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/functions/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/functions/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/functions/rename.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/functions/rename.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/iterator.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/iterator.rs`

 * *Files 3% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+use polars_arrow::error::PolarsResult;
+
 use crate::prelude::*;
 macro_rules! push_expr {
     ($current_expr:expr, $push:ident, $iter:ident) => {{
         use Expr::*;
         match $current_expr {
             Nth(_) | Column(_) | Literal(_) | Wildcard | Columns(_) | DtypeColumn(_) | Count => {}
             Alias(e, _) => $push(e),
@@ -87,14 +89,16 @@
                 // latest, so that it is popped first
                 $push(input);
             }
             Exclude(e, _) => $push(e),
             KeepName(e) => $push(e),
             Cache { input, .. } => $push(input),
             RenameAlias { expr, .. } => $push(expr),
+            // pass
+            Selector(_) => {}
         }
     }};
 }
 
 impl Expr {
     /// Expr::mutate().apply(fn())
     pub fn mutate(&mut self) -> ExprMut {
@@ -113,24 +117,32 @@
     /// # Arguments
     /// * `f` - A function that may mutate an expression. If the function returns `true` iteration
     /// continues.
     pub fn apply<F>(&mut self, mut f: F)
     where
         F: FnMut(&mut Expr) -> bool,
     {
+        let _ = self.try_apply(|e| Ok(f(e)));
+    }
+
+    pub fn try_apply<F>(&mut self, mut f: F) -> PolarsResult<()>
+    where
+        F: FnMut(&mut Expr) -> PolarsResult<bool>,
+    {
         while let Some(current_expr) = self.stack.pop() {
             // the order is important, we first modify the Expr
             // before we push its children on the stack.
             // The modification can make the children invalid.
-            if !f(current_expr) {
+            if !f(current_expr)? {
                 break;
             }
             let mut push = |e: &'a mut Expr| self.stack.push(e);
             push_expr!(current_expr, push, iter_mut);
         }
+        Ok(())
     }
 }
 
 pub struct ExprIter<'a> {
     stack: Vec<&'a Expr>,
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/lit.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/lit.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -45,15 +45,14 @@
 #[cfg(feature = "serde")]
 use serde::{Deserialize, Serialize};
 
 #[cfg(any(feature = "ipc", feature = "parquet", feature = "csv", feature = "cse"))]
 pub use crate::logical_plan::optimizer::file_caching::{
     collect_fingerprints, find_column_union_and_fingerprints, FileCacher, FileFingerPrint,
 };
-use crate::logical_plan::schema::FileInfo;
 
 #[derive(Clone, Copy, Debug)]
 pub enum Context {
     /// Any operation that is done on groups
     Aggregation,
     /// Any operation that is done while projection/ selection of data
     Default,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/cache_states.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/cache_states.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/cse.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/cse.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/delay_rechunk.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/delay_rechunk.rs`

 * *Files 7% similar despite different names*

```diff
@@ -28,16 +28,14 @@
             ALogicalPlan::Aggregate { input, .. } => {
                 if !self.processed.insert(node.0) {
                     return None;
                 };
 
                 use ALogicalPlan::*;
                 let mut input_node = None;
-                let mut union_parent = None;
-                let mut previous_node = *input;
                 for (node, lp) in (&*lp_arena).iter(*input) {
                     match lp {
                         // we get the input node
                         #[cfg(feature = "parquet")]
                         ParquetScan { .. } => {
                             input_node = Some(node);
                             break;
@@ -48,48 +46,42 @@
                             break;
                         }
                         #[cfg(feature = "ipc")]
                         IpcScan { .. } => {
                             input_node = Some(node);
                             break;
                         }
-                        Union { .. } => union_parent = Some(previous_node),
+                        Union { .. } => {
+                            input_node = Some(node);
+                            break;
+                        }
                         // don't delay rechunk if there is a join first
                         Join { .. } => break,
                         _ => {}
                     }
-                    previous_node = node;
                 }
 
                 if let Some(node) = input_node {
                     match lp_arena.get_mut(node) {
                         #[cfg(feature = "csv")]
                         CsvScan { options, .. } => {
                             options.rechunk = false;
                         }
                         #[cfg(feature = "parquet")]
                         ParquetScan { options, .. } => options.rechunk = false,
                         #[cfg(feature = "ipc")]
                         IpcScan { options, .. } => {
                             options.rechunk = false;
                         }
+                        Union { options, .. } => {
+                            options.rechunk = false;
+                        }
                         _ => unreachable!(),
                     }
                 };
-                if let Some(parent_node) = union_parent {
-                    // remove the rechunk function
-                    if let MapFunction {
-                        input,
-                        function: FunctionNode::Rechunk,
-                        ..
-                    } = lp_arena.get(parent_node)
-                    {
-                        lp_arena.swap(*input, parent_node)
-                    }
-                }
 
                 None
             }
             _ => None,
         }
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/drop_nulls.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/drop_nulls.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/fast_projection.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/fast_projection.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/file_caching.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/file_caching.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/flatten_union.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/flatten_union.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/fused.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/fused.rs`

 * *Files 8% similar despite different names*

```diff
@@ -1,20 +1,25 @@
 use super::*;
 
 pub struct FusedArithmetic {}
 
 fn get_expr(input: Vec<Node>, op: FusedOperator) -> AExpr {
+    let mut options = FunctionOptions {
+        collect_groups: ApplyOptions::ApplyFlat,
+        cast_to_supertypes: true,
+        ..Default::default()
+    };
+    // order of operations change because of FMA
+    // so we must toggle this check off
+    // it is still safe as it is a trusted operation
+    unsafe { options.no_check_lengths() }
     AExpr::Function {
         input,
         function: FunctionExpr::Fused(op),
-        options: FunctionOptions {
-            collect_groups: ApplyOptions::ApplyFlat,
-            cast_to_supertypes: true,
-            ..Default::default()
-        },
+        options,
     }
 }
 
 fn check_eligible(
     left: &Node,
     right: &Node,
     lp_node: Node,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/keys.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/keys.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -429,15 +429,15 @@
                             // any operation that checks for equality or ordering can be wrong because
                             // the join can produce null values
                             matches!(e, AExpr::BinaryExpr {op, ..} if !matches!(op, Operator::NotEq));
                     if has_aexpr(predicate, expr_arena, matches)
                         // join might create null values.
                         || has_aexpr(predicate, expr_arena, checks_nulls)
                         // only these join types produce null values
-                        && join_produces_null(&options.how) {
+                        && join_produces_null(&options.args.how) {
                         local_predicates.push(predicate);
                         continue;
                     }
                     // these indicate to which tables we are going to push down the predicate
                     let mut filter_left = false;
                     let mut filter_right = false;
 
@@ -462,15 +462,15 @@
                                 &mut pushdown_right,
                                 predicate,
                                 expr_arena,
                             );
                             filter_right = true;
                         }
                     }
-                    match (filter_left, filter_right, &options.how) {
+                    match (filter_left, filter_right, &options.args.how) {
                         // if not pushed down on one of the tables we have to do it locally.
                         (false, false, _) |
                         // if left join and predicate only available in right table,
                         // 'we should not filter right, because that would lead to
                         // invalid results.
                         // see: #2057
                         (false, true, JoinType::Left)
@@ -617,15 +617,15 @@
                         // simplify expressions before we translate them to pyarrow
                         let lp = PythonScan {options: options.clone(), predicate: Some(predicate)};
                         let lp_top = lp_arena.add(lp);
                         let stack_opt = StackOptimizer{};
                         let lp_top = stack_opt.optimize_loop(&mut [Box::new(SimplifyExprRule{})], expr_arena, lp_arena, lp_top).unwrap();
                         let PythonScan {options: _, predicate: Some(predicate)} = lp_arena.take(lp_top) else {unreachable!()};
 
-                        match super::super::pyarrow::predicate_to_pa(predicate, expr_arena) {
+                        match super::super::pyarrow::predicate_to_pa(predicate, expr_arena, Default::default()) {
                             // we we able to create a pyarrow string, mutate the options
                             Some(eval_str) => {
                                 options.predicate = Some(eval_str)
                             },
                             // we were not able to translate the predicate
                             // apply here
                             None => {
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/rename.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/rename.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/utils.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/melt.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/melt.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/generic.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/generic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/groupby.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/groupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/hstack.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/hstack.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/joins.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/joins.rs`

 * *Files 2% similar despite different names*

```diff
@@ -47,15 +47,15 @@
     let n = acc_projections.len() * 2;
     let mut pushdown_left = Vec::with_capacity(n);
     let mut pushdown_right = Vec::with_capacity(n);
     let mut names_left = PlHashSet::with_capacity(n);
     let mut names_right = PlHashSet::with_capacity(n);
     let mut local_projection = Vec::with_capacity(n);
 
-    let JoinType::AsOf(asof_options) = &options.how else {unreachable!()};
+    let JoinType::AsOf(asof_options) = &options.args.how else {unreachable!()};
 
     // if there are no projections we don't have to do anything (all columns are projected)
     // otherwise we build local projections to sort out proper column names due to the
     // join operation
     //
     // Joins on columns with different names, for example
     // left_on = "a", right_on = "b
@@ -200,15 +200,15 @@
     acc_projections: Vec<Node>,
     _projected_names: PlHashSet<Arc<str>>,
     projections_seen: usize,
     lp_arena: &mut Arena<ALogicalPlan>,
     expr_arena: &mut Arena<AExpr>,
 ) -> PolarsResult<ALogicalPlan> {
     #[cfg(feature = "asof_join")]
-    if matches!(options.how, JoinType::AsOf(_)) {
+    if matches!(options.args.how, JoinType::AsOf(_)) {
         return process_asof_join(
             proj_pd,
             input_left,
             input_right,
             left_on,
             right_on,
             options,
@@ -359,15 +359,15 @@
     // did not succeed push down in any tables.,
     // this might be due to the suffix in the projection name
     // this branch tries to pushdown the column without suffix
     {
         // Column name of the projection without any alias.
         let leaf_column_name = aexpr_to_leaf_names(proj, expr_arena).pop().unwrap();
 
-        let suffix = options.suffix.as_ref();
+        let suffix = options.args.suffix();
         // If _right suffix exists we need to push a projection down without this
         // suffix.
         if leaf_column_name.ends_with(suffix) {
             // downwards name is the name without the _right i.e. "foo".
             let (downwards_name, _) =
                 leaf_column_name.split_at(leaf_column_name.len() - suffix.len());
 
@@ -435,24 +435,23 @@
     left_on: Vec<Node>,
     right_on: Vec<Node>,
     options: JoinOptions,
     lp_arena: &mut Arena<ALogicalPlan>,
     expr_arena: &mut Arena<AExpr>,
     local_projection: &mut [Node],
 ) -> ALogicalPlan {
-    let suffix = options.suffix.clone();
-
+    let suffix = options.args.suffix();
     let alp = ALogicalPlanBuilder::new(input_left, expr_arena, lp_arena)
-        .join(input_right, left_on, right_on, options)
+        .join(input_right, left_on, right_on, options.clone())
         .build();
     let schema_after_join = alp.schema(lp_arena);
 
     for proj in local_projection {
         for name in aexpr_to_leaf_names(*proj, expr_arena) {
-            if name.contains(suffix.as_ref()) && schema_after_join.get(&name).is_none() {
+            if name.contains(suffix) && schema_after_join.get(&name).is_none() {
                 let new_name = &name.as_ref()[..name.len() - suffix.len()];
 
                 let renamed = aexpr_assign_renamed_leaf(*proj, expr_arena, &name, new_name);
 
                 let aliased = expr_arena.add(AExpr::Alias(renamed, name));
                 *proj = aliased;
             }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/mod.rs`

 * *Files 0% similar despite different names*

```diff
@@ -641,15 +641,15 @@
             Join {
                 input_left,
                 input_right,
                 left_on,
                 right_on,
                 options,
                 ..
-            } => match options.how {
+            } => match options.args.how {
                 #[cfg(feature = "semi_anti_join")]
                 JoinType::Semi | JoinType::Anti => process_semi_anti_join(
                     self,
                     input_left,
                     input_right,
                     left_on,
                     right_on,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/projection.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/projection.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/rename.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/rename.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/semi_anti_join.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/semi_anti_join.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/simplify_expr.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/simplify_expr.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_expr.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_expr.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_lp.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_lp.rs`

 * *Files 1% similar despite different names*

```diff
@@ -223,15 +223,15 @@
 
                 let lp_right = lp_arena.take(input_right);
                 let lp_right = self.pushdown(lp_right, None, lp_arena, expr_arena)?;
                 let input_right = lp_arena.add(lp_right);
 
                 // then assign the slice state to the join operation
 
-                options.slice = Some((state.offset, state.len as usize));
+                options.args.slice = Some((state.offset, state.len as usize));
 
                 Ok(Join {
                     input_left,
                     input_right,
                     schema,
                     left_on,
                     right_on,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/stack_opt.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/stack_opt.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/binary.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/options.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/options.rs`

 * *Files 8% similar despite different names*

```diff
@@ -123,14 +123,15 @@
 pub struct UnionOptions {
     pub slice: Option<(i64, usize)>,
     pub parallel: bool,
     // known row_output, estimated row output
     pub rows: (Option<usize>, usize),
     pub from_partitioned_ds: bool,
     pub flattened_by_opt: bool,
+    pub rechunk: bool,
 }
 
 #[derive(Clone, Debug, PartialEq, Eq, Default)]
 #[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
 pub struct GroupbyOptions {
     #[cfg(feature = "dynamic_groupby")]
     pub dynamic: Option<DynamicGroupOptions>,
@@ -152,30 +153,40 @@
     pub maintain_order: bool,
     /// Which rows to keep.
     pub keep_strategy: UniqueKeepStrategy,
     /// Take only a slice of the result
     pub slice: Option<(i64, usize)>,
 }
 
-#[derive(Copy, Clone, Debug, PartialEq, Eq)]
+#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]
 #[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
 pub enum ApplyOptions {
     /// Collect groups to a list and apply the function over the groups.
     /// This can be important in aggregation context.
     // e.g. [g1, g1, g2] -> [[g1, g2], g2]
     ApplyGroups,
     // collect groups to a list and then apply
     // e.g. [g1, g1, g2] -> list([g1, g1, g2])
     ApplyList,
     // do not collect before apply
     // e.g. [g1, g1, g2] -> [g1, g1, g2]
     ApplyFlat,
 }
 
-#[derive(Clone, Copy, PartialEq, Eq, Debug)]
+// a boolean that can only be set to `false` safely
+#[derive(Clone, Copy, PartialEq, Eq, Debug, Hash)]
+#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
+pub struct UnsafeBool(bool);
+impl Default for UnsafeBool {
+    fn default() -> Self {
+        UnsafeBool(true)
+    }
+}
+
+#[derive(Clone, Copy, PartialEq, Eq, Debug, Hash)]
 #[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
 pub struct FunctionOptions {
     /// Collect groups to a list and apply the function over the groups.
     /// This can be important in aggregation context.
     pub collect_groups: ApplyOptions,
     /// There can be two ways of expanding wildcards:
     ///
@@ -213,37 +224,49 @@
     // apply physical expression may rename the output of this function
     pub allow_rename: bool,
     // if set, then the `Series` passed to the function in the groupby operation
     // will ensure the name is set. This is an extra heap allocation per group.
     pub pass_name_to_apply: bool,
     // For example a `unique` or a `slice`
     pub changes_length: bool,
+    // Validate the output of a `map`.
+    // this should always be true or we could OOB
+    pub check_lengths: UnsafeBool,
 }
 
 impl FunctionOptions {
     /// Any function that is sensitive to the number of elements in a group
     /// - Aggregations
     /// - Sorts
     /// - Counts
     pub fn is_groups_sensitive(&self) -> bool {
         matches!(self.collect_groups, ApplyOptions::ApplyGroups)
     }
+
+    #[cfg(feature = "fused")]
+    pub(crate) unsafe fn no_check_lengths(&mut self) {
+        self.check_lengths = UnsafeBool(false);
+    }
+    pub fn check_lengths(&self) -> bool {
+        self.check_lengths.0
+    }
 }
 
 impl Default for FunctionOptions {
     fn default() -> Self {
         FunctionOptions {
             collect_groups: ApplyOptions::ApplyGroups,
             input_wildcard_expansion: false,
             auto_explode: false,
             fmt_str: "",
             cast_to_supertypes: false,
             allow_rename: false,
             pass_name_to_apply: false,
             changes_length: false,
+            check_lengths: UnsafeBool(true),
         }
     }
 }
 
 #[derive(Clone, Copy, PartialEq, Eq, Debug)]
 pub struct LogicalPlanUdfOptions {
     ///  allow predicate pushdown optimizations
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/projection.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/projection.rs`

 * *Files 22% similar despite different names*

```diff
@@ -93,16 +93,16 @@
 /// that are selected by that regex in `result`.
 fn expand_regex(
     expr: &Expr,
     result: &mut Vec<Expr>,
     schema: &Schema,
     pattern: &str,
 ) -> PolarsResult<()> {
-    let re = regex::Regex::new(pattern)
-        .unwrap_or_else(|_| panic!("invalid regular expression in column: {pattern}"));
+    let re =
+        regex::Regex::new(pattern).map_err(|e| polars_err!(ComputeError: "invalid regex {}", e))?;
     for name in schema.iter_names() {
         if re.is_match(name) {
             let mut new_expr = expr.clone();
 
             new_expr.mutate().apply(|e| match &e {
                 Expr::Column(pat) if pat.as_ref() == pattern => {
                     *e = Expr::Column(Arc::from(name.as_str()));
@@ -330,14 +330,54 @@
             }
             Some(st_val) => st = get_supertype(&st_val, &dtype),
         }
     }
     st
 }
 
+#[derive(Copy, Clone)]
+struct ExpansionFlags {
+    multiple_columns: bool,
+    has_nth: bool,
+    has_wildcard: bool,
+    replace_fill_null_type: bool,
+    has_selector: bool,
+}
+
+fn find_flags(expr: &Expr) -> ExpansionFlags {
+    let mut multiple_columns = false;
+    let mut has_nth = false;
+    let mut has_wildcard = false;
+    let mut replace_fill_null_type = false;
+    let mut has_selector = false;
+
+    // do a single pass and collect all flags at once.
+    // supertypes/modification that can be done in place are also don e in that pass
+    for expr in expr {
+        match expr {
+            Expr::Columns(_) | Expr::DtypeColumn(_) => multiple_columns = true,
+            Expr::Nth(_) => has_nth = true,
+            Expr::Wildcard => has_wildcard = true,
+            Expr::Selector(_) => has_selector = true,
+            Expr::Function {
+                function: FunctionExpr::FillNull { .. },
+                ..
+            } => replace_fill_null_type = true,
+            _ => {}
+        }
+    }
+    ExpansionFlags {
+        multiple_columns,
+        has_nth,
+        has_wildcard,
+        replace_fill_null_type,
+        has_selector,
+    }
+}
+
 /// In case of single col(*) -> do nothing, no selection is the same as select all
 /// In other cases replace the wildcard with an expression with all columns
 pub(crate) fn rewrite_projections(
     exprs: Vec<Expr>,
     schema: &Schema,
     keys: &[Expr],
 ) -> PolarsResult<Vec<Expr>> {
@@ -345,84 +385,30 @@
 
     for mut expr in exprs {
         let result_offset = result.len();
 
         // functions can have col(["a", "b"]) or col(Utf8) as inputs
         expr = expand_function_inputs(expr, schema);
 
-        let mut multiple_columns = false;
-        let mut has_nth = false;
-        let mut has_wildcard = false;
-        let mut replace_fill_null_type = false;
-
-        // do a single pass and collect all flags at once.
-        // supertypes/modification that can be done in place are also don e in that pass
-        for expr in &expr {
-            match expr {
-                Expr::Columns(_) | Expr::DtypeColumn(_) => multiple_columns = true,
-                Expr::Nth(_) => has_nth = true,
-                Expr::Wildcard => has_wildcard = true,
-                Expr::Function {
-                    function: FunctionExpr::FillNull { .. },
-                    ..
-                } => replace_fill_null_type = true,
-                _ => {}
-            }
+        let mut flags = find_flags(&expr);
+        if flags.has_selector {
+            replace_selector(&mut expr, schema, keys)?;
+            // the selector is replaced with Expr::Columns
+            flags.multiple_columns = true;
         }
 
-        if has_nth {
-            replace_nth(&mut expr, schema);
-        }
-
-        // has multiple column names
-        // the expanded columns are added to the result
-        if multiple_columns {
-            if let Some(e) = expr
-                .into_iter()
-                .find(|e| matches!(e, Expr::Columns(_) | Expr::DtypeColumn(_)))
-            {
-                match &e {
-                    Expr::Columns(names) => expand_columns(&expr, &mut result, names)?,
-                    Expr::DtypeColumn(dtypes) => {
-                        // keep track of column excluded from the dtypes
-                        let exclude = prepare_excluded(&expr, schema, keys)?;
-                        expand_dtypes(&expr, &mut result, schema, dtypes, &exclude)?
-                    }
-                    _ => {}
-                }
-            }
-        }
-        // has multiple column names due to wildcards
-        else if has_wildcard {
-            // keep track of column excluded from the wildcard
-            let exclude = prepare_excluded(&expr, schema, keys)?;
-            // this path prepares the wildcard as input for the Function Expr
-            replace_wildcard(&expr, &mut result, &exclude, schema)?;
-        }
-        // can have multiple column names due to a regex
-        else {
-            #[allow(clippy::collapsible_else_if)]
-            #[cfg(feature = "regex")]
-            {
-                replace_regex(&expr, &mut result, schema)?
-            }
-            #[cfg(not(feature = "regex"))]
-            {
-                let expr = rewrite_special_aliases(expr)?;
-                result.push(expr)
-            }
-        }
+        replace_and_add_to_results(expr, flags, &mut result, schema, keys)?;
 
         // this is done after all expansion (wildcard, column, dtypes)
         // have been done. This will ensure the conversion to aexpr does
         // not panic because of an unexpected wildcard etc.
 
         // the expanded expressions are written to result, so we pick
         // them up there.
-        if replace_fill_null_type {
+        if flags.replace_fill_null_type {
             for e in &mut result[result_offset..] {
                 e.mutate().apply(|e| {
                     if let Expr::Function {
                         input,
                         function: FunctionExpr::FillNull { super_type },
                         ..
                     } = e
@@ -436,7 +422,137 @@
                     true
                 })
             }
         }
     }
     Ok(result)
 }
+
+fn replace_and_add_to_results(
+    mut expr: Expr,
+    flags: ExpansionFlags,
+    result: &mut Vec<Expr>,
+    schema: &Schema,
+    keys: &[Expr],
+) -> PolarsResult<()> {
+    if flags.has_nth {
+        replace_nth(&mut expr, schema);
+    }
+
+    // has multiple column names
+    // the expanded columns are added to the result
+    if flags.multiple_columns {
+        if let Some(e) = expr
+            .into_iter()
+            .find(|e| matches!(e, Expr::Columns(_) | Expr::DtypeColumn(_)))
+        {
+            match &e {
+                Expr::Columns(names) => expand_columns(&expr, result, names)?,
+                Expr::DtypeColumn(dtypes) => {
+                    // keep track of column excluded from the dtypes
+                    let exclude = prepare_excluded(&expr, schema, keys)?;
+                    expand_dtypes(&expr, result, schema, dtypes, &exclude)?
+                }
+                _ => {}
+            }
+        }
+    }
+    // has multiple column names due to wildcards
+    else if flags.has_wildcard {
+        // keep track of column excluded from the wildcard
+        let exclude = prepare_excluded(&expr, schema, keys)?;
+        // this path prepares the wildcard as input for the Function Expr
+        replace_wildcard(&expr, result, &exclude, schema)?;
+    }
+    // can have multiple column names due to a regex
+    else {
+        #[allow(clippy::collapsible_else_if)]
+        #[cfg(feature = "regex")]
+        {
+            replace_regex(&expr, result, schema)?
+        }
+        #[cfg(not(feature = "regex"))]
+        {
+            let expr = rewrite_special_aliases(expr)?;
+            result.push(expr)
+        }
+    }
+    Ok(())
+}
+
+fn replace_selector_inner(
+    s: Selector,
+    members: &mut PlIndexSet<Expr>,
+    scratch: &mut Vec<Expr>,
+    schema: &Schema,
+    keys: &[Expr],
+) -> PolarsResult<()> {
+    match s {
+        Selector::Root(expr) => {
+            let local_flags = find_flags(&expr);
+            replace_and_add_to_results(*expr, local_flags, scratch, schema, keys)?;
+            members.extend(scratch.drain(..))
+        }
+        Selector::Add(lhs, rhs) => {
+            replace_selector_inner(*lhs, members, scratch, schema, keys)?;
+            replace_selector_inner(*rhs, members, scratch, schema, keys)?;
+        }
+        Selector::Sub(lhs, rhs) => {
+            // fill lhs
+            replace_selector_inner(*lhs, members, scratch, schema, keys)?;
+
+            // subtract rhs
+            let mut rhs_members = Default::default();
+            replace_selector_inner(*rhs, &mut rhs_members, scratch, schema, keys)?;
+
+            let mut new_members = PlIndexSet::with_capacity(members.len());
+            for e in members.drain(..) {
+                if !rhs_members.contains(&e) {
+                    new_members.insert(e);
+                }
+            }
+
+            *members = new_members;
+        }
+        Selector::InterSect(lhs, rhs) => {
+            // fill lhs
+            replace_selector_inner(*lhs, members, scratch, schema, keys)?;
+
+            // fill rhs
+            let mut rhs_members = Default::default();
+            replace_selector_inner(*rhs, &mut rhs_members, scratch, schema, keys)?;
+
+            *members = members.intersection(&rhs_members).cloned().collect()
+        }
+    }
+    Ok(())
+}
+
+fn replace_selector(expr: &mut Expr, schema: &Schema, keys: &[Expr]) -> PolarsResult<()> {
+    // first pass we replace the selectors
+    // with Expr::Columns
+    // we expand the `to_add` columns
+    // and then subtract the `to_subtract` columns
+    expr.mutate().try_apply(|e| match e {
+        Expr::Selector(s) => {
+            let mut swapped = Selector::Root(Box::new(Expr::Wildcard));
+            std::mem::swap(s, &mut swapped);
+
+            let mut members = PlIndexSet::new();
+            replace_selector_inner(swapped, &mut members, &mut vec![], schema, keys)?;
+
+            *e = Expr::Columns(
+                members
+                    .into_iter()
+                    .map(|e| {
+                        let Expr::Column(name) = e else {unreachable!()};
+                        name.to_string()
+                    })
+                    .collect(),
+            );
+
+            Ok(true)
+        }
+        _ => Ok(true),
+    })?;
+    Ok(())
+}
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/pyarrow.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/pyarrow.rs`

 * *Files 4% similar despite different names*

```diff
@@ -1,36 +1,51 @@
 use std::fmt::Write;
 
 use polars_core::datatypes::AnyValue;
 
 use crate::prelude::*;
 
+#[derive(Default, Copy, Clone)]
+pub(super) struct Args {
+    // pyarrow doesn't allow `filter([True, False])`
+    // but does allow `filter(field("a").isin([True, False]))`
+    allow_literal_series: bool,
+}
+
 // convert to a pyarrow expression that can be evaluated with pythons eval
-pub(super) fn predicate_to_pa(predicate: Node, expr_arena: &Arena<AExpr>) -> Option<String> {
+pub(super) fn predicate_to_pa(
+    predicate: Node,
+    expr_arena: &Arena<AExpr>,
+    args: Args,
+) -> Option<String> {
     match expr_arena.get(predicate) {
         AExpr::BinaryExpr { left, right, op } => {
             if op.is_comparison() {
-                let left = predicate_to_pa(*left, expr_arena)?;
-                let right = predicate_to_pa(*right, expr_arena)?;
+                let left = predicate_to_pa(*left, expr_arena, args)?;
+                let right = predicate_to_pa(*right, expr_arena, args)?;
                 Some(format!("({left} {op} {right})"))
             } else {
                 None
             }
         }
         AExpr::Column(name) => Some(format!("pa.compute.field('{}')", name.as_ref())),
-        AExpr::Alias(input, _) => predicate_to_pa(*input, expr_arena),
+        AExpr::Alias(input, _) => predicate_to_pa(*input, expr_arena, args),
         AExpr::Literal(LiteralValue::Series(s)) => {
-            if s.is_empty() || s.len() > 100 {
+            if !args.allow_literal_series || s.is_empty() || s.len() > 100 {
                 None
             } else {
                 let mut list_repr = String::with_capacity(s.len() * 5);
                 list_repr.push('[');
                 for av in s.iter() {
-                    write!(list_repr, "{av}").ok()?;
-                    list_repr.push(',');
+                    if let AnyValue::Boolean(v) = av {
+                        let s = if v { "True" } else { "False" };
+                        write!(list_repr, "{},", s).unwrap();
+                    } else {
+                        write!(list_repr, "{av},").unwrap();
+                    }
                 }
 
                 // pop last comma
                 list_repr.pop();
                 list_repr.push(']');
 
                 Some(list_repr)
@@ -105,41 +120,43 @@
         }
         AExpr::Function {
             function: FunctionExpr::Boolean(BooleanFunction::IsNot),
             input,
             ..
         } => {
             let input = input.first().unwrap();
-            let input = predicate_to_pa(*input, expr_arena)?;
+            let input = predicate_to_pa(*input, expr_arena, args)?;
             Some(format!("~({input})"))
         }
         AExpr::Function {
             function: FunctionExpr::Boolean(BooleanFunction::IsNull),
             input,
             ..
         } => {
             let input = input.first().unwrap();
-            let input = predicate_to_pa(*input, expr_arena)?;
+            let input = predicate_to_pa(*input, expr_arena, args)?;
             Some(format!("({input}).is_null()"))
         }
         AExpr::Function {
             function: FunctionExpr::Boolean(BooleanFunction::IsNotNull),
             input,
             ..
         } => {
             let input = input.first().unwrap();
-            let input = predicate_to_pa(*input, expr_arena)?;
+            let input = predicate_to_pa(*input, expr_arena, args)?;
             Some(format!("~({input}).is_null()"))
         }
         AExpr::Function {
             function: FunctionExpr::Boolean(BooleanFunction::IsIn),
             input,
             ..
         } => {
-            let col = predicate_to_pa(*input.get(0)?, expr_arena)?;
-            let values = predicate_to_pa(*input.get(1)?, expr_arena)?;
+            let col = predicate_to_pa(*input.get(0)?, expr_arena, args)?;
+            let mut args = args;
+            args.allow_literal_series = true;
+            let values = predicate_to_pa(*input.get(1)?, expr_arena, args)?;
 
             Some(format!("({col}).isin({values})"))
         }
         _ => None,
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/logical_plan/schema.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/logical_plan/schema.rs`

 * *Files 3% similar despite different names*

```diff
@@ -139,15 +139,15 @@
                 let (known_size, estimated_size, filter_count_left) =
                     set_estimated_row_counts(input_left, lp_arena, expr_arena, 0);
                 options.rows_left = estimate_sizes(known_size, estimated_size, filter_count_left);
                 let (known_size, estimated_size, filter_count_right) =
                     set_estimated_row_counts(input_right, lp_arena, expr_arena, 0);
                 options.rows_right = estimate_sizes(known_size, estimated_size, filter_count_right);
 
-                let mut out = match options.how {
+                let mut out = match options.args.how {
                     JoinType::Left => {
                         let (known_size, estimated_size) = options.rows_left;
                         (known_size, estimated_size, filter_count_left)
                     }
                     JoinType::Cross | JoinType::Outer => {
                         let (known_size_left, estimated_size_left) = options.rows_left;
                         let (known_size_right, estimated_size_right) = options.rows_right;
@@ -164,15 +164,15 @@
                         if estimated_size_left > estimated_size_right {
                             (known_size_left, estimated_size_left, 0)
                         } else {
                             (known_size_right, estimated_size_right, 0)
                         }
                     }
                 };
-                apply_slice(&mut out, options.slice);
+                apply_slice(&mut out, options.args.slice);
                 lp_arena.replace(
                     root,
                     Join {
                         input_left,
                         input_right,
                         options,
                         schema,
@@ -223,15 +223,15 @@
 pub(crate) fn det_join_schema(
     schema_left: &SchemaRef,
     schema_right: &SchemaRef,
     left_on: &[Expr],
     right_on: &[Expr],
     options: &JoinOptions,
 ) -> PolarsResult<SchemaRef> {
-    match options.how {
+    match options.args.how {
         // semi and anti joins are just filtering operations
         // the schema will never change.
         #[cfg(feature = "semi_anti_join")]
         JoinType::Semi | JoinType::Anti => Ok(schema_left.clone()),
         _ => {
             // column names of left table
             let mut names: PlHashSet<&str> =
@@ -253,26 +253,25 @@
                 new_schema.with_column(field.name, field.dtype);
                 arena.clear();
             }
             // except in asof joins. Asof joins are not equi-joins
             // so the columns that are joined on, may have different
             // values so if the right has a different name, it is added to the schema
             #[cfg(feature = "asof_join")]
-            if let JoinType::AsOf(_) = &options.how {
+            if let JoinType::AsOf(_) = &options.args.how {
                 for (left_on, right_on) in left_on.iter().zip(right_on) {
                     let field_left =
                         left_on.to_field_amortized(schema_left, Context::Default, &mut arena)?;
                     let field_right =
                         right_on.to_field_amortized(schema_right, Context::Default, &mut arena)?;
                     if field_left.name != field_right.name {
                         if schema_left.contains(&field_right.name) {
                             use polars_core::frame::hash_join::_join_suffix_name;
                             new_schema.with_column(
-                                _join_suffix_name(&field_right.name, options.suffix.as_ref())
-                                    .into(),
+                                _join_suffix_name(&field_right.name, options.args.suffix()).into(),
                                 field_right.dtype,
                             );
                         } else {
                             new_schema.with_column(field_right.name, field_right.dtype);
                         }
                     }
                 }
@@ -284,28 +283,28 @@
                 right_names.insert(field.name);
             }
 
             for (name, dtype) in schema_right.iter() {
                 if !right_names.contains(name.as_str()) {
                     if names.contains(name.as_str()) {
                         #[cfg(feature = "asof_join")]
-                        if let JoinType::AsOf(asof_options) = &options.how {
+                        if let JoinType::AsOf(asof_options) = &options.args.how {
                             if let (Some(left_by), Some(right_by)) =
                                 (&asof_options.left_by, &asof_options.right_by)
                             {
                                 {
                                     // Do not add suffix. The column of the left table will be used
                                     if left_by.contains(name) && right_by.contains(name) {
                                         continue;
                                     }
                                 }
                             }
                         }
 
-                        let new_name = format_smartstring!("{}{}", name, options.suffix.as_ref());
+                        let new_name = format_smartstring!("{}{}", name, options.args.suffix());
                         new_schema.with_column(new_name, dtype.clone());
                     } else {
                         new_schema.with_column(name.clone(), dtype.clone());
                     }
                 }
             }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/prelude.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/prelude.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-plan/src/utils.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/src/utils.rs`

 * *Files 0% similar despite different names*

```diff
@@ -190,15 +190,15 @@
 /// unpack alias(col) to name of the root column name
 pub fn expr_to_leaf_column_name(expr: &Expr) -> PolarsResult<Arc<str>> {
     let mut roots = expr_to_root_column_exprs(expr);
     polars_ensure!(roots.len() <= 1, ComputeError: "found more than one root column name");
     match roots.pop() {
         Some(Expr::Column(name)) => Ok(name),
         Some(Expr::Wildcard) => polars_bail!(
-            ComputeError: "wildcard has not root column name",
+            ComputeError: "wildcard has no root column name",
         ),
         Some(_) => unreachable!(),
         None => polars_bail!(
             ComputeError: "no root column name found",
         ),
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/Cargo.toml` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/Cargo.toml`

 * *Files 12% similar despite different names*

```diff
@@ -2,14 +2,15 @@
 name = "polars-io"
 version= "0.30.0"
 authors = ["ritchie46 <ritchie46@gmail.com>"]
 edition = "2021"
 license = "MIT"
 repository = "https://github.com/pola-rs/polars"
 description = "IO related logic for the Polars DataFrame library"
+resolver = "2"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [features]
 # support for arrows json parsing
 json = ["arrow/io_json_write", "polars-json", "simd-json", "memmap", "lexical", "lexical-core", "serde_json"]
 # support for arrows ipc file parsing
@@ -32,26 +33,25 @@
 ]
 timezones = [
   "chrono-tz",
   "dtype-datetime",
 ]
 dtype-time = ["polars-core/dtype-time", "polars-core/temporal", "polars-time/dtype-time"]
 dtype-struct = ["polars-core/dtype-struct"]
+dtype-decimal = ["polars-core/dtype-decimal"]
 fmt = ["polars-core/fmt"]
 lazy = []
 parquet = ["polars-core/parquet", "arrow/io_parquet", "arrow/io_parquet_compression", "memmap"]
 async = ["async-trait", "futures", "tokio", "arrow/io_ipc_write_async", "polars-error/regex"]
 cloud = ["object_store", "async", "url"]
 aws = ["object_store/aws", "cloud", "polars-core/aws"]
 azure = ["object_store/azure", "cloud", "polars-core/azure"]
 gcp = ["object_store/gcp", "cloud", "polars-core/gcp"]
 partition = ["polars-core/partition_by"]
 temporal = ["dtype-datetime", "dtype-date", "dtype-time"]
-# don't use this
-private = ["polars-time/private"]
 simd = []
 
 [dependencies]
 ahash= "0.8"
 async-trait = { version = "0.1.59", optional = true }
 bytes = "1.3.0"
 chrono = { version = "0.4", default-features = false, features = ["std"], optional = true }
@@ -61,36 +61,36 @@
 futures = { version = "0.3.25", optional = true }
 home = "0.5.4"
 lexical = { version = "6", optional = true, default-features = false, features = ["std", "parse-integers"] }
 lexical-core = { version = "0.8", optional = true }
 memchr= "2"
 memmap = { package = "memmap2", version = "0.5.2", optional = true }
 num-traits= "0.2"
-object_store = { version = "0.5.3", default-features = false, optional = true }
+object_store = { version = "0.6.0", default-features = false, optional = true }
 once_cell = "1"
 polars-arrow = { version = "0.30.0", path = "../polars-arrow" }
-polars-core = { version = "0.30.0", path = "../polars-core", features = ["private"], default-features = false }
+polars-core = { version = "0.30.0", path = "../polars-core", features = [], default-features = false }
 polars-error = { version = "0.30.0", path = "../polars-error", default-features = false }
 polars-json = { version = "0.30.0", optional = true, path = "../polars-json" }
-polars-time = { version = "0.30.0", path = "../polars-time", features = ["private"], default-features = false, optional = true }
+polars-time = { version = "0.30.0", path = "../polars-time", features = [], default-features = false, optional = true }
 polars-utils = { version = "0.30.0", path = "../polars-utils" }
 rayon= "1.6"
 regex = "1.6"
 serde = { version = "1", features = ["derive"], optional = true }
 serde_json = { version = "1", optional = true, default-features = false, features = ["alloc", "raw_value"] }
 simd-json = { version = "0.10", optional = true, features = ["allow-non-simd", "known-key"] }
 simdutf8 = { version = "0.1", optional = true }
 tokio = { version = "1.26.0", features = ["net"], optional = true }
 url = { version = "2.3.1", optional = true }
 
 [dependencies.arrow]
 package = "arrow2"
-# git = "https://github.com/jorgecarleitao/arrow2"
+git = "https://github.com/jorgecarleitao/arrow2"
 # git = "https://github.com/ritchie46/arrow2"
-# rev = "1491c6e8f4fd100f53c358e4f3ef1536d9e75090"
+rev = "fb5e4d591c7149df590a330365fae55d2370962f"
 # path = "../arrow2"
 # branch = "polars_2023-05-25"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
@@ -99,14 +99,11 @@
   "compute_cast",
   "compute_comparison",
   "compute_concatenate",
   "compute_filter",
   "compute_if_then_else",
 ]
 
-[dev-dependencies]
-tempdir = "0.3.7"
-
 [package.metadata.docs.rs]
 all-features = true
 # defines the configuration attribute `docsrs`
 rustdoc-args = ["--cfg", "docsrs"]
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/LICENSE` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/avro/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/avro/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/avro/read.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/avro/read.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/avro/write.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/avro/write.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/cloud/adaptors.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/cloud/adaptors.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/cloud/glob.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/cloud/glob.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/cloud/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/cloud/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/buffer.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/buffer.rs`

 * *Files 3% similar despite different names*

```diff
@@ -419,45 +419,35 @@
     } else if !ignore_errors && std::str::from_utf8(bytes).is_err() {
         polars_bail!(ComputeError: "invalid utf-8 sequence");
     } else {
         buf.builder.append_null();
         return Ok(());
     };
 
-    match &buf.compiled {
-        Some(compiled) => match DatetimeInfer::<T::Native>::try_from(compiled.pattern) {
-            Ok(mut infer) => {
-                let parsed = infer.parse(val);
-                buf.compiled = Some(infer);
-                buf.builder.append_option(parsed);
-                Ok(())
-            }
-            Err(_) => {
-                buf.builder.append_null();
-                Ok(())
-            }
-        },
+    let pattern = match &buf.compiled {
+        Some(compiled) => compiled.pattern,
         None => match infer_pattern_single(val) {
+            Some(pattern) => pattern,
             None => {
                 buf.builder.append_null();
-                Ok(())
+                return Ok(());
             }
-            Some(pattern) => match DatetimeInfer::<T::Native>::try_from(pattern) {
-                Ok(mut infer) => {
-                    let parsed = infer.parse(val);
-                    buf.compiled = Some(infer);
-                    buf.builder.append_option(parsed);
-                    Ok(())
-                }
-                Err(_) => {
-                    buf.builder.append_null();
-                    Ok(())
-                }
-            },
         },
+    };
+    match DatetimeInfer::<T::Native>::try_from(pattern) {
+        Ok(mut infer) => {
+            let parsed = infer.parse(val);
+            buf.compiled = Some(infer);
+            buf.builder.append_option(parsed);
+            Ok(())
+        }
+        Err(_) => {
+            buf.builder.append_null();
+            Ok(())
+        }
     }
 }
 
 #[cfg(any(feature = "dtype-datetime", feature = "dtype-date"))]
 impl<T> ParsedBuffer for DatetimeField<T>
 where
     T: PolarsNumericType,
@@ -530,18 +520,18 @@
                     capacity,
                     str_capacity,
                     quote_char,
                     encoding,
                     ignore_errors,
                 )),
                 #[cfg(feature = "dtype-datetime")]
-                DataType::Datetime(tu, offset) => Buffer::Datetime {
+                DataType::Datetime(time_unit, time_zone) => Buffer::Datetime {
                     buf: DatetimeField::new(name, capacity),
-                    tu: *tu,
-                    offset: offset.clone(),
+                    time_unit: *time_unit,
+                    time_zone: time_zone.clone(),
                 },
                 #[cfg(feature = "dtype-date")]
                 &DataType::Date => Buffer::Date(DatetimeField::new(name, capacity)),
                 #[cfg(feature = "dtype-categorical")]
                 &DataType::Categorical(_) => {
                     Buffer::Categorical(CategoricalField::new(name, capacity, quote_char))
                 }
@@ -564,16 +554,16 @@
     Float32(PrimitiveChunkedBuilder<Float32Type>),
     Float64(PrimitiveChunkedBuilder<Float64Type>),
     /// Stores the Utf8 fields and the total string length seen for that column
     Utf8(Utf8Field),
     #[cfg(feature = "dtype-datetime")]
     Datetime {
         buf: DatetimeField<Int64Type>,
-        tu: TimeUnit,
-        offset: Option<String>,
+        time_unit: TimeUnit,
+        time_zone: Option<TimeZone>,
     },
     #[cfg(feature = "dtype-date")]
     Date(DatetimeField<Int32Type>),
     #[allow(dead_code)]
     Categorical(CategoricalField<'a>),
 }
 
@@ -584,19 +574,23 @@
             Buffer::Int32(v) => v.finish().into_series(),
             Buffer::Int64(v) => v.finish().into_series(),
             Buffer::UInt32(v) => v.finish().into_series(),
             Buffer::UInt64(v) => v.finish().into_series(),
             Buffer::Float32(v) => v.finish().into_series(),
             Buffer::Float64(v) => v.finish().into_series(),
             #[cfg(feature = "dtype-datetime")]
-            Buffer::Datetime { buf, tu, offset } => buf
+            Buffer::Datetime {
+                buf,
+                time_unit,
+                time_zone,
+            } => buf
                 .builder
                 .finish()
                 .into_series()
-                .cast(&DataType::Datetime(tu, offset))
+                .cast(&DataType::Datetime(time_unit, time_zone))
                 .unwrap(),
             #[cfg(feature = "dtype-date")]
             Buffer::Date(v) => v
                 .builder
                 .finish()
                 .into_series()
                 .cast(&DataType::Date)
@@ -696,15 +690,15 @@
             Buffer::Int64(_) => DataType::Int64,
             Buffer::UInt32(_) => DataType::UInt32,
             Buffer::UInt64(_) => DataType::UInt64,
             Buffer::Float32(_) => DataType::Float32,
             Buffer::Float64(_) => DataType::Float64,
             Buffer::Utf8(_) => DataType::Utf8,
             #[cfg(feature = "dtype-datetime")]
-            Buffer::Datetime { tu, .. } => DataType::Datetime(*tu, None),
+            Buffer::Datetime { time_unit, .. } => DataType::Datetime(*time_unit, None),
             #[cfg(feature = "dtype-date")]
             Buffer::Date(_) => DataType::Date,
             Buffer::Categorical(_) => {
                 #[cfg(feature = "dtype-categorical")]
                 {
                     DataType::Categorical(None)
                 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/mod.rs`

 * *Files 4% similar despite different names*

```diff
@@ -42,17 +42,14 @@
 //!
 pub(crate) mod buffer;
 pub(crate) mod parser;
 pub mod read_impl;
 
 mod read;
 pub(super) mod splitfields;
-#[cfg(not(feature = "private"))]
-pub(crate) mod utils;
-#[cfg(feature = "private")]
 pub mod utils;
 mod write;
 pub(super) mod write_impl;
 
 use std::fs::File;
 use std::io::Write;
 use std::path::PathBuf;
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/parser.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/parser.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/read.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/read.rs`

 * *Files 4% similar despite different names*

```diff
@@ -309,15 +309,14 @@
 
     /// Automatically try to parse dates/ datetimes and time. If parsing fails, columns remain of dtype `[DataType::Utf8]`.
     pub fn with_try_parse_dates(mut self, toggle: bool) -> Self {
         self.try_parse_dates = toggle;
         self
     }
 
-    #[cfg(feature = "private")]
     pub fn with_predicate(mut self, predicate: Option<Arc<dyn PhysicalIoExpr>>) -> Self {
         self.predicate = predicate;
         self
     }
 }
 
 impl<'a> CsvReader<'a, File> {
@@ -366,20 +365,24 @@
             to_cast,
             self.skip_rows_after_header,
             std::mem::take(&mut self.row_count),
             self.try_parse_dates,
         )
     }
 
-    fn prepare_schema_overwrite(&self, overwriting_schema: &Schema) -> (Schema, Vec<Field>, bool) {
+    fn prepare_schema_overwrite(
+        &self,
+        overwriting_schema: &Schema,
+    ) -> PolarsResult<(Schema, Vec<Field>, bool)> {
         // This branch we check if there are dtypes we cannot parse.
         // We only support a few dtypes in the parser and later cast to the required dtype
         let mut to_cast = Vec::with_capacity(overwriting_schema.len());
 
         let mut _has_categorical = false;
+        let mut _err: Option<PolarsError> = None;
 
         let schema = overwriting_schema
             .iter_fields()
             .filter_map(|mut fld| {
                 use DataType::*;
                 match fld.data_type() {
                     Time => {
@@ -394,37 +397,55 @@
                         Some(fld)
                     }
                     #[cfg(feature = "dtype-categorical")]
                     Categorical(_) => {
                         _has_categorical = true;
                         Some(fld)
                     }
+                    #[cfg(feature = "dtype-decimal")]
+                    Decimal(precision, scale) => match (precision, scale) {
+                        (_, Some(_)) => {
+                            to_cast.push(fld.clone());
+                            fld.coerce(Utf8);
+                            Some(fld)
+                        }
+                        _ => {
+                            _err = Some(PolarsError::ComputeError(
+                                "'scale' must be set when reading csv column as Decimal".into(),
+                            ));
+                            None
+                        }
+                    },
                     _ => Some(fld),
                 }
             })
             .collect::<Schema>();
 
-        (schema, to_cast, _has_categorical)
+        if let Some(err) = _err {
+            Err(err)
+        } else {
+            Ok((schema, to_cast, _has_categorical))
+        }
     }
 
     pub fn batched_borrowed_mmap(&'a mut self) -> PolarsResult<BatchedCsvReaderMmap<'a>> {
         if let Some(schema) = self.schema_overwrite.as_deref() {
-            let (schema, to_cast, has_cat) = self.prepare_schema_overwrite(schema);
+            let (schema, to_cast, has_cat) = self.prepare_schema_overwrite(schema)?;
             let schema = Arc::new(schema);
 
             let csv_reader = self.core_reader(Some(schema), to_cast)?;
             csv_reader.batched_mmap(has_cat)
         } else {
             let csv_reader = self.core_reader(self.schema.clone(), vec![])?;
             csv_reader.batched_mmap(false)
         }
     }
     pub fn batched_borrowed_read(&'a mut self) -> PolarsResult<BatchedCsvReaderRead<'a>> {
         if let Some(schema) = self.schema_overwrite.as_deref() {
-            let (schema, to_cast, has_cat) = self.prepare_schema_overwrite(schema);
+            let (schema, to_cast, has_cat) = self.prepare_schema_overwrite(schema)?;
             let schema = Arc::new(schema);
 
             let csv_reader = self.core_reader(Some(schema), to_cast)?;
             csv_reader.batched_read(has_cat)
         } else {
             let csv_reader = self.core_reader(self.schema.clone(), vec![])?;
             csv_reader.batched_read(false)
@@ -535,15 +556,15 @@
         let schema_overwrite = self.schema_overwrite.clone();
         let low_memory = self.low_memory;
 
         #[cfg(feature = "dtype-categorical")]
         let mut _cat_lock = None;
 
         let mut df = if let Some(schema) = schema_overwrite.as_deref() {
-            let (schema, to_cast, _has_cat) = self.prepare_schema_overwrite(schema);
+            let (schema, to_cast, _has_cat) = self.prepare_schema_overwrite(schema)?;
 
             #[cfg(feature = "dtype-categorical")]
             if _has_cat {
                 _cat_lock = Some(polars_core::IUseStringCache::new())
             }
 
             let mut csv_reader = self.core_reader(Some(Arc::new(schema)), to_cast)?;
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/read_impl/batched_mmap.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/read_impl/batched_mmap.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/read_impl/batched_read.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/read_impl/batched_read.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/read_impl/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/read_impl/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/splitfields.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/splitfields.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/utils.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/write.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/write.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/csv/write_impl.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/csv/write_impl.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/ipc/ipc_file.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/ipc/ipc_file.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/ipc/ipc_stream.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/ipc/ipc_stream.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/ipc/mmap.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/ipc/mmap.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/ipc/write.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/ipc/write.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/ipc/write_async.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/ipc/write_async.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/json/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/json/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/lib.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/lib.rs`

 * *Files 2% similar despite different names*

```diff
@@ -25,18 +25,15 @@
     feature = "ipc",
     feature = "json"
 ))]
 pub mod mmap;
 mod options;
 #[cfg(feature = "parquet")]
 pub mod parquet;
-#[cfg(feature = "private")]
 pub mod predicates;
-#[cfg(not(feature = "private"))]
-pub(crate) mod predicates;
 pub mod prelude;
 #[cfg(all(test, feature = "csv"))]
 mod tests;
 pub(crate) mod utils;
 
 #[cfg(feature = "partition")]
 pub mod partition;
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/mmap.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/mmap.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/ndjson/buffer.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/ndjson/buffer.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/ndjson/core.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/ndjson/core.rs`

 * *Files 2% similar despite different names*

```diff
@@ -155,15 +155,14 @@
         let schema = match schema {
             Some(schema) => Cow::Borrowed(schema),
             None => {
                 let bytes: &[u8] = &reader_bytes;
                 let mut cursor = Cursor::new(bytes);
 
                 let data_type = polars_json::ndjson::infer(&mut cursor, infer_schema_len)?;
-                dbg!(&data_type);
                 let schema = StructArray::get_fields(&data_type).iter().collect();
 
                 Cow::Owned(schema)
             }
         };
         Ok(CoreJsonReader {
             reader_bytes: Some(reader_bytes),
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/parquet/async_impl.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/parquet/async_impl.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/parquet/mmap.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/parquet/mmap.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/parquet/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/parquet/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/parquet/predicates.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/parquet/predicates.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/parquet/read.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/parquet/read.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/parquet/read_impl.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/parquet/read_impl.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/parquet/write.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/parquet/write.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/partition.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/partition.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/predicates.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/predicates.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/prelude.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/prelude.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-io/src/utils.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/Cargo.toml` & `polars_lts_cpu-0.18.1/local_dependencies/polars/Cargo.toml`

 * *Files 2% similar despite different names*

```diff
@@ -4,14 +4,15 @@
 authors = ["ritchie46 <ritchie46@gmail.com>"]
 edition = "2021"
 keywords = ["dataframe", "query-engine", "arrow"]
 license = "MIT"
 readme = "../README.md"
 repository = "https://github.com/pola-rs/polars"
 description = "DataFrame Library based on Apache Arrow"
+resolver = "2"
 
 [features]
 sql = ["polars-sql"]
 rows = ["polars-core/rows"]
 simd = ["polars-core/simd", "polars-io/simd", "polars-ops/simd"]
 avx512 = ["polars-core/avx512"]
 nightly = ["polars-core/nightly", "polars-ops/nightly", "simd"]
@@ -152,15 +153,14 @@
 propagate_nans = ["polars-lazy/propagate_nans"]
 coalesce = ["polars-lazy/coalesce"]
 streaming = ["polars-lazy/streaming"]
 fused = ["polars-ops/fused", "polars-lazy/fused"]
 
 test = [
   "lazy",
-  "private",
   "rolling_window",
   "rank",
   "round_series",
   "csv",
   "dtype-categorical",
   "cum_agg",
   "fmt",
@@ -168,17 +168,14 @@
   "abs",
   "parquet",
   "ipc",
   "ipc_streaming",
   "json",
 ]
 
-# don't use this
-private = ["polars-lazy/private", "polars-core/private", "polars-time/private", "polars-sql/private"]
-
 # all opt-in datatypes
 dtype-full = [
   "dtype-date",
   "dtype-datetime",
   "dtype-duration",
   "dtype-time",
   "dtype-array",
@@ -225,15 +222,20 @@
 dtype-array = [
   "polars-core/dtype-array",
   "polars-lazy/dtype-array",
   "polars-ops/dtype-array",
 ]
 dtype-i8 = ["polars-core/dtype-i8", "polars-lazy/dtype-i8", "polars-ops/dtype-i8"]
 dtype-i16 = ["polars-core/dtype-i16", "polars-lazy/dtype-i16", "polars-ops/dtype-i16"]
-dtype-decimal = ["polars-core/dtype-decimal", "polars-lazy/dtype-decimal", "polars-ops/dtype-decimal"]
+dtype-decimal = [
+  "polars-core/dtype-decimal",
+  "polars-lazy/dtype-decimal",
+  "polars-ops/dtype-decimal",
+  "polars-io/dtype-decimal",
+]
 dtype-u8 = ["polars-core/dtype-u8", "polars-lazy/dtype-u8", "polars-ops/dtype-u8"]
 dtype-u16 = ["polars-core/dtype-u16", "polars-lazy/dtype-u16", "polars-ops/dtype-u16"]
 dtype-categorical = [
   "polars-core/dtype-categorical",
   "polars-io/dtype-categorical",
   "polars-lazy/dtype-categorical",
   "polars-ops/dtype-categorical",
@@ -299,30 +301,26 @@
 
 bench = [
   "lazy",
 ]
 
 [dependencies]
 polars-algo = { version = "0.30.0", path = "../polars-algo", optional = true }
-polars-core = { version = "0.30.0", path = "../polars-core", features = ["docs", "private"], default-features = false }
-polars-io = { version = "0.30.0", path = "../polars-io", features = ["private"], default-features = false, optional = true }
-polars-lazy = { version = "0.30.0", path = "../polars-lazy", features = ["private"], default-features = false, optional = true }
+polars-core = { version = "0.30.0", path = "../polars-core", features = ["docs"], default-features = false }
+polars-io = { version = "0.30.0", path = "../polars-io", features = [], default-features = false, optional = true }
+polars-lazy = { version = "0.30.0", path = "../polars-lazy", features = [], default-features = false, optional = true }
 polars-ops = { version = "0.30.0", path = "../polars-ops" }
 polars-sql = { version = "0.30.0", path = "../polars-sql", default-features = false, optional = true }
 polars-time = { version = "0.30.0", path = "../polars-time", default-features = false, optional = true }
 
 # enable js feature for getrandom to work in wasm
 [target.'cfg(target_family = "wasm")'.dependencies.getrandom]
 version = "0.2"
 features = ["js"]
 
-[dev-dependencies]
-ahash = "0.8"
-rand = "0.8"
-
 [build-dependencies]
 version_check = "0.9.4"
 
 [package.metadata.docs.rs]
 # all-features = true
 features = ["docs-selection"]
 # defines the configuration attribute `docsrs`
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/LICENSE` & `polars_lts_cpu-0.18.1/local_dependencies/polars-json/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/Makefile` & `polars_lts_cpu-0.18.1/local_dependencies/polars/Makefile`

 * *Files 1% similar despite different names*

```diff
@@ -79,15 +79,15 @@
 	    -p polars-arrow \
 			-p polars-sql
 
 pre-commit: fmt clippy clippy-default  ## Run autoformatting and linting
 
 
 check-features:
-	cargo hack check --each-feature --no-dev-deps --features private 
+	cargo hack check --each-feature --no-dev-deps
 
 bench-save:
 	cargo bench --features=random --bench $(BENCH) -- --save-baseline $(SAVE)
 
 bench-cmp:
 	cargo bench --features=random --bench $(BENCH) -- --load-baseline $(FEAT) --baseline $(BASE)
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/src/docs/eager.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/src/docs/eager.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/src/docs/lazy.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/src/docs/lazy.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/src/docs/performance.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/src/docs/performance.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/src/lib.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/src/lib.rs`

 * *Files 1% similar despite different names*

```diff
@@ -226,15 +226,15 @@
 //!     - `dot_product` - Dot/inner product on Series and Expressions.
 //!     - `concat_str` - Concat string data in linear time.
 //!     - `reinterpret` - Utility to reinterpret bits to signed/unsigned
 //!     - `take_opt_iter` - Take from a Series with `Iterator<Item=Option<usize>>`
 //!     - `mode` - [Return the most occurring value(s)](crate::chunked_array::ops::ChunkUnique::mode)
 //!     - `cum_agg` - cumsum, cummin, cummax aggregation.
 //!     - `rolling_window` - rolling window functions, like rolling_mean
-//!     - `interpolate` [interpolate None values](crate::chunked_array::ops::Interpolate)
+//!     - `interpolate` [interpolate None values](polars_ops::chunked_array::interpolate)
 //!     - `extract_jsonpath` - [Run jsonpath queries on Utf8Chunked](https://goessner.net/articles/JsonPath/)
 //!     - `list` - List utils.
 //!         - `list_take` take sublist by multiple indices
 //!     - `rank` - Ranking algorithms.
 //!     - `moment` - kurtosis and skew statistics
 //!     - `ewma` - Exponential moving average windows
 //!     - `abs` - Get absolute values of Series
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/date_like.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/date_like.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/groupby.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/groupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/joins.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/joins.rs`

 * *Files 3% similar despite different names*

```diff
@@ -17,15 +17,20 @@
     ]?;
 
     let band_instruments = accumulate_dataframes_vertical(split_df(&mut band_instruments, 2)?)?;
     let band_members = accumulate_dataframes_vertical(split_df(&mut band_members, 2)?)?;
     assert_eq!(band_instruments.n_chunks(), 2);
     assert_eq!(band_members.n_chunks(), 2);
 
-    let out = band_instruments.join(&band_members, ["name"], ["name"], JoinType::Left, None)?;
+    let out = band_instruments.join(
+        &band_members,
+        ["name"],
+        ["name"],
+        JoinArgs::new(JoinType::Left),
+    )?;
     let expected = df![
         "name" => ["john", "paul", "keith"],
         "plays" => ["guitar", "bass", "guitar"],
         "band" => [Some("beatles"), Some("beatles"), None],
     ]?;
     assert!(out.frame_equal_missing(&expected));
 
@@ -219,31 +224,31 @@
         Some("const"),
     ];
 
     assert_eq!(Vec::from(ca), correct_ham);
 
     // now check the join with multiple columns
     let joined = df_a
-        .join(&df_b, ["a", "b"], ["foo", "bar"], JoinType::Left, None)
+        .join(&df_b, ["a", "b"], ["foo", "bar"], JoinType::Left.into())
         .unwrap();
     let ca = joined.column("ham").unwrap().utf8().unwrap();
     assert_eq!(Vec::from(ca), correct_ham);
     let joined_inner_hack = df_a.inner_join(&df_b, ["dummy"], ["dummy"]).unwrap();
     let joined_inner = df_a
-        .join(&df_b, ["a", "b"], ["foo", "bar"], JoinType::Inner, None)
+        .join(&df_b, ["a", "b"], ["foo", "bar"], JoinType::Inner.into())
         .unwrap();
 
     assert!(joined_inner_hack
         .column("ham")
         .unwrap()
         .series_equal_missing(joined_inner.column("ham").unwrap()));
 
     let joined_outer_hack = df_a.outer_join(&df_b, ["dummy"], ["dummy"]).unwrap();
     let joined_outer = df_a
-        .join(&df_b, ["a", "b"], ["foo", "bar"], JoinType::Outer, None)
+        .join(&df_b, ["a", "b"], ["foo", "bar"], JoinType::Outer.into())
         .unwrap();
     assert!(joined_outer_hack
         .column("ham")
         .unwrap()
         .series_equal_missing(joined_outer.column("ham").unwrap()));
 }
 
@@ -258,15 +263,15 @@
 
     df_a.try_apply("b", |s| s.cast(&DataType::Categorical(None)))
         .unwrap();
     df_b.try_apply("bar", |s| s.cast(&DataType::Categorical(None)))
         .unwrap();
 
     let out = df_a
-        .join(&df_b, ["b"], ["bar"], JoinType::Left, None)
+        .join(&df_b, ["b"], ["bar"], JoinType::Left.into())
         .unwrap();
     assert_eq!(out.shape(), (6, 5));
     let correct_ham = &[
         Some("let"),
         None,
         Some("var"),
         Some("const"),
@@ -276,15 +281,15 @@
     let ham_col = out.column("ham").unwrap();
     let ca = ham_col.utf8().unwrap();
 
     assert_eq!(Vec::from(ca), correct_ham);
 
     // test dispatch
     for jt in [JoinType::Left, JoinType::Inner, JoinType::Outer] {
-        let out = df_a.join(&df_b, ["b"], ["bar"], jt, None).unwrap();
+        let out = df_a.join(&df_b, ["b"], ["bar"], jt.into()).unwrap();
         let out = out.column("b").unwrap();
         assert_eq!(out.dtype(), &DataType::Categorical(None));
     }
 
     // Test error when joining on different string cache
     let (mut df_a, mut df_b) = get_dfs();
     df_a.try_apply("b", |s| s.cast(&DataType::Categorical(None)))
@@ -293,15 +298,15 @@
     reset_string_cache();
 
     // _sc is needed to ensure we hold the string cache.
     let _sc = IUseStringCache::new();
 
     df_b.try_apply("bar", |s| s.cast(&DataType::Categorical(None)))
         .unwrap();
-    let out = df_a.join(&df_b, ["b"], ["bar"], JoinType::Left, None);
+    let out = df_a.join(&df_b, ["b"], ["bar"], JoinType::Left.into());
     assert!(out.is_err());
 }
 
 #[test]
 #[cfg_attr(miri, ignore)]
 fn empty_df_join() -> PolarsResult<()> {
     let empty: Vec<String> = vec![];
@@ -387,19 +392,19 @@
     let df2 = df![
         "a" => [1, 2, 3, 4],
         "b" => [true, true, true, false]
     ]?;
 
     // dtypes don't match, error
     assert!(df1
-        .join(&df2, vec!["a", "b"], vec!["a", "b"], JoinType::Left, None)
+        .join(&df2, vec!["a", "b"], vec!["a", "b"], JoinType::Left.into())
         .is_err());
     // length of join keys don't match error
     assert!(df1
-        .join(&df2, vec!["a"], vec!["a", "b"], JoinType::Left, None)
+        .join(&df2, vec!["a"], vec!["a", "b"], JoinType::Left.into())
         .is_err());
     Ok(())
 }
 
 #[test]
 #[cfg_attr(miri, ignore)]
 fn test_joins_with_duplicates() -> PolarsResult<()> {
@@ -473,48 +478,45 @@
     .unwrap();
 
     let df_inner_join = df_left
         .join(
             &df_right,
             &["col1", "join_col2"],
             &["join_col1", "col2"],
-            JoinType::Inner,
-            None,
+            JoinType::Inner.into(),
         )
         .unwrap();
 
     assert_eq!(df_inner_join.height(), 10);
     assert_eq!(df_inner_join.column("col1")?.null_count(), 0);
     assert_eq!(df_inner_join.column("join_col2")?.null_count(), 0);
     assert_eq!(df_inner_join.column("int_col")?.null_count(), 0);
     assert_eq!(df_inner_join.column("dbl_col")?.null_count(), 0);
 
     let df_left_join = df_left
         .join(
             &df_right,
             &["col1", "join_col2"],
             &["join_col1", "col2"],
-            JoinType::Left,
-            None,
+            JoinType::Left.into(),
         )
         .unwrap();
 
     assert_eq!(df_left_join.height(), 11);
     assert_eq!(df_left_join.column("col1")?.null_count(), 0);
     assert_eq!(df_left_join.column("join_col2")?.null_count(), 0);
     assert_eq!(df_left_join.column("int_col")?.null_count(), 0);
     assert_eq!(df_left_join.column("dbl_col")?.null_count(), 1);
 
     let df_outer_join = df_left
         .join(
             &df_right,
             &["col1", "join_col2"],
             &["join_col1", "col2"],
-            JoinType::Outer,
-            None,
+            JoinType::Outer.into(),
         )
         .unwrap();
 
     assert_eq!(df_outer_join.height(), 12);
     assert_eq!(df_outer_join.column("col1")?.null_count(), 0);
     assert_eq!(df_outer_join.column("join_col2")?.null_count(), 0);
     assert_eq!(df_outer_join.column("int_col")?.null_count(), 1);
@@ -538,28 +540,26 @@
         "ham" => &["let", "var", "const"]
     }?;
 
     let out = df_a.join(
         &df_b,
         vec!["a", "c"],
         vec!["foo", "bar"],
-        JoinType::Left,
-        None,
+        JoinType::Left.into(),
     )?;
     assert_eq!(
         Vec::from(out.column("ham")?.utf8()?),
         &[None, Some("var"), None, None]
     );
 
     let out = df_a.join(
         &df_b,
         vec!["a", "c"],
         vec!["foo", "bar"],
-        JoinType::Outer,
-        None,
+        JoinType::Outer.into(),
     )?;
     assert_eq!(
         out.dtypes(),
         &[
             DataType::Float64,
             DataType::Float64,
             DataType::Utf8,
@@ -606,11 +606,11 @@
     let mut right_b = range
         .map(|i| if i % 3 == 0 { None } else { Some(1) })
         .collect::<Int64Chunked>();
     right_a.rename("a");
     right_b.rename("b");
 
     let right_df = DataFrame::new(vec![right_a.into_series(), right_b.into_series()])?;
-    let out = left_df.join(&right_df, ["a", "b"], ["a", "b"], JoinType::Inner, None)?;
+    let out = left_df.join(&right_df, ["a", "b"], ["a", "b"], JoinType::Inner.into())?;
     assert_eq!(out.shape(), (1, 2));
     Ok(())
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/list.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/pivot.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/pivot.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/random.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/random.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/rolling_window.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/rolling_window.rs`

 * *Files 5% similar despite different names*

```diff
@@ -263,26 +263,33 @@
         .rolling_var(RollingOptionsImpl {
             window_size: Duration::new(4),
             min_periods: 3,
             center: true,
             ..Default::default()
         })
         .unwrap();
-    let out = out.f64().unwrap();
+    let out = out.f64().unwrap().to_vec();
 
-    assert_eq!(
-        Vec::from(out),
-        &[
-            None,
-            Some(17.333333333333332),
-            Some(11.583333333333334),
-            Some(21.583333333333332),
-            Some(24.666666666666668),
-            Some(34.33333333333334)
-        ]
+    let expres = &[
+        None,
+        Some(17.333333333333332),
+        Some(11.583333333333334),
+        Some(21.583333333333332),
+        Some(24.666666666666668),
+        Some(34.33333333333334),
+    ];
+    let testres = out.iter().zip(expres.iter()).all(|(&a, &b)| match (a, b) {
+        (None, None) => true,
+        (Some(a), Some(b)) => (a - b).abs() < 1e-12,
+        (_, _) => false,
+    });
+    assert!(
+        testres,
+        "{:?} is not approximately equal to {:?}",
+        out, expres
     );
 }
 
 #[test]
 fn test_median_quantile_types() {
     let s = Int32Chunked::new("foo", &[1, 2, 3, 2, 1]).into_series();
     let rol_med = s
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/core/series.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/core/series.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/io/csv.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/io/csv.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/io/ipc_stream.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/io/ipc_stream.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/io/json.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/io/json.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/io/parquet.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/io/parquet.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/joins.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/joins.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/aggregation.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/aggregation.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/cse.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/cse.rs`

 * *Files 18% similar despite different names*

```diff
@@ -11,15 +11,15 @@
     let q2: LazyFrame = df![
         "b" => [1],
     ]?
     .lazy();
 
     let q3 = q2
         .clone()
-        .join(q1.clone(), [col("b")], [col("b")], JoinType::Anti)
+        .join(q1.clone(), [col("b")], [col("b")], JoinType::Anti.into())
         .with_column(lit(0).alias("a"))
         .select([col("a"), col("b")]);
 
     let out = concat([q1, q3], true, true)
         .unwrap()
         .with_common_subplan_elimination(true)
         .collect()?;
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/expressions/apply.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/expressions/apply.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/expressions/arity.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/expressions/arity.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/expressions/expand.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/expressions/expand.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/expressions/filter.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/expressions/filter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/expressions/slice.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/expressions/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/expressions/window.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/expressions/window.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/folds.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/folds.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/functions.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/functions.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/groupby.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/groupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/groupby_dynamic.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/groupby_dynamic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/predicate_queries.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/predicate_queries.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/projection_queries.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/projection_queries.rs`

 * *Files 0% similar despite different names*

```diff
@@ -50,15 +50,15 @@
     .lazy();
 
     let out = ldf1
         .join(
             ldf2,
             [col("key1"), col("key2")],
             [col("key1"), col("key2")],
-            JoinType::Outer,
+            JoinType::Outer.into(),
         )
         .with_columns([col("key1")])
         .collect()?;
     assert_eq!(out.get_column_names(), &["key1", "key2", "val1", "val2"]);
     assert_eq!(
         Vec::from(out.column("key1")?.utf8()?),
         &[Some("bar"), Some("baz"), Some("foo")]
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/lazy/queries.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/lazy/queries.rs`

 * *Files 1% similar despite different names*

```diff
@@ -163,15 +163,15 @@
     let dfb = df![
         "a"=> [1, 2, 3]
     ]?;
 
     let out = dfa
         .lazy()
         .with_column(col("a").set_sorted_flag(IsSorted::Ascending))
-        .join(dfb.lazy(), [col("a")], [col("a")], JoinType::Left)
+        .join(dfb.lazy(), [col("a")], [col("a")], JoinType::Left.into())
         .collect()?;
 
     let s = out.column("a")?;
     assert_eq!(s.is_sorted_flag(), IsSorted::Ascending);
 
     Ok(())
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars/tests/it/schema.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars/tests/it/schema.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/Cargo.toml` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/Cargo.toml`

 * *Files 4% similar despite different names*

```diff
@@ -1,46 +1,48 @@
 [package]
 name = "polars-arrow"
 version= "0.30.0"
 authors = ["ritchie46 <ritchie46@gmail.com>"]
 edition = "2021"
 license = "MIT"
 description = "Arrow interfaces for Polars DataFrame library"
+resolver = "2"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
 atoi = { version = "2.0.0", optional = true }
 chrono = { version = "0.4", default-features = false, features = ["std"], optional = true }
 chrono-tz = { version = "0.8", optional = true }
+ethnum = { version = "1.3.2", optional = true }
 hashbrown= { version = "0.13.1", features = ["rayon", "ahash"] }
 multiversion= "0.7"
 num-traits= "0.2"
 polars-error = { version = "0.30.0", path = "../polars-error" }
 serde = { version = "1", features = ["derive"], optional = true }
 thiserror= "^1"
 
 [features]
-dtype-decimal = ["atoi"]
+dtype-decimal = ["atoi", "ethnum"]
 dtype-array = []
 nightly = ["hashbrown/nightly"]
 strings = []
 compute = ["arrow/compute_cast"]
 temporal = ["arrow/compute_temporal"]
 bigidx = []
 performant = []
 like = ["arrow/compute_like"]
 timezones = ["chrono-tz", "chrono"]
 simd = []
 
 [dependencies.arrow]
 package = "arrow2"
-# git = "https://github.com/jorgecarleitao/arrow2"
+git = "https://github.com/jorgecarleitao/arrow2"
 # git = "https://github.com/ritchie46/arrow2"
-# rev = "1491c6e8f4fd100f53c358e4f3ef1536d9e75090"
+rev = "fb5e4d591c7149df590a330365fae55d2370962f"
 # path = "../arrow2"
 # branch = "polars_2023-05-25"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/LICENSE` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/array/default_arrays.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/array/default_arrays.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/array/fixed_size_list.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/array/fixed_size_list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/array/get.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/array/get.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/array/list.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/array/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/array/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/array/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/array/null.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/array/null.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/array/slice.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/array/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/array/utf8.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/array/utf8.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/bit_util.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/bit_util.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/bitmap/mutable.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/bitmap/mutable.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/compute/bitwise.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/bitwise.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/compute/cast.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/cast.rs`

 * *Files 18% similar despite different names*

```diff
@@ -3,30 +3,33 @@
 use arrow::error::Result;
 
 pub fn cast(array: &dyn Array, to_type: &DataType) -> Result<Box<dyn Array>> {
     match to_type {
         #[cfg(feature = "dtype-decimal")]
         DataType::Decimal(precision, scale) if matches!(array.data_type(), DataType::LargeUtf8) => {
             let array = array.as_any().downcast_ref::<LargeStringArray>().unwrap();
-            Ok(cast_utf8_to_decimal(array, *precision, *scale))
+            Ok(cast_utf8_to_decimal(array, Some(*precision), *scale))
         }
         _ => arrow::compute::cast::cast(array, to_type, Default::default()),
     }
 }
 
 #[cfg(feature = "dtype-decimal")]
 use arrow::array::{PrimitiveArray, Utf8Array};
 
 #[cfg(feature = "dtype-decimal")]
 use super::decimal::*;
 #[cfg(feature = "dtype-decimal")]
 use crate::prelude::{ArrayRef, LargeStringArray};
 #[cfg(feature = "dtype-decimal")]
-pub fn cast_utf8_to_decimal(array: &Utf8Array<i64>, precision: usize, scale: usize) -> ArrayRef {
+pub fn cast_utf8_to_decimal(
+    array: &Utf8Array<i64>,
+    precision: Option<usize>,
+    scale: usize,
+) -> ArrayRef {
+    let precision = precision.map(|p| p as u8);
     let values: PrimitiveArray<i128> = array
         .iter()
-        .map(|val| {
-            val.and_then(|val| deserialize_decimal(val.as_bytes(), precision as u8, scale as u8))
-        })
+        .map(|val| val.and_then(|val| deserialize_decimal(val.as_bytes(), precision, scale as u8)))
         .collect();
     Box::new(values)
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/compute/decimal.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/decimal.rs`

 * *Files 26% similar despite different names*

```diff
@@ -11,42 +11,25 @@
 fn split_decimal_bytes(bytes: &[u8]) -> (Option<&[u8]>, Option<&[u8]>) {
     let mut a = bytes.split(|x| *x == b'.');
     let lhs = a.next();
     let rhs = a.next();
     (lhs, rhs)
 }
 
-pub fn infer_params(bytes: &[u8]) -> Option<(u8, u8)> {
-    let (lhs, rhs) = split_decimal_bytes(bytes);
-    match (lhs, rhs) {
-        (Some(lhs), Some(rhs)) => {
-            let lhs_s = significant_digits(lhs);
-            let rhs_s = significant_digits(rhs);
-
-            let precision = lhs_s + rhs_s;
-            let scale = rhs_s;
-            Some((precision, scale))
-        }
-        (None, Some(rhs)) => {
-            let precision = rhs.len() as u8;
-            Some((precision, precision))
-        }
-        (Some(lhs), None) => {
-            let precision = lhs.len() as u8;
-            Some((precision, 0))
-        }
-        (None, None) => None,
-    }
+pub fn infer_scale(bytes: &[u8]) -> Option<u8> {
+    let (_lhs, rhs) = split_decimal_bytes(bytes);
+    rhs.map(significant_digits)
 }
 
 /// Deserializes bytes to a single i128 representing a decimal
 /// The decimal precision and scale are not checked.
 #[inline]
-pub(super) fn deserialize_decimal(bytes: &[u8], precision: u8, scale: u8) -> Option<i128> {
+pub(super) fn deserialize_decimal(bytes: &[u8], precision: Option<u8>, scale: u8) -> Option<i128> {
     let (lhs, rhs) = split_decimal_bytes(bytes);
+    let precision = precision.unwrap_or(u8::MAX);
     match (lhs, rhs) {
         (Some(lhs), Some(rhs)) => atoi::<i128>(lhs).and_then(|x| {
             atoi::<i128>(rhs)
                 .map(|y| (x, lhs, y, rhs))
                 .and_then(|(lhs, lhs_b, rhs, rhs_b)| {
                     let lhs_s = significant_digits(lhs_b);
                     let leading_zeros_rhs = leading_zeros(rhs_b);
@@ -56,63 +39,64 @@
                     if lhs_s + rhs_s > precision || rhs_s > scale {
                         None
                     }
                     // significant digits don't fit scale
                     else if rhs_s < scale {
                         // scale: 2
                         // number: x.09
-                        // sign digits: 1
+                        // significant digits: 1
+                        // leading_zeros: 1
                         // parsed: 9
                         // so this is correct
                         if leading_zeros_rhs + rhs_s == scale {
                             Some((lhs, rhs))
                         }
                         // scale: 2
                         // number: x.9
-                        // sign digits: 1
+                        // significant digits: 1
                         // parsed: 9
                         // so we must multiply by 10 to get 90
                         else {
-                            let diff = scale as u32 - rhs_s as u32;
+                            let diff = scale as u32 - (rhs_s + leading_zeros_rhs) as u32;
                             Some((lhs, rhs * 10i128.pow(diff)))
                         }
                     }
                     // scale: 2
                     // number: x.90
-                    // sign digits: 2
+                    // significant digits: 2
                     // parsed: 90
                     // so this is correct
                     else {
                         Some((lhs, rhs))
                     }
                 })
                 .map(|(lhs, rhs)| lhs * 10i128.pow(scale as u32) + rhs)
         }),
         (None, Some(rhs)) => {
-            if rhs.len() != precision as usize || rhs.len() != scale as usize {
+            if rhs.len() > precision as usize || rhs.len() != scale as usize {
                 return None;
             }
             atoi::<i128>(rhs)
         }
         (Some(lhs), None) => {
-            if lhs.len() != precision as usize || scale != 0 {
+            if lhs.len() > precision as usize || scale != 0 {
                 return None;
             }
             atoi::<i128>(lhs)
         }
         (None, None) => None,
     }
 }
 
 #[cfg(test)]
 mod test {
     use super::*;
     #[test]
     fn test_decimal() {
-        let precision = 8;
+        let precision = Some(8);
         let scale = 2;
 
         let val = "12.09";
         assert_eq!(
             deserialize_decimal(val.as_bytes(), precision, scale),
             Some(1209)
         );
@@ -124,9 +108,16 @@
         );
 
         let val = "143.9";
         assert_eq!(
             deserialize_decimal(val.as_bytes(), precision, scale),
             Some(14390)
         );
+
+        let scale = 20;
+        let val = "0.01";
+        assert_eq!(
+            deserialize_decimal(val.as_bytes(), precision, scale),
+            Some(1000000000000000000)
+        );
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/compute/take/boolean.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/take/boolean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/compute/take/fixed_size_list.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/take/fixed_size_list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/compute/take/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/take/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/compute/tile.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/compute/tile.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/conversion.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/conversion.rs`

 * *Files 10% similar despite different names*

```diff
@@ -10,16 +10,18 @@
     StructArray::new(dtype, chunk.into_arrays(), None)
 }
 
 /// Returns its underlying [`Vec`], if possible.
 ///
 /// This operation returns [`Some`] iff this [`PrimitiveArray`]:
 /// * has not been sliced with an offset
-/// * has not been cloned (i.e. [`Arc`]`::get_mut` yields [`Some`])
+/// * has not been cloned (i.e. [`Arc::get_mut`][Arc::get_mut] yields [`Some`])
 /// * has not been imported from the c data interface (FFI)
+///
+/// [Arc::get_mut]: std::sync::Arc::get_mut
 pub fn primitive_to_vec<T: NativeType>(arr: ArrayRef) -> Option<Vec<T>> {
     let arr_ref = arr.as_any().downcast_ref::<PrimitiveArray<T>>().unwrap();
     let mut buffer = arr_ref.values().clone();
     drop(arr);
     // Safety:
     // if the `get_mut` is successful
     // we are the only owner and we drop it
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/data_types.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/data_types.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/floats/ord.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/floats/ord.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/index.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/index.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/is_valid.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/is_valid.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/agg_mean.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/agg_mean.rs`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-use std::simd::{Mask, Simd, SimdElement, SimdFloat, StdFloat, ToBitMask};
+use std::simd::{Mask, Simd, SimdCast, SimdElement, SimdFloat, StdFloat, ToBitMask};
 
 use arrow::array::{Array, PrimitiveArray};
 use arrow::bitmap::utils::{BitChunkIterExact, BitChunksExact};
 use arrow::bitmap::Bitmap;
 use arrow::datatypes::PhysicalType::Primitive;
 use arrow::types::NativeType;
 use multiversion::multiversion;
@@ -10,15 +10,15 @@
 
 use crate::data_types::IsFloat;
 use crate::utils::with_match_primitive_type;
 
 #[multiversion(targets = "simd")]
 fn nonnull_sum_as_f64<T>(values: &[T]) -> f64
 where
-    T: NativeType + SimdElement + ToPrimitive,
+    T: NativeType + SimdElement + ToPrimitive + SimdCast,
 {
     // we choose 8 as that the maximum size of f64x8 -> 512bit wide
     const LANES: usize = 8;
     let (head, simd_vals, tail) = unsafe { values.align_to::<Simd<T, LANES>>() };
 
     let mut reduced: Simd<f64, LANES> = Simd::splat(0.0);
     for chunk in simd_vals {
@@ -37,15 +37,15 @@
                 .sum::<f64>()
     }
 }
 
 #[multiversion(targets = "simd")]
 fn null_sum_as_f64_impl<T, I>(values: &[T], mut validity_masks: I) -> f64
 where
-    T: NativeType + SimdElement + ToPrimitive + IsFloat,
+    T: NativeType + SimdElement + ToPrimitive + IsFloat + SimdCast,
     I: BitChunkIterExact<u8>,
 {
     const LANES: usize = 8;
     let mut chunks = values.chunks_exact(LANES);
     let min_one = Simd::<f64, LANES>::splat(-1.0);
     let min_one_i64 = Simd::<i64, LANES>::splat(-1);
 
@@ -102,15 +102,15 @@
         }
     }
     sum
 }
 
 fn null_sum_as_f64<T>(values: &[T], bitmap: &Bitmap) -> f64
 where
-    T: NativeType + SimdElement + ToPrimitive + IsFloat,
+    T: NativeType + SimdElement + ToPrimitive + IsFloat + SimdCast,
 {
     let (slice, offset, length) = bitmap.as_slice();
     if offset == 0 {
         let validity_masks = BitChunksExact::<u8>::new(slice, length);
         null_sum_as_f64_impl(values, validity_masks)
     } else {
         let validity_masks = bitmap.chunks::<u8>();
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/comparison.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/comparison.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/concatenate.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/concatenate.rs`

 * *Files 14% similar despite different names*

```diff
@@ -1,14 +1,16 @@
 use arrow::array::growable::make_growable;
 use arrow::error::{Error as ArrowError, Result};
 
 use crate::prelude::*;
 
-/// Concatenate multiple [Array] of the same type into a single [`Array`].
+/// Concatenate multiple [`Array`][Array] of the same type into a single [`Array`][Array].
 /// This does not check the arrays types.
+///
+/// [Array]: arrow::array::Array
 pub fn concatenate_owned_unchecked(arrays: &[ArrayRef]) -> Result<ArrayRef> {
     if arrays.is_empty() {
         return Err(ArrowError::InvalidArgumentError(
             "concat requires input of at least one array".to_string(),
         ));
     }
     if arrays.len() == 1 {
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/ewm/average.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/ewm/average.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/ewm/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/ewm/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/ewm/variance.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/ewm/variance.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/float.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/float.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/list.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/list_bytes_iter.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/list_bytes_iter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/mod.rs`

 * *Files 8% similar despite different names*

```diff
@@ -1,13 +1,15 @@
 pub mod no_nulls;
 pub mod nulls;
 mod window;
 
+use std::any::Any;
 use std::cmp::Ordering;
 use std::ops::{Add, AddAssign, Div, Mul, Sub, SubAssign};
+use std::sync::Arc;
 
 use arrow::array::PrimitiveArray;
 use arrow::bitmap::{Bitmap, MutableBitmap};
 use arrow::types::NativeType;
 use num_traits::{Bounded, Float, NumCast, One, ToPrimitive, Zero};
 use window::*;
 
@@ -16,14 +18,15 @@
 use crate::utils::CustomIterTools;
 
 type Start = usize;
 type End = usize;
 type Idx = usize;
 type WindowSize = usize;
 type Len = usize;
+pub type DynArgs = Option<Arc<dyn Any + Sync + Send>>;
 
 #[inline]
 /// NaN will be smaller than every valid value
 pub fn compare_fn_nan_min<T>(a: &T, b: &T) -> Ordering
 where
     T: PartialOrd + IsFloat,
 {
@@ -129,7 +132,13 @@
         });
     } else {
         // Safety:
         // all integers are Ord
         unsafe { buf.sort_by(|a, b| a.partial_cmp(b).unwrap_unchecked()) };
     }
 }
+
+//Parameters allowed for rolling operations.
+#[derive(Clone, Copy, Debug)]
+pub struct RollingVarParams {
+    pub ddof: u8,
+}
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mean.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mean.rs`

 * *Files 6% similar despite different names*

```diff
@@ -8,17 +8,17 @@
 }
 
 impl<
         'a,
         T: NativeType + IsFloat + std::iter::Sum + AddAssign + SubAssign + Div<Output = T> + NumCast,
     > RollingAggWindowNoNulls<'a, T> for MeanWindow<'a, T>
 {
-    fn new(slice: &'a [T], start: usize, end: usize) -> Self {
+    fn new(slice: &'a [T], start: usize, end: usize, params: DynArgs) -> Self {
         Self {
-            sum: SumWindow::new(slice, start, end),
+            sum: SumWindow::new(slice, start, end, params),
         }
     }
 
     unsafe fn update(&mut self, start: usize, end: usize) -> T {
         let sum = self.sum.update(start, end);
         sum / NumCast::from(end - start).unwrap()
     }
@@ -26,30 +26,33 @@
 
 pub fn rolling_mean<T>(
     values: &[T],
     window_size: usize,
     min_periods: usize,
     center: bool,
     weights: Option<&[f64]>,
+    _params: DynArgs,
 ) -> ArrayRef
 where
     T: NativeType + Float + std::iter::Sum<T> + SubAssign + AddAssign + IsFloat,
 {
     match (center, weights) {
         (true, None) => rolling_apply_agg_window::<MeanWindow<_>, _, _>(
             values,
             window_size,
             min_periods,
             det_offsets_center,
+            None,
         ),
         (false, None) => rolling_apply_agg_window::<MeanWindow<_>, _, _>(
             values,
             window_size,
             min_periods,
             det_offsets,
+            None,
         ),
         (true, Some(weights)) => {
             let weights = no_nulls::coerce_weights(weights);
             no_nulls::rolling_apply_weights(
                 values,
                 window_size,
                 min_periods,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/min_max.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/min_max.rs`

 * *Files 3% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 use super::*;
 
 pub struct SortedMinMax<'a, T: NativeType> {
     slice: &'a [T],
 }
 
 impl<'a, T: NativeType> RollingAggWindowNoNulls<'a, T> for SortedMinMax<'a, T> {
-    fn new(slice: &'a [T], _start: usize, _end: usize) -> Self {
+    fn new(slice: &'a [T], _start: usize, _end: usize, _params: DynArgs) -> Self {
         Self { slice }
     }
 
     #[inline]
     unsafe fn update(&mut self, start: usize, _end: usize) -> T {
         *self.slice.get_unchecked(start)
     }
@@ -22,15 +22,15 @@
     slice: &'a [T],
     min: T,
     last_start: usize,
     last_end: usize,
 }
 
 impl<'a, T: NativeType + IsFloat + PartialOrd> RollingAggWindowNoNulls<'a, T> for MinWindow<'a, T> {
-    fn new(slice: &'a [T], start: usize, end: usize) -> Self {
+    fn new(slice: &'a [T], start: usize, end: usize, _params: DynArgs) -> Self {
         let min = *slice[start..end]
             .iter()
             .min_by(|a, b| compare_fn_nan_min(*a, *b))
             .unwrap_or(&slice[start]);
         Self {
             slice,
             min,
@@ -146,15 +146,15 @@
     slice: &'a [T],
     max: T,
     last_start: usize,
     last_end: usize,
 }
 
 impl<'a, T: NativeType + IsFloat + PartialOrd> RollingAggWindowNoNulls<'a, T> for MaxWindow<'a, T> {
-    fn new(slice: &'a [T], start: usize, end: usize) -> Self {
+    fn new(slice: &'a [T], start: usize, end: usize, _params: DynArgs) -> Self {
         let max = *slice[start..end]
             .iter()
             .max_by(|a, b| compare_fn_nan_max(*a, *b))
             .unwrap_or(&slice[start]);
         Self {
             slice,
             max,
@@ -309,51 +309,56 @@
 
 pub fn rolling_max<T>(
     values: &[T],
     window_size: usize,
     min_periods: usize,
     center: bool,
     weights: Option<&[f64]>,
+    _params: DynArgs,
 ) -> ArrayRef
 where
     T: NativeType + PartialOrd + IsFloat + Bounded + NumCast + Mul<Output = T>,
 {
     match (center, weights) {
         (true, None) => {
             // will be O(n2) if we don't take this path we hope that we hit an early return on not sorted data
             if is_reverse_sorted_max(values) {
                 rolling_apply_agg_window::<SortedMinMax<_>, _, _>(
                     values,
                     window_size,
                     min_periods,
                     det_offsets_center,
+                    None,
                 )
             } else {
                 rolling_apply_agg_window::<MaxWindow<_>, _, _>(
                     values,
                     window_size,
                     min_periods,
                     det_offsets_center,
+                    None,
                 )
             }
         }
         (false, None) => {
             if is_reverse_sorted_max(values) {
                 rolling_apply_agg_window::<SortedMinMax<_>, _, _>(
                     values,
                     window_size,
                     min_periods,
                     det_offsets,
+                    None,
                 )
             } else {
                 rolling_apply_agg_window::<MaxWindow<_>, _, _>(
                     values,
                     window_size,
                     min_periods,
                     det_offsets,
+                    None,
                 )
             }
         }
         (true, Some(weights)) => {
             assert!(
                 T::is_float(),
                 "implementation error, should only be reachable by float types"
@@ -404,52 +409,57 @@
 
 pub fn rolling_min<T>(
     values: &[T],
     window_size: usize,
     min_periods: usize,
     center: bool,
     weights: Option<&[f64]>,
+    _params: DynArgs,
 ) -> ArrayRef
 where
     T: NativeType + PartialOrd + NumCast + Mul<Output = T> + Bounded + IsFloat,
 {
     match (center, weights) {
         (true, None) => {
             // will be O(n2) if we don't take this path we hope that we hit an early return on not sorted data
             if is_sorted_min(values) {
                 rolling_apply_agg_window::<SortedMinMax<_>, _, _>(
                     values,
                     window_size,
                     min_periods,
                     det_offsets_center,
+                    None,
                 )
             } else {
                 rolling_apply_agg_window::<MinWindow<_>, _, _>(
                     values,
                     window_size,
                     min_periods,
                     det_offsets_center,
+                    None,
                 )
             }
         }
         (false, None) => {
             // will be O(n2)
             if is_sorted_min(values) {
                 rolling_apply_agg_window::<SortedMinMax<_>, _, _>(
                     values,
                     window_size,
                     min_periods,
                     det_offsets,
+                    None,
                 )
             } else {
                 rolling_apply_agg_window::<MinWindow<_>, _, _>(
                     values,
                     window_size,
                     min_periods,
                     det_offsets,
+                    None,
                 )
             }
         }
         (true, Some(weights)) => {
             assert!(
                 T::is_float(),
                 "implementation error, should only be reachable by float types"
@@ -492,40 +502,40 @@
 mod test {
     use super::*;
 
     #[test]
     fn test_rolling_min_max() {
         let values = &[1.0f64, 5.0, 3.0, 4.0];
 
-        let out = rolling_min(values, 2, 2, false, None);
+        let out = rolling_min(values, 2, 2, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[None, Some(1.0), Some(3.0), Some(3.0)]);
-        let out = rolling_max(values, 2, 2, false, None);
+        let out = rolling_max(values, 2, 2, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[None, Some(5.0), Some(5.0), Some(4.0)]);
 
-        let out = rolling_min(values, 2, 1, false, None);
+        let out = rolling_min(values, 2, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[Some(1.0), Some(1.0), Some(3.0), Some(3.0)]);
-        let out = rolling_max(values, 2, 1, false, None);
+        let out = rolling_max(values, 2, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[Some(1.0), Some(5.0), Some(5.0), Some(4.0)]);
 
-        let out = rolling_max(values, 3, 1, false, None);
+        let out = rolling_max(values, 3, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[Some(1.0), Some(5.0), Some(5.0), Some(5.0)]);
 
         // test nan handling.
         let values = &[1.0, 2.0, 3.0, f64::nan(), 5.0, 6.0, 7.0];
-        let out = rolling_min(values, 3, 3, false, None);
+        let out = rolling_min(values, 3, 3, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         // we cannot compare nans, so we compare the string values
         assert_eq!(
             format!("{:?}", out.as_slice()),
             format!(
                 "{:?}",
@@ -537,15 +547,15 @@
                     Some(f64::nan()),
                     Some(f64::nan()),
                     Some(5.0)
                 ]
             )
         );
 
-        let out = rolling_max(values, 3, 3, false, None);
+        let out = rolling_max(values, 3, 3, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(
             format!("{:?}", out.as_slice()),
             format!(
                 "{:?}",
                 &[
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -18,37 +18,38 @@
 pub use sum::*;
 pub use variance::*;
 
 use super::*;
 use crate::utils::CustomIterTools;
 
 pub trait RollingAggWindowNoNulls<'a, T: NativeType> {
-    fn new(slice: &'a [T], start: usize, end: usize) -> Self;
+    fn new(slice: &'a [T], start: usize, end: usize, params: DynArgs) -> Self;
 
     /// Update and recompute the window
     /// # Safety
     /// `start` and `end` must be within the windows bounds
     unsafe fn update(&mut self, start: usize, end: usize) -> T;
 }
 
 // Use an aggregation window that maintains the state
 pub(super) fn rolling_apply_agg_window<'a, Agg, T, Fo>(
     values: &'a [T],
     window_size: usize,
     min_periods: usize,
     det_offsets_fn: Fo,
+    params: DynArgs,
 ) -> ArrayRef
 where
     Fo: Fn(Idx, WindowSize, Len) -> (Start, End),
     Agg: RollingAggWindowNoNulls<'a, T>,
     T: Debug + IsFloat + NativeType,
 {
     let len = values.len();
     let (start, end) = det_offsets_fn(0, window_size, len);
-    let mut agg_window = Agg::new(values, start, end);
+    let mut agg_window = Agg::new(values, start, end, params);
 
     let out = (0..len)
         .map(|idx| {
             let (start, end) = det_offsets_fn(idx, window_size, len);
             // safety:
             // we are in bounds
             unsafe { agg_window.update(start, end) }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/quantile.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/quantile.rs`

 * *Files 1% similar despite different names*

```diff
@@ -120,14 +120,15 @@
 
 pub fn rolling_median<T>(
     values: &[T],
     window_size: usize,
     min_periods: usize,
     center: bool,
     weights: Option<&[f64]>,
+    _params: DynArgs,
 ) -> ArrayRef
 where
     T: NativeType
         + std::iter::Sum<T>
         + PartialOrd
         + ToPrimitive
         + NumCast
@@ -374,23 +375,23 @@
             QuantileInterpolOptions::Higher,
             QuantileInterpolOptions::Nearest,
             QuantileInterpolOptions::Midpoint,
             QuantileInterpolOptions::Linear,
         ];
 
         for interpol in interpol_options {
-            let out1 = rolling_min(values, 2, 2, false, None);
+            let out1 = rolling_min(values, 2, 2, false, None, None);
             let out1 = out1.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
             let out1 = out1.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
             let out2 = rolling_quantile(values, 0.0, interpol, 2, 2, false, None);
             let out2 = out2.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
             let out2 = out2.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
             assert_eq!(out1, out2);
 
-            let out1 = rolling_max(values, 2, 2, false, None);
+            let out1 = rolling_max(values, 2, 2, false, None, None);
             let out1 = out1.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
             let out1 = out1.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
             let out2 = rolling_quantile(values, 1.0, interpol, 2, 2, false, None);
             let out2 = out2.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
             let out2 = out2.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
             assert_eq!(out1, out2);
         }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/sum.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/sum.rs`

 * *Files 6% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     last_start: usize,
     last_end: usize,
 }
 
 impl<'a, T: NativeType + IsFloat + std::iter::Sum + AddAssign + SubAssign>
     RollingAggWindowNoNulls<'a, T> for SumWindow<'a, T>
 {
-    fn new(slice: &'a [T], start: usize, end: usize) -> Self {
+    fn new(slice: &'a [T], start: usize, end: usize, _params: DynArgs) -> Self {
         let sum = slice[start..end].iter().copied().sum::<T>();
         Self {
             slice,
             sum,
             last_start: start,
             last_end: end,
         }
@@ -69,30 +69,33 @@
 
 pub fn rolling_sum<T>(
     values: &[T],
     window_size: usize,
     min_periods: usize,
     center: bool,
     weights: Option<&[f64]>,
+    _params: DynArgs,
 ) -> ArrayRef
 where
     T: NativeType + std::iter::Sum + NumCast + Mul<Output = T> + AddAssign + SubAssign + IsFloat,
 {
     match (center, weights) {
         (true, None) => rolling_apply_agg_window::<SumWindow<_>, _, _>(
             values,
             window_size,
             min_periods,
             det_offsets_center,
+            None,
         ),
         (false, None) => rolling_apply_agg_window::<SumWindow<_>, _, _>(
             values,
             window_size,
             min_periods,
             det_offsets,
+            None,
         ),
         (true, Some(weights)) => {
             let weights = no_nulls::coerce_weights(weights);
             no_nulls::rolling_apply_weights(
                 values,
                 window_size,
                 min_periods,
@@ -118,42 +121,42 @@
 #[cfg(test)]
 mod test {
     use super::*;
     #[test]
     fn test_rolling_sum() {
         let values = &[1.0f64, 2.0, 3.0, 4.0];
 
-        let out = rolling_sum(values, 2, 2, false, None);
+        let out = rolling_sum(values, 2, 2, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[None, Some(3.0), Some(5.0), Some(7.0)]);
 
-        let out = rolling_sum(values, 2, 1, false, None);
+        let out = rolling_sum(values, 2, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[Some(1.0), Some(3.0), Some(5.0), Some(7.0)]);
 
-        let out = rolling_sum(values, 4, 1, false, None);
+        let out = rolling_sum(values, 4, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[Some(1.0), Some(3.0), Some(6.0), Some(10.0)]);
 
-        let out = rolling_sum(values, 4, 1, true, None);
+        let out = rolling_sum(values, 4, 1, true, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[Some(3.0), Some(6.0), Some(10.0), Some(9.0)]);
 
-        let out = rolling_sum(values, 4, 4, true, None);
+        let out = rolling_sum(values, 4, 4, true, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[None, None, Some(10.0), None]);
 
         // test nan handling.
         let values = &[1.0, 2.0, 3.0, f64::nan(), 5.0, 6.0, 7.0];
-        let out = rolling_sum(values, 3, 3, false, None);
+        let out = rolling_sum(values, 3, 3, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
 
         assert_eq!(
             format!("{:?}", out.as_slice()),
             format!(
                 "{:?}",
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/variance.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/variance.rs`

 * *Files 8% similar despite different names*

```diff
@@ -13,15 +13,15 @@
     // we get a accumulated error/drift
     last_recompute: u8,
 }
 
 impl<'a, T: NativeType + IsFloat + std::iter::Sum + AddAssign + SubAssign + Mul<Output = T>>
     RollingAggWindowNoNulls<'a, T> for SumSquaredWindow<'a, T>
 {
-    fn new(slice: &'a [T], start: usize, end: usize) -> Self {
+    fn new(slice: &'a [T], start: usize, end: usize, _params: DynArgs) -> Self {
         let sum = slice[start..end].iter().map(|v| *v * *v).sum::<T>();
         Self {
             slice,
             sum_of_squares: sum,
             last_start: start,
             last_end: end,
             last_recompute: 0,
@@ -76,50 +76,57 @@
 
 // E[(xi - E[x])^2]
 // can be expanded to
 // E[x^2] - E[x]^2
 pub struct VarWindow<'a, T> {
     mean: MeanWindow<'a, T>,
     sum_of_squares: SumSquaredWindow<'a, T>,
+    ddof: u8,
 }
 
 impl<
         'a,
         T: NativeType
             + IsFloat
+            + Float
             + std::iter::Sum
             + AddAssign
             + SubAssign
             + Div<Output = T>
             + NumCast
             + One
             + Zero
             + PartialOrd
             + Sub<Output = T>,
     > RollingAggWindowNoNulls<'a, T> for VarWindow<'a, T>
 {
-    fn new(slice: &'a [T], start: usize, end: usize) -> Self {
+    fn new(slice: &'a [T], start: usize, end: usize, params: DynArgs) -> Self {
         Self {
-            mean: MeanWindow::new(slice, start, end),
-            sum_of_squares: SumSquaredWindow::new(slice, start, end),
+            mean: MeanWindow::new(slice, start, end, None),
+            sum_of_squares: SumSquaredWindow::new(slice, start, end, None),
+            ddof: match params {
+                None => 1,
+                Some(pars) => pars.downcast_ref::<RollingVarParams>().unwrap().ddof,
+            },
         }
     }
 
     unsafe fn update(&mut self, start: usize, end: usize) -> T {
-        let count = NumCast::from(end - start).unwrap();
+        let count: T = NumCast::from(end - start).unwrap();
         let sum_of_squares = self.sum_of_squares.update(start, end);
-        let mean_of_squares = sum_of_squares / count;
         let mean = self.mean.update(start, end);
-        let var = mean_of_squares - mean * mean;
 
+        let denom = count - NumCast::from(self.ddof).unwrap();
         if end - start == 1 {
             T::zero()
+        } else if denom <= T::zero() {
+            //ddof would be greater than # of observations
+            T::infinity()
         } else {
-            // apply Bessel's correction
-            let out = var / (count - T::one()) * count;
+            let out = (sum_of_squares - count * mean * mean) / denom;
             // variance cannot be negative.
             // if it is negative it is due to numeric instability
             if out < T::zero() {
                 T::zero()
             } else {
                 out
             }
@@ -129,14 +136,15 @@
 
 pub fn rolling_var<T>(
     values: &[T],
     window_size: usize,
     min_periods: usize,
     center: bool,
     weights: Option<&[f64]>,
+    params: DynArgs,
 ) -> ArrayRef
 where
     T: NativeType
         + Float
         + IsFloat
         + std::iter::Sum
         + AddAssign
@@ -149,20 +157,22 @@
 {
     match (center, weights) {
         (true, None) => rolling_apply_agg_window::<VarWindow<_>, _, _>(
             values,
             window_size,
             min_periods,
             det_offsets_center,
+            params,
         ),
         (false, None) => rolling_apply_agg_window::<VarWindow<_>, _, _>(
             values,
             window_size,
             min_periods,
             det_offsets,
+            params,
         ),
         (true, Some(weights)) => {
             let weights = coerce_weights(weights);
             super::rolling_apply_weights(
                 values,
                 window_size,
                 min_periods,
@@ -192,29 +202,30 @@
     var: VarWindow<'a, T>,
 }
 
 impl<
         'a,
         T: NativeType
             + IsFloat
+            + Float
             + std::iter::Sum
             + AddAssign
             + SubAssign
             + Div<Output = T>
             + NumCast
             + One
             + Zero
             + Sub<Output = T>
             + PartialOrd
             + Pow<T, Output = T>,
     > RollingAggWindowNoNulls<'a, T> for StdWindow<'a, T>
 {
-    fn new(slice: &'a [T], start: usize, end: usize) -> Self {
+    fn new(slice: &'a [T], start: usize, end: usize, params: DynArgs) -> Self {
         Self {
-            var: VarWindow::new(slice, start, end),
+            var: VarWindow::new(slice, start, end, params),
         }
     }
 
     unsafe fn update(&mut self, start: usize, end: usize) -> T {
         let var = self.var.update(start, end);
         var.pow(NumCast::from(0.5).unwrap())
     }
@@ -222,14 +233,15 @@
 
 pub fn rolling_std<T>(
     values: &[T],
     window_size: usize,
     min_periods: usize,
     center: bool,
     weights: Option<&[f64]>,
+    params: DynArgs,
 ) -> ArrayRef
 where
     T: NativeType
         + Float
         + IsFloat
         + std::iter::Sum
         + AddAssign
@@ -243,20 +255,22 @@
 {
     match (center, weights) {
         (true, None) => rolling_apply_agg_window::<StdWindow<_>, _, _>(
             values,
             window_size,
             min_periods,
             det_offsets_center,
+            params,
         ),
         (false, None) => rolling_apply_agg_window::<StdWindow<_>, _, _>(
             values,
             window_size,
             min_periods,
             det_offsets,
+            params,
         ),
         (_, Some(_)) => {
             panic!("weights not yet supported for rolling_std")
         }
     }
 }
 
@@ -264,46 +278,52 @@
 mod test {
     use super::*;
 
     #[test]
     fn test_rolling_var() {
         let values = &[1.0f64, 5.0, 3.0, 4.0];
 
-        let out = rolling_var(values, 2, 2, false, None);
+        let out = rolling_var(values, 2, 2, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[None, Some(8.0), Some(2.0), Some(0.5)]);
 
-        let out = rolling_var(values, 2, 1, false, None);
+        let testpars = Some(Arc::new(RollingVarParams { ddof: 0 }) as Arc<dyn Any + Send + Sync>);
+        let out = rolling_var(values, 2, 2, false, None, testpars);
+        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
+        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
+        assert_eq!(out, &[None, Some(4.0), Some(1.0), Some(0.25)]);
+
+        let out = rolling_var(values, 2, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out
             .into_iter()
             .map(|v| v.copied().unwrap())
             .collect::<Vec<_>>();
         // we cannot compare nans, so we compare the string values
         assert_eq!(
             format!("{:?}", out.as_slice()),
             format!("{:?}", &[0.0, 8.0, 2.0, 0.5])
         );
         // test nan handling.
         let values = &[-10.0, 2.0, 3.0, f64::nan(), 5.0, 6.0, 7.0];
-        let out = rolling_var(values, 3, 3, false, None);
+        let out = rolling_var(values, 3, 3, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         // we cannot compare nans, so we compare the string values
         assert_eq!(
             format!("{:?}", out.as_slice()),
             format!(
                 "{:?}",
                 &[
                     None,
                     None,
-                    Some(52.33333333333333),
+                    Some(52.333333333333336),
                     Some(f64::nan()),
                     Some(f64::nan()),
                     Some(f64::nan()),
-                    Some(0.9999999999999964)
+                    Some(1.0)
                 ]
             )
         );
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mean.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mean.rs`

 * *Files 13% similar despite different names*

```diff
@@ -6,17 +6,23 @@
 }
 
 impl<
         'a,
         T: NativeType + IsFloat + Add<Output = T> + Sub<Output = T> + NumCast + Div<Output = T>,
     > RollingAggWindowNulls<'a, T> for MeanWindow<'a, T>
 {
-    unsafe fn new(slice: &'a [T], validity: &'a Bitmap, start: usize, end: usize) -> Self {
+    unsafe fn new(
+        slice: &'a [T],
+        validity: &'a Bitmap,
+        start: usize,
+        end: usize,
+        params: DynArgs,
+    ) -> Self {
         Self {
-            sum: SumWindow::new(slice, validity, start, end),
+            sum: SumWindow::new(slice, validity, start, end, params),
         }
     }
 
     unsafe fn update(&mut self, start: usize, end: usize) -> Option<T> {
         let sum = self.sum.update(start, end);
         sum.map(|sum| sum / NumCast::from(end - start - self.sum.null_count).unwrap())
     }
@@ -27,14 +33,15 @@
 
 pub fn rolling_mean<T>(
     arr: &PrimitiveArray<T>,
     window_size: usize,
     min_periods: usize,
     center: bool,
     weights: Option<&[f64]>,
+    _params: DynArgs,
 ) -> ArrayRef
 where
     T: NativeType
         + IsFloat
         + PartialOrd
         + Add<Output = T>
         + Sub<Output = T>
@@ -47,18 +54,20 @@
     if center {
         rolling_apply_agg_window::<MeanWindow<_>, _, _>(
             arr.values().as_slice(),
             arr.validity().as_ref().unwrap(),
             window_size,
             min_periods,
             det_offsets_center,
+            None,
         )
     } else {
         rolling_apply_agg_window::<MeanWindow<_>, _, _>(
             arr.values().as_slice(),
             arr.validity().as_ref().unwrap(),
             window_size,
             min_periods,
             det_offsets,
+            None,
         )
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/nulls/min_max.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/nulls/min_max.rs`

 * *Files 3% similar despite different names*

```diff
@@ -44,15 +44,21 @@
     fn count_nulls(&self, start: usize, end: usize) -> usize {
         let (bytes, offset, _) = self.validity.as_slice();
         count_zeros(bytes, offset + start, end - start)
     }
 }
 
 impl<'a, T: NativeType> RollingAggWindowNulls<'a, T> for SortedMinMax<'a, T> {
-    unsafe fn new(slice: &'a [T], validity: &'a Bitmap, start: usize, end: usize) -> Self {
+    unsafe fn new(
+        slice: &'a [T],
+        validity: &'a Bitmap,
+        start: usize,
+        end: usize,
+        _params: DynArgs,
+    ) -> Self {
         let mut out = Self {
             slice,
             validity,
             last_start: start,
             last_end: end,
             null_count: 0,
         };
@@ -291,15 +297,21 @@
 }
 
 fn take_min<T: NativeType + IsFloat + PartialOrd>(a: T, b: T) -> T {
     std::cmp::min_by(a, b, compare_fn_nan_min)
 }
 
 impl<'a, T: NativeType + IsFloat + PartialOrd> RollingAggWindowNulls<'a, T> for MinWindow<'a, T> {
-    unsafe fn new(slice: &'a [T], validity: &'a Bitmap, start: usize, end: usize) -> Self {
+    unsafe fn new(
+        slice: &'a [T],
+        validity: &'a Bitmap,
+        start: usize,
+        end: usize,
+        _params: DynArgs,
+    ) -> Self {
         Self {
             inner: MinMaxWindow::new(
                 slice,
                 validity,
                 start,
                 end,
                 compare_fn_nan_min,
@@ -320,50 +332,59 @@
 
 pub fn rolling_min<T>(
     arr: &PrimitiveArray<T>,
     window_size: usize,
     min_periods: usize,
     center: bool,
     weights: Option<&[f64]>,
+    _params: DynArgs,
 ) -> ArrayRef
 where
     T: NativeType + std::iter::Sum + Zero + AddAssign + Copy + PartialOrd + Bounded + IsFloat,
 {
     if weights.is_some() {
         panic!("weights not yet supported on array with null values")
     }
     if center {
         rolling_apply_agg_window::<MinWindow<_>, _, _>(
             arr.values().as_slice(),
             arr.validity().as_ref().unwrap(),
             window_size,
             min_periods,
             det_offsets_center,
+            None,
         )
     } else {
         rolling_apply_agg_window::<MinWindow<_>, _, _>(
             arr.values().as_slice(),
             arr.validity().as_ref().unwrap(),
             window_size,
             min_periods,
             det_offsets,
+            None,
         )
     }
 }
 
 pub struct MaxWindow<'a, T: NativeType + PartialOrd + IsFloat> {
     inner: MinMaxWindow<'a, T>,
 }
 
 fn take_max<T: NativeType + IsFloat + PartialOrd>(a: T, b: T) -> T {
     std::cmp::max_by(a, b, compare_fn_nan_max)
 }
 
 impl<'a, T: NativeType + IsFloat + PartialOrd> RollingAggWindowNulls<'a, T> for MaxWindow<'a, T> {
-    unsafe fn new(slice: &'a [T], validity: &'a Bitmap, start: usize, end: usize) -> Self {
+    unsafe fn new(
+        slice: &'a [T],
+        validity: &'a Bitmap,
+        start: usize,
+        end: usize,
+        _params: DynArgs,
+    ) -> Self {
         Self {
             inner: MinMaxWindow::new(
                 slice,
                 validity,
                 start,
                 end,
                 compare_fn_nan_max,
@@ -384,14 +405,15 @@
 
 pub fn rolling_max<T>(
     arr: &PrimitiveArray<T>,
     window_size: usize,
     min_periods: usize,
     center: bool,
     weights: Option<&[f64]>,
+    _params: DynArgs,
 ) -> ArrayRef
 where
     T: NativeType + std::iter::Sum + Zero + AddAssign + Copy + PartialOrd + Bounded + IsFloat,
 {
     if weights.is_some() {
         panic!("weights not yet supported on array with null values")
     }
@@ -399,36 +421,40 @@
         if is_reverse_sorted_max_nulls(arr.values().as_slice(), arr.validity().as_ref().unwrap()) {
             rolling_apply_agg_window::<SortedMinMax<_>, _, _>(
                 arr.values().as_slice(),
                 arr.validity().as_ref().unwrap(),
                 window_size,
                 min_periods,
                 det_offsets_center,
+                None,
             )
         } else {
             rolling_apply_agg_window::<MaxWindow<_>, _, _>(
                 arr.values().as_slice(),
                 arr.validity().as_ref().unwrap(),
                 window_size,
                 min_periods,
                 det_offsets_center,
+                None,
             )
         }
     } else if is_reverse_sorted_max_nulls(arr.values().as_slice(), arr.validity().as_ref().unwrap())
     {
         rolling_apply_agg_window::<SortedMinMax<_>, _, _>(
             arr.values().as_slice(),
             arr.validity().as_ref().unwrap(),
             window_size,
             min_periods,
             det_offsets,
+            None,
         )
     } else {
         rolling_apply_agg_window::<MaxWindow<_>, _, _>(
             arr.values().as_slice(),
             arr.validity().as_ref().unwrap(),
             window_size,
             min_periods,
             det_offsets,
+            None,
         )
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mod.rs`

 * *Files 5% similar despite different names*

```diff
@@ -11,15 +11,21 @@
 pub use variance::*;
 
 use super::*;
 
 pub trait RollingAggWindowNulls<'a, T: NativeType> {
     /// # Safety
     /// `start` and `end` must be in bounds for `slice` and `validity`
-    unsafe fn new(slice: &'a [T], validity: &'a Bitmap, start: usize, end: usize) -> Self;
+    unsafe fn new(
+        slice: &'a [T],
+        validity: &'a Bitmap,
+        start: usize,
+        end: usize,
+        params: DynArgs,
+    ) -> Self;
 
     /// # Safety
     /// `start` and `end` must be in bounds of `slice` and `bitmap`
     unsafe fn update(&mut self, start: usize, end: usize) -> Option<T>;
 
     fn is_valid(&self, min_periods: usize) -> bool;
 }
@@ -27,24 +33,25 @@
 // Use an aggregation window that maintains the state
 pub(super) fn rolling_apply_agg_window<'a, Agg, T, Fo>(
     values: &'a [T],
     validity: &'a Bitmap,
     window_size: usize,
     min_periods: usize,
     det_offsets_fn: Fo,
+    params: DynArgs,
 ) -> ArrayRef
 where
     Fo: Fn(Idx, WindowSize, Len) -> (Start, End) + Copy,
     Agg: RollingAggWindowNulls<'a, T>,
     T: IsFloat + NativeType,
 {
     let len = values.len();
     let (start, end) = det_offsets_fn(0, window_size, len);
     // Safety; we are in bounds
-    let mut agg_window = unsafe { Agg::new(values, validity, start, end) };
+    let mut agg_window = unsafe { Agg::new(values, validity, start, end, params) };
 
     let mut validity = match create_validity(min_periods, len, window_size, det_offsets_fn) {
         Some(v) => v,
         None => {
             let mut validity = MutableBitmap::with_capacity(len);
             validity.extend_constant(len, true);
             validity
@@ -107,119 +114,137 @@
         let buf = Buffer::from(vec![1.0, 2.0, 3.0, 4.0]);
         let arr = &PrimitiveArray::new(
             DataType::Float64,
             buf,
             Some(Bitmap::from(&[true, false, true, true])),
         );
 
-        let out = rolling_sum(arr, 2, 2, false, None);
+        let out = rolling_sum(arr, 2, 2, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[None, None, None, Some(7.0)]);
 
-        let out = rolling_sum(arr, 2, 1, false, None);
+        let out = rolling_sum(arr, 2, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[Some(1.0), Some(1.0), Some(3.0), Some(7.0)]);
 
-        let out = rolling_sum(arr, 4, 1, false, None);
+        let out = rolling_sum(arr, 4, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[Some(1.0), Some(1.0), Some(4.0), Some(8.0)]);
 
-        let out = rolling_sum(arr, 4, 1, true, None);
+        let out = rolling_sum(arr, 4, 1, true, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[Some(1.0), Some(4.0), Some(8.0), Some(7.0)]);
 
-        let out = rolling_sum(arr, 4, 4, true, None);
+        let out = rolling_sum(arr, 4, 4, true, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[None, None, None, None]);
     }
 
     #[test]
     fn test_rolling_mean_nulls() {
         let arr = get_null_arr();
         let arr = &arr;
 
-        let out = rolling_mean(arr, 2, 2, false, None);
+        let out = rolling_mean(arr, 2, 2, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[None, None, None, Some(1.5)]);
 
-        let out = rolling_mean(arr, 2, 1, false, None);
+        let out = rolling_mean(arr, 2, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[Some(1.0), Some(1.0), Some(-1.0), Some(1.5)]);
 
-        let out = rolling_mean(arr, 4, 1, false, None);
+        let out = rolling_mean(arr, 4, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[Some(1.0), Some(1.0), Some(0.0), Some(4.0 / 3.0)]);
     }
 
     #[test]
     fn test_rolling_var_nulls() {
         let arr = get_null_arr();
         let arr = &arr;
 
-        let out = rolling_var(arr, 3, 1, false, None);
+        let out = rolling_var(arr, 3, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out
             .into_iter()
             .map(|v| v.copied().unwrap())
             .collect::<Vec<_>>();
 
         assert_eq!(out, &[0.0, 0.0, 2.0, 12.5]);
 
-        let out = rolling_var(arr, 4, 1, false, None);
+        let testpars = Some(Arc::new(RollingVarParams { ddof: 0 }) as Arc<dyn Any + Send + Sync>);
+        let out = rolling_var(arr, 3, 1, false, None, testpars.clone());
+        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
+        let out = out
+            .into_iter()
+            .map(|v| v.copied().unwrap())
+            .collect::<Vec<_>>();
+
+        assert_eq!(out, &[0.0, 0.0, 1.0, 6.25]);
+
+        let out = rolling_var(arr, 4, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out
             .into_iter()
             .map(|v| v.copied().unwrap())
             .collect::<Vec<_>>();
         assert_eq!(out, &[0.0, 0.0, 2.0, 6.333333333333334]);
+
+        let out = rolling_var(arr, 4, 1, false, None, testpars.clone());
+        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
+        let out = out
+            .into_iter()
+            .map(|v| v.copied().unwrap())
+            .collect::<Vec<_>>();
+        assert_eq!(out, &[0.0, 0.0, 1.0, 4.222222222222222]);
     }
 
     #[test]
     fn test_rolling_max_no_nulls() {
         let buf = Buffer::from(vec![1.0, 2.0, 3.0, 4.0]);
         let arr = &PrimitiveArray::new(
             DataType::Float64,
             buf,
             Some(Bitmap::from(&[true, true, true, true])),
         );
-        let out = rolling_max(arr, 4, 1, false, None);
+        let out = rolling_max(arr, 4, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[Some(1.0), Some(2.0), Some(3.0), Some(4.0)]);
 
-        let out = rolling_max(arr, 2, 2, false, None);
+        let out = rolling_max(arr, 2, 2, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[None, Some(2.0), Some(3.0), Some(4.0)]);
 
-        let out = rolling_max(arr, 4, 4, false, None);
+        let out = rolling_max(arr, 4, 4, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[None, None, None, Some(4.0)]);
 
         let buf = Buffer::from(vec![4.0, 3.0, 2.0, 1.0]);
         let arr = &PrimitiveArray::new(
             DataType::Float64,
             buf,
             Some(Bitmap::from(&[true, true, true, true])),
         );
-        let out = rolling_max(arr, 2, 1, false, None);
+        let out = rolling_max(arr, 2, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[Some(4.0), Some(4.0), Some(3.0), Some(2.0)]);
 
-        let out = super::no_nulls::rolling_max(arr.values().as_slice(), 2, 1, false, None);
+        let out = super::no_nulls::rolling_max(arr.values().as_slice(), 2, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
         assert_eq!(out, &[Some(4.0), Some(4.0), Some(3.0), Some(2.0)]);
     }
 
     #[test]
     fn test_rolling_extrema_nulls() {
@@ -234,14 +259,15 @@
 
         let out = rolling_apply_agg_window::<MaxWindow<_>, _, _>(
             arr.values().as_slice(),
             arr.validity().as_ref().unwrap(),
             window_size,
             min_periods,
             det_offsets,
+            None,
         );
         let arr = out.as_any().downcast_ref::<Int32Array>().unwrap();
         assert_eq!(arr.null_count(), 2);
         assert_eq!(
             &arr.values().as_slice()[2..],
             &[3, 10, 10, 10, 10, 10, 9, 8, 7, 6, 5, 4, 3]
         );
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/nulls/quantile.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/nulls/quantile.rs`

 * *Files 0% similar despite different names*

```diff
@@ -202,14 +202,15 @@
 }
 pub fn rolling_median<T>(
     arr: &PrimitiveArray<T>,
     window_size: usize,
     min_periods: usize,
     center: bool,
     weights: Option<&[f64]>,
+    _params: DynArgs,
 ) -> ArrayRef
 where
     T: NativeType
         + std::iter::Sum
         + Zero
         + AddAssign
         + Copy
@@ -345,23 +346,23 @@
             QuantileInterpolOptions::Higher,
             QuantileInterpolOptions::Nearest,
             QuantileInterpolOptions::Midpoint,
             QuantileInterpolOptions::Linear,
         ];
 
         for interpol in interpol_options {
-            let out1 = rolling_min(values, 2, 1, false, None);
+            let out1 = rolling_min(values, 2, 1, false, None, None);
             let out1 = out1.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
             let out1 = out1.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
             let out2 = rolling_quantile(values, 0.0, interpol, 2, 1, false, None);
             let out2 = out2.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
             let out2 = out2.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
             assert_eq!(out1, out2);
 
-            let out1 = rolling_max(values, 2, 1, false, None);
+            let out1 = rolling_max(values, 2, 1, false, None, None);
             let out1 = out1.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
             let out1 = out1.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
             let out2 = rolling_quantile(values, 1.0, interpol, 2, 1, false, None);
             let out2 = out2.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
             let out2 = out2.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
             assert_eq!(out1, out2);
         }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/nulls/sum.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/nulls/sum.rs`

 * *Files 10% similar despite different names*

```diff
@@ -34,15 +34,21 @@
         sum
     }
 }
 
 impl<'a, T: NativeType + IsFloat + Add<Output = T> + Sub<Output = T>> RollingAggWindowNulls<'a, T>
     for SumWindow<'a, T>
 {
-    unsafe fn new(slice: &'a [T], validity: &'a Bitmap, start: usize, end: usize) -> Self {
+    unsafe fn new(
+        slice: &'a [T],
+        validity: &'a Bitmap,
+        start: usize,
+        end: usize,
+        _params: DynArgs,
+    ) -> Self {
         let mut out = Self {
             slice,
             validity,
             sum: None,
             last_start: start,
             last_end: end,
             null_count: 0,
@@ -119,32 +125,35 @@
 
 pub fn rolling_sum<T>(
     arr: &PrimitiveArray<T>,
     window_size: usize,
     min_periods: usize,
     center: bool,
     weights: Option<&[f64]>,
+    _params: DynArgs,
 ) -> ArrayRef
 where
     T: NativeType + IsFloat + PartialOrd + Add<Output = T> + Sub<Output = T>,
 {
     if weights.is_some() {
         panic!("weights not yet supported on array with null values")
     }
     if center {
         rolling_apply_agg_window::<SumWindow<_>, _, _>(
             arr.values().as_slice(),
             arr.validity().as_ref().unwrap(),
             window_size,
             min_periods,
             det_offsets_center,
+            None,
         )
     } else {
         rolling_apply_agg_window::<SumWindow<_>, _, _>(
             arr.values().as_slice(),
             arr.validity().as_ref().unwrap(),
             window_size,
             min_periods,
             det_offsets,
+            None,
         )
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/nulls/variance.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/nulls/variance.rs`

 * *Files 11% similar despite different names*

```diff
@@ -38,15 +38,21 @@
         sum_of_squares
     }
 }
 
 impl<'a, T: NativeType + IsFloat + Add<Output = T> + Sub<Output = T> + Mul<Output = T>>
     RollingAggWindowNulls<'a, T> for SumSquaredWindow<'a, T>
 {
-    unsafe fn new(slice: &'a [T], validity: &'a Bitmap, start: usize, end: usize) -> Self {
+    unsafe fn new(
+        slice: &'a [T],
+        validity: &'a Bitmap,
+        start: usize,
+        end: usize,
+        _params: DynArgs,
+    ) -> Self {
         let mut out = Self {
             slice,
             validity,
             sum_of_squares: None,
             last_start: start,
             last_end: end,
             null_count: 0,
@@ -123,113 +129,137 @@
 
 // E[(xi - E[x])^2]
 // can be expanded to
 // E[x^2] - E[x]^2
 pub struct VarWindow<'a, T> {
     mean: MeanWindow<'a, T>,
     sum_of_squares: SumSquaredWindow<'a, T>,
+    ddof: u8,
 }
 
 impl<
         'a,
         T: NativeType
             + IsFloat
+            + Float
             + std::iter::Sum
             + AddAssign
             + SubAssign
             + Div<Output = T>
             + NumCast
             + One
+            + Zero
+            + PartialOrd
             + Add<Output = T>
             + Sub<Output = T>,
     > RollingAggWindowNulls<'a, T> for VarWindow<'a, T>
 {
-    unsafe fn new(slice: &'a [T], validity: &'a Bitmap, start: usize, end: usize) -> Self {
+    unsafe fn new(
+        slice: &'a [T],
+        validity: &'a Bitmap,
+        start: usize,
+        end: usize,
+        params: DynArgs,
+    ) -> Self {
         Self {
-            mean: MeanWindow::new(slice, validity, start, end),
-            sum_of_squares: SumSquaredWindow::new(slice, validity, start, end),
+            mean: MeanWindow::new(slice, validity, start, end, None),
+            sum_of_squares: SumSquaredWindow::new(slice, validity, start, end, None),
+            ddof: match params {
+                None => 1,
+                Some(pars) => pars.downcast_ref::<RollingVarParams>().unwrap().ddof,
+            },
         }
     }
 
     unsafe fn update(&mut self, start: usize, end: usize) -> Option<T> {
         let sum_of_squares = self.sum_of_squares.update(start, end)?;
         let null_count = self.sum_of_squares.null_count;
-        let count = NumCast::from(end - start - null_count).unwrap();
+        let count: T = NumCast::from(end - start - null_count).unwrap();
 
-        let mean_of_squares = sum_of_squares / count;
         let mean = self.mean.update(start, end)?;
+        let ddof = NumCast::from(self.ddof).unwrap();
 
-        if count == T::one() {
+        let denom = count - ddof;
+
+        if count == T::zero() {
+            None
+        } else if count == T::one() {
             NumCast::from(0)
+        } else if denom <= T::zero() {
+            Some(T::infinity())
         } else {
-            let var = mean_of_squares - mean * mean;
-
-            // apply Bessel's correction
-            Some(var / (count - T::one()) * count)
+            let var = (sum_of_squares - count * mean * mean) / denom;
+            Some(if var < T::zero() { T::zero() } else { var })
         }
     }
     fn is_valid(&self, min_periods: usize) -> bool {
         self.mean.is_valid(min_periods)
     }
 }
 
 pub fn rolling_var<T>(
     arr: &PrimitiveArray<T>,
     window_size: usize,
     min_periods: usize,
     center: bool,
     weights: Option<&[f64]>,
+    params: DynArgs,
 ) -> ArrayRef
 where
     T: NativeType + std::iter::Sum<T> + Zero + AddAssign + SubAssign + IsFloat + Float,
 {
     if weights.is_some() {
         panic!("weights not yet supported on array with null values")
     }
-    if center {
-        rolling_apply_agg_window::<VarWindow<_>, _, _>(
-            arr.values().as_slice(),
-            arr.validity().as_ref().unwrap(),
-            window_size,
-            min_periods,
-            det_offsets_center,
-        )
+    let offsets_fn = if center {
+        det_offsets_center
     } else {
-        rolling_apply_agg_window::<VarWindow<_>, _, _>(
-            arr.values().as_slice(),
-            arr.validity().as_ref().unwrap(),
-            window_size,
-            min_periods,
-            det_offsets,
-        )
-    }
+        det_offsets
+    };
+    rolling_apply_agg_window::<VarWindow<_>, _, _>(
+        arr.values().as_slice(),
+        arr.validity().as_ref().unwrap(),
+        window_size,
+        min_periods,
+        offsets_fn,
+        params,
+    )
 }
 
 pub struct StdWindow<'a, T> {
     var: VarWindow<'a, T>,
 }
 
 impl<
         'a,
         T: NativeType
             + IsFloat
+            + Float
             + std::iter::Sum
             + AddAssign
             + SubAssign
             + Div<Output = T>
             + NumCast
             + One
+            + Zero
+            + PartialOrd
             + Add<Output = T>
             + Sub<Output = T>
             + Pow<T, Output = T>,
     > RollingAggWindowNulls<'a, T> for StdWindow<'a, T>
 {
-    unsafe fn new(slice: &'a [T], validity: &'a Bitmap, start: usize, end: usize) -> Self {
+    unsafe fn new(
+        slice: &'a [T],
+        validity: &'a Bitmap,
+        start: usize,
+        end: usize,
+        params: DynArgs,
+    ) -> Self {
         Self {
-            var: VarWindow::new(slice, validity, start, end),
+            var: VarWindow::new(slice, validity, start, end, params),
         }
     }
 
     unsafe fn update(&mut self, start: usize, end: usize) -> Option<T> {
         self.var
             .update(start, end)
             .map(|var| var.pow(NumCast::from(0.5).unwrap()))
@@ -241,39 +271,36 @@
 
 pub fn rolling_std<T>(
     arr: &PrimitiveArray<T>,
     window_size: usize,
     min_periods: usize,
     center: bool,
     weights: Option<&[f64]>,
+    params: DynArgs,
 ) -> ArrayRef
 where
     T: NativeType
         + std::iter::Sum<T>
         + Zero
         + AddAssign
         + SubAssign
         + IsFloat
         + Float
         + Pow<T, Output = T>,
 {
     if weights.is_some() {
         panic!("weights not yet supported on array with null values")
     }
-    if center {
-        rolling_apply_agg_window::<StdWindow<_>, _, _>(
-            arr.values().as_slice(),
-            arr.validity().as_ref().unwrap(),
-            window_size,
-            min_periods,
-            det_offsets_center,
-        )
+    let offsets_fn = if center {
+        det_offsets_center
     } else {
-        rolling_apply_agg_window::<StdWindow<_>, _, _>(
-            arr.values().as_slice(),
-            arr.validity().as_ref().unwrap(),
-            window_size,
-            min_periods,
-            det_offsets,
-        )
-    }
+        det_offsets
+    };
+    rolling_apply_agg_window::<StdWindow<_>, _, _>(
+        arr.values().as_slice(),
+        arr.validity().as_ref().unwrap(),
+        window_size,
+        min_periods,
+        offsets_fn,
+        params,
+    )
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/rolling/window.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/rolling/window.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/set.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/set.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/sort_partition.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/sort_partition.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/sorted_join/inner.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/sorted_join/inner.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/sorted_join/left.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/sorted_join/left.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/string.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/string.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/take_agg/boolean.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/take_agg/boolean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/take_agg/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/take_agg/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/take_agg/var.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/take_agg/var.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/kernels/time.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/kernels/time.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/slice.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/trusted_len/boolean.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/trusted_len/boolean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/trusted_len/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/trusted_len/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/trusted_len/push_unchecked.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/trusted_len/push_unchecked.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-arrow/src/utils.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-arrow/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-row/Cargo.toml` & `polars_lts_cpu-0.18.1/local_dependencies/polars-row/Cargo.toml`

 * *Files 22% similar despite different names*

```diff
@@ -1,26 +1,27 @@
 [package]
 name = "polars-row"
 version= "0.30.0"
 edition = "2021"
 license = "MIT"
 repository = "https://github.com/pola-rs/polars"
 description = "Row encodings for the Polars DataFrame library"
+resolver = "2"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
 polars-error = { version = "0.30.0", path = "../polars-error" }
 polars-utils = { version = "0.30.0", path = "../polars-utils" }
 
 [dependencies.arrow]
 package = "arrow2"
-# git = "https://github.com/jorgecarleitao/arrow2"
+git = "https://github.com/jorgecarleitao/arrow2"
 # git = "https://github.com/ritchie46/arrow2"
-# rev = "1491c6e8f4fd100f53c358e4f3ef1536d9e75090"
+rev = "fb5e4d591c7149df590a330365fae55d2370962f"
 # path = "../arrow2"
 # branch = "polars_2023-05-25"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-row/LICENSE` & `polars_lts_cpu-0.18.1/local_dependencies/polars-io/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-row/src/encode.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-row/src/encode.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-row/src/encodings/fixed.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-row/src/encodings/fixed.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-row/src/encodings/variable.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-row/src/encodings/variable.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-row/src/lib.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-row/src/lib.rs`

 * *Files 1% similar despite different names*

```diff
@@ -117,20 +117,20 @@
 //! ```
 //!
 //! This approach is loosely inspired by [COBS] encoding, and chosen over more traditional
 //! [byte stuffing] as it is more amenable to vectorisation, in particular AVX-256.
 //!
 //! ## Dictionary Encoding
 //!
-//! [`RowConverter`] needs to support converting dictionary encoded arrays with unsorted, and
+//! [`RowsEncoded`] needs to support converting dictionary encoded arrays with unsorted, and
 //! potentially distinct dictionaries. One simple mechanism to avoid this would be to reverse
 //! the dictionary encoding, and encode the array values directly, however, this would lose
 //! the benefits of dictionary encoding to reduce memory and CPU consumption.
 //!
-//! As such the [`RowConverter`] creates an order-preserving mapping
+//! As such the [`RowsEncoded`] creates an order-preserving mapping
 //! for each dictionary encoded column, which allows new dictionary
 //! values to be added whilst preserving the sort order.
 //!
 //! A null dictionary value is encoded as `0_u8`.
 //!
 //! A non-null dictionary value is encoded as `1_u8` followed by a null-terminated byte array
 //! key determined by the order-preserving dictionary encoding
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-row/src/row.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-row/src/row.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-row/src/utils.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-row/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/Cargo.toml` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/Cargo.toml`

 * *Files 8% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 [package]
 name = "polars-sql"
 version= "0.30.0"
 edition = "2021"
 license = "MIT"
 repository = "https://github.com/pola-rs/polars"
 description = "SQL transpiler for polars. Converts SQL to polars logical plans"
+resolver = "2"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 [features]
 csv = ["polars-lazy/csv"]
 json = ["polars-lazy/json"]
 default = []
 ipc = ["polars-lazy/ipc"]
 parquet = ["polars-lazy/parquet"]
-private = []
 
 [dependencies]
 polars-arrow = { version = "0.30.0", path = "../polars-arrow", features = ["like"] }
 polars-core = { version = "0.30.0", path = "../polars-core", features = [] }
 polars-lazy = { version = "0.30.0", path = "../polars-lazy", features = ["compile", "strings", "cross_join", "trigonometry", "abs", "round_series", "log", "regex", "is_in", "meta", "cum_agg"] }
 polars-plan = { version = "0.30.0", path = "../polars-plan", features = ["compile"] }
 serde = "1"
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/LICENSE` & `polars_lts_cpu-0.18.1/local_dependencies/polars-plan/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/src/context.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/src/context.rs`

 * *Files 1% similar despite different names*

```diff
@@ -601,24 +601,21 @@
                 expr.exclude(idents.iter().map(|i| &i.value))
             }
             _ => expr,
         })
     }
 }
 
-#[cfg(feature = "private")]
 impl SQLContext {
     /// Get internal table map. For internal use only.
-    #[cfg(feature = "private")]
     pub fn get_table_map(&self) -> PlHashMap<String, LazyFrame> {
         self.table_map.clone()
     }
 
     /// Create a new SQLContext from a table map. For internal use only
-    #[cfg(feature = "private")]
     pub fn new_from_table_map(table_map: PlHashMap<String, LazyFrame>) -> Self {
         Self {
             table_map,
             cte_map: RefCell::new(PlHashMap::new()),
         }
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/src/functions.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/src/functions.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/src/keywords.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/src/keywords.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/src/sql_expr.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/src/sql_expr.rs`

 * *Files 8% similar despite different names*

```diff
@@ -1,16 +1,19 @@
+use polars_arrow::error::to_compute_err;
 use polars_core::prelude::*;
 use polars_lazy::dsl::Expr;
 use polars_lazy::prelude::*;
 use polars_plan::prelude::{col, when};
 use sqlparser::ast::{
     ArrayAgg, BinaryOperator as SQLBinaryOperator, BinaryOperator, DataType as SQLDataType,
     Expr as SqlExpr, Function as SQLFunction, JoinConstraint, OrderByExpr, TrimWhereField,
     UnaryOperator, Value as SqlValue,
 };
+use sqlparser::dialect::GenericDialect;
+use sqlparser::parser::{Parser, ParserOptions};
 
 use crate::functions::SqlFunctionVisitor;
 use crate::SQLContext;
 
 pub(crate) fn map_sql_polars_datatype(data_type: &SQLDataType) -> PolarsResult<DataType> {
     Ok(match data_type {
         SQLDataType::Array(Some(inner_type)) => {
@@ -461,7 +464,39 @@
         if !idents.is_empty() {
             let cols = &idents[0].value;
             return Ok((col(cols), col(cols)));
         }
     }
     polars_bail!(InvalidOperation: "SQL join constraint {:?} is not yet supported", constraint);
 }
+
+/// parse a SQL expression to a polars expression
+/// # Example
+/// ```rust
+/// # use polars_sql::{SQLContext, sql_expr};
+/// # use polars_core::prelude::*;
+/// # use polars_lazy::prelude::*;
+/// # fn main() {
+///
+/// let mut ctx = SQLContext::new();
+/// let df = df! {
+///    "a" =>  [1, 2, 3],
+/// }
+/// .unwrap();
+/// let expr = sql_expr("MAX(a)").unwrap();
+/// df.lazy().select(vec![expr]).collect().unwrap();
+/// # }
+/// ```
+pub fn sql_expr<S: AsRef<str>>(s: S) -> PolarsResult<Expr> {
+    let ctx = SQLContext::new();
+
+    let mut parser = Parser::new(&GenericDialect);
+    parser = parser.with_options(ParserOptions {
+        trailing_commas: true,
+    });
+
+    let mut ast = parser.try_with_sql(s.as_ref()).map_err(to_compute_err)?;
+
+    let expr = ast.parse_expr().map_err(to_compute_err)?;
+
+    parse_sql_expr(&expr, &ctx)
+}
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/src/table_functions.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/src/table_functions.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/functions_cumulative.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/functions_cumulative.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/functions_io.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/functions_io.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/functions_math.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/functions_math.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/functions_meta.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/functions_meta.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/functions_string.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/functions_string.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/iss_7436.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/iss_7436.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/iss_7437.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/iss_7437.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/iss_7440.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/iss_7440.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/iss_8395.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/iss_8395.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/iss_8419.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/iss_8419.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/ops_distinct_on.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/ops_distinct_on.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/simple_exprs.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/simple_exprs.rs`

 * *Files 2% similar despite different names*

```diff
@@ -520,7 +520,16 @@
         .when(col("a").lt_eq(lit(5)))
         .then(lit("lteq_5"))
         .otherwise(lit("no match"))
         .alias("sign");
     let df_pl = df.lazy().select(&[case_expr]).collect().unwrap();
     assert!(df_sql.frame_equal(&df_pl));
 }
+
+#[test]
+fn test_sql_expr() {
+    let df = create_sample_df().unwrap();
+    let expr = sql_expr("MIN(a)").unwrap();
+    let actual = df.clone().lazy().select(&[expr]).collect().unwrap();
+    let expected = df.lazy().select(&[col("a").min()]).collect().unwrap();
+    assert!(actual.frame_equal(&expected));
+}
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-sql/tests/statements.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/tests/statements.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/Cargo.toml` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/Cargo.toml`

 * *Files 6% similar despite different names*

```diff
@@ -1,25 +1,26 @@
 [package]
 name = "polars-pipe"
 version= "0.30.0"
 edition = "2021"
 license = "MIT"
 repository = "https://github.com/pola-rs/polars"
 description = "Lazy query engine for the Polars DataFrame library"
+resolver = "2"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
 crossbeam-channel = { version = "0.5", optional = true }
 crossbeam-queue = { version = "0.3", optional = true }
 enum_dispatch = "0.3"
 hashbrown= { version = "0.13.1", features = ["rayon", "ahash"] }
 num-traits= "0.2"
 polars-arrow = { version = "0.30.0", path = "../polars-arrow", default-features = false }
-polars-core = { version = "0.30.0", path = "../polars-core", features = ["lazy", "private", "zip_with", "random"], default-features = false }
+polars-core = { version = "0.30.0", path = "../polars-core", features = ["lazy", "zip_with", "random"], default-features = false }
 polars-io = { version = "0.30.0", path = "../polars-io", default-features = false, features = ["ipc", "async"] }
 polars-ops = { version = "0.30.0", path = "../polars-ops", features = ["search_sorted"] }
 polars-plan = { version = "0.30.0", path = "../polars-plan", default-features = false, features = ["compile"] }
 polars-row = { version = "0.30.0", path = "../polars-row" }
 polars-utils = { version = "0.30.0", path = "../polars-utils", features = ["sysinfo"] }
 rayon= "1.6"
 smartstring = { version = "1" }
@@ -36,7 +37,8 @@
 dtype-u16 = ["polars-core/dtype-u16"]
 dtype-i8 = ["polars-core/dtype-i8"]
 dtype-i16 = ["polars-core/dtype-i16"]
 dtype-decimal = ["polars-core/dtype-decimal"]
 dtype-array = ["polars-core/dtype-array"]
 dtype-categorical = ["polars-core/dtype-categorical"]
 trigger_ooc = []
+test = ["compile", "polars-core/chunked_ids"]
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/LICENSE` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/operators/filter.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/operators/filter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/operators/function.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/operators/function.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/operators/pass.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/operators/pass.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/operators/placeholder.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/operators/placeholder.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/operators/projection.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/operators/projection.rs`

 * *Files 10% similar despite different names*

```diff
@@ -5,31 +5,45 @@
 use polars_core::schema::SchemaRef;
 
 use crate::expressions::PhysicalPipedExpr;
 use crate::operators::{DataChunk, Operator, OperatorResult, PExecutionContext};
 
 #[derive(Clone)]
 pub(crate) struct FastProjectionOperator {
-    pub(crate) columns: Arc<[Arc<str>]>,
+    columns: Arc<[Arc<str>]>,
+    input_schema: SchemaRef,
+}
+
+impl FastProjectionOperator {
+    pub(crate) fn new(columns: Arc<[Arc<str>]>, input_schema: SchemaRef) -> Self {
+        Self {
+            columns,
+            input_schema,
+        }
+    }
 }
 
 impl Operator for FastProjectionOperator {
     fn execute(
         &mut self,
         _context: &PExecutionContext,
         chunk: &DataChunk,
     ) -> PolarsResult<OperatorResult> {
-        let chunk = chunk.with_data(chunk.data.select(self.columns.as_ref())?);
+        let chunk = chunk.with_data(
+            chunk
+                .data
+                .select_with_schema_unchecked(self.columns.as_ref(), &self.input_schema)?,
+        );
         Ok(OperatorResult::Finished(chunk))
     }
     fn split(&self, _thread_no: usize) -> Box<dyn Operator> {
         Box::new(self.clone())
     }
     fn fmt(&self) -> &str {
-        "fast_join_projection"
+        "fast_projection"
     }
 }
 
 #[derive(Clone)]
 pub(crate) struct ProjectionOperator {
     pub(crate) exprs: Vec<Arc<dyn PhysicalPipedExpr>>,
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/operators/reproject.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/operators/reproject.rs`

 * *Files 23% similar despite different names*

```diff
@@ -24,19 +24,26 @@
 
 pub(crate) fn reproject_chunk(
     chunk: &mut DataChunk,
     positions: &mut Vec<usize>,
     schema: &Schema,
 ) -> PolarsResult<()> {
     let out = if positions.is_empty() {
-        let out = chunk.data.select(schema.iter_names())?;
+        // use the chunk schema to cache
+        // the positions for subsequent calls
+        let chunk_schema = chunk.data.schema();
+
+        let out = chunk
+            .data
+            .select_with_schema_unchecked(schema.iter_names(), &chunk_schema)?;
+
         *positions = out
             .get_columns()
             .iter()
-            .map(|s| schema.get_full(s.name()).unwrap().0)
+            .map(|s| chunk_schema.get_full(s.name()).unwrap().0)
             .collect();
         out
     } else {
         let columns = chunk.data.get_columns();
         let cols = positions.iter().map(|i| columns[*i].clone()).collect();
         DataFrame::new_no_checks(cols)
     };
@@ -72,7 +79,42 @@
         })
     }
 
     fn fmt(&self) -> &str {
         "re-project-operator"
     }
 }
+
+#[cfg(test)]
+mod test {
+    use polars_core::prelude::*;
+
+    use super::*;
+
+    #[test]
+    fn test_reproject_chunk() {
+        let df = df![
+            "a" => [1, 2],
+            "b" => [1, 2],
+            "c" => [1, 2],
+            "d" => [1, 2],
+        ]
+        .unwrap();
+
+        let mut chunk1 = DataChunk::new(0, df.clone());
+        let mut chunk2 = DataChunk::new(1, df);
+
+        let mut positions = vec![];
+
+        let mut out_schema = Schema::new();
+        out_schema.with_column("c".into(), DataType::Int32);
+        out_schema.with_column("b".into(), DataType::Int32);
+        out_schema.with_column("d".into(), DataType::Int32);
+        out_schema.with_column("a".into(), DataType::Int32);
+
+        reproject_chunk(&mut chunk1, &mut positions, &out_schema).unwrap();
+        // second call cached the positions
+        reproject_chunk(&mut chunk2, &mut positions, &out_schema).unwrap();
+        assert_eq!(&chunk1.data.schema(), &out_schema);
+        assert_eq!(&chunk2.data.schema(), &out_schema);
+    }
+}
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/file_sink.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/file_sink.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/convert.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/convert.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/count.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/count.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/first.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/first.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/interface.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/interface.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/last.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/last.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mean.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/min_max.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/min_max.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/null.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/null.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/sum.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/sum.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/eval.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/eval.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/global.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/global.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/hash_table.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/hash_table.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/ooc_state.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/ooc_state.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/sink.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/sink.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/source.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/source.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/thread_local.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/thread_local.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc_state.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc_state.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/primitive/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/primitive/mod.rs`

 * *Files 0% similar despite different names*

```diff
@@ -8,17 +8,17 @@
 use polars_arrow::kernels::sort_partition::partition_to_groups_amortized;
 use polars_core::export::ahash::RandomState;
 use polars_core::frame::row::AnyValueBuffer;
 use polars_core::prelude::*;
 use polars_core::series::IsSorted;
 use polars_core::utils::_set_partition_size;
 use polars_core::POOL;
+use polars_utils::hash_to_partition;
 use polars_utils::slice::GetSaferUnchecked;
 use polars_utils::unwrap::UnwrapUncheckedRelease;
-use polars_utils::{hash_to_partition, HashSingle};
 use rayon::prelude::*;
 
 use super::aggregates::AggregateFn;
 use crate::executors::sinks::groupby::aggregates::AggregateFunction;
 use crate::executors::sinks::groupby::ooc_state::OocState;
 use crate::executors::sinks::groupby::physical_agg_to_logical;
 use crate::executors::sinks::groupby::string::{apply_aggregate, write_agg_idx};
@@ -221,15 +221,15 @@
         partition_to_groups_amortized(values, 0, false, 0, &mut self.sort_partitions);
 
         let pre_agg_len = self.pre_agg_partitions.len();
 
         for group in &self.sort_partitions {
             let [offset, length] = group;
             let first_g_value = unsafe { *values.get_unchecked_release(*offset as usize) };
-            let h = self.hb.hash_single(first_g_value);
+            let h = self.hb.hash_one(first_g_value);
 
             let agg_idx = insert_and_get(
                 h,
                 Some(first_g_value),
                 pre_agg_len,
                 &mut self.pre_agg_partitions,
                 &mut self.aggregators,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/string.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/string.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/groupby/utils.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/groupby/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/io.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/io.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/joins/cross.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/joins/cross.rs`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 use std::any::Any;
-use std::borrow::Cow;
 use std::iter::StepBy;
 use std::ops::Range;
 use std::sync::Arc;
 use std::vec;
 
 use polars_core::error::PolarsResult;
 use polars_core::frame::DataFrame;
@@ -13,19 +12,19 @@
     chunks_to_df_unchecked, DataChunk, FinalizedSink, Operator, OperatorResult, PExecutionContext,
     Sink, SinkResult,
 };
 
 #[derive(Default)]
 pub struct CrossJoin {
     chunks: Vec<DataChunk>,
-    suffix: Cow<'static, str>,
+    suffix: SmartString,
 }
 
 impl CrossJoin {
-    pub(crate) fn new(suffix: Cow<'static, str>) -> Self {
+    pub(crate) fn new(suffix: SmartString) -> Self {
         CrossJoin {
             chunks: vec![],
             suffix,
         }
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/joins/generic_build.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/joins/generic_build.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/joins/inner_left.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/joins/inner_left.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/memory.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/memory.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/ordered.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/ordered.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/reproject.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/reproject.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/slice.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/sort/ooc.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/sort/ooc.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/sort/sink.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/sort/sink.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/sort/sink_multiple.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/sort/sink_multiple.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/sort/source.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/sort/source.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sinks/utils.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sinks/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sources/csv.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sources/csv.rs`

 * *Files 18% similar despite different names*

```diff
@@ -11,69 +11,74 @@
 use super::*;
 use crate::pipeline::determine_chunk_size;
 
 pub(crate) struct CsvSource {
     #[allow(dead_code)]
     // this exist because we need to keep ownership
     schema: SchemaRef,
-    reader: *mut CsvReader<'static, File>,
-    batched_reader: Either<*mut BatchedCsvReaderMmap<'static>, *mut BatchedCsvReaderRead<'static>>,
+    reader: Option<*mut CsvReader<'static, File>>,
+    batched_reader:
+        Option<Either<*mut BatchedCsvReaderMmap<'static>, *mut BatchedCsvReaderRead<'static>>>,
     n_threads: usize,
     chunk_index: IdxSize,
+    path: Option<PathBuf>,
+    options: Option<CsvParserOptions>,
+    verbose: bool,
 }
 
 impl CsvSource {
-    pub(crate) fn new(
-        path: PathBuf,
-        schema: SchemaRef,
-        options: CsvParserOptions,
-        verbose: bool,
-    ) -> PolarsResult<Self> {
+    // Delay initializing the reader
+    // otherwise all files would be opened during construction of the pipeline
+    // leading to Too many Open files error
+    fn init_reader(&mut self) -> PolarsResult<()> {
+        let options = self.options.take().unwrap();
+        let path = self.path.take().unwrap();
         let mut with_columns = options.with_columns;
         let mut projected_len = 0;
         with_columns.as_ref().map(|columns| {
             projected_len = columns.len();
             columns
         });
 
         if projected_len == 0 {
             with_columns = None;
         }
-        let n_rows = _set_n_rows_for_scan(options.n_rows);
 
         let n_cols = if projected_len > 0 {
             projected_len
         } else {
-            schema.len()
+            self.schema.len()
         };
+        let n_rows = _set_n_rows_for_scan(options.n_rows);
         // inversely scale the chunk size by the number of threads so that we reduce memory pressure
         // in streaming
         let chunk_size = determine_chunk_size(n_cols, POOL.current_num_threads())?;
 
-        if verbose {
+        if self.verbose {
             eprintln!("STREAMING CHUNK SIZE: {chunk_size} rows")
         }
 
         let reader = CsvReader::from_path(&path)
             .unwrap()
             .has_header(options.has_header)
-            .with_schema(schema.clone())
+            .with_schema(self.schema.clone())
             .with_delimiter(options.delimiter)
             .with_ignore_errors(options.ignore_errors)
             .with_skip_rows(options.skip_rows)
             .with_n_rows(n_rows)
             .with_columns(with_columns.map(|mut cols| std::mem::take(Arc::make_mut(&mut cols))))
             .low_memory(options.low_memory)
             .with_null_values(options.null_values)
             .with_encoding(CsvEncoding::LossyUtf8)
             .with_comment_char(options.comment_char)
             .with_quote_char(options.quote_char)
             .with_end_of_line_char(options.eol_char)
             .with_encoding(options.encoding)
-            .with_rechunk(options.rechunk)
+            // never rechunk in streaming
+            .with_rechunk(false)
             .with_chunk_size(chunk_size)
             .with_row_count(options.row_count)
             .with_try_parse_dates(options.try_parse_dates);
 
         let reader = Box::new(reader);
         let reader = Box::leak(reader) as *mut CsvReader<'static, File>;
 
@@ -82,47 +87,68 @@
             let batched_reader = Box::leak(batched_reader) as *mut BatchedCsvReaderRead;
             Either::Right(batched_reader)
         } else {
             let batched_reader = unsafe { Box::new((*reader).batched_borrowed_mmap()?) };
             let batched_reader = Box::leak(batched_reader) as *mut BatchedCsvReaderMmap;
             Either::Left(batched_reader)
         };
+        self.reader = Some(reader);
+        self.batched_reader = Some(batched_reader);
+        Ok(())
+    }
 
+    pub(crate) fn new(
+        path: PathBuf,
+        schema: SchemaRef,
+        options: CsvParserOptions,
+        verbose: bool,
+    ) -> PolarsResult<Self> {
         Ok(CsvSource {
             schema,
-            reader,
-            batched_reader,
+            reader: None,
+            batched_reader: None,
             n_threads: POOL.current_num_threads(),
             chunk_index: 0,
+            path: Some(path),
+            options: Some(options),
+            verbose,
         })
     }
 }
 
 impl Drop for CsvSource {
     fn drop(&mut self) {
         unsafe {
             match self.batched_reader {
-                Either::Left(ptr) => {
+                Some(Either::Left(ptr)) => {
                     let _to_drop = Box::from_raw(ptr);
                 }
-                Either::Right(ptr) => {
+                Some(Either::Right(ptr)) => {
                     let _to_drop = Box::from_raw(ptr);
                 }
+                // nothing initialized, nothing to drop
+                _ => {}
+            }
+            if let Some(ptr) = self.reader {
+                let _to_drop = Box::from_raw(ptr);
             }
-            let _to_drop = Box::from_raw(self.reader);
         };
     }
 }
 
 unsafe impl Send for CsvSource {}
 unsafe impl Sync for CsvSource {}
 
 impl Source for CsvSource {
     fn get_batches(&mut self, _context: &PExecutionContext) -> PolarsResult<SourceResult> {
-        let batches = match self.batched_reader {
+        if self.reader.is_none() {
+            self.init_reader()?
+        }
+
+        let batches = match self.batched_reader.unwrap() {
             Either::Left(batched_reader) => {
                 let reader = unsafe { &mut *batched_reader };
 
                 reader.next_batches(self.n_threads)?
             }
             Either::Right(batched_reader) => {
                 let reader = unsafe { &mut *batched_reader };
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sources/frame.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sources/frame.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sources/ipc_one_shot.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sources/ipc_one_shot.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sources/parquet.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sources/parquet.rs`

 * *Files 20% similar despite different names*

```diff
@@ -11,54 +11,58 @@
 use polars_plan::prelude::ParquetOptions;
 use polars_utils::IdxSize;
 
 use crate::operators::{DataChunk, PExecutionContext, Source, SourceResult};
 use crate::pipeline::determine_chunk_size;
 
 pub struct ParquetSource {
-    batched_reader: BatchedParquetReader,
+    batched_reader: Option<BatchedParquetReader>,
     n_threads: usize,
     chunk_index: IdxSize,
+    path: Option<PathBuf>,
+    options: Option<ParquetOptions>,
+    #[allow(dead_code)]
+    cloud_options: Option<CloudOptions>,
+    schema: Option<SchemaRef>,
+    verbose: bool,
 }
 
 impl ParquetSource {
-    #[allow(unused_variables)]
-    pub(crate) fn new(
-        path: PathBuf,
-        options: ParquetOptions,
-        cloud_options: Option<CloudOptions>,
-        schema: &Schema,
-        verbose: bool,
-    ) -> PolarsResult<Self> {
+    // Delay initializing the reader
+    // otherwise all files would be opened during construction of the pipeline
+    // leading to Too many Open files error
+    fn init_reader(&mut self) -> PolarsResult<()> {
+        let path = self.path.take().unwrap();
+        let options = self.options.take().unwrap();
+        let schema = self.schema.take().unwrap();
         let projection: Option<Vec<_>> = options.with_columns.map(|with_columns| {
             with_columns
                 .iter()
                 .map(|name| schema.index_of(name).unwrap())
                 .collect()
         });
 
         let n_cols = projection.as_ref().map(|v| v.len()).unwrap_or(schema.len());
-        let n_threads = POOL.current_num_threads();
-        let chunk_size = determine_chunk_size(n_cols, n_threads)?;
+        let chunk_size = determine_chunk_size(n_cols, self.n_threads)?;
 
-        if verbose {
+        if self.verbose {
             eprintln!("STREAMING CHUNK SIZE: {chunk_size} rows")
         }
 
         let batched_reader = if is_cloud_url(&path) {
             #[cfg(not(feature = "async"))]
             {
                 panic!(
                     "Feature 'async' (or more likely one of the cloud provider features) is required to access parquet files on cloud storage."
                 )
             }
             #[cfg(feature = "async")]
             {
                 let uri = path.to_string_lossy();
-                ParquetAsyncReader::from_uri(&uri, cloud_options.as_ref())?
+                ParquetAsyncReader::from_uri(&uri, self.cloud_options.as_ref())?
                     .with_n_rows(options.n_rows)
                     .with_row_count(options.row_count)
                     .with_projection(projection)
                     .use_statistics(options.use_statistics)
                     .batched(chunk_size)?
             }
         } else {
@@ -67,26 +71,51 @@
             ParquetReader::new(file)
                 .with_n_rows(options.n_rows)
                 .with_row_count(options.row_count)
                 .with_projection(projection)
                 .use_statistics(options.use_statistics)
                 .batched(chunk_size)?
         };
+        self.batched_reader = Some(batched_reader);
+        Ok(())
+    }
+
+    #[allow(unused_variables)]
+    pub(crate) fn new(
+        path: PathBuf,
+        options: ParquetOptions,
+        cloud_options: Option<CloudOptions>,
+        schema: SchemaRef,
+        verbose: bool,
+    ) -> PolarsResult<Self> {
+        let n_threads = POOL.current_num_threads();
 
         Ok(ParquetSource {
-            batched_reader,
+            batched_reader: None,
             n_threads,
             chunk_index: 0,
+            options: Some(options),
+            path: Some(path),
+            cloud_options,
+            schema: Some(schema),
+            verbose,
         })
     }
 }
 
 impl Source for ParquetSource {
     fn get_batches(&mut self, _context: &PExecutionContext) -> PolarsResult<SourceResult> {
-        let batches = self.batched_reader.next_batches(self.n_threads)?;
+        if self.batched_reader.is_none() {
+            self.init_reader()?;
+        }
+        let batches = self
+            .batched_reader
+            .as_mut()
+            .unwrap()
+            .next_batches(self.n_threads)?;
         Ok(match batches {
             None => SourceResult::Finished,
             Some(batches) => SourceResult::GotMoreData(
                 batches
                     .into_iter()
                     .map(|data| {
                         let chunk_index = self.chunk_index;
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sources/reproject.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sources/reproject.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/executors/sources/union.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/executors/sources/union.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/operators/chunks.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/operators/chunks.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/operators/operator.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/operators/operator.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/operators/sink.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/operators/sink.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/pipeline/convert.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/pipeline/convert.rs`

 * *Files 1% similar despite different names*

```diff
@@ -101,15 +101,15 @@
                 let op = Box::new(op) as Box<dyn Operator>;
                 operator_objects.push(op)
             }
             let src = sources::ParquetSource::new(
                 path,
                 options,
                 cloud_options,
-                &file_info.schema,
+                file_info.schema,
                 verbose,
             )?;
             Ok(Box::new(src) as Box<dyn Source>)
         }
         _ => todo!(),
     }
 }
@@ -146,20 +146,20 @@
             input_right,
             options,
             left_on,
             right_on,
             ..
         } => {
             // slice pushdown optimization should not set this one in a streaming query.
-            assert!(options.slice.is_none());
+            assert!(options.args.slice.is_none());
 
-            match &options.how {
+            match &options.args.how {
                 #[cfg(feature = "cross_join")]
                 JoinType::Cross => {
-                    Box::new(CrossJoin::new(options.suffix.clone())) as Box<dyn Sink>
+                    Box::new(CrossJoin::new(options.args.suffix().into())) as Box<dyn Sink>
                 }
                 join_type @ JoinType::Inner | join_type @ JoinType::Left => {
                     let input_schema_left = lp_arena.get(*input_left).schema(lp_arena);
                     let join_columns_left = Arc::new(exprs_to_physical(
                         left_on,
                         expr_arena,
                         to_physical,
@@ -178,20 +178,20 @@
                     let (join_columns_left, join_columns_right) = if swapped {
                         (join_columns_right, join_columns_left)
                     } else {
                         (join_columns_left, join_columns_right)
                     };
 
                     Box::new(GenericBuild::new(
-                        Arc::from(options.suffix.as_ref()),
+                        Arc::from(options.args.suffix()),
                         join_type.clone(),
                         swapped,
                         join_columns_left,
                         join_columns_right,
-                    ))
+                    )) as Box<dyn Sink>
                 }
                 _ => unimplemented!(),
             }
         }
         Slice { offset, len, .. } => {
             let slice = SliceSink::new(*offset as u64, *len as usize);
             Box::new(slice) as Box<dyn Sink>
@@ -423,21 +423,19 @@
             let input_schema = lp_arena.get(*input).schema(lp_arena);
             let predicate = to_physical(*predicate, expr_arena, Some(input_schema.as_ref()))?;
             let op = operators::FilterOperator { predicate };
             Box::new(op) as Box<dyn Operator>
         }
         MapFunction {
             function: FunctionNode::FastProjection { columns },
-            ..
+            input,
         } => {
-            // TODO! pass schema to FastProjection so that
-            // projection can be based on already known schema.
-            let op = operators::FastProjectionOperator {
-                columns: columns.clone(),
-            };
+            let input_schema = lp_arena.get(*input).schema(lp_arena);
+            let op =
+                operators::FastProjectionOperator::new(columns.clone(), input_schema.into_owned());
             Box::new(op) as Box<dyn Operator>
         }
         MapFunction { function, .. } => {
             let op = operators::FunctionOperator::new(function.clone());
             Box::new(op) as Box<dyn Operator>
         }
         Union { .. } => {
@@ -559,13 +557,13 @@
         sink_nodes,
         operator_offset,
         verbose,
     ))
 }
 
 pub fn swap_join_order(options: &JoinOptions) -> bool {
-    matches!(options.how, JoinType::Left)
+    matches!(options.args.how, JoinType::Left)
         || match (options.rows_left, options.rows_right) {
             ((Some(left), _), (Some(right), _)) => left > right,
             ((_, left), (_, right)) => left > right,
         }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/pipeline/dispatcher.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/pipeline/dispatcher.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-pipe/src/pipeline/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/src/pipeline/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-utils/Cargo.toml` & `polars_lts_cpu-0.18.1/local_dependencies/polars-utils/Cargo.toml`

 * *Files 20% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 [package]
 name = "polars-utils"
 version= "0.30.0"
 authors = ["ritchie46 <ritchie46@gmail.com>"]
 edition = "2021"
 license = "MIT"
 description = "private utils for the polars dataframe library"
+resolver = "2"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
 ahash= "0.8"
 hashbrown= { version = "0.13.1", features = ["rayon", "ahash"] }
 once_cell= "1"
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-utils/LICENSE` & `polars_lts_cpu-0.18.1/local_dependencies/polars-pipe/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/arena.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/arena.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/atomic.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/atomic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/cell.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/cell.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/contention_pool.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/contention_pool.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/functions.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/functions.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/iter/enumerate_idx.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/iter/enumerate_idx.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/macros.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/macros.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/slice.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/sort.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/sort.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/sync.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/sync.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/unwrap.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/unwrap.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-utils/src/wasm.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-utils/src/wasm.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/Cargo.toml` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/Cargo.toml`

 * *Files 2% similar despite different names*

```diff
@@ -2,43 +2,39 @@
 name = "polars-lazy"
 version= "0.30.0"
 authors = ["ritchie46 <ritchie46@gmail.com>"]
 edition = "2021"
 license = "MIT"
 repository = "https://github.com/pola-rs/polars"
 description = "Lazy query engine for the Polars DataFrame library"
-
-# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
-
-[dev-dependencies]
-serde_json = "1"
+resolver = "2"
 
 [dependencies]
 ahash= "0.8"
 bitflags= "1.3"
 glob = "0.3"
 once_cell = "1"
 polars-arrow = { version = "0.30.0", path = "../polars-arrow" }
-polars-core = { version = "0.30.0", path = "../polars-core", features = ["lazy", "private", "zip_with", "random"], default-features = false }
-polars-io = { version = "0.30.0", path = "../polars-io", features = ["lazy", "csv", "private"], default-features = false }
+polars-core = { version = "0.30.0", path = "../polars-core", features = ["lazy", "zip_with", "random"], default-features = false }
+polars-io = { version = "0.30.0", path = "../polars-io", features = ["lazy", "csv"], default-features = false }
 polars-json = { version = "0.30.0", path = "../polars-json", optional = true }
 polars-ops = { version = "0.30.0", path = "../polars-ops", default-features = false }
 polars-pipe = { version = "0.30.0", path = "../polars-pipe", optional = true }
 polars-plan = { version = "0.30.0", path = "../polars-plan" }
 polars-time = { version = "0.30.0", path = "../polars-time", optional = true }
 polars-utils = { version = "0.30.0", path = "../polars-utils" }
-pyo3 = { version = "0.18", optional = true }
+pyo3 = { version = "0.19", optional = true }
 rayon= "1.6"
 smartstring= { version = "1" }
 
 [features]
 nightly = ["polars-core/nightly", "polars-pipe/nightly"]
 compile = ["polars-plan/compile"]
 streaming = ["chunked_ids", "polars-pipe/compile", "polars-plan/streaming"]
-default = ["compile", "private"]
+default = ["compile"]
 parquet = ["polars-core/parquet", "polars-io/parquet", "polars-plan/parquet", "polars-pipe/parquet"]
 async = [
   "polars-plan/async",
   "polars-io/cloud",
   "polars-pipe/async",
   "streaming",
 ]
@@ -55,15 +51,15 @@
 dtype-i8 = ["polars-plan/dtype-i8", "polars-pipe/dtype-i8"]
 dtype-i16 = ["polars-plan/dtype-i16", "polars-pipe/dtype-i16"]
 dtype-decimal = ["polars-plan/dtype-decimal", "polars-pipe/dtype-decimal"]
 dtype-date = ["polars-plan/dtype-date", "polars-time/dtype-date", "temporal"]
 dtype-datetime = ["polars-plan/dtype-datetime", "polars-time/dtype-datetime", "temporal"]
 dtype-duration = ["polars-plan/dtype-duration", "polars-time/dtype-duration", "temporal"]
 dtype-time = ["polars-core/dtype-time", "temporal"]
-dtype-array = ["polars-plan/dtype-array", "polars-pipe/dtype-array"]
+dtype-array = ["polars-plan/dtype-array", "polars-pipe/dtype-array", "polars-ops/dtype-array"]
 dtype-categorical = ["polars-plan/dtype-categorical", "polars-pipe/dtype-categorical"]
 dtype-struct = ["polars-plan/dtype-struct"]
 object = ["polars-plan/object"]
 date_offset = ["polars-plan/date_offset"]
 trigonometry = ["polars-plan/trigonometry"]
 sign = ["polars-plan/sign"]
 timezones = ["polars-plan/timezones"]
@@ -129,25 +125,21 @@
   "polars-io/serde",
   "polars-ops/serde",
 ]
 fused = ["polars-plan/fused", "polars-ops/fused"]
 
 binary_encoding = ["polars-plan/binary_encoding"]
 
-# no guarantees whatsoever
-private = ["polars-plan/private"]
-
 bigidx = ["polars-plan/bigidx"]
 
 panic_on_schema = ["polars-plan/panic_on_schema"]
 
 test = [
   "polars-plan/debugging",
   "panic_on_schema",
-  "private",
   "rolling_window",
   "rank",
   "round_series",
   "csv",
   "dtype-categorical",
   "cum_agg",
   "regex",
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/LICENSE` & `polars_lts_cpu-0.18.1/local_dependencies/polars-row/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/dot.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/dot.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/dsl/eval.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/dsl/eval.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/dsl/functions.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/dsl/functions.rs`

 * *Files 12% similar despite different names*

```diff
@@ -11,52 +11,69 @@
 pub(crate) fn concat_impl<L: AsRef<[LazyFrame]>>(
     inputs: L,
     rechunk: bool,
     parallel: bool,
     from_partitioned_ds: bool,
 ) -> PolarsResult<LazyFrame> {
     let mut inputs = inputs.as_ref().to_vec();
-    let lf = std::mem::take(
+
+    let mut lf = std::mem::take(
         inputs
             .get_mut(0)
             .ok_or_else(|| polars_err!(NoData: "empty container given"))?,
     );
-    let mut opt_state = lf.opt_state;
-    let mut lps = Vec::with_capacity(inputs.len());
-    lps.push(lf.logical_plan);
 
-    for lf in &mut inputs[1..] {
-        // ensure we enable file caching if any lf has it enabled
-        opt_state.file_caching |= lf.opt_state.file_caching;
-        let lp = std::mem::take(&mut lf.logical_plan);
-        lps.push(lp)
-    }
+    let mut opt_state = lf.opt_state;
     let options = UnionOptions {
         parallel,
         from_partitioned_ds,
+        rechunk,
         ..Default::default()
     };
 
-    let lp = LogicalPlan::Union {
-        inputs: lps,
-        options,
-    };
-    let mut lf = LazyFrame::from(lp);
-    lf.opt_state = opt_state;
+    match &mut lf.logical_plan {
+        // re-use the same union
+        LogicalPlan::Union {
+            inputs: existing_inputs,
+            options: opts,
+        } if opts == &options => {
+            for lf in &mut inputs[1..] {
+                // ensure we enable file caching if any lf has it enabled
+                opt_state.file_caching |= lf.opt_state.file_caching;
+                let lp = std::mem::take(&mut lf.logical_plan);
+                existing_inputs.push(lp)
+            }
+            Ok(lf)
+        }
+        _ => {
+            let mut lps = Vec::with_capacity(inputs.len());
+            lps.push(lf.logical_plan);
+
+            for lf in &mut inputs[1..] {
+                // ensure we enable file caching if any lf has it enabled
+                opt_state.file_caching |= lf.opt_state.file_caching;
+                let lp = std::mem::take(&mut lf.logical_plan);
+                lps.push(lp)
+            }
+
+            let lp = LogicalPlan::Union {
+                inputs: lps,
+                options,
+            };
+            let mut lf = LazyFrame::from(lp);
+            lf.opt_state = opt_state;
 
-    if rechunk {
-        Ok(lf.map_private(FunctionNode::Rechunk))
-    } else {
-        Ok(lf)
+            Ok(lf)
+        }
     }
 }
 
 #[cfg(feature = "diagonal_concat")]
 /// Concat [LazyFrame]s diagonally.
-/// Calls [concat] internally.
+/// Calls [`concat`][concat()] internally.
 pub fn diag_concat_lf<L: AsRef<[LazyFrame]>>(
     lfs: L,
     rechunk: bool,
     parallel: bool,
 ) -> PolarsResult<LazyFrame> {
     let lfs = lfs.as_ref().to_vec();
     let schemas = lfs
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/dsl/list.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/dsl/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/dsl/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/dsl/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/frame/anonymous_scan.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/anonymous_scan.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/frame/csv.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/csv.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/frame/file_list_reader.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/file_list_reader.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/frame/ipc.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/ipc.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/frame/ndjson.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/ndjson.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/frame/parquet.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/parquet.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/frame/pivot.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/frame/pivot.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/lib.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/lib.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/cache.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/cache.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/executor.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/executor.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/ext_context.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/ext_context.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/filter.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/filter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/groupby.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/groupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_dynamic.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_dynamic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_partitioned.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_partitioned.rs`

 * *Files 2% similar despite different names*

```diff
@@ -225,25 +225,27 @@
 impl PartitionGroupByExec {
     #[cfg(feature = "streaming")]
     fn run_streaming(
         &mut self,
         state: &mut ExecutionState,
         original_df: DataFrame,
     ) -> Option<PolarsResult<DataFrame>> {
+        #[allow(clippy::needless_update)]
+        let groupby_options = GroupbyOptions {
+            slice: self.slice,
+            ..Default::default()
+        };
         let lp = LogicalPlan::Aggregate {
             input: Box::new(original_df.lazy().logical_plan),
             keys: Arc::new(std::mem::take(&mut self.keys)),
             aggs: std::mem::take(&mut self.aggs),
             schema: self.output_schema.clone(),
             apply: None,
             maintain_order: false,
-            options: GroupbyOptions {
-                slice: self.slice,
-                ..Default::default()
-            },
+            options: groupby_options,
         };
         let mut expr_arena = Default::default();
         let mut lp_arena = Default::default();
         let node = to_alp(lp, &mut expr_arena, &mut lp_arena).unwrap();
 
         let inserted = streaming::insert_streaming_nodes(
             node,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_rolling.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_rolling.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/join.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/join.rs`

 * *Files 7% similar despite different names*

```diff
@@ -1,41 +1,37 @@
+use polars_core::frame::hash_join::JoinArgs;
+
 use super::*;
 
 pub struct JoinExec {
     input_left: Option<Box<dyn Executor>>,
     input_right: Option<Box<dyn Executor>>,
-    how: JoinType,
     left_on: Vec<Arc<dyn PhysicalExpr>>,
     right_on: Vec<Arc<dyn PhysicalExpr>>,
     parallel: bool,
-    suffix: Cow<'static, str>,
-    slice: Option<(i64, usize)>,
+    args: JoinArgs,
 }
 
 impl JoinExec {
     #[allow(clippy::too_many_arguments)]
     pub(crate) fn new(
         input_left: Box<dyn Executor>,
         input_right: Box<dyn Executor>,
-        how: JoinType,
         left_on: Vec<Arc<dyn PhysicalExpr>>,
         right_on: Vec<Arc<dyn PhysicalExpr>>,
         parallel: bool,
-        suffix: Cow<'static, str>,
-        slice: Option<(i64, usize)>,
+        args: JoinArgs,
     ) -> Self {
         JoinExec {
             input_left: Some(input_left),
             input_right: Some(input_right),
-            how,
             left_on,
             right_on,
             parallel,
-            suffix,
-            slice,
+            args,
         }
     }
 }
 
 impl Executor for JoinExec {
     fn execute<'a>(&'a mut self, state: &'a mut ExecutionState) -> PolarsResult<DataFrame> {
         #[cfg(debug_assertions)]
@@ -108,15 +104,15 @@
                 df_right.with_column(s.clone())?;
             }
 
             // prepare the tolerance
             // we must ensure that we use the right units
             #[cfg(feature = "asof_join")]
             {
-                if let JoinType::AsOf(options) = &mut self.how {
+                if let JoinType::AsOf(options) = &mut self.args.how {
                     use polars_core::utils::arrow::temporal_conversions::MILLISECONDS_IN_DAY;
                     if let Some(tol) = &options.tolerance_str {
                         let duration = polars_time::Duration::parse(tol);
                         polars_ensure!(
                             duration.months() == 0,
                             ComputeError: "cannot use month offset in timedelta of an asof join; \
                             consider using 4 weeks"
@@ -148,22 +144,20 @@
                 }
             }
 
             let df = df_left._join_impl(
                 &df_right,
                 left_on_series,
                 right_on_series,
-                self.how.clone(),
-                Some(self.suffix.clone().into_owned()),
-                self.slice,
+                self.args.clone(),
                 true,
                 state.verbose(),
             );
 
             if state.verbose() {
-                eprintln!("{:?} join dataframes finished", self.how);
+                eprintln!("{:?} join dataframes finished", self.args.how);
             };
             df
 
         }, profile_name)
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/projection.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/projection.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/python_scan.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/python_scan.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/scan/csv.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/scan/csv.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ipc.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ipc.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/scan/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/scan/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ndjson.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ndjson.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/scan/parquet.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/scan/parquet.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/slice.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/sort.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/sort.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/stack.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/stack.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/udf.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/udf.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/union.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/union.rs`

 * *Files 2% similar despite different names*

```diff
@@ -101,9 +101,15 @@
                             .collect::<PolarsResult<Vec<_>>>()
                     })
                     .collect::<PolarsResult<Vec<_>>>()
             });
 
             concat_df(out?.iter().flat_map(|dfs| dfs.iter()))
         }
+        .map(|mut df| {
+            if self.options.rechunk {
+                df.as_single_chunk_par();
+            }
+            df
+        })
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/executors/unique.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/executors/unique.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/exotic.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/exotic.rs`

 * *Files 6% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 use polars_core::prelude::*;
 
 use crate::physical_plan::planner::create_physical_expr;
 use crate::prelude::*;
 
+#[cfg(feature = "pivot")]
 pub(crate) fn prepare_eval_expr(mut expr: Expr) -> Expr {
     expr.mutate().apply(|e| match e {
         Expr::Column(name) => {
             *name = Arc::from("");
             true
         }
         Expr::Nth(_) => {
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/aggregation.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/aggregation.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/alias.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/cache.rs`

 * *Files 18% similar despite different names*

```diff
@@ -1,102 +1,89 @@
-use std::sync::Arc;
+use super::*;
 
-use polars_core::frame::groupby::GroupsProxy;
-use polars_core::prelude::*;
-
-use crate::physical_plan::state::ExecutionState;
-use crate::prelude::*;
-
-pub struct AliasExpr {
+pub struct CacheExpr {
     pub(crate) physical_expr: Arc<dyn PhysicalExpr>,
-    pub(crate) name: Arc<str>,
     expr: Expr,
+    id: usize,
 }
 
-impl AliasExpr {
-    pub fn new(physical_expr: Arc<dyn PhysicalExpr>, name: Arc<str>, expr: Expr) -> Self {
+impl CacheExpr {
+    pub fn new(physical_expr: Arc<dyn PhysicalExpr>, expr: Expr, id: usize) -> Self {
         Self {
             physical_expr,
-            name,
             expr,
+            id,
         }
     }
-    fn finish(&self, mut input: Series) -> Series {
-        input.rename(&self.name);
-        input
-    }
 }
 
-impl PhysicalExpr for AliasExpr {
+impl PhysicalExpr for CacheExpr {
     fn as_expression(&self) -> Option<&Expr> {
         Some(&self.expr)
     }
 
     fn evaluate(&self, df: &DataFrame, state: &ExecutionState) -> PolarsResult<Series> {
-        let series = self.physical_expr.evaluate(df, state)?;
-        Ok(self.finish(series))
+        if let Some(cached) = state.get_expr_cache(self.id) {
+            let mut hit = true;
+            let out = cached
+                .get_or_try_init(|| {
+                    hit = false;
+                    self.physical_expr.evaluate(df, state)
+                })
+                .cloned();
+            if state.verbose() {
+                if hit {
+                    eprintln!("cache hit: {:?}", self.expr)
+                } else {
+                    eprintln!("cache miss: {:?}", self.expr)
+                }
+            }
+            out
+        } else {
+            self.physical_expr.evaluate(df, state)
+        }
     }
 
     #[allow(clippy::ptr_arg)]
     fn evaluate_on_groups<'a>(
         &self,
         df: &DataFrame,
         groups: &'a GroupsProxy,
         state: &ExecutionState,
     ) -> PolarsResult<AggregationContext<'a>> {
-        let mut ac = self.physical_expr.evaluate_on_groups(df, groups, state)?;
-        let s = ac.take();
-        let s = self.finish(s);
-
-        if ac.is_literal() {
-            ac.with_literal(s);
+        if let Some(cached) = state.get_expr_cache(self.id) {
+            let mut hit = true;
+            let aggregated = cached
+                .get_or_try_init(|| {
+                    let mut agg = self.physical_expr.evaluate_on_groups(df, groups, state)?;
+                    hit = false;
+                    PolarsResult::Ok(agg.aggregated())
+                })?
+                .clone();
+            if state.verbose() {
+                if hit {
+                    eprintln!("cache hit: {:?}", self.expr)
+                } else {
+                    eprintln!("cache miss: {:?}", self.expr)
+                }
+            }
+            Ok(AggregationContext::new(
+                aggregated,
+                Cow::Borrowed(groups),
+                true,
+            ))
         } else {
-            ac.with_series(s, ac.is_aggregated(), Some(&self.expr))?;
+            self.physical_expr.evaluate_on_groups(df, groups, state)
         }
-        Ok(ac)
     }
 
     fn to_field(&self, input_schema: &Schema) -> PolarsResult<Field> {
-        Ok(Field::new(
-            &self.name,
-            self.physical_expr
-                .to_field(input_schema)?
-                .data_type()
-                .clone(),
-        ))
+        self.physical_expr.to_field(input_schema)
     }
 
     fn as_partitioned_aggregator(&self) -> Option<&dyn PartitionedAggregation> {
-        Some(self)
+        None
     }
     fn is_valid_aggregation(&self) -> bool {
         self.physical_expr.is_valid_aggregation()
     }
 }
-
-impl PartitionedAggregation for AliasExpr {
-    fn evaluate_partitioned(
-        &self,
-        df: &DataFrame,
-        groups: &GroupsProxy,
-        state: &ExecutionState,
-    ) -> PolarsResult<Series> {
-        let agg = self.physical_expr.as_partitioned_aggregator().unwrap();
-        agg.evaluate_partitioned(df, groups, state).map(|mut s| {
-            s.rename(&self.name);
-            s
-        })
-    }
-
-    fn finalize(
-        &self,
-        partitioned: Series,
-        groups: &GroupsProxy,
-        state: &ExecutionState,
-    ) -> PolarsResult<Series> {
-        let agg = self.physical_expr.as_partitioned_aggregator().unwrap();
-        agg.finalize(partitioned, groups, state).map(|mut s| {
-            s.rename(&self.name);
-            s
-        })
-    }
-}
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/apply.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/apply.rs`

 * *Files 1% similar despite different names*

```diff
@@ -21,14 +21,15 @@
     pub expr: Expr,
     pub collect_groups: ApplyOptions,
     pub auto_explode: bool,
     pub allow_rename: bool,
     pub pass_name_to_apply: bool,
     pub input_schema: Option<SchemaRef>,
     pub allow_threading: bool,
+    pub check_lengths: bool,
 }
 
 impl ApplyExpr {
     pub(crate) fn new_minimal(
         inputs: Vec<Arc<dyn PhysicalExpr>>,
         function: SpecialEq<Arc<dyn SeriesUdf>>,
         expr: Expr,
@@ -40,14 +41,15 @@
             expr,
             collect_groups,
             auto_explode: false,
             allow_rename: false,
             pass_name_to_apply: false,
             input_schema: None,
             allow_threading: true,
+            check_lengths: true,
         }
     }
 
     #[allow(clippy::ptr_arg)]
     fn prepare_multiple_inputs<'a>(
         &self,
         df: &DataFrame,
@@ -169,15 +171,15 @@
             AggState::NotAggregated(s) | AggState::Literal(s) => {
                 let (out, aggregated) = (self.eval_and_flatten(&mut [s.clone()])?, false);
                 check_map_output_len(s.len(), out.len(), &self.expr)?;
                 (out, aggregated)
             }
         };
 
-        ac.with_series(s, aggregated, Some(&self.expr))?;
+        ac.with_series_and_args(s, aggregated, Some(&self.expr), true)?;
         Ok(ac)
     }
     fn apply_multiple_group_aware<'a>(
         &self,
         mut acs: Vec<AggregationContext<'a>>,
         df: &DataFrame,
     ) -> PolarsResult<AggregationContext<'a>> {
@@ -307,15 +309,20 @@
                 ApplyOptions::ApplyFlat => {
                     if acs
                         .iter()
                         .any(|ac| matches!(ac.agg_state(), AggState::AggregatedList(_)))
                     {
                         self.apply_multiple_group_aware(acs, df)
                     } else {
-                        apply_multiple_elementwise(acs, self.function.as_ref(), &self.expr)
+                        apply_multiple_elementwise(
+                            acs,
+                            self.function.as_ref(),
+                            &self.expr,
+                            self.check_lengths,
+                        )
                     }
                 }
             }
         }
     }
     fn to_field(&self, input_schema: &Schema) -> PolarsResult<Field> {
         self.expr.to_field(input_schema, Context::Default)
@@ -346,14 +353,15 @@
     }
 }
 
 fn apply_multiple_elementwise<'a>(
     mut acs: Vec<AggregationContext<'a>>,
     function: &dyn SeriesUdf,
     expr: &Expr,
+    check_lengths: bool,
 ) -> PolarsResult<AggregationContext<'a>> {
     match acs.first().unwrap().agg_state() {
         // a fast path that doesn't drop groups of the first arg
         // this doesn't require group re-computation
         AggState::AggregatedList(s) => {
             let ca = s.list().unwrap();
 
@@ -384,21 +392,23 @@
                         ac.groups();
                     }
 
                     ac.flat_naive().into_owned()
                 })
                 .collect::<Vec<_>>();
 
-            let input_len = s.iter().map(|s| s.len()).max().unwrap();
+            let input_len = s[0].len();
             let s = function.call_udf(&mut s)?.unwrap();
-            check_map_output_len(input_len, s.len(), expr)?;
+            if check_lengths {
+                check_map_output_len(input_len, s.len(), expr)?;
+            }
 
             // take the first aggregation context that as that is the input series
             let mut ac = acs.swap_remove(0);
-            ac.with_series(s, false, None)?;
+            ac.with_series_and_args(s, false, None, true)?;
             Ok(ac)
         }
     }
 }
 
 #[cfg(feature = "parquet")]
 impl StatsEvaluator for ApplyExpr {
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/binary.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/binary.rs`

 * *Files 1% similar despite different names*

```diff
@@ -52,14 +52,16 @@
             ChunkCompare::<&Series>::not_equal(left, right).map(|ca| ca.into_series())
         }
         Operator::Plus => Ok(left + right),
         Operator::Minus => Ok(left - right),
         Operator::Multiply => Ok(left * right),
         Operator::Divide => Ok(left / right),
         Operator::TrueDivide => match left.dtype() {
+            #[cfg(feature = "dtype-decimal")]
+            Decimal(_, _) => Ok(left / right),
             Date | Datetime(_, _) | Float32 | Float64 => Ok(left / right),
             _ => Ok(&left.cast(&Float64)? / &right.cast(&Float64)?),
         },
         Operator::FloorDivide => {
             #[cfg(feature = "round_series")]
             {
                 floor_div_series(left, right)
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/cast.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/cast.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/column.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/column.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/count.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/count.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/filter.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/filter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/group_iter.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/group_iter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/literal.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/literal.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -322,14 +322,26 @@
     /// the columns dtype)
     pub(crate) fn with_series(
         &mut self,
         series: Series,
         aggregated: bool,
         expr: Option<&Expr>,
     ) -> PolarsResult<&mut Self> {
+        self.with_series_and_args(series, aggregated, expr, false)
+    }
+
+    pub(crate) fn with_series_and_args(
+        &mut self,
+        series: Series,
+        aggregated: bool,
+        expr: Option<&Expr>,
+        // if the applied function was a `map` instead of an `apply`
+        // this will keep functions applied over literals as literals: F(lit) = lit
+        mapped: bool,
+    ) -> PolarsResult<&mut Self> {
         self.state = match (aggregated, series.dtype()) {
             (true, &DataType::List(_)) => {
                 if series.len() != self.groups.len() {
                     let fmt_expr = if let Some(e) = expr {
                         format!("'{e}' ")
                     } else {
                         String::new()
@@ -346,15 +358,15 @@
             (true, _) => AggState::AggregatedFlat(series),
             _ => {
                 match self.state {
                     // already aggregated to sum, min even this series was flattened it never could
                     // retrieve the length before grouping, so it stays  in this state.
                     AggState::AggregatedFlat(_) => AggState::AggregatedFlat(series),
                     // applying a function on a literal, keeps the literal state
-                    AggState::Literal(_) if series.len() == 1 && self.groups.len() > 1 => {
+                    AggState::Literal(_) if series.len() == 1 && mapped => {
                         AggState::Literal(series)
                     }
                     _ => AggState::NotAggregated(series),
                 }
             }
         };
         Ok(self)
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/slice.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/sort.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/sort.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/sortby.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/sortby.rs`

 * *Files 2% similar despite different names*

```diff
@@ -193,16 +193,20 @@
                                         // we are already in par iter.
                                         multithreaded: false,
                                         ..Default::default()
                                     });
                                     map_sorted_indices_to_group_slice(&sorted_idx, first)
                                 }
                             };
+                            let first = new_idx.first().unwrap_or_else(|| {
+                                invalid.store(true, Ordering::Relaxed);
+                                &0
+                            });
 
-                            (new_idx[0], new_idx)
+                            (*first, new_idx)
                         })
                         .collect()
                 });
 
                 (GroupsProxy::Idx(groups), ordered_by_group_operation)
             } else {
                 let mut ac_sort_by = self
@@ -272,16 +276,20 @@
                                         descending: descending.clone(),
                                         multithreaded: false,
                                     };
                                     let sorted_idx = groups[0].arg_sort_multiple(&options).unwrap();
                                     map_sorted_indices_to_group_slice(&sorted_idx, first)
                                 }
                             };
+                            let first = new_idx.first().unwrap_or_else(|| {
+                                invalid.store(true, Ordering::Relaxed);
+                                &0
+                            });
 
-                            (new_idx[0], new_idx)
+                            (*first, new_idx)
                         })
                         .collect()
                 });
 
                 (GroupsProxy::Idx(groups), ordered_by_group_operation)
             };
             polars_ensure!(
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/take.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/take.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/ternary.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/ternary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/expressions/window.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/expressions/window.rs`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 use std::fmt::Write;
 use std::sync::Arc;
 
 use polars_arrow::export::arrow::array::PrimitiveArray;
 use polars_core::export::arrow::bitmap::Bitmap;
 use polars_core::frame::groupby::{GroupBy, GroupsProxy};
 use polars_core::frame::hash_join::{
-    default_join_ids, private_left_join_multiple_keys, JoinOptIds,
+    default_join_ids, private_left_join_multiple_keys, ChunkJoinOptIds, JoinValidation,
 };
 use polars_core::prelude::*;
 use polars_core::series::IsSorted;
 use polars_core::utils::_split_offsets;
 use polars_core::{downcast_as_macro_arg_physical, POOL};
 use polars_utils::format_smartstring;
 use polars_utils::sort::perfect_sort;
@@ -551,15 +551,18 @@
                         let keys = gb.keys();
                         cache_gb(gb, state, &cache_key);
 
                         let get_join_tuples = || {
                             if groupby_columns.len() == 1 {
                                 // group key from right column
                                 let right = &keys[0];
-                                groupby_columns[0].hash_join_left(right).1
+                                groupby_columns[0]
+                                    .hash_join_left(right, JoinValidation::ManyToMany)
+                                    .unwrap()
+                                    .1
                             } else {
                                 let df_right = DataFrame::new_no_checks(keys);
                                 let df_left = DataFrame::new_no_checks(groupby_columns);
                                 private_left_join_multiple_keys(&df_left, &df_right, None, None).1
                             }
                         };
 
@@ -615,15 +618,15 @@
     }
 
     fn is_valid_aggregation(&self) -> bool {
         false
     }
 }
 
-fn materialize_column(join_opt_ids: &JoinOptIds, out_column: &Series) -> Series {
+fn materialize_column(join_opt_ids: &ChunkJoinOptIds, out_column: &Series) -> Series {
     #[cfg(feature = "chunked_ids")]
     {
         use polars_arrow::export::arrow::Either;
 
         match join_opt_ids {
             Either::Left(ids) => unsafe {
                 out_column.take_opt_iter_unchecked(
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/file_cache.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/file_cache.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/node_timer.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/node_timer.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/planner/expr.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/planner/expr.rs`

 * *Files 1% similar despite different names*

```diff
@@ -459,14 +459,15 @@
                 expr: node_to_expr(expression, expr_arena),
                 collect_groups: options.collect_groups,
                 auto_explode: options.auto_explode,
                 allow_rename: options.allow_rename,
                 pass_name_to_apply: options.pass_name_to_apply,
                 input_schema: schema.cloned(),
                 allow_threading: !state.has_cache,
+                check_lengths: options.check_lengths(),
             }))
         }
         Function {
             input,
             function,
             options,
             ..
@@ -493,14 +494,15 @@
                 expr: node_to_expr(expression, expr_arena),
                 collect_groups: options.collect_groups,
                 auto_explode: options.auto_explode,
                 allow_rename: options.allow_rename,
                 pass_name_to_apply: options.pass_name_to_apply,
                 input_schema: schema.cloned(),
                 allow_threading: !state.has_cache,
+                check_lengths: options.check_lengths(),
             }))
         }
         Slice {
             input,
             offset,
             length,
         } => {
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/planner/lp.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/planner/lp.rs`

 * *Files 0% similar despite different names*

```diff
@@ -522,20 +522,18 @@
                 expr_arena,
                 None,
                 &mut Default::default(),
             )?;
             Ok(Box::new(executors::JoinExec::new(
                 input_left,
                 input_right,
-                options.how,
                 left_on,
                 right_on,
                 parallel,
-                options.suffix,
-                options.slice,
+                options.args,
             )))
         }
         HStack { input, exprs, .. } => {
             let input_schema = lp_arena.get(input).schema(lp_arena).into_owned();
             let input = create_physical_plan(input, lp_arena, expr_arena)?;
 
             let mut state =
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/state.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/state.rs`

 * *Files 2% similar despite different names*

```diff
@@ -2,24 +2,24 @@
 use std::sync::atomic::{AtomicU8, Ordering};
 use std::sync::{Mutex, RwLock};
 
 use bitflags::bitflags;
 use once_cell::sync::OnceCell;
 use polars_core::config::verbose;
 use polars_core::frame::groupby::GroupsProxy;
-use polars_core::frame::hash_join::JoinOptIds;
+use polars_core::frame::hash_join::ChunkJoinOptIds;
 use polars_core::prelude::*;
 #[cfg(any(feature = "parquet", feature = "csv", feature = "ipc"))]
 use polars_plan::logical_plan::FileFingerPrint;
 
 #[cfg(any(feature = "ipc", feature = "parquet", feature = "csv"))]
 use super::file_cache::FileCache;
 use crate::physical_plan::node_timer::NodeTimer;
 
-pub type JoinTuplesCache = Arc<Mutex<PlHashMap<String, JoinOptIds>>>;
+pub type JoinTuplesCache = Arc<Mutex<PlHashMap<String, ChunkJoinOptIds>>>;
 pub type GroupsProxyCache = Arc<Mutex<PlHashMap<String, GroupsProxy>>>;
 
 bitflags! {
     #[repr(transparent)]
     pub(super) struct StateFlags: u8 {
         /// More verbose logging
         const VERBOSE = 0x01;
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/streaming/checks.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/streaming/checks.rs`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-use polars_core::prelude::JoinType;
+use polars_core::prelude::{JoinArgs, JoinType};
 use polars_plan::prelude::*;
 
 pub(super) fn is_streamable_sort(args: &SortArguments) -> bool {
     // check if slice is positive
     match args.slice {
         Some((offset, _)) => offset >= 0,
         None => true,
@@ -57,15 +57,16 @@
 /// check if all expressions are a simple column projection
 pub(super) fn all_column(exprs: &[Node], expr_arena: &Arena<AExpr>) -> bool {
     exprs
         .iter()
         .all(|node| matches!(expr_arena.get(*node), AExpr::Column(_)))
 }
 
-pub(super) fn streamable_join(join_type: &JoinType) -> bool {
-    match join_type {
+pub(super) fn streamable_join(args: &JoinArgs) -> bool {
+    let supported = match args.how {
         #[cfg(feature = "cross_join")]
         JoinType::Cross => true,
         JoinType::Inner | JoinType::Left => true,
         _ => false,
-    }
+    };
+    supported && !args.validation.needs_checks()
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/streaming/construct_pipeline.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/streaming/construct_pipeline.rs`

 * *Files 0% similar despite different names*

```diff
@@ -59,15 +59,19 @@
     // slice AFTER the join has happened and the join will be an
     // operator
     use ALogicalPlan::*;
     match lp_arena.get(node) {
         Join {
             options:
                 JoinOptions {
-                    slice: Some((offset, len)),
+                    args:
+                        JoinArgs {
+                            slice: Some((offset, len)),
+                            ..
+                        },
                     ..
                 },
             ..
         }
         | Union {
             options:
                 UnionOptions {
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/streaming/convert_alp.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/streaming/convert_alp.rs`

 * *Files 1% similar despite different names*

```diff
@@ -215,15 +215,15 @@
                 }
             }
             Join {
                 input_left,
                 input_right,
                 options,
                 ..
-            } if streamable_join(&options.how) => {
+            } if streamable_join(&options.args) => {
                 let input_left = *input_left;
                 let input_right = *input_right;
                 state.streamable = true;
                 state.join_count += 1;
 
                 // We swap so that the build phase contains the smallest table
                 // and then we stream the larger table
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/physical_plan/streaming/tree.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/physical_plan/streaming/tree.rs`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,15 @@
 use std::collections::BTreeSet;
 use std::fmt::Debug;
 
+#[cfg(debug_assertions)]
 use polars_plan::prelude::*;
-use polars_utils::arena::{Arena, Node};
+#[cfg(debug_assertions)]
+use polars_utils::arena::Arena;
+use polars_utils::arena::Node;
 
 #[derive(Copy, Clone, Debug)]
 pub(super) enum PipelineNode {
     Sink(Node),
     Operator(Node),
     RhsJoin(Node),
     Union(Node),
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/prelude.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/prelude.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/aggregations.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/aggregations.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/arity.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/arity.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/cse.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/cse.rs`

 * *Files 1% similar despite different names*

```diff
@@ -163,15 +163,15 @@
 
     let a = x.left_join(z.clone(), col("a"), col("a"));
     let b = y.left_join(z.clone(), col("a"), col("a"));
     let c = a.join(
         b,
         &[col("a"), col("b")],
         &[col("a"), col("b")],
-        JoinType::Left,
+        JoinType::Left.into(),
     );
 
     let (mut expr_arena, mut lp_arena) = get_arenas();
     let lp = c.optimize(&mut lp_arena, &mut expr_arena).unwrap();
 
     // ensure we get only one cache and the it is not above the join
     // and ensure that every cache only has 1 hit.
@@ -214,27 +214,27 @@
     .lazy();
 
     let q = lf2
         .join(
             lf1.clone().select([col("id"), col("freq")]),
             [col("id")],
             [col("id")],
-            JoinType::Semi,
+            JoinType::Semi.into(),
         )
         .join(
             lf1.clone().filter(col("x").neq(lit(8))),
             [col("id")],
             [col("id")],
-            JoinType::Semi,
+            JoinType::Semi.into(),
         )
         .join(
             lf1.clone().filter(col("x").neq(lit(8))),
             [col("id")],
             [col("id")],
-            JoinType::Semi,
+            JoinType::Semi.into(),
         );
 
     let q = q.with_common_subplan_elimination(true);
 
     let (mut expr_arena, mut lp_arena) = get_arenas();
     let lp = q.optimize(&mut lp_arena, &mut expr_arena).unwrap();
 
@@ -271,15 +271,15 @@
     .lazy();
 
     let left = left.cross_join(right.clone().select([col("A")]));
     let q = left.join(
         right.rename(["B"], ["C"]),
         [col("A"), col("C")],
         [col("A"), col("C")],
-        JoinType::Left,
+        JoinType::Left.into(),
     );
 
     let out = q.collect()?;
 
     assert_eq!(out.get_column_names(), &["C", "A", "D"]);
 
     Ok(())
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/io.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/io.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/logical.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/logical.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/optimization_checks.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/optimization_checks.rs`

 * *Files 2% similar despite different names*

```diff
@@ -144,15 +144,20 @@
     let df2 = df![
         "bar" => [5, 6],
         "idx2" => [0, 1],
     ]?;
 
     let out = df1
         .lazy()
-        .join(df2.lazy(), [col("idx1")], [col("idx2")], JoinType::Left)
+        .join(
+            df2.lazy(),
+            [col("idx1")],
+            [col("idx2")],
+            JoinType::Left.into(),
+        )
         .filter(col("bar").eq(lit(5i32)))
         .collect()?;
 
     let expected = df![
         "foo" => ["abc", "def"],
         "idx1" => [0, 0],
         "bar" => [5, 5],
@@ -185,27 +190,32 @@
 #[cfg(feature = "cse")]
 pub fn test_slice_pushdown_join() -> PolarsResult<()> {
     let _guard = SINGLE_LOCK.lock().unwrap();
     let q1 = scan_foods_parquet(false).limit(3);
     let q2 = scan_foods_parquet(false);
 
     let q = q1
-        .join(q2, [col("category")], [col("category")], JoinType::Left)
+        .join(
+            q2,
+            [col("category")],
+            [col("category")],
+            JoinType::Left.into(),
+        )
         .slice(1, 3)
         // this inserts a cache and blocks slice pushdown
         .with_common_subplan_elimination(false);
     // test if optimization continued beyond the join node
     assert!(slice_at_scan(q.clone()));
 
     let (mut expr_arena, mut lp_arena) = get_arenas();
     let lp = q.clone().optimize(&mut lp_arena, &mut expr_arena).unwrap();
     assert!((&lp_arena).iter(lp).all(|(_, lp)| {
         use ALogicalPlan::*;
         match lp {
-            Join { options, .. } => options.slice == Some((1, 3)),
+            Join { options, .. } => options.args.slice == Some((1, 3)),
             Slice { .. } => false,
             _ => true,
         }
     }));
     let out = q.collect()?;
     assert_eq!(out.shape(), (3, 7));
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/predicate_queries.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/predicate_queries.rs`

 * *Files 2% similar despite different names*

```diff
@@ -174,27 +174,27 @@
     ]?
     .lazy()
     .with_column(lit(true).alias("flag"));
 
     let out = a
         .clone()
         .lazy()
-        .join(b.clone(), [col("key")], [col("key")], JoinType::Left)
+        .join(b.clone(), [col("key")], [col("key")], JoinType::Left.into())
         .filter(col("flag").is_null())
         .collect()?;
     let expected = df![
         "key" => ["foo"],
         "bar" => [1],
         "flag" => &[None, Some(true)][0..1]
     ]?;
     assert!(out.frame_equal_missing(&expected));
 
     let out = a
         .lazy()
-        .join(b.clone(), [col("key")], [col("key")], JoinType::Left)
+        .join(b.clone(), [col("key")], [col("key")], JoinType::Left.into())
         .filter(col("flag").eq(lit(NULL)))
         .with_predicate_pushdown(false)
         .collect()?;
     assert!(out.frame_equal_missing(&expected));
 
     Ok(())
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/projection_queries.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/projection_queries.rs`

 * *Files 2% similar despite different names*

```diff
@@ -96,15 +96,15 @@
         let partial = lf.clone().select([col("category")]).limit(5);
         let q = lf
             .clone()
             .join(
                 partial,
                 [col("category")],
                 [col("category")],
-                JoinType::Inner,
+                JoinType::Inner.into(),
             )
             .with_common_subplan_elimination(cse);
         let out = q.collect()?;
         assert_eq!(
             out.get_column_names(),
             &["category", "calories", "fats_g", "sugars_g"]
         );
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/queries.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/queries.rs`

 * *Files 0% similar despite different names*

```diff
@@ -264,15 +264,15 @@
                 .alias("diff_cases"),
         ])
         .explode([col("day"), col("diff_cases")])
         .join(
             base_df,
             [col("uid"), col("day")],
             [col("uid"), col("day")],
-            JoinType::Inner,
+            JoinType::Inner.into(),
         )
         .collect()
         .unwrap();
     assert_eq!(
         Vec::from(out.column("diff_cases").unwrap().i32().unwrap()),
         &[None, Some(2), Some(3), None, Some(5), Some(11)]
     );
@@ -364,15 +364,15 @@
 
     let out = sales
         .lazy()
         .join(
             cities.lazy(),
             [col("Sales.City")],
             [col("Cities.City")],
-            JoinType::Inner,
+            JoinType::Inner.into(),
         )
         .groupby([col("Cities.Country")])
         .agg([col("Sales.Amount").sum().alias("sum")])
         .sort("sum", Default::default())
         .collect()?;
     let vals = out
         .column("sum")?
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/streaming.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/streaming.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/tests/tpch.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/tests/tpch.rs`

 * *Files 4% similar despite different names*

```diff
@@ -60,15 +60,15 @@
         .clone()
         .groupby([col("p_partkey")])
         .agg([col("ps_supplycost").min()])
         .join(
             q1.clone(),
             [col("p_partkey"), col("ps_supplycost")],
             [col("p_partkey"), col("ps_supplycost")],
-            JoinType::Inner,
+            JoinType::Inner.into(),
         )
         .select([cols([
             "s_acctbal",
             "s_name",
             "n_name",
             "p_partkey",
             "p_mfgr",
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-lazy/src/utils.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-lazy/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/Cargo.toml` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/Cargo.toml`

 * *Files 5% similar despite different names*

```diff
@@ -2,25 +2,26 @@
 name = "polars-core"
 version= "0.30.0"
 authors = ["ritchie46 <ritchie46@gmail.com>"]
 edition = "2021"
 license = "MIT"
 repository = "https://github.com/pola-rs/polars"
 description = "Core of the Polars DataFrame library"
+resolver = "2"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [features]
 simd = ["arrow/simd", "polars-arrow/simd"]
 nightly = ["simd", "hashbrown/nightly", "polars-utils/nightly", "polars-arrow/nightly"]
 avx512 = []
 docs = []
 temporal = ["regex", "chrono", "polars-error/regex"]
 random = ["rand", "rand_distr"]
-default = ["docs", "temporal", "private"]
+default = ["docs", "temporal"]
 lazy = []
 
 # ~40% faster collect, needed until trustedlength iter stabilizes
 # more fast paths, slower compilation
 performant = ["polars-arrow/performant"]
 
 # extra utilities for Utf8Chunked
@@ -33,16 +34,14 @@
 
 # opt-in features
 # sort by multiple columns
 sort_multiple = []
 # create from row values
 # and include pivot operation
 rows = []
-# dont use this
-private = []
 
 # operations
 is_in = []
 zip_with = []
 round_series = []
 checked_arithmetic = []
 repeat_by = []
@@ -154,18 +153,18 @@
 bitflags= "1.3"
 chrono = { version = "0.4", default-features = false, features = ["std"], optional = true }
 chrono-tz = { version = "0.8", optional = true }
 comfy-table = { version = "6.1.4", optional = true, default_features = false }
 either= "1.8"
 hashbrown= { version = "0.13.1", features = ["rayon", "ahash"] }
 indexmap= { version = "1", features = ["std"] }
-itoap = { version = "1", optional = true, feature = ["simd"] }
+itoap = { version = "1", optional = true, features = ["simd"] }
 ndarray = { version = "0.15", optional = true, default_features = false }
 num-traits= "0.2"
-object_store = { version = "0.5.3", default-features = false, optional = true }
+object_store = { version = "0.6.0", default-features = false, optional = true }
 once_cell= "1"
 polars-arrow = { version = "0.30.0", path = "../polars-arrow", features = ["compute"] }
 polars-error = { version = "0.30.0", path = "../polars-error" }
 polars-row = { version = "0.30.0", path = "../polars-row" }
 polars-utils = { version = "0.30.0", path = "../polars-utils" }
 rand = { version = "0.8", optional = true, features = ["small_rng", "std"] }
 rand_distr = { version = "0.4", optional = true }
@@ -177,17 +176,17 @@
 smartstring= { version = "1" }
 thiserror= "^1"
 url = { version = "2.3.1", optional = true }
 xxhash-rust= { version = "0.8.6", features = ["xxh3"] }
 
 [dependencies.arrow]
 package = "arrow2"
-# git = "https://github.com/jorgecarleitao/arrow2"
+git = "https://github.com/jorgecarleitao/arrow2"
 # git = "https://github.com/ritchie46/arrow2"
-# rev = "1491c6e8f4fd100f53c358e4f3ef1536d9e75090"
+rev = "fb5e4d591c7149df590a330365fae55d2370962f"
 # path = "../arrow2"
 # branch = "polars_2023-05-25"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
@@ -199,16 +198,13 @@
   "compute_filter",
   "compute_if_then_else",
 ]
 
 [target.'cfg(target_family = "wasm")'.dependencies]
 wasm-timer = "0.2.5"
 
-[dev-dependencies]
-bincode = "1"
-
 [package.metadata.docs.rs]
 # not all because arrow 4.3 does not compile with simd
 # all-features = true
 features = ["docs-selection"]
 # defines the configuration attribute `docsrs`
 rustdoc-args = ["--cfg", "docsrs"]
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/LICENSE` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/array/iterator.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/array/iterator.rs`

 * *Files 19% similar despite different names*

```diff
@@ -1,36 +1,34 @@
 use std::ptr::NonNull;
 
 use super::*;
 use crate::chunked_array::list::iterator::AmortizedListIter;
-use crate::series::unstable::ArrayBox;
+use crate::series::unstable::{ArrayBox, UnstableSeries};
 
 impl ArrayChunked {
     /// This is an iterator over a ListChunked that save allocations.
     /// A Series is:
-    ///     1. Arc<ChunkedArray>
+    ///     1. [`Arc<ChunkedArray>`]
     ///     ChunkedArray is:
     ///         2. Vec< 3. ArrayRef>
     ///
     /// The ArrayRef we indicated with 3. will be updated during iteration.
     /// The Series will be pinned in memory, saving an allocation for
     /// 1. Arc<..>
     /// 2. Vec<...>
     ///
     /// # Warning
     /// Though memory safe in the sense that it will not read unowned memory, UB, or memory leaks
     /// this function still needs precautions. The returned should never be cloned or taken longer
     /// than a single iteration, as every call on `next` of the iterator will change the contents of
     /// that Series.
-    #[cfg(feature = "private")]
     pub fn amortized_iter(&self) -> AmortizedListIter<impl Iterator<Item = Option<ArrayBox>> + '_> {
         self.amortized_iter_with_name("")
     }
 
-    #[cfg(feature = "private")]
     pub fn amortized_iter_with_name(
         &self,
         name: &str,
     ) -> AmortizedListIter<impl Iterator<Item = Option<ArrayBox>> + '_> {
         // we create the series container from the inner array
         // so that the container has the proper dtype.
         let arr = self.downcast_iter().next().unwrap();
@@ -62,8 +60,45 @@
             self.len(),
             series_container,
             NonNull::new(ptr).unwrap(),
             self.downcast_iter().flat_map(|arr| arr.iter()),
             inner_dtype,
         )
     }
+
+    pub fn try_apply_amortized<'a, F>(&'a self, mut f: F) -> PolarsResult<ListChunked>
+    where
+        F: FnMut(UnstableSeries<'a>) -> PolarsResult<Series>,
+    {
+        if self.is_empty() {
+            return Ok(Series::new_empty(
+                self.name(),
+                &DataType::List(Box::new(self.inner_dtype())),
+            )
+            .list()
+            .unwrap()
+            .clone());
+        }
+        let mut fast_explode = self.null_count() == 0;
+        let mut ca: ListChunked = self
+            .amortized_iter()
+            .map(|opt_v| {
+                opt_v
+                    .map(|v| {
+                        let out = f(v);
+                        if let Ok(out) = &out {
+                            if out.is_empty() {
+                                fast_explode = false
+                            }
+                        };
+                        out
+                    })
+                    .transpose()
+            })
+            .collect::<PolarsResult<_>>()?;
+        ca.rename(self.name());
+        if fast_explode {
+            ca.set_fast_explode();
+        }
+        Ok(ca)
+    }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/array/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/array/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/bitwise.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/bitwise.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/builder/binary.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/builder/binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/builder/boolean.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/builder/boolean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/builder/fixed_size_list.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/builder/fixed_size_list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/builder/from.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/builder/from.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/builder/list.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/builder/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/builder/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/builder/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/builder/primitive.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/builder/primitive.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/builder/utf8.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/builder/utf8.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/cast.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/cast.rs`

 * *Files 0% similar despite different names*

```diff
@@ -170,26 +170,26 @@
                 let ca = builder.finish();
                 Ok(ca.into_series())
             }
             #[cfg(feature = "dtype-struct")]
             DataType::Struct(fields) => cast_single_to_struct(self.name(), &self.chunks, fields),
             #[cfg(feature = "dtype-decimal")]
             DataType::Decimal(precision, scale) => match (precision, scale) {
-                (Some(precision), Some(scale)) => {
+                (precision, Some(scale)) => {
                     let chunks = self
                         .downcast_iter()
                         .map(|arr| {
                             polars_arrow::compute::cast::cast_utf8_to_decimal(
                                 arr, *precision, *scale,
                             )
                         })
                         .collect();
                     unsafe {
                         Ok(Int128Chunked::from_chunks(self.name(), chunks)
-                            .into_decimal_unchecked(Some(*precision), *scale)
+                            .into_decimal_unchecked(*precision, *scale)
                             .into_series())
                     }
                 }
                 (None, None) => self.to_decimal(100),
                 _ => {
                     polars_bail!(ComputeError: "expected 'precision' or 'scale' when casting to Decimal")
                 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/comparison/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/comparison/mod.rs`

 * *Files 0% similar despite different names*

```diff
@@ -294,17 +294,37 @@
 
     fn equal_missing(&self, rhs: &BooleanChunked) -> BooleanChunked {
         // broadcast
         match (self.len(), rhs.len()) {
             (_, 1) => {
                 if let Some(value) = rhs.get(0) {
                     if value {
-                        self.clone()
+                        if self.null_count() == 0 {
+                            self.clone()
+                        } else {
+                            self.apply_kernel(&|arr| {
+                                if let Some(validity) = arr.validity() {
+                                    Box::new(BooleanArray::from_data_default(
+                                        arr.values() & validity,
+                                        None,
+                                    )) as ArrayRef
+                                } else {
+                                    Box::new(arr.clone())
+                                }
+                            })
+                        }
                     } else {
-                        self.not()
+                        self.apply_kernel(&|arr| {
+                            let bitmap = if let Some(validity) = arr.validity() {
+                                arr.values() ^ validity
+                            } else {
+                                arr.values().not()
+                            };
+                            Box::new(BooleanArray::from_data_default(bitmap, None)) as ArrayRef
+                        })
                     }
                 } else {
                     self.is_null()
                 }
             }
             (1, _) => rhs.equal_missing(self),
             _ => {
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/comparison/scalar.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/comparison/scalar.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/drop.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/drop.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/float.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/float.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/from.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/from.rs`

 * *Files 4% similar despite different names*

```diff
@@ -81,14 +81,22 @@
     pub unsafe fn from_chunks(name: &str, mut chunks: Vec<ArrayRef>) -> Self {
         let dtype = match T::get_dtype() {
             dtype @ DataType::List(_) => from_chunks_list_dtype(&mut chunks, dtype),
             #[cfg(feature = "dtype-array")]
             dtype @ DataType::Array(_, _) => from_chunks_list_dtype(&mut chunks, dtype),
             dt => dt,
         };
+        // assertions in debug mode
+        // that check if the data types in the arrays are as expected
+        #[cfg(debug_assertions)]
+        {
+            if !chunks.is_empty() && dtype.is_primitive() {
+                assert_eq!(chunks[0].data_type(), &dtype.to_physical().to_arrow())
+            }
+        }
         let field = Arc::new(Field::new(name, dtype));
         let mut out = ChunkedArray {
             field,
             chunks,
             phantom: PhantomData,
             bit_settings: Default::default(),
             length: 0,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/iterator/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/iterator/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/iterator/par/list.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/iterator/par/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/iterator/par/utf8.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/iterator/par/utf8.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/kernels/take.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/kernels/take.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/list/iterator.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/list/iterator.rs`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 use std::marker::PhantomData;
 use std::ptr::NonNull;
 
 use crate::prelude::*;
 use crate::series::unstable::{ArrayBox, UnstableSeries};
 use crate::utils::CustomIterTools;
 
-#[cfg(feature = "private")]
 pub struct AmortizedListIter<'a, I: Iterator<Item = Option<ArrayBox>>> {
     len: usize,
     series_container: Box<Series>,
     inner: NonNull<ArrayRef>,
     lifetime: PhantomData<&'a ArrayRef>,
     iter: I,
     // used only if feature="dtype-struct"
@@ -87,40 +86,37 @@
     fn size_hint(&self) -> (usize, Option<usize>) {
         (self.len, Some(self.len))
     }
 }
 
 // # Safety
 // we correctly implemented size_hint
-#[cfg(feature = "private")]
 unsafe impl<'a, I: Iterator<Item = Option<ArrayBox>>> TrustedLen for AmortizedListIter<'a, I> {}
 
 impl ListChunked {
     /// This is an iterator over a ListChunked that save allocations.
     /// A Series is:
-    ///     1. Arc<ChunkedArray>
+    ///     1. [`Arc<ChunkedArray>`]
     ///     ChunkedArray is:
     ///         2. Vec< 3. ArrayRef>
     ///
     /// The ArrayRef we indicated with 3. will be updated during iteration.
     /// The Series will be pinned in memory, saving an allocation for
     /// 1. Arc<..>
     /// 2. Vec<...>
     ///
     /// # Warning
     /// Though memory safe in the sense that it will not read unowned memory, UB, or memory leaks
     /// this function still needs precautions. The returned should never be cloned or taken longer
     /// than a single iteration, as every call on `next` of the iterator will change the contents of
     /// that Series.
-    #[cfg(feature = "private")]
     pub fn amortized_iter(&self) -> AmortizedListIter<impl Iterator<Item = Option<ArrayBox>> + '_> {
         self.amortized_iter_with_name("")
     }
 
-    #[cfg(feature = "private")]
     pub fn amortized_iter_with_name(
         &self,
         name: &str,
     ) -> AmortizedListIter<impl Iterator<Item = Option<ArrayBox>> + '_> {
         // we create the series container from the inner array
         // so that the container has the proper dtype.
         let arr = self.downcast_iter().next().unwrap();
@@ -154,15 +150,14 @@
             NonNull::new(ptr).unwrap(),
             self.downcast_iter().flat_map(|arr| arr.iter()),
             inner_dtype,
         )
     }
 
     /// Apply a closure `F` elementwise.
-    #[cfg(feature = "private")]
     #[must_use]
     pub fn apply_amortized<'a, F>(&'a self, mut f: F) -> Self
     where
         F: FnMut(UnstableSeries<'a>) -> Series,
     {
         if self.is_empty() {
             return self.clone();
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/list/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/list/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -14,15 +14,14 @@
     }
 
     pub fn set_inner_dtype(&mut self, dtype: DataType) {
         assert_eq!(dtype.to_physical(), self.inner_dtype().to_physical());
         let field = Arc::make_mut(&mut self.field);
         field.coerce(DataType::List(Box::new(dtype)));
     }
-    #[cfg(feature = "private")]
     pub fn set_fast_explode(&mut self) {
         self.bit_settings.insert(Settings::FAST_EXPLODE_LIST)
     }
     pub(crate) fn unset_fast_explode(&mut self) {
         self.bit_settings.remove(Settings::FAST_EXPLODE_LIST)
     }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/builder.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/builder.rs`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 use std::fmt::{Debug, Formatter};
 use std::hash::{Hash, Hasher};
 
 use arrow::array::*;
 use hashbrown::hash_map::{Entry, RawEntryMut};
 use polars_arrow::trusted_len::PushUnchecked;
-use polars_utils::HashSingle;
 
 use crate::datatypes::PlHashMap;
 use crate::frame::groupby::hashing::HASHMAP_INIT_SIZE;
 use crate::prelude::*;
 use crate::{using_string_cache, StringCache, POOL};
 
 pub enum RevMappingBuilder {
@@ -222,15 +221,15 @@
             local_mapping: Default::default(),
             hashes: vec![],
         }
     }
 }
 impl<'a> CategoricalChunkedBuilder<'a> {
     fn push_impl(&mut self, s: &'a str, store_hashes: bool) {
-        let h = self.local_mapping.hasher().hash_single(s);
+        let h = self.local_mapping.hasher().hash_one(s);
         let key = StrHashLocal::new(s, h);
         let mut idx = self.local_mapping.len() as u32;
 
         let entry = self
             .local_mapping
             .raw_entry_mut()
             .from_key_hashed_nocheck(h, &key);
@@ -246,15 +245,15 @@
             }
         };
         self.cat_builder.push(Some(idx));
     }
 
     /// Check if this categorical already exists
     pub fn exits(&self, s: &str) -> bool {
-        let h = self.local_mapping.hasher().hash_single(s);
+        let h = self.local_mapping.hasher().hash_one(s);
         let key = StrHashLocal::new(s, h);
         self.local_mapping.contains_key(&key)
     }
 
     #[inline]
     pub fn append_value(&mut self, s: &'a str) {
         self.push_impl(s, false)
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/from.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/from.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/merge.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/merge.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/append.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/append.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/take_random.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/take_random.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/unique.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/unique.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/zip.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/zip.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/categorical/stringcache.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/categorical/stringcache.rs`

 * *Files 4% similar despite different names*

```diff
@@ -2,15 +2,14 @@
 use std::sync::atomic::{AtomicU32, Ordering};
 use std::sync::{RwLock, RwLockReadGuard, RwLockWriteGuard};
 use std::time::{SystemTime, UNIX_EPOCH};
 
 use ahash::RandomState;
 use hashbrown::hash_map::RawEntryMut;
 use once_cell::sync::Lazy;
-use polars_utils::HashSingle;
 use smartstring::{LazyCompact, SmartString};
 
 use crate::datatypes::PlIdHashMap;
 use crate::frame::groupby::hashing::HASHMAP_INIT_SIZE;
 use crate::prelude::InitHashMaps;
 
 /// We use atomic reference counting
@@ -143,15 +142,15 @@
             }
         }
         global_idx
     }
 
     #[inline]
     pub(crate) fn get_cat(&self, s: &str) -> Option<u32> {
-        let h = StringCache::get_hash_builder().hash_single(s);
+        let h = StringCache::get_hash_builder().hash_one(s);
         // as StrHashGlobal may allocate a string
         self.map
             .raw_entry()
             .from_hash(h, |key| {
                 (key.hash == h) && {
                     let pos = key.idx as usize;
                     let value = unsafe { self.payloads.get_unchecked(pos) };
@@ -159,15 +158,15 @@
                 }
             })
             .map(|(k, _)| k.idx)
     }
 
     #[inline]
     pub(crate) fn insert(&mut self, s: &str) -> u32 {
-        let h = StringCache::get_hash_builder().hash_single(s);
+        let h = StringCache::get_hash_builder().hash_one(s);
         self.insert_from_hash(h, s)
     }
 }
 
 impl Default for SCacheInner {
     fn default() -> Self {
         Self {
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/date.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/date.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/datetime.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/datetime.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/decimal.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/decimal.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/duration.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/duration.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -60,15 +60,15 @@
 impl<K: PolarsDataType, T: PolarsDataType> DerefMut for Logical<K, T> {
     fn deref_mut(&mut self) -> &mut Self::Target {
         &mut self.0
     }
 }
 
 impl<K: PolarsDataType, T: PolarsDataType> Logical<K, T> {
-    pub fn new_logical<J: PolarsDataType>(ca: ChunkedArray<T>) -> Logical<J, T> {
+    pub(crate) fn new_logical<J: PolarsDataType>(ca: ChunkedArray<T>) -> Logical<J, T> {
         Logical(ca, PhantomData, None)
     }
 }
 
 pub trait LogicalType {
     /// Get data type of ChunkedArray.
     fn dtype(&self) -> &DataType;
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/struct_/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/struct_/mod.rs`

 * *Files 3% similar despite different names*

```diff
@@ -129,15 +129,15 @@
         let n_chunks = self.fields[0].chunks().len();
         for i in offset..n_chunks {
             let field_arrays = self
                 .fields
                 .iter()
                 .map(|s| match s.dtype() {
                     #[cfg(feature = "object")]
-                    DataType::Object(_) => s.to_arrow(0),
+                    DataType::Object(_) => s.to_arrow(i),
                     _ => s.chunks()[i].clone(),
                 })
                 .collect::<Vec<_>>();
 
             // we determine fields from arrays as there might be object arrays
             // where the dtype is bound to that single array
             let new_fields = arrays_to_fields(&field_arrays, &self.fields);
@@ -178,31 +178,55 @@
         out
     }
 
     fn set_null_count(&mut self) {
         let mut null_count = 0;
         let chunks_lens = self.fields()[0].chunks().len();
 
+        // fast path
+        // we early return if a column doesn't have nulls
+        for i in 0..chunks_lens {
+            for s in self.fields() {
+                let arr = &s.chunks()[i];
+                let has_nulls = arr.null_count() > 0 || matches!(s.dtype(), DataType::Null);
+                if !has_nulls {
+                    self.null_count = 0;
+                    return;
+                }
+            }
+        }
+
+        // slow path
+        // we bitand every null validity bitmask to determine
+        // in which rows all values are null
         for i in 0..chunks_lens {
-            // If all fields are null we count it as null
-            // so we bitand every chunk
             let mut validity_agg = None;
 
+            let mut all_null_array = true;
             for s in self.fields() {
                 let arr = &s.chunks()[i];
 
-                match (&validity_agg, arr.validity()) {
-                    (Some(agg), Some(validity)) => validity_agg = Some(validity.bitand(agg)),
-                    (None, Some(validity)) => validity_agg = Some(validity.clone()),
-                    _ => {}
+                if !matches!(s.dtype(), DataType::Null) {
+                    all_null_array = false;
+                    match (&validity_agg, arr.validity()) {
+                        (Some(agg), Some(validity)) => validity_agg = Some(validity.bitand(agg)),
+                        (None, Some(validity)) => validity_agg = Some(validity.clone()),
+                        _ => {}
+                    }
                 }
             }
+            // we add the null count
             if let Some(validity) = &validity_agg {
                 null_count += validity.unset_bits()
             }
+            // all arrays are null arrays
+            // we add the length of the chunk to the null_count
+            else if all_null_array {
+                null_count += self.fields()[0].chunks()[i].len()
+            }
         }
         self.null_count = null_count
     }
 
     /// Get access to one of this `[StructChunked]`'s fields
     pub fn field_by_name(&self, name: &str) -> PolarsResult<Series> {
         self.fields
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/logical/time.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/logical/time.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/mod.rs`

 * *Files 0% similar despite different names*

```diff
@@ -266,15 +266,15 @@
                     series,
                     self.dtype()
                 ),
             }
         }
     }
 
-    /// Series to ChunkedArray<T>
+    /// Series to [`ChunkedArray<T>`]
     pub fn unpack_series_matching_type(&self, series: &Series) -> PolarsResult<&ChunkedArray<T>> {
         polars_ensure!(
             self.dtype() == series.dtype(),
             SchemaMismatch: "cannot unpack series of type `{}` into `{}`",
             series.dtype(),
             self.dtype(),
         );
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ndarray.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ndarray.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/builder.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/builder.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/extension/drop.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/extension/drop.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/extension/list.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/extension/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/extension/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/extension/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/extension/polars_extension.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/extension/polars_extension.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/iterator.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/iterator.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/mod.rs`

 * *Files 0% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 use std::any::Any;
 use std::fmt::{Debug, Display};
 use std::hash::Hash;
-use std::sync::Arc;
 
 use arrow::bitmap::Bitmap;
 
 pub use crate::prelude::*;
 
 pub mod builder;
 #[cfg(feature = "object")]
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/object/registry.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/object/registry.rs`

 * *Files 4% similar despite different names*

```diff
@@ -22,21 +22,23 @@
     // A function that converts AnyValue to Box<dyn Any> of the object type
     object_converter: ObjectConverter,
 }
 
 static GLOBAL_OBJECT_REGISTRY: Lazy<RwLock<Option<GlobalObjectRegistry>>> =
     Lazy::new(Default::default);
 
-/// This trait can be registers and then that global registration
+/// This trait can be registered, after which that global registration
 /// can be used to materialize object types
 pub trait AnonymousObjectBuilder {
     /// Append a `null` value.
     fn append_null(&mut self);
 
-    /// Append a `T` of [`ObjectChunked<T>`] made generic via the [`Any`] trait.
+    /// Append a `T` of [`ObjectChunked<T>`][ObjectChunked<T>] made generic via the [`Any`] trait.
+    ///
+    /// [ObjectChunked<T>]: crate::chunked_array::object::ObjectChunked
     fn append_value(&mut self, value: &dyn Any);
 
     /// Take the current state and materialize as a [`Series`]
     /// the builder should not be used after that.
     fn to_series(&mut self) -> Series;
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/aggregate/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/aggregate/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/aggregate/quantile.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/aggregate/quantile.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/aggregate/var.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/aggregate/var.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/any_value.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/any_value.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/append.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/append.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/apply.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/apply.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/bit_repr.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/bit_repr.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/chunkops.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/chunkops.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/compare_inner.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/compare_inner.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/concat_str.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/concat_str.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/cum_agg.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/cum_agg.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/downcast.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/downcast.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/explode.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/explode.rs`

 * *Files 17% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 use std::convert::TryFrom;
 
 use arrow::array::*;
 use arrow::bitmap::{Bitmap, MutableBitmap};
-use arrow::offset::OffsetsBuffer;
 use polars_arrow::array::list::AnonymousBuilder;
 use polars_arrow::array::PolarsArray;
 use polars_arrow::bit_util::unset_bit_raw;
 #[cfg(feature = "dtype-array")]
 use polars_arrow::is_valid::IsValid;
 use polars_arrow::prelude::*;
 use polars_arrow::trusted_len::PushUnchecked;
@@ -411,201 +410,14 @@
     for _ in 0..capacity.saturating_sub(idx.len()) {
         idx.push(last_idx);
     }
     idx.truncate(capacity);
     idx
 }
 
-impl ChunkExplode for ListChunked {
-    fn explode_and_offsets(&self) -> PolarsResult<(Series, OffsetsBuffer<i64>)> {
-        // A list array's memory layout is actually already 'exploded', so we can just take the values array
-        // of the list. And we also return a slice of the offsets. This slice can be used to find the old
-        // list layout or indexes to expand the DataFrame in the same manner as the 'explode' operation
-        let ca = self.rechunk();
-        let listarr: &LargeListArray = ca
-            .downcast_iter()
-            .next()
-            .ok_or_else(|| polars_err!(NoData: "cannot explode empty list"))?;
-        let offsets_buf = listarr.offsets().clone();
-        let offsets = listarr.offsets().as_slice();
-        let mut values = listarr.values().clone();
-
-        let mut s = if ca._can_fast_explode() {
-            // ensure that the value array is sliced
-            // as a list only slices its offsets on a slice operation
-
-            // we only do this in fast-explode as for the other
-            // branch the offsets must coincide with the values.
-            if !offsets.is_empty() {
-                let start = offsets[0] as usize;
-                let len = offsets[offsets.len() - 1] as usize - start;
-                // safety:
-                // we are in bounds
-                values = unsafe { values.sliced_unchecked(start, len) };
-            }
-            // safety: inner_dtype should be correct
-            unsafe {
-                Series::from_chunks_and_dtype_unchecked(
-                    self.name(),
-                    vec![values],
-                    &self.inner_dtype().to_physical(),
-                )
-            }
-        } else {
-            // during tests
-            // test that this code branch is not hit with list arrays that could be fast exploded
-            #[cfg(test)]
-            {
-                let mut last = offsets[0];
-                let mut has_empty = false;
-                for &o in &offsets[1..] {
-                    if o == last {
-                        has_empty = true;
-                    }
-                    last = o;
-                }
-                if !has_empty && offsets[0] == 0 {
-                    panic!("could have fast exploded")
-                }
-            }
-
-            // safety: inner_dtype should be correct
-            let values = unsafe {
-                Series::from_chunks_and_dtype_unchecked(
-                    self.name(),
-                    vec![values],
-                    &self.inner_dtype().to_physical(),
-                )
-            };
-            values.explode_by_offsets(offsets)
-        };
-        debug_assert_eq!(s.name(), self.name());
-        // restore logical type
-        unsafe {
-            s = s.cast_unchecked(&self.inner_dtype()).unwrap();
-        }
-
-        Ok((s, offsets_buf))
-    }
-}
-
-impl ChunkExplode for Utf8Chunked {
-    fn explode_and_offsets(&self) -> PolarsResult<(Series, OffsetsBuffer<i64>)> {
-        // A list array's memory layout is actually already 'exploded', so we can just take the values array
-        // of the list. And we also return a slice of the offsets. This slice can be used to find the old
-        // list layout or indexes to expand the DataFrame in the same manner as the 'explode' operation
-        let ca = self.rechunk();
-        let array: &Utf8Array<i64> = ca
-            .downcast_iter()
-            .next()
-            .ok_or_else(|| polars_err!(NoData: "cannot explode empty str"))?;
-
-        let values = array.values();
-        let old_offsets = array.offsets().clone();
-
-        let (new_offsets, validity) = if let Some(validity) = array.validity() {
-            // capacity estimate
-            let capacity = self.get_values_size() + validity.unset_bits();
-
-            let old_offsets = old_offsets.as_slice();
-            let mut old_offset = old_offsets[0];
-            let mut new_offsets = Vec::with_capacity(capacity + 1);
-            new_offsets.push(old_offset);
-
-            let mut bitmap = MutableBitmap::with_capacity(capacity);
-            let values = values.as_slice();
-            for (&offset, valid) in old_offsets[1..].iter().zip(validity) {
-                // safety:
-                // new_offsets already has a single value, so -1 is always in bounds
-                let latest_offset = unsafe { *new_offsets.get_unchecked(new_offsets.len() - 1) };
-
-                if valid {
-                    debug_assert!(old_offset as usize <= values.len());
-                    debug_assert!(offset as usize <= values.len());
-                    let val = unsafe { values.get_unchecked(old_offset as usize..offset as usize) };
-
-                    // take the string value and find the char offsets
-                    // create a new offset value for each char boundary
-                    // safety:
-                    // we know we have string data.
-                    let str_val = unsafe { std::str::from_utf8_unchecked(val) };
-
-                    let char_offsets = str_val
-                        .char_indices()
-                        .skip(1)
-                        .map(|t| t.0 as i64 + latest_offset);
-
-                    // extend the chars
-                    // also keep track of the amount of offsets added
-                    // as we must update the validity bitmap
-                    let len_before = new_offsets.len();
-                    new_offsets.extend(char_offsets);
-                    new_offsets.push(latest_offset + str_val.len() as i64);
-                    bitmap.extend_constant(new_offsets.len() - len_before, true);
-                } else {
-                    // no data, just add old offset and set null bit
-                    new_offsets.push(latest_offset);
-                    bitmap.push(false)
-                }
-                old_offset = offset;
-            }
-
-            (new_offsets.into(), bitmap.into())
-        } else {
-            // fast(er) explode
-
-            // we cannot naively explode, because there might be empty strings.
-
-            // capacity estimate
-            let capacity = self.get_values_size();
-            let old_offsets = old_offsets.as_slice();
-            let mut old_offset = old_offsets[0];
-            let mut new_offsets = Vec::with_capacity(capacity + 1);
-            new_offsets.push(old_offset);
-
-            let values = values.as_slice();
-            for &offset in &old_offsets[1..] {
-                // safety:
-                // new_offsets already has a single value, so -1 is always in bounds
-                let latest_offset = unsafe { *new_offsets.get_unchecked(new_offsets.len() - 1) };
-                debug_assert!(old_offset as usize <= values.len());
-                debug_assert!(offset as usize <= values.len());
-                let val = unsafe { values.get_unchecked(old_offset as usize..offset as usize) };
-
-                // take the string value and find the char offsets
-                // create a new offset value for each char boundary
-                // safety:
-                // we know we have string data.
-                let str_val = unsafe { std::str::from_utf8_unchecked(val) };
-
-                let char_offsets = str_val
-                    .char_indices()
-                    .skip(1)
-                    .map(|t| t.0 as i64 + latest_offset);
-
-                // extend the chars
-                new_offsets.extend(char_offsets);
-                new_offsets.push(latest_offset + str_val.len() as i64);
-                old_offset = offset;
-            }
-
-            (new_offsets.into(), None)
-        };
-
-        let array = unsafe {
-            Utf8Array::<i64>::from_data_unchecked_default(new_offsets, values.clone(), validity)
-        };
-
-        let new_arr = Box::new(array) as ArrayRef;
-
-        let s = Series::try_from((self.name(), new_arr)).unwrap();
-        Ok((s, old_offsets))
-    }
-}
-
 #[cfg(test)]
 mod test {
     use super::*;
     use crate::chunked_array::builder::get_list_builder;
 
     #[test]
     fn test_explode_list() -> PolarsResult<()> {
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/extend.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/extend.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/fill_null.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/fill_null.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/filter.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/filter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/full.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/full.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/is_in.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/is_in.rs`

 * *Files 8% similar despite different names*

```diff
@@ -77,16 +77,16 @@
                         .collect_trusted()
                 };
                 ca.rename(self.name());
                 Ok(ca)
             }
             _ => {
                 // first make sure that the types are equal
-                let st = try_get_supertype(self.dtype(), other.dtype())?;
                 if self.dtype() != other.dtype() {
+                    let st = try_get_supertype(self.dtype(), other.dtype())?;
                     let left = self.cast(&st)?;
                     let right = other.cast(&st)?;
                     return left.is_in(&right);
                 }
                 // now that the types are equal, we coerce every 32 bit array to u32
                 // and every 64 bit array to u64 (including floats)
                 // this allows hashing them and greatly reduces the number of code paths.
@@ -324,14 +324,38 @@
 
                 polars_ensure!(
                     self.fields().len() == other.fields().len(),
                     ComputeError: "`is_in`: mismatch in the number of struct fields: {} and {}",
                     self.fields().len(), other.fields().len()
                 );
 
+                // first make sure that the types are equal
+                let self_dtypes: Vec<_> = self.fields().iter().map(|f| f.dtype()).collect();
+                let other_dtypes: Vec<_> = other.fields().iter().map(|f| f.dtype()).collect();
+                if self_dtypes != other_dtypes {
+                    let self_names = self.fields().iter().map(|f| f.name());
+                    let other_names = other.fields().iter().map(|f| f.name());
+                    let supertypes = self_dtypes
+                        .iter()
+                        .zip(other_dtypes.iter())
+                        .map(|(dt1, dt2)| try_get_supertype(dt1, dt2))
+                        .collect::<Result<Vec<_>, _>>()?;
+                    let self_supertype_fields = self_names
+                        .zip(supertypes.iter())
+                        .map(|(name, st)| Field::new(name, st.clone()))
+                        .collect();
+                    let self_super = self.cast(&DataType::Struct(self_supertype_fields))?;
+                    let other_supertype_fields = other_names
+                        .zip(supertypes.iter())
+                        .map(|(name, st)| Field::new(name, st.clone()))
+                        .collect();
+                    let other_super = other.cast(&DataType::Struct(other_supertype_fields))?;
+                    return self_super.is_in(&other_super);
+                }
+
                 let mut anyvalues = Vec::with_capacity(other.len() * other.fields().len());
                 // Safety:
                 // the iterator is unsafe as the lifetime is tied to the iterator
                 // so we copy to an owned buffer first
                 other.into_iter().for_each(|val| {
                     anyvalues.extend_from_slice(val);
                 });
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/min_max_binary.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/min_max_binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -20,14 +20,15 @@
 mod concat_str;
 #[cfg(feature = "cum_agg")]
 mod cum_agg;
 #[cfg(feature = "dtype-decimal")]
 mod decimal;
 pub(crate) mod downcast;
 pub(crate) mod explode;
+mod explode_and_offsets;
 mod extend;
 mod fill_null;
 mod filter;
 pub mod full;
 #[cfg(feature = "interpolate")]
 mod interpolate;
 #[cfg(feature = "is_in")]
@@ -69,15 +70,15 @@
     }
 
     fn reinterpret_unsigned(&self) -> Series {
         unimplemented!()
     }
 }
 
-/// Transmute ChunkedArray to bit representation.
+/// Transmute [`ChunkedArray`] to bit representation.
 /// This is useful in hashing context and reduces no.
 /// of compiled code paths.
 pub(crate) trait ToBitRepr {
     fn bit_repr_is_large() -> bool;
 
     fn bit_repr_large(&self) -> UInt64Chunked;
     fn bit_repr_small(&self) -> UInt32Chunked;
@@ -280,18 +281,18 @@
     ///
     /// # Safety
     /// - This doesn't do utf8 validation checking when casting from binary
     /// - This doesn't do categorical bound checking when casting from UInt32
     unsafe fn cast_unchecked(&self, data_type: &DataType) -> PolarsResult<Series>;
 }
 
-/// Fastest way to do elementwise operations on a ChunkedArray<T> when the operation is cheaper than
+/// Fastest way to do elementwise operations on a [`ChunkedArray<T>`] when the operation is cheaper than
 /// branching due to null checking
 pub trait ChunkApply<'a, A, B> {
-    /// Apply a closure elementwise and cast to a Numeric ChunkedArray. This is fastest when the null check branching is more expensive
+    /// Apply a closure elementwise and cast to a Numeric [`ChunkedArray`]. This is fastest when the null check branching is more expensive
     /// than the closure application.
     ///
     /// Null values remain null.
     fn apply_cast_numeric<F, S>(&'a self, f: F) -> ChunkedArray<S>
     where
         F: Fn(A) -> S::Native + Copy,
         S: PolarsNumericType;
@@ -467,15 +468,15 @@
     /// The most occurring value(s). Can return multiple Values
     #[cfg(feature = "mode")]
     fn mode(&self) -> PolarsResult<ChunkedArray<T>> {
         polars_bail!(opq = mode, T::get_dtype());
     }
 }
 
-#[derive(Copy, Clone, Eq, PartialEq, Debug)]
+#[derive(Copy, Clone, Eq, PartialEq, Debug, Hash)]
 #[cfg_attr(feature = "serde-lazy", derive(Serialize, Deserialize))]
 pub struct SortOptions {
     pub descending: bool,
     pub nulls_last: bool,
     pub multithreaded: bool,
 }
 
@@ -555,15 +556,15 @@
 
 pub trait ChunkFullNull {
     fn full_null(_name: &str, _length: usize) -> Self
     where
         Self: Sized;
 }
 
-/// Reverse a ChunkedArray<T>
+/// Reverse a [`ChunkedArray<T>`]
 pub trait ChunkReverse {
     /// Return a reversed version of this array.
     fn reverse(&self) -> Self;
 }
 
 /// Filter values by a boolean mask.
 pub trait ChunkFilter<T: PolarsDataType> {
@@ -673,26 +674,26 @@
         match opt_val {
             Some(val) => ObjectChunked::<T>::full(self.name(), val.clone(), length),
             None => ObjectChunked::<T>::full_null(self.name(), length),
         }
     }
 }
 
-/// Shift the values of a ChunkedArray by a number of periods.
+/// Shift the values of a [`ChunkedArray`] by a number of periods.
 pub trait ChunkShiftFill<T: PolarsDataType, V> {
     /// Shift the values by a given period and fill the parts that will be empty due to this operation
     /// with `fill_value`.
     fn shift_and_fill(&self, periods: i64, fill_value: V) -> ChunkedArray<T>;
 }
 
 pub trait ChunkShift<T: PolarsDataType> {
     fn shift(&self, periods: i64) -> ChunkedArray<T>;
 }
 
-/// Combine 2 ChunkedArrays based on some predicate.
+/// Combine two [`ChunkedArray`] based on some predicate.
 pub trait ChunkZip<T: PolarsDataType> {
     /// Create a new ChunkedArray with values from self where the mask evaluates `true` and values
     /// from `other` where the mask evaluates `false`
     fn zip_with(
         &self,
         mask: &BooleanChunked,
         other: &ChunkedArray<T>,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/nulls.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/nulls.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/peaks.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/peaks.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/repeat_by.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/repeat_by.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/reverse.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/reverse.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/rolling_window.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/rolling_window.rs`

 * *Files 4% similar despite different names*

```diff
@@ -1,27 +1,31 @@
+use polars_arrow::prelude::DynArgs;
+
 #[derive(Clone)]
 pub struct RollingOptionsFixedWindow {
     /// The length of the window.
     pub window_size: usize,
     /// Amount of elements in the window that should be filled before computing a result.
     pub min_periods: usize,
     /// An optional slice with the same length as the window that will be multiplied
     ///              elementwise with the values in the window.
     pub weights: Option<Vec<f64>>,
     /// Set the labels at the center of the window.
     pub center: bool,
+    pub fn_params: DynArgs,
 }
 
 impl Default for RollingOptionsFixedWindow {
     fn default() -> Self {
         RollingOptionsFixedWindow {
             window_size: 3,
             min_periods: 1,
             weights: None,
             center: false,
+            fn_params: None,
         }
     }
 }
 
 #[cfg(feature = "rolling_window")]
 mod inner_mod {
     use std::ops::SubAssign;
@@ -66,29 +70,27 @@
         T: PolarsNumericType,
         Self: IntoSeries,
     {
         /// Apply a rolling custom function. This is pretty slow because of dynamic dispatch.
         fn rolling_apply(
             &self,
             f: &dyn Fn(&Series) -> Series,
-            options: RollingOptionsFixedWindow,
+            mut options: RollingOptionsFixedWindow,
         ) -> PolarsResult<Series> {
             check_input(options.window_size, options.min_periods)?;
 
             let ca = self.rechunk();
             if options.weights.is_some()
                 && !matches!(self.dtype(), DataType::Float64 | DataType::Float32)
             {
                 let s = self.cast(&DataType::Float64)?;
                 return s.rolling_apply(f, options);
             }
 
-            if options.window_size >= self.len() {
-                return Ok(Self::full_null(self.name(), self.len()).into_series());
-            }
+            options.window_size = std::cmp::min(self.len(), options.window_size);
 
             let len = self.len();
             let arr = ca.downcast_iter().next().unwrap();
             let mut series_container =
                 ChunkedArray::<T>::from_slice("", &[T::Native::zero()]).into_series();
             let array_ptr = series_container.array_ref(0);
             let ptr = array_ptr.as_ref() as *const dyn Array as *mut dyn Array
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/set.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/set.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/shift.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/shift.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort_multiple.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort_multiple.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/sort/categorical.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/sort/categorical.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/sort/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/sort/mod.rs`

 * *Files 0% similar despite different names*

```diff
@@ -80,15 +80,14 @@
         match descending {
             true => slice.sort_unstable_by(descending_order_fn),
             false => slice.sort_unstable_by(ascending_order_fn),
         }
     }
 }
 
-#[cfg(feature = "private")]
 pub fn arg_sort_no_nulls<Idx, T>(slice: &mut [(Idx, T)], descending: bool, parallel: bool)
 where
     T: PartialOrd + Send + IsFloat,
     Idx: PartialOrd + Send,
 {
     arg_sort_branch(
         slice,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/take/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/take/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/take/take_chunked.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/take/take_chunked.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/take/take_random.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/take/take_random.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/take/take_single.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/take/take_single.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/take/traits.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/take/traits.rs`

 * *Files 1% similar despite different names*

```diff
@@ -164,15 +164,15 @@
     I: TakeIterator,
 {
     fn from(iter: I) -> Self {
         TakeIdx::Iter(iter)
     }
 }
 
-/// Conversion from Iterator<Item=Option<usize>> to Unchecked TakeIdx
+/// Conversion from [`Iterator<Item=Option<usize>>`] to Unchecked [`TakeIdx`]
 impl<'a, I> From<I> for TakeIdx<'a, Dummy<usize>, I>
 where
     I: TakeIteratorNulls,
 {
     fn from(iter: I) -> Self {
         TakeIdx::IterNulls(iter)
     }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/unique/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/unique/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -59,21 +59,14 @@
     }
 
     fn arg_unique(&self) -> PolarsResult<IdxCa> {
         polars_bail!(opq = arg_unique, self.dtype());
     }
 }
 
-fn fill_set<A>(a: impl Iterator<Item = A>) -> PlHashSet<A>
-where
-    A: Hash + Eq,
-{
-    a.collect()
-}
-
 fn arg_unique<T>(a: impl Iterator<Item = T>, capacity: usize) -> Vec<IdxSize>
 where
     T: Hash + Eq,
 {
     let mut set = PlHashSet::new();
     let mut unique = Vec::with_capacity(capacity);
     a.enumerate().for_each(|(idx, val)| {
@@ -182,18 +175,26 @@
     }
 
     fn arg_unique(&self) -> PolarsResult<IdxCa> {
         Ok(IdxCa::from_vec(self.name(), arg_unique_ca!(self)))
     }
 
     fn n_unique(&self) -> PolarsResult<usize> {
+        let mut set: PlHashSet<T::Native> = PlHashSet::new();
         if self.null_count() > 0 {
-            Ok(fill_set(self.into_iter().flatten()).len() + 1)
+            for arr in self.downcast_iter() {
+                set.extend(arr.into_iter().flatten())
+            }
+            Ok(set.len() + 1)
         } else {
-            Ok(fill_set(self.into_no_null_iter()).len())
+            for arr in self.downcast_iter() {
+                let slice = arr.values().as_slice();
+                set.extend(slice.iter().copied())
+            }
+            Ok(set.len())
         }
     }
 
     #[cfg(feature = "mode")]
     fn mode(&self) -> PolarsResult<Self> {
         Ok(mode(self))
     }
@@ -249,18 +250,25 @@
     }
 
     fn arg_unique(&self) -> PolarsResult<IdxCa> {
         Ok(IdxCa::from_vec(self.name(), arg_unique_ca!(self)))
     }
 
     fn n_unique(&self) -> PolarsResult<usize> {
+        let mut set: PlHashSet<&[u8]> = PlHashSet::new();
         if self.null_count() > 0 {
-            Ok(fill_set(self.into_iter().flatten()).len() + 1)
+            for arr in self.downcast_iter() {
+                set.extend(arr.into_iter().flatten())
+            }
+            Ok(set.len() + 1)
         } else {
-            Ok(fill_set(self.into_no_null_iter()).len())
+            for arr in self.downcast_iter() {
+                set.extend(arr.values_iter())
+            }
+            Ok(set.len())
         }
     }
 
     #[cfg(feature = "mode")]
     fn mode(&self) -> PolarsResult<Self> {
         Ok(mode(self))
     }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/unique/rank.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/unique/rank.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/ops/zip.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/ops/zip.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/random.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/random.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/temporal/conversion.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/temporal/conversion.rs`

 * *Files 14% similar despite different names*

```diff
@@ -31,27 +31,24 @@
             AnyValue::Time(v) => time64ns_to_time(*v),
             _ => panic!("can only convert date/datetime to NaiveTime"),
         }
     }
 }
 
 // Used by lazy for literal conversion
-#[cfg(feature = "private")]
 pub fn datetime_to_timestamp_ns(v: NaiveDateTime) -> i64 {
     v.timestamp_nanos()
 }
 
 // Used by lazy for literal conversion
-#[cfg(feature = "private")]
 pub fn datetime_to_timestamp_ms(v: NaiveDateTime) -> i64 {
     v.timestamp_millis()
 }
 
 // Used by lazy for literal conversion
-#[cfg(feature = "private")]
 pub fn datetime_to_timestamp_us(v: NaiveDateTime) -> i64 {
     let us = v.timestamp() * 1_000_000;
     us + v.timestamp_subsec_micros() as i64
 }
 
 pub(crate) fn naive_datetime_to_date(v: NaiveDateTime) -> i32 {
     (datetime_to_timestamp_ms(v) / (MILLISECONDS * SECONDS_IN_DAY)) as i32
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/temporal/date.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/temporal/date.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/temporal/datetime.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/temporal/datetime.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/temporal/duration.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/temporal/duration.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/temporal/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/temporal/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/temporal/time.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/temporal/time.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/to_vec.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/to_vec.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/trusted_len.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/trusted_len.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/chunked_array/upstream_traits.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/chunked_array/upstream_traits.rs`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-//! Implementations of upstream traits for ChunkedArray<T>
+//! Implementations of upstream traits for [`ChunkedArray<T>`]
 use std::borrow::{Borrow, Cow};
 use std::collections::LinkedList;
 use std::iter::FromIterator;
 use std::marker::PhantomData;
 use std::sync::Arc;
 
 use arrow::array::{BooleanArray, PrimitiveArray, Utf8Array};
@@ -113,15 +113,15 @@
 {
     fn from_iter<I: IntoIterator<Item = Option<Ptr>>>(iter: I) -> Self {
         let arr = Utf8Array::<i64>::from_iter(iter);
         unsafe { Self::from_chunks("", vec![Box::new(arr)]) }
     }
 }
 
-/// Local AsRef<T> trait to circumvent the orphan rule.
+/// Local [`AsRef<T>`] trait to circumvent the orphan rule.
 pub trait PolarsAsRef<T: ?Sized>: AsRef<T> {}
 
 impl PolarsAsRef<str> for String {}
 impl PolarsAsRef<str> for &str {}
 // &["foo", "bar"]
 impl PolarsAsRef<str> for &&str {}
 impl<'a> PolarsAsRef<str> for Cow<'a, str> {}
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/cloud.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/cloud.rs`

 * *Files 9% similar despite different names*

```diff
@@ -110,17 +110,22 @@
     /// Build the ObjectStore implementation for AWS.
     #[cfg(feature = "aws")]
     pub fn build_aws(&self, bucket_name: &str) -> PolarsResult<impl ObjectStore> {
         let options = self
             .aws
             .as_ref()
             .ok_or_else(|| polars_err!(ComputeError: "`aws` configuration missing"))?;
-        AmazonS3Builder::new()
-            .try_with_options(options.clone().into_iter())
-            .and_then(|b| b.with_bucket_name(bucket_name).build())
+
+        let mut builder = AmazonS3Builder::new();
+        for (key, value) in options.iter() {
+            builder = builder.with_config(*key, value);
+        }
+        builder
+            .with_bucket_name(bucket_name)
+            .build()
             .map_err(polars_error::to_compute_err)
     }
 
     /// Set the configuration for Azure connections. This is the preferred API from rust.
     #[cfg(feature = "azure")]
     pub fn with_azure<I: IntoIterator<Item = (AzureConfigKey, impl Into<String>)>>(
         mut self,
@@ -138,17 +143,22 @@
     /// Build the ObjectStore implementation for Azure.
     #[cfg(feature = "azure")]
     pub fn build_azure(&self, container_name: &str) -> PolarsResult<impl ObjectStore> {
         let options = self
             .azure
             .as_ref()
             .ok_or_else(|| polars_err!(ComputeError: "`azure` configuration missing"))?;
-        MicrosoftAzureBuilder::new()
-            .try_with_options(options.clone().into_iter())
-            .and_then(|b| b.with_container_name(container_name).build())
+
+        let mut builder = MicrosoftAzureBuilder::new();
+        for (key, value) in options.iter() {
+            builder = builder.with_config(*key, value);
+        }
+        builder
+            .with_container_name(container_name)
+            .build()
             .map_err(polars_error::to_compute_err)
     }
 
     /// Set the configuration for GCP connections. This is the preferred API from rust.
     #[cfg(feature = "gcp")]
     pub fn with_gcp<I: IntoIterator<Item = (GoogleConfigKey, impl Into<String>)>>(
         mut self,
@@ -166,17 +176,22 @@
     /// Build the ObjectStore implementation for GCP.
     #[cfg(feature = "gcp")]
     pub fn build_gcp(&self, bucket_name: &str) -> PolarsResult<impl ObjectStore> {
         let options = self
             .gcp
             .as_ref()
             .ok_or_else(|| polars_err!(ComputeError: "`gcp` configuration missing"))?;
-        GoogleCloudStorageBuilder::new()
-            .try_with_options(options.clone().into_iter())
-            .and_then(|b| b.with_bucket_name(bucket_name).build())
+
+        let mut builder = GoogleCloudStorageBuilder::new();
+        for (key, value) in options.iter() {
+            builder = builder.with_config(*key, value);
+        }
+        builder
+            .with_bucket_name(bucket_name)
+            .build()
             .map_err(polars_error::to_compute_err)
     }
 
     /// Parse a configuration from a Hashmap. This is the interface from Python.
     #[allow(unused_variables)]
     pub fn from_untyped_config<I: IntoIterator<Item = (impl AsRef<str>, impl Into<String>)>>(
         url: &str,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/config.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/config.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/datatypes/_serde.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/datatypes/_serde.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/datatypes/aliases.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/datatypes/aliases.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/datatypes/any_value.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/datatypes/any_value.rs`

 * *Files 0% similar despite different names*

```diff
@@ -371,15 +371,14 @@
             StructOwned(payload) => DataType::Struct(payload.1.clone()),
             Binary(_) => DataType::Binary,
             _ => unimplemented!(),
         }
     }
     /// Extract a numerical value from the AnyValue
     #[doc(hidden)]
-    #[cfg(feature = "private")]
     #[inline]
     pub fn extract<T: NumCast>(&self) -> Option<T> {
         use AnyValue::*;
         match self {
             Int8(v) => NumCast::from(*v),
             Int16(v) => NumCast::from(*v),
             Int32(v) => NumCast::from(*v),
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/datatypes/dtype.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/datatypes/dtype.rs`

 * *Files 2% similar despite different names*

```diff
@@ -156,15 +156,15 @@
 
     /// Check if datatype is a primitive type. By that we mean that
     /// it is not a container type.
     pub fn is_primitive(&self) -> bool {
         self.is_numeric() | matches!(self, DataType::Boolean | DataType::Utf8 | DataType::Binary)
     }
 
-    /// Check if this [`DataType`] is a numeric type
+    /// Check if this [`DataType`] is a numeric type.
     pub fn is_numeric(&self) -> bool {
         // allow because it cannot be replaced when object feature is activated
         #[allow(clippy::match_like_matches_macro)]
         match self {
             DataType::Utf8
             | DataType::List(_)
             | DataType::Date
@@ -177,14 +177,16 @@
             DataType::Binary => false,
             #[cfg(feature = "object")]
             DataType::Object(_) => false,
             #[cfg(feature = "dtype-categorical")]
             DataType::Categorical(_) => false,
             #[cfg(feature = "dtype-struct")]
             DataType::Struct(_) => false,
+            #[cfg(feature = "dtype-decimal")]
+            DataType::Decimal(_, _) => false,
             _ => true,
         }
     }
 
     pub fn is_float(&self) -> bool {
         matches!(self, DataType::Float32 | DataType::Float64)
     }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/datatypes/field.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/datatypes/field.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/datatypes/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/datatypes/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/datatypes/time_unit.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/datatypes/time_unit.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/doc/changelog/v0_10_0_11.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/doc/changelog/v0_10_0_11.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/doc/changelog/v0_7.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/doc/changelog/v0_7.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/doc/changelog/v0_8.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/doc/changelog/v0_8.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/doc/changelog/v0_9.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/doc/changelog/v0_9.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/fmt.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/fmt.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/arithmetic.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/arithmetic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/asof_join/asof.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/asof_join/asof.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/asof_join/groups.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/asof_join/groups.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/asof_join/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/asof_join/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/chunks.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/chunks.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/cross_join.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/cross_join.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/explode.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/explode.rs`

 * *Files 0% similar despite different names*

```diff
@@ -11,14 +11,16 @@
 use crate::utils::try_get_supertype;
 use crate::POOL;
 
 fn get_exploded(series: &Series) -> PolarsResult<(Series, OffsetsBuffer<i64>)> {
     match series.dtype() {
         DataType::List(_) => series.list().unwrap().explode_and_offsets(),
         DataType::Utf8 => series.utf8().unwrap().explode_and_offsets(),
+        #[cfg(feature = "dtype-array")]
+        DataType::Array(_, _) => series.array().unwrap().explode_and_offsets(),
         _ => polars_bail!(opq = explode, series.dtype()),
     }
 }
 
 /// Arguments for `[DataFrame::melt]` function
 #[derive(Clone, Default, Debug, PartialEq)]
 #[cfg_attr(feature = "serde-lazy", derive(Serialize, Deserialize))]
@@ -294,15 +296,15 @@
 
         // The column name of the variable that is melted
         let mut variable_col = MutableUtf8Array::<i64>::with_capacities(
             len * value_vars.len() + 1,
             len * values_len + 1,
         );
         // prepare ids
-        let ids_ = self.select(id_vars)?;
+        let ids_ = self.select_with_schema_unchecked(id_vars, &schema)?;
         let mut ids = ids_.clone();
         if ids.width() > 0 {
             for _ in 0..value_vars.len() - 1 {
                 ids.vstack_mut_unchecked(&ids_)
             }
         }
         ids.as_single_chunk_par();
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/from.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/from.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/aggregations/agg_list.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/aggregations/agg_list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/aggregations/boolean.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/aggregations/boolean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/aggregations/dispatch.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/aggregations/dispatch.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/aggregations/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/aggregations/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -11,14 +11,15 @@
 use num_traits::{Bounded, Num, NumCast, ToPrimitive, Zero};
 use polars_arrow::data_types::IsFloat;
 use polars_arrow::kernels::rolling;
 use polars_arrow::kernels::rolling::no_nulls::{
     MaxWindow, MeanWindow, MinWindow, RollingAggWindowNoNulls, StdWindow, SumWindow, VarWindow,
 };
 use polars_arrow::kernels::rolling::nulls::RollingAggWindowNulls;
+use polars_arrow::kernels::rolling::{DynArgs, RollingVarParams};
 use polars_arrow::kernels::take_agg::*;
 use polars_arrow::prelude::QuantileInterpolOptions;
 use polars_arrow::trusted_len::PushUnchecked;
 use rayon::prelude::*;
 
 #[cfg(feature = "object")]
 use crate::chunked_array::object::extension::create_extension;
@@ -53,14 +54,15 @@
 }
 
 // Use an aggregation window that maintains the state
 pub fn _rolling_apply_agg_window_nulls<'a, Agg, T, O>(
     values: &'a [T],
     validity: &'a Bitmap,
     offsets: O,
+    params: DynArgs,
 ) -> ArrayRef
 where
     O: Iterator<Item = (IdxSize, IdxSize)> + TrustedLen,
     Agg: RollingAggWindowNulls<'a, T>,
     T: IsFloat + NativeType,
 {
     if values.is_empty() {
@@ -70,15 +72,15 @@
 
     // This iterators length can be trusted
     // these represent the number of groups in the groupby operation
     let output_len = offsets.size_hint().0;
     // start with a dummy index, will be overwritten on first iteration.
     // Safety:
     // we are in bounds
-    let mut agg_window = unsafe { Agg::new(values, validity, 0, 0) };
+    let mut agg_window = unsafe { Agg::new(values, validity, 0, 0, params) };
 
     let mut validity = MutableBitmap::with_capacity(output_len);
     validity.extend_constant(output_len, true);
 
     let out = offsets
         .enumerate()
         .map(|(idx, (start, len))| {
@@ -108,27 +110,31 @@
         T::PRIMITIVE.into(),
         out.into(),
         Some(validity.into()),
     ))
 }
 
 // Use an aggregation window that maintains the state
-pub fn _rolling_apply_agg_window_no_nulls<'a, Agg, T, O>(values: &'a [T], offsets: O) -> ArrayRef
+pub fn _rolling_apply_agg_window_no_nulls<'a, Agg, T, O>(
+    values: &'a [T],
+    offsets: O,
+    params: DynArgs,
+) -> ArrayRef
 where
     // items (offset, len) -> so offsets are offset, offset + len
     Agg: RollingAggWindowNoNulls<'a, T>,
     O: Iterator<Item = (IdxSize, IdxSize)> + TrustedLen,
     T: IsFloat + NativeType,
 {
     if values.is_empty() {
         let out: Vec<T> = vec![];
         return Box::new(PrimitiveArray::new(T::PRIMITIVE.into(), out.into(), None));
     }
     // start with a dummy index, will be overwritten on first iteration.
-    let mut agg_window = Agg::new(values, 0, 0);
+    let mut agg_window = Agg::new(values, 0, 0, params);
 
     let out = offsets
         .map(|(start, len)| {
             let end = start + len;
 
             if start == end {
                 None
@@ -413,20 +419,23 @@
                     let arr = self.downcast_iter().next().unwrap();
                     let values = arr.values().as_slice();
                     let offset_iter = groups_slice.iter().map(|[first, len]| (*first, *len));
                     let arr = match arr.validity() {
                         None => _rolling_apply_agg_window_no_nulls::<MinWindow<_>, _, _>(
                             values,
                             offset_iter,
+                            None,
                         ),
                         Some(validity) => _rolling_apply_agg_window_nulls::<
                             rolling::nulls::MinWindow<_>,
                             _,
                             _,
-                        >(values, validity, offset_iter),
+                        >(
+                            values, validity, offset_iter, None
+                        ),
                     };
                     Self::from_chunks("", vec![arr]).into_series()
                 } else {
                     _agg_helper_slice::<T, _>(groups_slice, |[first, len]| {
                         debug_assert!(len <= self.len() as IdxSize);
                         match len {
                             0 => None,
@@ -493,20 +502,23 @@
                     let arr = self.downcast_iter().next().unwrap();
                     let values = arr.values().as_slice();
                     let offset_iter = groups_slice.iter().map(|[first, len]| (*first, *len));
                     let arr = match arr.validity() {
                         None => _rolling_apply_agg_window_no_nulls::<MaxWindow<_>, _, _>(
                             values,
                             offset_iter,
+                            None,
                         ),
                         Some(validity) => _rolling_apply_agg_window_nulls::<
                             rolling::nulls::MaxWindow<_>,
                             _,
                             _,
-                        >(values, validity, offset_iter),
+                        >(
+                            values, validity, offset_iter, None
+                        ),
                     };
                     Self::from_chunks("", vec![arr]).into_series()
                 } else {
                     _agg_helper_slice::<T, _>(groups_slice, |[first, len]| {
                         debug_assert!(len <= self.len() as IdxSize);
                         match len {
                             0 => None,
@@ -557,20 +569,23 @@
                     let arr = self.downcast_iter().next().unwrap();
                     let values = arr.values().as_slice();
                     let offset_iter = groups.iter().map(|[first, len]| (*first, *len));
                     let arr = match arr.validity() {
                         None => _rolling_apply_agg_window_no_nulls::<SumWindow<_>, _, _>(
                             values,
                             offset_iter,
+                            None,
                         ),
                         Some(validity) => _rolling_apply_agg_window_nulls::<
                             rolling::nulls::SumWindow<_>,
                             _,
                             _,
-                        >(values, validity, offset_iter),
+                        >(
+                            values, validity, offset_iter, None
+                        ),
                     };
                     Self::from_chunks("", vec![arr]).into_series()
                 } else {
                     _agg_helper_slice::<T, _>(groups, |[first, len]| {
                         debug_assert!(len <= self.len() as IdxSize);
                         match len {
                             0 => None,
@@ -648,20 +663,23 @@
                     let arr = self.downcast_iter().next().unwrap();
                     let values = arr.values().as_slice();
                     let offset_iter = groups.iter().map(|[first, len]| (*first, *len));
                     let arr = match arr.validity() {
                         None => _rolling_apply_agg_window_no_nulls::<MeanWindow<_>, _, _>(
                             values,
                             offset_iter,
+                            None,
                         ),
                         Some(validity) => _rolling_apply_agg_window_nulls::<
                             rolling::nulls::MeanWindow<_>,
                             _,
                             _,
-                        >(values, validity, offset_iter),
+                        >(
+                            values, validity, offset_iter, None
+                        ),
                     };
                     ChunkedArray::<T>::from_chunks("", vec![arr]).into_series()
                 } else {
                     _agg_helper_slice::<T, _>(groups, |[first, len]| {
                         debug_assert!(len <= self.len() as IdxSize);
                         match len {
                             0 => None,
@@ -673,15 +691,18 @@
                         }
                     })
                 }
             }
         }
     }
 
-    pub(crate) unsafe fn agg_var(&self, groups: &GroupsProxy, ddof: u8) -> Series {
+    pub(crate) unsafe fn agg_var(&self, groups: &GroupsProxy, ddof: u8) -> Series
+    where
+        <T as datatypes::PolarsNumericType>::Native: num_traits::Float,
+    {
         let ca = &self.0.rechunk();
         match groups {
             GroupsProxy::Idx(groups) => {
                 let ca = ca.rechunk();
                 let arr = ca.downcast_iter().next().unwrap();
                 let no_nulls = arr.null_count() == 0;
                 agg_helper_idx_on_all::<T, _>(groups, |idx| {
@@ -702,20 +723,24 @@
                     let arr = self.downcast_iter().next().unwrap();
                     let values = arr.values().as_slice();
                     let offset_iter = groups.iter().map(|[first, len]| (*first, *len));
                     let arr = match arr.validity() {
                         None => _rolling_apply_agg_window_no_nulls::<VarWindow<_>, _, _>(
                             values,
                             offset_iter,
+                            Some(Arc::new(RollingVarParams { ddof })),
                         ),
-                        Some(validity) => _rolling_apply_agg_window_nulls::<
-                            rolling::nulls::VarWindow<_>,
-                            _,
-                            _,
-                        >(values, validity, offset_iter),
+                        Some(validity) => {
+                            _rolling_apply_agg_window_nulls::<rolling::nulls::VarWindow<_>, _, _>(
+                                values,
+                                validity,
+                                offset_iter,
+                                Some(Arc::new(RollingVarParams { ddof })),
+                            )
+                        }
                     };
                     ChunkedArray::<T>::from_chunks("", vec![arr]).into_series()
                 } else {
                     _agg_helper_slice::<T, _>(groups, |[first, len]| {
                         debug_assert!(len <= self.len() as IdxSize);
                         match len {
                             0 => None,
@@ -726,15 +751,18 @@
                             }
                         }
                     })
                 }
             }
         }
     }
-    pub(crate) unsafe fn agg_std(&self, groups: &GroupsProxy, ddof: u8) -> Series {
+    pub(crate) unsafe fn agg_std(&self, groups: &GroupsProxy, ddof: u8) -> Series
+    where
+        <T as datatypes::PolarsNumericType>::Native: num_traits::Float,
+    {
         let ca = &self.0.rechunk();
         match groups {
             GroupsProxy::Idx(groups) => {
                 let arr = self.downcast_iter().next().unwrap();
                 let no_nulls = arr.null_count() == 0;
                 agg_helper_idx_on_all::<T, _>(groups, |idx| {
                     debug_assert!(idx.len() <= ca.len());
@@ -754,20 +782,24 @@
                     let arr = self.downcast_iter().next().unwrap();
                     let values = arr.values().as_slice();
                     let offset_iter = groups.iter().map(|[first, len]| (*first, *len));
                     let arr = match arr.validity() {
                         None => _rolling_apply_agg_window_no_nulls::<StdWindow<_>, _, _>(
                             values,
                             offset_iter,
+                            Some(Arc::new(RollingVarParams { ddof })),
                         ),
-                        Some(validity) => _rolling_apply_agg_window_nulls::<
-                            rolling::nulls::StdWindow<_>,
-                            _,
-                            _,
-                        >(values, validity, offset_iter),
+                        Some(validity) => {
+                            _rolling_apply_agg_window_nulls::<rolling::nulls::StdWindow<_>, _, _>(
+                                values,
+                                validity,
+                                offset_iter,
+                                Some(Arc::new(RollingVarParams { ddof })),
+                            )
+                        }
                     };
                     ChunkedArray::<T>::from_chunks("", vec![arr]).into_series()
                 } else {
                     _agg_helper_slice::<T, _>(groups, |[first, len]| {
                         debug_assert!(len <= self.len() as IdxSize);
                         match len {
                             0 => None,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/aggregations/utf8.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/aggregations/utf8.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/hashing.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/hashing.rs`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 use std::hash::{BuildHasher, Hash};
 
 use hashbrown::hash_map::{Entry, RawEntryMut};
 use hashbrown::HashMap;
 use polars_utils::iter::EnumerateIdxTrait;
 use polars_utils::sync::SyncPtr;
-use polars_utils::HashSingle;
 use rayon::prelude::*;
 
 use super::GroupsProxy;
 use crate::datatypes::PlHashMap;
 use crate::frame::groupby::{GroupsIdx, IdxItem};
 use crate::hashing::{
     df_rows_to_hashes_threaded_vertical, series_to_hashes, this_partition, AsU64, IdBuildHasher,
@@ -215,22 +214,22 @@
 
                     let mut cnt = 0;
                     keys.iter().for_each(|k| {
                         let idx = cnt + offset;
                         cnt += 1;
 
                         if this_partition(k.as_u64(), thread_no, n_partitions) {
-                            let hash = hasher.hash_single(k);
+                            let hash = hasher.hash_one(k);
                             let entry = hash_tbl.raw_entry_mut().from_key_hashed_nocheck(hash, k);
 
                             match entry {
                                 RawEntryMut::Vacant(entry) => {
                                     let tuples = vec![idx];
                                     entry.insert_with_hasher(hash, *k, (idx, tuples), |k| {
-                                        hasher.hash_single(k)
+                                        hasher.hash_one(k)
                                     });
                                 }
                                 RawEntryMut::Occupied(mut entry) => {
                                     let v = entry.get_mut();
                                     v.1.push(idx);
                                 }
                             }
@@ -279,22 +278,22 @@
 
                     let mut cnt = 0;
                     keys.for_each(|k| {
                         let idx = cnt + offset;
                         cnt += 1;
 
                         if this_partition(k.as_u64(), thread_no, n_partitions) {
-                            let hash = hasher.hash_single(k);
+                            let hash = hasher.hash_one(k);
                             let entry = hash_tbl.raw_entry_mut().from_key_hashed_nocheck(hash, &k);
 
                             match entry {
                                 RawEntryMut::Vacant(entry) => {
                                     let tuples = vec![idx];
                                     entry.insert_with_hasher(hash, k, (idx, tuples), |k| {
-                                        hasher.hash_single(k)
+                                        hasher.hash_one(k)
                                     });
                                 }
                                 RawEntryMut::Occupied(mut entry) => {
                                     let v = entry.get_mut();
                                     v.1.push(idx);
                                 }
                             }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/into_groups.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/into_groups.rs`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 #[cfg(feature = "groupby_list")]
 use polars_arrow::kernels::list_bytes_iter::numeric_list_bytes_iter;
 use polars_arrow::kernels::sort_partition::{create_clean_partitions, partition_to_groups};
 use polars_arrow::prelude::*;
-use polars_utils::HashSingle;
 
 use super::*;
 use crate::config::verbose;
 use crate::utils::_split_offsets;
 use crate::utils::flatten::flatten_par;
 
 /// Used to create the tuples for a groupby operation.
@@ -252,15 +251,15 @@
                 split
                     .into_par_iter()
                     .map(|(offset, len)| {
                         let ca = self.slice(offset as i64, len);
                         ca.into_iter()
                             .map(|opt_b| {
                                 let hash = match opt_b {
-                                    Some(s) => hb.hash_single(s),
+                                    Some(s) => hb.hash_one(s),
                                     None => null_h,
                                 };
                                 // Safety:
                                 // the underlying data is tied to self
                                 unsafe {
                                     std::mem::transmute::<BytesHash<'_>, BytesHash<'a>>(
                                         BytesHash::new(opt_b, hash),
@@ -274,15 +273,15 @@
             let byte_hashes = byte_hashes.iter().collect::<Vec<_>>();
             groupby_threaded_slice(byte_hashes, n_partitions as u64, sorted)
         } else {
             let byte_hashes = self
                 .into_iter()
                 .map(|opt_b| {
                     let hash = match opt_b {
-                        Some(s) => hb.hash_single(s),
+                        Some(s) => hb.hash_one(s),
                         None => null_h,
                     };
                     BytesHash::new(opt_b, hash)
                 })
                 .collect_trusted::<Vec<_>>();
             groupby(byte_hashes.iter(), sorted)
         };
@@ -306,15 +305,15 @@
 
             let arr_to_hashes = |ca: &ListChunked| {
                 let mut out = Vec::with_capacity(ca.len());
 
                 for arr in ca.downcast_iter() {
                     out.extend(numeric_list_bytes_iter(arr)?.map(|opt_bytes| {
                         let hash = match opt_bytes {
-                            Some(s) => hb.hash_single(s),
+                            Some(s) => hb.hash_one(s),
                             None => null_h,
                         };
 
                         // Safety:
                         // the underlying data is tied to self
                         unsafe {
                             std::mem::transmute::<BytesHash<'_>, BytesHash<'a>>(BytesHash::new(
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/mod.rs`

 * *Files 0% similar despite different names*

```diff
@@ -217,23 +217,23 @@
                 .collect(),
         );
         self
     }
 
     /// Get the internal representation of the GroupBy operation.
     /// The Vec returned contains:
-    ///     (first_idx, Vec<indexes>)
+    ///     (first_idx, [`Vec<indexes>`])
     ///     Where second value in the tuple is a vector with all matching indexes.
     pub fn get_groups(&self) -> &GroupsProxy {
         &self.groups
     }
 
     /// Get the internal representation of the GroupBy operation.
     /// The Vec returned contains:
-    ///     (first_idx, Vec<indexes>)
+    ///     (first_idx, [`Vec<indexes>`])
     ///     Where second value in the tuple is a vector with all matching indexes.
     ///
     /// # Safety
     /// Groups should always be in bounds of the `DataFrame` hold by this `[GroupBy]`.
     /// If you mutate it, you must hold that invariant.
     pub unsafe fn get_groups_mut(&mut self) -> &mut GroupsProxy {
         &mut self.groups
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/perfect.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/perfect.rs`

 * *Files 2% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 use num_traits::FromPrimitive;
 use polars_arrow::bit_util::round_upto_multiple_of_64;
 use polars_utils::slice::GetSaferUnchecked;
 use polars_utils::sync::SyncPtr;
 use polars_utils::IdxSize;
 use rayon::prelude::*;
 
-#[cfg(feature = "dtype-categorical")]
+#[cfg(all(feature = "dtype-categorical", feature = "performant"))]
 use crate::config::verbose;
 use crate::datatypes::*;
 use crate::hashing::AsU64;
 use crate::prelude::*;
 use crate::POOL;
 
 impl<T> ChunkedArray<T>
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/groupby/proxy.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/groupby/proxy.rs`

 * *Files 0% similar despite different names*

```diff
@@ -304,15 +304,14 @@
 impl Default for GroupsProxy {
     fn default() -> Self {
         GroupsProxy::Idx(GroupsIdx::default())
     }
 }
 
 impl GroupsProxy {
-    #[cfg(feature = "private")]
     pub fn into_idx(self) -> GroupsIdx {
         match self {
             GroupsProxy::Idx(groups) => groups,
             GroupsProxy::Slice { groups, .. } => {
                 eprintln!("Had to reallocate groups, missed an optimization opportunity. Please open an issue.");
                 groups
                     .iter()
@@ -322,15 +321,14 @@
         }
     }
 
     pub fn iter(&self) -> GroupsProxyIter {
         GroupsProxyIter::new(self)
     }
 
-    #[cfg(feature = "private")]
     pub fn sort(&mut self) {
         match self {
             GroupsProxy::Idx(groups) => {
                 if !groups.is_sorted_flag() {
                     groups.sort()
                 }
             }
@@ -365,15 +363,14 @@
             GroupsProxy::Idx(mut groups) => std::mem::take(&mut groups.first),
             GroupsProxy::Slice { groups, .. } => {
                 groups.into_iter().map(|[first, _len]| first).collect()
             }
         }
     }
 
-    #[cfg(feature = "private")]
     pub fn par_iter(&self) -> GroupsProxyParIter {
         GroupsProxyParIter::new(self)
     }
 
     /// Get a reference to the `GroupsIdx`.
     ///
     /// # Panic
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/mod.rs`

 * *Files 5% similar despite different names*

```diff
@@ -1,7 +1,8 @@
+mod args;
 pub(crate) mod multiple_keys;
 pub(super) mod single_keys;
 mod single_keys_dispatch;
 mod single_keys_inner;
 mod single_keys_left;
 mod single_keys_outer;
 #[cfg(feature = "semi_anti_join")]
@@ -9,14 +10,15 @@
 pub(super) mod sort_merge;
 mod zip_outer;
 
 use std::fmt::{Debug, Display, Formatter};
 use std::hash::{BuildHasher, Hash, Hasher};
 
 use ahash::RandomState;
+pub use args::*;
 #[cfg(feature = "chunked_ids")]
 use arrow::Either;
 use hashbrown::hash_map::{Entry, RawEntryMut};
 use hashbrown::HashMap;
 use polars_arrow::utils::CustomIterTools;
 use rayon::prelude::*;
 #[cfg(feature = "serde")]
@@ -28,15 +30,14 @@
 use single_keys_left::*;
 use single_keys_outer::*;
 #[cfg(feature = "semi_anti_join")]
 use single_keys_semi_anti::*;
 pub use sort_merge::*;
 pub(crate) use zip_outer::*;
 
-#[cfg(feature = "private")]
 pub use self::multiple_keys::private_left_join_multiple_keys;
 use crate::datatypes::PlHashMap;
 use crate::frame::groupby::hashing::HASHMAP_INIT_SIZE;
 pub use crate::frame::hash_join::multiple_keys::{
     _inner_join_multiple_keys, _left_join_multiple_keys, _outer_join_multiple_keys,
 };
 #[cfg(feature = "semi_anti_join")]
@@ -47,31 +48,15 @@
     create_hash_and_keys_threaded_vectorized, prepare_hashed_relation_threaded, this_partition,
     AsU64, BytesHash,
 };
 use crate::prelude::*;
 use crate::utils::{_set_partition_size, slice_slice, split_ca};
 use crate::POOL;
 
-pub type LeftJoinIds = (JoinIds, JoinOptIds);
-
-#[cfg(feature = "chunked_ids")]
-pub(super) type JoinIds = Either<Vec<IdxSize>, Vec<ChunkId>>;
-#[cfg(feature = "chunked_ids")]
-pub type JoinOptIds = Either<Vec<Option<IdxSize>>, Vec<Option<ChunkId>>>;
-
-#[cfg(not(feature = "chunked_ids"))]
-pub type JoinOptIds = Vec<Option<IdxSize>>;
-
-#[cfg(not(feature = "chunked_ids"))]
-pub type JoinIds = Vec<IdxSize>;
-
-/// [ChunkIdx, DfIdx]
-pub type ChunkId = [IdxSize; 2];
-
-pub fn default_join_ids() -> JoinOptIds {
+pub fn default_join_ids() -> ChunkJoinOptIds {
     #[cfg(feature = "chunked_ids")]
     {
         Either::Left(vec![])
     }
     #[cfg(not(feature = "chunked_ids"))]
     {
         vec![]
@@ -113,54 +98,14 @@
             ComputeError: "joins/or comparisons on categoricals can only happen if they were \
             created under the same global string cache"
         );
     }
     Ok(())
 }
 
-#[derive(Clone, PartialEq, Eq)]
-#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
-pub enum JoinType {
-    Left,
-    Inner,
-    Outer,
-    #[cfg(feature = "asof_join")]
-    AsOf(AsOfOptions),
-    Cross,
-    #[cfg(feature = "semi_anti_join")]
-    Semi,
-    #[cfg(feature = "semi_anti_join")]
-    Anti,
-}
-
-impl Display for JoinType {
-    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
-        use JoinType::*;
-        let val = match self {
-            Left => "LEFT",
-            Inner => "INNER",
-            Outer => "OUTER",
-            #[cfg(feature = "asof_join")]
-            AsOf(_) => "ASOF",
-            Cross => "CROSS",
-            #[cfg(feature = "semi_anti_join")]
-            Semi => "SEMI",
-            #[cfg(feature = "semi_anti_join")]
-            Anti => "ANTI",
-        };
-        write!(f, "{val}")
-    }
-}
-
-impl Debug for JoinType {
-    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
-        write!(f, "{self}")
-    }
-}
-
 pub(crate) unsafe fn get_hash_tbl_threaded_join_partitioned<Item>(
     h: u64,
     hash_tables: &[Item],
     len: u64,
 ) -> &Item {
     let i = hash_to_partition(h, len as usize);
     hash_tables.get_unchecked(i)
@@ -252,81 +197,81 @@
     }
 
     #[cfg(not(feature = "chunked_ids"))]
     pub fn _finish_left_join(
         &self,
         ids: LeftJoinIds,
         other: &DataFrame,
-        suffix: Option<String>,
-        slice: Option<(i64, usize)>,
+        args: JoinArgs,
     ) -> PolarsResult<DataFrame> {
         let (left_idx, right_idx) = ids;
         let materialize_left = || {
             let mut left_idx = &*left_idx;
-            if let Some((offset, len)) = slice {
+            if let Some((offset, len)) = args.slice {
                 left_idx = slice_slice(left_idx, offset, len);
             }
             unsafe { self._create_left_df_from_slice(left_idx, true, true) }
         };
 
         let materialize_right = || {
             let mut right_idx = &*right_idx;
-            if let Some((offset, len)) = slice {
+            if let Some((offset, len)) = args.slice {
                 right_idx = slice_slice(right_idx, offset, len);
             }
             unsafe {
                 other.take_opt_iter_unchecked(
                     right_idx.iter().map(|opt_i| opt_i.map(|i| i as usize)),
                 )
             }
         };
         let (df_left, df_right) = POOL.join(materialize_left, materialize_right);
 
-        _finish_join(df_left, df_right, suffix.as_deref())
+        _finish_join(df_left, df_right, args.suffix.as_deref())
     }
 
     #[cfg(feature = "chunked_ids")]
     pub fn _finish_left_join(
         &self,
         ids: LeftJoinIds,
         other: &DataFrame,
-        suffix: Option<String>,
-        slice: Option<(i64, usize)>,
+        args: JoinArgs,
     ) -> PolarsResult<DataFrame> {
+        let suffix = &args.suffix;
+        let slice = args.slice;
         let (left_idx, right_idx) = ids;
         let materialize_left = || match left_idx {
-            JoinIds::Left(left_idx) => {
+            ChunkJoinIds::Left(left_idx) => {
                 let mut left_idx = &*left_idx;
                 if let Some((offset, len)) = slice {
                     left_idx = slice_slice(left_idx, offset, len);
                 }
                 unsafe { self._create_left_df_from_slice(left_idx, true, true) }
             }
-            JoinIds::Right(left_idx) => {
+            ChunkJoinIds::Right(left_idx) => {
                 let mut left_idx = &*left_idx;
                 if let Some((offset, len)) = slice {
                     left_idx = slice_slice(left_idx, offset, len);
                 }
                 unsafe { self.create_left_df_chunked(left_idx, true) }
             }
         };
 
         let materialize_right = || match right_idx {
-            JoinOptIds::Left(right_idx) => {
+            ChunkJoinOptIds::Left(right_idx) => {
                 let mut right_idx = &*right_idx;
                 if let Some((offset, len)) = slice {
                     right_idx = slice_slice(right_idx, offset, len);
                 }
                 unsafe {
                     other.take_opt_iter_unchecked(
                         right_idx.iter().map(|opt_i| opt_i.map(|i| i as usize)),
                     )
                 }
             }
-            JoinOptIds::Right(right_idx) => {
+            ChunkJoinOptIds::Right(right_idx) => {
                 let mut right_idx = &*right_idx;
                 if let Some((offset, len)) = slice {
                     right_idx = slice_slice(right_idx, offset, len);
                 }
                 unsafe { other.take_opt_chunked_unchecked(right_idx) }
             }
         };
@@ -336,16 +281,15 @@
     }
 
     pub fn _left_join_from_series(
         &self,
         other: &DataFrame,
         s_left: &Series,
         s_right: &Series,
-        suffix: Option<String>,
-        slice: Option<(i64, usize)>,
+        args: JoinArgs,
         verbose: bool,
     ) -> PolarsResult<DataFrame> {
         #[cfg(feature = "dtype-categorical")]
         _check_categorical_src(s_left.dtype(), s_right.dtype())?;
 
         // ensure that the chunks are aligned otherwise we go OOB
         let mut left = self.clone();
@@ -356,16 +300,16 @@
             left.as_single_chunk_par();
             s_left = s_left.rechunk();
         }
         if right.should_rechunk() {
             right.as_single_chunk_par();
             s_right = s_right.rechunk();
         }
-        let ids = sort_or_hash_left(&s_left, &s_right, verbose);
-        left._finish_left_join(ids, &right.drop(s_right.name()).unwrap(), suffix, slice)
+        let ids = sort_or_hash_left(&s_left, &s_right, verbose, args.validation)?;
+        left._finish_left_join(ids, &right.drop(s_right.name()).unwrap(), args)
     }
 
     #[cfg(feature = "semi_anti_join")]
     /// # Safety
     /// `idx` must be in bounds
     pub unsafe fn _finish_anti_semi_join(
         &self,
@@ -396,28 +340,27 @@
         Ok(unsafe { self._finish_anti_semi_join(&idx, slice) })
     }
     pub fn _outer_join_from_series(
         &self,
         other: &DataFrame,
         s_left: &Series,
         s_right: &Series,
-        suffix: Option<String>,
-        slice: Option<(i64, usize)>,
+        args: JoinArgs,
     ) -> PolarsResult<DataFrame> {
         #[cfg(feature = "dtype-categorical")]
         _check_categorical_src(s_left.dtype(), s_right.dtype())?;
 
         // store this so that we can keep original column order.
         let join_column_index = self.iter().position(|s| s.name() == s_left.name()).unwrap();
 
         // Get the indexes of the joined relations
-        let opt_join_tuples = s_left.hash_join_outer(s_right);
+        let opt_join_tuples = s_left.hash_join_outer(s_right, args.validation)?;
         let mut opt_join_tuples = &*opt_join_tuples;
 
-        if let Some((offset, len)) = slice {
+        if let Some((offset, len)) = args.slice {
             opt_join_tuples = slice_slice(opt_join_tuples, offset, len);
         }
 
         // Take the left and right dataframes by join tuples
         let (mut df_left, df_right) = POOL.join(
             || unsafe {
                 self.drop(s_left.name()).unwrap().take_opt_iter_unchecked(
@@ -456,10 +399,10 @@
             | dt @ DataType::Time
             | dt @ DataType::Date
             | dt @ DataType::Duration(_) => s.cast(dt).unwrap(),
             _ => s,
         };
 
         unsafe { df_left.get_columns_mut().insert(join_column_index, s) };
-        _finish_join(df_left, df_right, suffix.as_deref())
+        _finish_join(df_left, df_right, args.suffix.as_deref())
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/multiple_keys.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/multiple_keys.rs`

 * *Files 1% similar despite different names*

```diff
@@ -236,15 +236,14 @@
 
                 results
             })
             .unzip()
     })
 }
 
-#[cfg(feature = "private")]
 pub fn private_left_join_multiple_keys(
     a: &DataFrame,
     b: &DataFrame,
     // map the global indices to [chunk_idx, array_idx]
     // only needed if we have non contiguous memory
     chunk_mapping_left: Option<&[ChunkId]>,
     chunk_mapping_right: Option<&[ChunkId]>,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/single_keys.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/single_keys.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/single_keys_dispatch.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/single_keys_dispatch.rs`

 * *Files 24% similar despite different names*

```diff
@@ -2,43 +2,47 @@
 
 use super::single_keys_inner::hash_join_tuples_inner;
 use super::*;
 #[cfg(feature = "chunked_ids")]
 use crate::utils::create_chunked_index_mapping;
 
 impl Series {
-    #[cfg(feature = "private")]
     #[doc(hidden)]
-    pub fn hash_join_left(&self, other: &Series) -> LeftJoinIds {
+    pub fn hash_join_left(
+        &self,
+        other: &Series,
+        validate: JoinValidation,
+    ) -> PolarsResult<LeftJoinIds> {
         let (lhs, rhs) = (self.to_physical_repr(), other.to_physical_repr());
+        validate.validate_probe(&lhs, &rhs, false)?;
 
         use DataType::*;
         match lhs.dtype() {
             Utf8 => {
-                let lhs = lhs.cast(&Binary).unwrap();
-                let rhs = rhs.cast(&Binary).unwrap();
+                let lhs = lhs.utf8().unwrap();
+                let rhs = rhs.utf8().unwrap();
 
-                let lhs = lhs.binary().unwrap();
-                let rhs = rhs.binary().unwrap();
-                lhs.hash_join_left(rhs)
+                let lhs = lhs.as_binary();
+                let rhs = rhs.as_binary();
+                lhs.hash_join_left(&rhs, validate)
             }
             Binary => {
                 let lhs = lhs.binary().unwrap();
                 let rhs = rhs.binary().unwrap();
-                lhs.hash_join_left(rhs)
+                lhs.hash_join_left(rhs, validate)
             }
             _ => {
                 if self.bit_repr_is_large() {
                     let lhs = lhs.bit_repr_large();
                     let rhs = rhs.bit_repr_large();
-                    num_group_join_left(&lhs, &rhs)
+                    num_group_join_left(&lhs, &rhs, validate)
                 } else {
                     let lhs = lhs.bit_repr_small();
                     let rhs = rhs.bit_repr_small();
-                    num_group_join_left(&lhs, &rhs)
+                    num_group_join_left(&lhs, &rhs, validate)
                 }
             }
         }
     }
 
     #[cfg(feature = "semi_anti_join")]
     pub(super) fn hash_join_semi_anti(&self, other: &Series, anti: bool) -> Vec<IdxSize> {
@@ -70,76 +74,83 @@
                     num_group_join_anti_semi(&lhs, &rhs, anti)
                 }
             }
         }
     }
 
     // returns the join tuples and whether or not the lhs tuples are sorted
-    pub(super) fn hash_join_inner(&self, other: &Series) -> ((Vec<IdxSize>, Vec<IdxSize>), bool) {
+    pub(super) fn hash_join_inner(
+        &self,
+        other: &Series,
+        validate: JoinValidation,
+    ) -> PolarsResult<(InnerJoinIds, bool)> {
         let (lhs, rhs) = (self.to_physical_repr(), other.to_physical_repr());
+        validate.validate_probe(&lhs, &rhs, true)?;
 
         use DataType::*;
         match lhs.dtype() {
             Utf8 => {
-                let lhs = lhs.cast(&Binary).unwrap();
-                let rhs = rhs.cast(&Binary).unwrap();
+                let lhs = lhs.utf8().unwrap();
+                let rhs = rhs.utf8().unwrap();
 
-                let lhs = lhs.binary().unwrap();
-                let rhs = rhs.binary().unwrap();
-                lhs.hash_join_inner(rhs)
+                let lhs = lhs.as_binary();
+                let rhs = rhs.as_binary();
+                lhs.hash_join_inner(&rhs, validate)
             }
             Binary => {
                 let lhs = lhs.binary().unwrap();
                 let rhs = rhs.binary().unwrap();
-                lhs.hash_join_inner(rhs)
+                lhs.hash_join_inner(rhs, validate)
             }
             _ => {
                 if self.bit_repr_is_large() {
                     let lhs = self.bit_repr_large();
                     let rhs = other.bit_repr_large();
-                    num_group_join_inner(&lhs, &rhs)
+                    num_group_join_inner(&lhs, &rhs, validate)
                 } else {
                     let lhs = self.bit_repr_small();
                     let rhs = other.bit_repr_small();
-                    num_group_join_inner(&lhs, &rhs)
+                    num_group_join_inner(&lhs, &rhs, validate)
                 }
             }
         }
     }
 
     pub(super) fn hash_join_outer(
         &self,
         other: &Series,
-    ) -> Vec<(Option<IdxSize>, Option<IdxSize>)> {
+        validate: JoinValidation,
+    ) -> PolarsResult<Vec<(Option<IdxSize>, Option<IdxSize>)>> {
         let (lhs, rhs) = (self.to_physical_repr(), other.to_physical_repr());
+        validate.validate_probe(&lhs, &rhs, true)?;
 
         use DataType::*;
         match lhs.dtype() {
             Utf8 => {
-                let lhs = lhs.cast(&Binary).unwrap();
-                let rhs = rhs.cast(&Binary).unwrap();
+                let lhs = lhs.utf8().unwrap();
+                let rhs = rhs.utf8().unwrap();
 
-                let lhs = lhs.binary().unwrap();
-                let rhs = rhs.binary().unwrap();
-                lhs.hash_join_outer(rhs)
+                let lhs = lhs.as_binary();
+                let rhs = rhs.as_binary();
+                lhs.hash_join_outer(&rhs, validate)
             }
             Binary => {
                 let lhs = lhs.binary().unwrap();
                 let rhs = rhs.binary().unwrap();
-                lhs.hash_join_outer(rhs)
+                lhs.hash_join_outer(rhs, validate)
             }
             _ => {
                 if self.bit_repr_is_large() {
                     let lhs = self.bit_repr_large();
                     let rhs = other.bit_repr_large();
-                    lhs.hash_join_outer(&rhs)
+                    lhs.hash_join_outer(&rhs, validate)
                 } else {
                     let lhs = self.bit_repr_small();
                     let rhs = other.bit_repr_small();
-                    lhs.hash_join_outer(&rhs)
+                    lhs.hash_join_outer(&rhs, validate)
                 }
             }
         }
     }
 }
 
 fn splitted_to_slice<T>(splitted: &[ChunkedArray<T>]) -> Vec<&[T::Native]>
@@ -171,15 +182,16 @@
     })
 }
 
 // returns the join tuples and whether or not the lhs tuples are sorted
 fn num_group_join_inner<T>(
     left: &ChunkedArray<T>,
     right: &ChunkedArray<T>,
-) -> ((Vec<IdxSize>, Vec<IdxSize>), bool)
+    validate: JoinValidation,
+) -> PolarsResult<(InnerJoinIds, bool)>
 where
     T: PolarsIntegerType,
     T::Native: Hash + Eq + Send + AsU64 + Copy,
     Option<T::Native>: AsU64,
 {
     let n_threads = POOL.current_num_threads();
     let (a, b, swap) = det_hash_prone_order!(left, right);
@@ -190,25 +202,34 @@
         right.null_count() == 0,
         left.chunks.len(),
         right.chunks.len(),
     ) {
         (true, true, 1, 1) => {
             let keys_a = splitted_to_slice(&splitted_a);
             let keys_b = splitted_to_slice(&splitted_b);
-            (hash_join_tuples_inner(keys_a, keys_b, swap), !swap)
+            Ok((
+                hash_join_tuples_inner(keys_a, keys_b, swap, validate)?,
+                !swap,
+            ))
         }
         (true, true, _, _) => {
             let keys_a = splitted_by_chunks(&splitted_a);
             let keys_b = splitted_by_chunks(&splitted_b);
-            (hash_join_tuples_inner(keys_a, keys_b, swap), !swap)
+            Ok((
+                hash_join_tuples_inner(keys_a, keys_b, swap, validate)?,
+                !swap,
+            ))
         }
         _ => {
             let keys_a = splitted_to_opt_vec(&splitted_a);
             let keys_b = splitted_to_opt_vec(&splitted_b);
-            (hash_join_tuples_inner(keys_a, keys_b, swap), !swap)
+            Ok((
+                hash_join_tuples_inner(keys_a, keys_b, swap, validate)?,
+                !swap,
+            ))
         }
     }
 }
 
 #[cfg(feature = "chunked_ids")]
 fn create_mappings(
     chunks_left: &[ArrayRef],
@@ -241,15 +262,19 @@
     _chunks_right: &[ArrayRef],
     _left_len: usize,
     _right_len: usize,
 ) -> (Option<Vec<ChunkId>>, Option<Vec<ChunkId>>) {
     (None, None)
 }
 
-fn num_group_join_left<T>(left: &ChunkedArray<T>, right: &ChunkedArray<T>) -> LeftJoinIds
+fn num_group_join_left<T>(
+    left: &ChunkedArray<T>,
+    right: &ChunkedArray<T>,
+    validate: JoinValidation,
+) -> PolarsResult<LeftJoinIds>
 where
     T: PolarsIntegerType,
     T::Native: Hash + Eq + Send + AsU64,
     Option<T::Native>: AsU64,
 {
     let n_threads = POOL.current_num_threads();
     let splitted_a = split_ca(left, n_threads).unwrap();
@@ -259,50 +284,56 @@
         right.null_count(),
         left.chunks.len(),
         right.chunks.len(),
     ) {
         (0, 0, 1, 1) => {
             let keys_a = splitted_to_slice(&splitted_a);
             let keys_b = splitted_to_slice(&splitted_b);
-            hash_join_tuples_left(keys_a, keys_b, None, None)
+            hash_join_tuples_left(keys_a, keys_b, None, None, validate)
         }
         (0, 0, _, _) => {
             let keys_a = splitted_by_chunks(&splitted_a);
             let keys_b = splitted_by_chunks(&splitted_b);
 
             let (mapping_left, mapping_right) =
                 create_mappings(left.chunks(), right.chunks(), left.len(), right.len());
             hash_join_tuples_left(
                 keys_a,
                 keys_b,
                 mapping_left.as_deref(),
                 mapping_right.as_deref(),
+                validate,
             )
         }
         _ => {
             let keys_a = splitted_to_opt_vec(&splitted_a);
             let keys_b = splitted_to_opt_vec(&splitted_b);
             let (mapping_left, mapping_right) =
                 create_mappings(left.chunks(), right.chunks(), left.len(), right.len());
             hash_join_tuples_left(
                 keys_a,
                 keys_b,
                 mapping_left.as_deref(),
                 mapping_right.as_deref(),
+                validate,
             )
         }
     }
 }
 
 impl<T> ChunkedArray<T>
 where
     T: PolarsIntegerType + Sync,
     T::Native: Eq + Hash + NumCast,
 {
-    fn hash_join_outer(&self, other: &ChunkedArray<T>) -> Vec<(Option<IdxSize>, Option<IdxSize>)> {
+    fn hash_join_outer(
+        &self,
+        other: &ChunkedArray<T>,
+        validate: JoinValidation,
+    ) -> PolarsResult<Vec<(Option<IdxSize>, Option<IdxSize>)>> {
         let (a, b, swap) = det_hash_prone_order!(self, other);
 
         let n_partitions = _set_partition_size();
         let splitted_a = split_ca(a, n_partitions).unwrap();
         let splitted_b = split_ca(b, n_partitions).unwrap();
 
         match (a.null_count(), b.null_count()) {
@@ -311,26 +342,26 @@
                     .iter()
                     .map(|ca| ca.into_no_null_iter())
                     .collect::<Vec<_>>();
                 let iters_b = splitted_b
                     .iter()
                     .map(|ca| ca.into_no_null_iter())
                     .collect::<Vec<_>>();
-                hash_join_tuples_outer(iters_a, iters_b, swap)
+                hash_join_tuples_outer(iters_a, iters_b, swap, validate)
             }
             _ => {
                 let iters_a = splitted_a
                     .iter()
                     .map(|ca| ca.into_iter())
                     .collect::<Vec<_>>();
                 let iters_b = splitted_b
                     .iter()
                     .map(|ca| ca.into_iter())
                     .collect::<Vec<_>>();
-                hash_join_tuples_outer(iters_a, iters_b, swap)
+                hash_join_tuples_outer(iters_a, iters_b, swap, validate)
             }
         }
     }
 }
 
 pub(crate) fn prepare_bytes<'a>(
     been_split: &'a [BinaryChunked],
@@ -371,36 +402,45 @@
         let splitted_a = split_ca(a, n_threads).unwrap();
         let splitted_b = split_ca(b, n_threads).unwrap();
 
         (splitted_a, splitted_b, swap, hb)
     }
 
     // returns the join tuples and whether or not the lhs tuples are sorted
-    fn hash_join_inner(&self, other: &BinaryChunked) -> ((Vec<IdxSize>, Vec<IdxSize>), bool) {
+    fn hash_join_inner(
+        &self,
+        other: &BinaryChunked,
+        validate: JoinValidation,
+    ) -> PolarsResult<(InnerJoinIds, bool)> {
         let (splitted_a, splitted_b, swap, hb) = self.prepare(other, true);
         let str_hashes_a = prepare_bytes(&splitted_a, &hb);
         let str_hashes_b = prepare_bytes(&splitted_b, &hb);
-        (
-            hash_join_tuples_inner(str_hashes_a, str_hashes_b, swap),
+        Ok((
+            hash_join_tuples_inner(str_hashes_a, str_hashes_b, swap, validate)?,
             !swap,
-        )
+        ))
     }
 
-    fn hash_join_left(&self, other: &BinaryChunked) -> LeftJoinIds {
+    fn hash_join_left(
+        &self,
+        other: &BinaryChunked,
+        validate: JoinValidation,
+    ) -> PolarsResult<LeftJoinIds> {
         let (splitted_a, splitted_b, _, hb) = self.prepare(other, false);
         let str_hashes_a = prepare_bytes(&splitted_a, &hb);
         let str_hashes_b = prepare_bytes(&splitted_b, &hb);
 
         let (mapping_left, mapping_right) =
             create_mappings(self.chunks(), other.chunks(), self.len(), other.len());
         hash_join_tuples_left(
             str_hashes_a,
             str_hashes_b,
             mapping_left.as_deref(),
             mapping_right.as_deref(),
+            validate,
         )
     }
 
     #[cfg(feature = "semi_anti_join")]
     fn hash_join_semi_anti(&self, other: &BinaryChunked, anti: bool) -> Vec<IdxSize> {
         let (splitted_a, splitted_b, _, hb) = self.prepare(other, false);
         let str_hashes_a = prepare_bytes(&splitted_a, &hb);
@@ -408,15 +448,19 @@
         if anti {
             hash_join_tuples_left_anti(str_hashes_a, str_hashes_b)
         } else {
             hash_join_tuples_left_semi(str_hashes_a, str_hashes_b)
         }
     }
 
-    fn hash_join_outer(&self, other: &BinaryChunked) -> Vec<(Option<IdxSize>, Option<IdxSize>)> {
+    fn hash_join_outer(
+        &self,
+        other: &BinaryChunked,
+        validate: JoinValidation,
+    ) -> PolarsResult<Vec<(Option<IdxSize>, Option<IdxSize>)>> {
         let (a, b, swap) = det_hash_prone_order!(self, other);
 
         let n_partitions = _set_partition_size();
         let splitted_a = split_ca(a, n_partitions).unwrap();
         let splitted_b = split_ca(b, n_partitions).unwrap();
 
         match (a.has_validity(), b.has_validity()) {
@@ -425,26 +469,26 @@
                     .iter()
                     .map(|ca| ca.into_no_null_iter())
                     .collect::<Vec<_>>();
                 let iters_b = splitted_b
                     .iter()
                     .map(|ca| ca.into_no_null_iter())
                     .collect::<Vec<_>>();
-                hash_join_tuples_outer(iters_a, iters_b, swap)
+                hash_join_tuples_outer(iters_a, iters_b, swap, validate)
             }
             _ => {
                 let iters_a = splitted_a
                     .iter()
                     .map(|ca| ca.into_iter())
                     .collect::<Vec<_>>();
                 let iters_b = splitted_b
                     .iter()
                     .map(|ca| ca.into_iter())
                     .collect::<Vec<_>>();
-                hash_join_tuples_outer(iters_a, iters_b, swap)
+                hash_join_tuples_outer(iters_a, iters_b, swap, validate)
             }
         }
     }
 }
 
 #[cfg(feature = "semi_anti_join")]
 fn num_group_join_anti_semi<T>(
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/single_keys_inner.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/single_keys_inner.rs`

 * *Files 9% similar despite different names*

```diff
@@ -35,30 +35,36 @@
 }
 
 pub(super) fn hash_join_tuples_inner<T, IntoSlice>(
     probe: Vec<IntoSlice>,
     build: Vec<IntoSlice>,
     // Because b should be the shorter relation we could need to swap to keep left left and right right.
     swap: bool,
-) -> (Vec<IdxSize>, Vec<IdxSize>)
+    validate: JoinValidation,
+) -> PolarsResult<(Vec<IdxSize>, Vec<IdxSize>)>
 where
     IntoSlice: AsRef<[T]> + Send + Sync,
     T: Send + Hash + Eq + Sync + Copy + AsU64,
 {
     // NOTE: see the left join for more elaborate comments
 
     // first we hash one relation
     let hash_tbls = create_probe_table(build);
+    if validate.needs_checks() {
+        let build_size = hash_tbls.iter().map(|m| m.len()).sum();
+        let expected_size = probe.iter().map(|v| v.as_ref().len()).sum();
+        validate.validate_build(build_size, expected_size, swap)?;
+    }
 
     let n_tables = hash_tbls.len() as u64;
     debug_assert!(n_tables.is_power_of_two());
     let offsets = probe_to_offsets(&probe);
     // next we probe the other relation
     // code duplication is because we want to only do the swap check once
-    POOL.install(|| {
+    let out = POOL.install(|| {
         let tuples = probe
             .into_par_iter()
             .zip(offsets)
             .map(|(probe, offset)| {
                 let probe = probe.as_ref();
                 // local reference
                 let hash_tbls = &hash_tbls;
@@ -119,9 +125,10 @@
             });
         unsafe {
             left.set_len(cap);
             right.set_len(cap);
         }
 
         (left, right)
-    })
+    });
+    Ok(out)
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/single_keys_left.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/single_keys_left.rs`

 * *Files 3% similar despite different names*

```diff
@@ -24,21 +24,23 @@
 pub(super) fn finish_left_join_mappings(
     result_idx_left: Vec<IdxSize>,
     result_idx_right: Vec<Option<IdxSize>>,
     chunk_mapping_left: Option<&[ChunkId]>,
     chunk_mapping_right: Option<&[ChunkId]>,
 ) -> LeftJoinIds {
     let left = match chunk_mapping_left {
-        None => JoinIds::Left(result_idx_left),
-        Some(mapping) => JoinIds::Right(unsafe { apply_mapping(result_idx_left, mapping) }),
+        None => ChunkJoinIds::Left(result_idx_left),
+        Some(mapping) => ChunkJoinIds::Right(unsafe { apply_mapping(result_idx_left, mapping) }),
     };
 
     let right = match chunk_mapping_right {
-        None => JoinOptIds::Left(result_idx_right),
-        Some(mapping) => JoinOptIds::Right(unsafe { apply_opt_mapping(result_idx_right, mapping) }),
+        None => ChunkJoinOptIds::Left(result_idx_right),
+        Some(mapping) => {
+            ChunkJoinOptIds::Right(unsafe { apply_opt_mapping(result_idx_right, mapping) })
+        }
     };
     (left, right)
 }
 
 #[cfg(not(feature = "chunked_ids"))]
 pub(super) fn finish_left_join_mappings(
     _result_idx_left: Vec<IdxSize>,
@@ -54,38 +56,38 @@
     {
         let left = if result[0].0.is_left() {
             let lefts = result
                 .iter()
                 .map(|join_id| join_id.0.as_ref().left().unwrap())
                 .collect::<Vec<_>>();
             let lefts = flatten_par(&lefts);
-            JoinIds::Left(lefts)
+            ChunkJoinIds::Left(lefts)
         } else {
             let lefts = result
                 .iter()
                 .map(|join_id| join_id.0.as_ref().right().unwrap())
                 .collect::<Vec<_>>();
             let lefts = flatten_par(&lefts);
-            JoinIds::Right(lefts)
+            ChunkJoinIds::Right(lefts)
         };
 
         let right = if result[0].1.is_left() {
             let rights = result
                 .iter()
                 .map(|join_id| join_id.1.as_ref().left().unwrap())
                 .collect::<Vec<_>>();
             let rights = flatten_par(&rights);
-            JoinOptIds::Left(rights)
+            ChunkJoinOptIds::Left(rights)
         } else {
             let rights = result
                 .iter()
                 .map(|join_id| join_id.1.as_ref().right().unwrap())
                 .collect::<Vec<_>>();
             let rights = flatten_par(&rights);
-            JoinOptIds::Right(rights)
+            ChunkJoinOptIds::Right(rights)
         };
 
         (left, right)
     }
     #[cfg(not(feature = "chunked_ids"))]
     {
         let lefts = result.iter().map(|join_id| &join_id.0).collect::<Vec<_>>();
@@ -99,21 +101,27 @@
 pub(super) fn hash_join_tuples_left<T, IntoSlice>(
     probe: Vec<IntoSlice>,
     build: Vec<IntoSlice>,
     // map the global indices to [chunk_idx, array_idx]
     // only needed if we have non contiguous memory
     chunk_mapping_left: Option<&[ChunkId]>,
     chunk_mapping_right: Option<&[ChunkId]>,
-) -> LeftJoinIds
+    validate: JoinValidation,
+) -> PolarsResult<LeftJoinIds>
 where
     IntoSlice: AsRef<[T]> + Send + Sync,
     T: Send + Hash + Eq + Sync + Copy + AsU64,
 {
     // first we hash one relation
     let hash_tbls = create_probe_table(build);
+    if validate.needs_checks() {
+        let build_size = hash_tbls.iter().map(|m| m.len()).sum();
+        let expected_size = probe.iter().map(|v| v.as_ref().len()).sum();
+        validate.validate_build(build_size, expected_size, false)?;
+    }
 
     // we determine the offset so that we later know which index to store in the join tuples
     let offsets = probe_to_offsets(&probe);
 
     let n_tables = hash_tbls.len() as u64;
     debug_assert!(n_tables.is_power_of_two());
 
@@ -162,9 +170,9 @@
                     chunk_mapping_left,
                     chunk_mapping_right,
                 )
             })
             .collect()
     });
 
-    flatten_left_join_ids(result)
+    Ok(flatten_left_join_ids(result))
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/single_keys_outer.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/single_keys_outer.rs`

 * *Files 6% similar despite different names*

```diff
@@ -57,41 +57,47 @@
             }
         });
     }
 }
 
 /// Hash join outer. Both left and right can have no match so Options
 pub(super) fn hash_join_tuples_outer<T, I, J>(
-    a: Vec<I>,
-    b: Vec<J>,
+    probe: Vec<I>,
+    build: Vec<J>,
     swap: bool,
-) -> Vec<(Option<IdxSize>, Option<IdxSize>)>
+    validate: JoinValidation,
+) -> PolarsResult<Vec<(Option<IdxSize>, Option<IdxSize>)>>
 where
     I: Iterator<Item = T> + Send + TrustedLen,
     J: Iterator<Item = T> + Send + TrustedLen,
     T: Hash + Eq + Copy + Sync + Send,
 {
     // This function is partially multi-threaded.
     // Parts that are done in parallel:
     //  - creation of the probe tables
     //  - creation of the hashes
 
     // during the probe phase values are removed from the tables, that's done single threaded to
     // keep it lock free.
 
-    let size = a.iter().map(|a| a.size_hint().0).sum::<usize>()
-        + b.iter().map(|b| b.size_hint().0).sum::<usize>();
+    let size = probe.iter().map(|a| a.size_hint().0).sum::<usize>()
+        + build.iter().map(|b| b.size_hint().0).sum::<usize>();
     let mut results = Vec::with_capacity(size);
 
     // prepare hash table
-    let mut hash_tbls = prepare_hashed_relation_threaded(b);
+    let mut hash_tbls = prepare_hashed_relation_threaded(build);
+    if validate.needs_checks() {
+        let build_size = hash_tbls.iter().map(|m| m.len()).sum();
+        let expected_size = probe.iter().map(|i| i.size_hint().0).sum();
+        validate.validate_build(build_size, expected_size, true)?;
+    }
     let random_state = hash_tbls[0].hasher().clone();
 
     // we pre hash the probing values
-    let (probe_hashes, _) = create_hash_and_keys_threaded_vectorized(a, Some(random_state));
+    let (probe_hashes, _) = create_hash_and_keys_threaded_vectorized(probe, Some(random_state));
 
     let n_tables = hash_tbls.len() as u64;
 
     // probe the hash table.
     // Note: indexes from b that are not matched will be None, Some(idx_b)
     // Therefore we remove the matches and the remaining will be joined from the right
 
@@ -113,9 +119,9 @@
             &mut results,
             n_tables,
             |idx_a, idx_b| (Some(idx_a), Some(idx_b)),
             |idx_a| (Some(idx_a), None),
             |idx_b| (None, Some(idx_b)),
         )
     }
-    results
+    Ok(results)
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/single_keys_semi_anti.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/single_keys_semi_anti.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/sort_merge.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/sort_merge.rs`

 * *Files 6% similar despite different names*

```diff
@@ -174,42 +174,48 @@
 }
 
 #[cfg(not(feature = "performant"))]
 pub fn _sort_or_hash_inner(
     s_left: &Series,
     s_right: &Series,
     _verbose: bool,
-) -> ((Vec<IdxSize>, Vec<IdxSize>), bool) {
-    s_left.hash_join_inner(s_right)
+    validate: JoinValidation,
+) -> PolarsResult<(InnerJoinIds, bool)> {
+    s_left.hash_join_inner(s_right, validate)
 }
 
 #[cfg(feature = "performant")]
 pub fn _sort_or_hash_inner(
     s_left: &Series,
     s_right: &Series,
     verbose: bool,
-) -> ((Vec<IdxSize>, Vec<IdxSize>), bool) {
+    validate: JoinValidation,
+) -> PolarsResult<(InnerJoinIds, bool)> {
     // We check if keys are sorted.
     // - If they are we can do a sorted merge join
     // If one of the keys is not, it can still be faster to sort that key and use
     // the `arg_sort` indices to revert the sort once the join keys are determined.
     let size_factor_rhs = s_right.len() as f32 / s_left.len() as f32;
     let size_factor_lhs = s_left.len() as f32 / s_right.len() as f32;
     let size_factor_acceptable = std::env::var("POLARS_JOIN_SORT_FACTOR")
         .map(|s| s.parse::<f32>().unwrap())
         .unwrap_or(1.0);
     let is_numeric = s_left.dtype().to_physical().is_numeric();
 
+    if validate.needs_checks() {
+        return s_left.hash_join_inner(s_right, validate);
+    }
+
     let no_nulls = s_left.null_count() == 0 && s_right.null_count() == 0;
     match (s_left.is_sorted_flag(), s_right.is_sorted_flag(), no_nulls) {
         (IsSorted::Ascending, IsSorted::Ascending, true) if is_numeric => {
             if verbose {
                 eprintln!("inner join: keys are sorted: use sorted merge join");
             }
-            (par_sorted_merge_inner_no_nulls(s_left, s_right), true)
+            Ok((par_sorted_merge_inner_no_nulls(s_left, s_right), true))
         }
         (IsSorted::Ascending, _, true)
             if is_numeric && size_factor_rhs < size_factor_acceptable =>
         {
             if verbose {
                 eprintln!("right key will be descending sorted in inner join operation.")
             }
@@ -227,15 +233,15 @@
 
             POOL.install(|| {
                 right.par_iter_mut().for_each(|idx| {
                     *idx = unsafe { *reverse_idx_map.get_unchecked(*idx as usize) };
                 });
             });
 
-            ((left, right), true)
+            Ok(((left, right), true))
         }
         (_, IsSorted::Ascending, true)
             if is_numeric && size_factor_lhs < size_factor_acceptable =>
         {
             if verbose {
                 eprintln!("left key will be descending sorted in inner join operation.")
             }
@@ -254,42 +260,56 @@
             POOL.install(|| {
                 left.par_iter_mut().for_each(|idx| {
                     *idx = unsafe { *reverse_idx_map.get_unchecked(*idx as usize) };
                 });
             });
 
             // set sorted to `false` as we descending sorted the left key.
-            ((left, right), false)
+            Ok(((left, right), false))
         }
-        _ => s_left.hash_join_inner(s_right),
+        _ => s_left.hash_join_inner(s_right, validate),
     }
 }
 
 #[cfg(not(feature = "performant"))]
-pub(super) fn sort_or_hash_left(s_left: &Series, s_right: &Series, _verbose: bool) -> LeftJoinIds {
-    s_left.hash_join_left(s_right)
+pub(super) fn sort_or_hash_left(
+    s_left: &Series,
+    s_right: &Series,
+    _verbose: bool,
+    validate: JoinValidation,
+) -> PolarsResult<LeftJoinIds> {
+    s_left.hash_join_left(s_right, validate)
 }
 
 #[cfg(feature = "performant")]
-pub(super) fn sort_or_hash_left(s_left: &Series, s_right: &Series, verbose: bool) -> LeftJoinIds {
+pub(super) fn sort_or_hash_left(
+    s_left: &Series,
+    s_right: &Series,
+    verbose: bool,
+    validate: JoinValidation,
+) -> PolarsResult<LeftJoinIds> {
+    if validate.needs_checks() {
+        return s_left.hash_join_left(s_right, validate);
+    }
+
     let size_factor_rhs = s_right.len() as f32 / s_left.len() as f32;
     let size_factor_acceptable = std::env::var("POLARS_JOIN_SORT_FACTOR")
         .map(|s| s.parse::<f32>().unwrap())
         .unwrap_or(1.0);
     let is_numeric = s_left.dtype().to_physical().is_numeric();
 
     let no_nulls = s_left.null_count() == 0 && s_right.null_count() == 0;
 
     match (s_left.is_sorted_flag(), s_right.is_sorted_flag(), no_nulls) {
         (IsSorted::Ascending, IsSorted::Ascending, true) if is_numeric => {
             if verbose {
                 eprintln!("left join: keys are sorted: use sorted merge join");
             }
             let (left_idx, right_idx) = par_sorted_merge_left(s_left, s_right);
-            to_left_join_ids(left_idx, right_idx)
+            Ok(to_left_join_ids(left_idx, right_idx))
         }
         (IsSorted::Ascending, _, true)
             if is_numeric && size_factor_rhs < size_factor_acceptable =>
         {
             if verbose {
                 eprintln!("right key will be reverse sorted in left join operation.")
             }
@@ -308,13 +328,13 @@
             POOL.install(|| {
                 right.par_iter_mut().for_each(|opt_idx| {
                     *opt_idx =
                         opt_idx.map(|idx| unsafe { *reverse_idx_map.get_unchecked(idx as usize) });
                 });
             });
 
-            to_left_join_ids(left, right)
+            Ok(to_left_join_ids(left, right))
         }
         // don't reverse sort a left join key yet. Have to figure out how to set sorted flag
-        _ => s_left.hash_join_left(s_right),
+        _ => s_left.hash_join_left(s_right, validate),
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/hash_join/zip_outer.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/hash_join/zip_outer.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -521,15 +521,14 @@
     /// # Ok::<(), PolarsError>(())
     /// ```
     #[inline]
     pub fn get_columns(&self) -> &[Series] {
         &self.columns
     }
 
-    #[cfg(feature = "private")]
     #[inline]
     /// Get mutable access to the underlying columns.
     /// # Safety
     /// The caller must ensure the length of all [`Series`] remains equal.
     pub unsafe fn get_columns_mut(&mut self) -> &mut Vec<Series> {
         &mut self.columns
     }
@@ -1425,14 +1424,71 @@
 
     fn select_impl(&self, cols: &[SmartString]) -> PolarsResult<Self> {
         self.select_check_duplicates(cols)?;
         let selected = self.select_series_impl(cols)?;
         Ok(DataFrame::new_no_checks(selected))
     }
 
+    /// Select with a known schema.
+    pub fn select_with_schema<I, S>(&self, selection: I, schema: &SchemaRef) -> PolarsResult<Self>
+    where
+        I: IntoIterator<Item = S>,
+        S: AsRef<str>,
+    {
+        let cols = selection
+            .into_iter()
+            .map(|s| SmartString::from(s.as_ref()))
+            .collect::<Vec<_>>();
+        self.select_with_schema_impl(&cols, schema, true)
+    }
+
+    /// Select with a known schema. This doesn't check for duplicates.
+    pub fn select_with_schema_unchecked<I, S>(
+        &self,
+        selection: I,
+        schema: &Schema,
+    ) -> PolarsResult<Self>
+    where
+        I: IntoIterator<Item = S>,
+        S: AsRef<str>,
+    {
+        let cols = selection
+            .into_iter()
+            .map(|s| SmartString::from(s.as_ref()))
+            .collect::<Vec<_>>();
+        self.select_with_schema_impl(&cols, schema, false)
+    }
+
+    fn select_with_schema_impl(
+        &self,
+        cols: &[SmartString],
+        schema: &Schema,
+        check_duplicates: bool,
+    ) -> PolarsResult<Self> {
+        if check_duplicates {
+            self.select_check_duplicates(cols)?;
+        }
+        let selected = self.select_series_impl_with_schema(cols, schema)?;
+        Ok(DataFrame::new_no_checks(selected))
+    }
+
+    /// A non generic implementation to reduce compiler bloat.
+    fn select_series_impl_with_schema(
+        &self,
+        cols: &[SmartString],
+        schema: &Schema,
+    ) -> PolarsResult<Vec<Series>> {
+        cols.iter()
+            .map(|name| {
+                let index = schema.try_get_full(name)?.0;
+                Ok(self.columns[index].clone())
+            })
+            .collect()
+    }
+
     pub fn select_physical<I, S>(&self, selection: I) -> PolarsResult<Self>
     where
         I: IntoIterator<Item = S>,
         S: AsRef<str>,
     {
         let cols = selection
             .into_iter()
@@ -1782,15 +1838,14 @@
         self.columns = self
             .sort_impl(by_column, descending, false, None, true)?
             .columns;
         Ok(self)
     }
 
     /// This is the dispatch of Self::sort, and exists to reduce compile bloat by monomorphization.
-    #[cfg(feature = "private")]
     pub fn sort_impl(
         &self,
         by_column: Vec<Series>,
         descending: Vec<bool>,
         nulls_last: bool,
         slice: Option<(i64, usize)>,
         parallel: bool,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/row/av_buffer.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/row/av_buffer.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/row/dataframe.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/row/dataframe.rs`

 * *Files 20% similar despite different names*

```diff
@@ -82,14 +82,56 @@
                     s
                 }
             })
             .collect();
         DataFrame::new(v)
     }
 
+    /// Create a new DataFrame from an iterator over rows. This should only be used when you have row wise data,
+    /// as this is a lot slower than creating the `Series` in a columnar fashion
+    pub fn try_from_rows_iter_and_schema<'a, I>(mut rows: I, schema: &Schema) -> PolarsResult<Self>
+    where
+        I: Iterator<Item = PolarsResult<&'a Row<'a>>>,
+    {
+        let capacity = rows.size_hint().0;
+
+        let mut buffers: Vec<_> = schema
+            .iter_dtypes()
+            .map(|dtype| {
+                let buf: AnyValueBuffer = (dtype, capacity).into();
+                buf
+            })
+            .collect();
+
+        let mut expected_len = 0;
+        rows.try_for_each::<_, PolarsResult<()>>(|row| {
+            expected_len += 1;
+            for (value, buf) in row?.0.iter().zip(&mut buffers) {
+                buf.add_fallible(value)?
+            }
+            Ok(())
+        })?;
+        let v = buffers
+            .into_iter()
+            .zip(schema.iter_names())
+            .map(|(b, name)| {
+                let mut s = b.into_series();
+                // if the schema adds a column not in the rows, we
+                // fill it with nulls
+                if s.is_empty() {
+                    Series::full_null(name, expected_len, s.dtype())
+                } else {
+                    s.rename(name);
+                    s
+                }
+            })
+            .collect();
+        DataFrame::new(v)
+    }
+
     /// Create a new DataFrame from rows. This should only be used when you have row wise data,
     /// as this is a lot slower than creating the `Series` in a columnar fashion
     pub fn from_rows(rows: &[Row]) -> PolarsResult<Self> {
         let schema = rows_to_schema_first_non_null(rows, Some(50));
         let has_nulls = schema
             .iter_dtypes()
             .any(|dtype| matches!(dtype, DataType::Null));
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/row/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/row/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/row/transpose.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/row/transpose.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/top_k.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/top_k.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/frame/upstream_traits.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/frame/upstream_traits.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/functions.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/functions.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/hashing/fx.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/hashing/fx.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/hashing/identity.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/hashing/identity.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/hashing/partition.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/hashing/partition.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/hashing/vector_hasher.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/hashing/vector_hasher.rs`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 use arrow::bitmap::utils::get_bit_unchecked;
 use hashbrown::hash_map::RawEntryMut;
 use hashbrown::HashMap;
 use polars_arrow::utils::CustomIterTools;
-use polars_utils::HashSingle;
 use rayon::prelude::*;
 use xxhash_rust::xxh3::xxh3_64_with_seed;
 
 use super::*;
 use crate::datatypes::UInt64Chunked;
 use crate::prelude::*;
 use crate::utils::arrow::array::Array;
@@ -218,16 +217,16 @@
     }
 }
 
 impl VecHash for BooleanChunked {
     fn vec_hash(&self, random_state: RandomState, buf: &mut Vec<u64>) {
         buf.clear();
         buf.reserve(self.len());
-        let true_h = random_state.hash_single(true);
-        let false_h = random_state.hash_single(false);
+        let true_h = random_state.hash_one(true);
+        let false_h = random_state.hash_one(false);
         let null_h = get_null_hash_value(random_state);
         self.downcast_iter().for_each(|arr| {
             if arr.null_count() == 0 {
                 buf.extend(arr.values_iter().map(|v| if v { true_h } else { false_h }))
             } else {
                 buf.extend(arr.into_iter().map(|opt_v| match opt_v {
                     Some(true) => true_h,
@@ -235,16 +234,16 @@
                     None => null_h,
                 }))
             }
         });
     }
 
     fn vec_hash_combine(&self, random_state: RandomState, hashes: &mut [u64]) {
-        let true_h = random_state.hash_single(true);
-        let false_h = random_state.hash_single(false);
+        let true_h = random_state.hash_one(true);
+        let false_h = random_state.hash_one(false);
         let null_h = get_null_hash_value(random_state);
 
         let mut offset = 0;
         self.downcast_iter().for_each(|arr| {
             match arr.null_count() {
                 0 => arr
                     .values_iter()
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/lib.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/lib.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/named_from.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/named_from.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/prelude.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/prelude.rs`

 * *Files 1% similar despite different names*

```diff
@@ -32,16 +32,16 @@
 pub use crate::datatypes::*;
 pub use crate::error::{polars_bail, polars_ensure, polars_err, PolarsError, PolarsResult};
 #[cfg(feature = "asof_join")]
 pub use crate::frame::asof_join::*;
 pub use crate::frame::explode::MeltArgs;
 pub(crate) use crate::frame::groupby::aggregations::*;
 pub use crate::frame::groupby::{GroupsIdx, GroupsProxy, GroupsSlice, IntoGroupsProxy};
-pub use crate::frame::hash_join::JoinType;
 pub(crate) use crate::frame::hash_join::*;
+pub use crate::frame::hash_join::{JoinArgs, JoinType};
 pub use crate::frame::{DataFrame, UniqueKeepStrategy};
 pub use crate::hashing::{FxHash, VecHash};
 pub use crate::named_from::{NamedFrom, NamedFromOwned};
 pub use crate::schema::*;
 #[cfg(feature = "checked_arithmetic")]
 pub use crate::series::arithmetic::checked::NumOpsDispatchChecked;
 pub use crate::series::arithmetic::{LhsNumOps, NumOpsDispatch};
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/schema.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/schema.rs`

 * *Files 0% similar despite different names*

```diff
@@ -294,15 +294,15 @@
 
     /// Change the field at the given index to the given `dtype` and return the previous dtype
     ///
     /// If the index is out of bounds, the schema is not modified and `None` is returned. Otherwise returns
     /// `Some(old_dtype)`.
     ///
     /// This method only ever modifies an existing index and never adds a new field to the schema. To add a new field,
-    /// use [`with_column`] or [`insert_at_index`][Self::insert_at_index].
+    /// use [`with_column`][Self::with_column] or [`insert_at_index`][Self::insert_at_index].
     pub fn set_dtype_at_index(&mut self, index: usize, dtype: DataType) -> Option<DataType> {
         let (_, old_dtype) = self.inner.get_index_mut(index)?;
         Some(std::mem::replace(old_dtype, dtype))
     }
 
     /// Insert a new column in the [`Schema`]
     ///
@@ -377,15 +377,14 @@
 
     fn into_iter(self) -> Self::IntoIter {
         self.inner.into_iter()
     }
 }
 
 /// This trait exists to be unify the API of polars Schema and arrows Schema
-#[cfg(feature = "private")]
 pub trait IndexOfSchema: Debug {
     /// Get the index of a column by name.
     fn index_of(&self, name: &str) -> Option<usize>;
 
     /// Get a vector of all column names.
     fn get_names(&self) -> Vec<&str>;
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/serde/chunked_array.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/serde/chunked_array.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/serde/df.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/serde/df.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/serde/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/serde/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/serde/series.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/serde/series.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/any_value.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/any_value.rs`

 * *Files 0% similar despite different names*

```diff
@@ -327,15 +327,15 @@
                 return Ok(builder.to_series());
             }
             DataType::Null => Series::full_null(name, av.len(), &DataType::Null),
             #[cfg(feature = "dtype-categorical")]
             DataType::Categorical(_) => {
                 let ca = if let Some(single_av) = av.first() {
                     match single_av {
-                        AnyValue::Utf8(_) | AnyValue::Utf8Owned(_) => {
+                        AnyValue::Utf8(_) | AnyValue::Utf8Owned(_) | AnyValue::Null => {
                             any_values_to_utf8(av, strict)?
                         }
                         _ => polars_bail!(
                              ComputeError:
                              "categorical dtype with any-values of dtype {} not supported",
                              single_av.dtype()
                         ),
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/arithmetic/borrowed.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/arithmetic/borrowed.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/arithmetic/owned.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/arithmetic/owned.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/comparison.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/comparison.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/from.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/from.rs`

 * *Files 10% similar despite different names*

```diff
@@ -6,14 +6,15 @@
     feature = "dtype-datetime",
     feature = "dtype-time"
 ))]
 use arrow::temporal_conversions::*;
 use polars_arrow::compute::cast::cast;
 #[cfg(any(feature = "dtype-struct", feature = "dtype-categorical"))]
 use polars_arrow::kernels::concatenate::concatenate_owned_unchecked;
+use polars_error::feature_gated;
 
 use crate::chunked_array::cast::cast_chunks;
 #[cfg(feature = "object")]
 use crate::chunked_array::object::extension::polars_extension::PolarsExtension;
 #[cfg(feature = "object")]
 use crate::chunked_array::object::extension::EXTENSION_NAME;
 #[cfg(all(feature = "dtype-decimal", feature = "python"))]
@@ -138,21 +139,31 @@
                 Ok(BinaryChunked::from_chunks(name, chunks).into_series())
             }
             ArrowDataType::Binary => {
                 let chunks = cast_chunks(&chunks, &DataType::Binary, false).unwrap();
                 Ok(BinaryChunked::from_chunks(name, chunks).into_series())
             }
             ArrowDataType::List(_) | ArrowDataType::LargeList(_) => {
-                let chunks = chunks.iter().map(convert_inner_types).collect();
-                Ok(ListChunked::from_chunks(name, chunks).into_series())
+                let (chunks, dtype) = to_physical_and_dtype(chunks);
+                unsafe {
+                    Ok(
+                        ListChunked::from_chunks_and_dtype_unchecked(name, chunks, dtype)
+                            .into_series(),
+                    )
+                }
             }
             #[cfg(feature = "dtype-array")]
             ArrowDataType::FixedSizeList(_, _) => {
-                let chunks = chunks.iter().map(convert_inner_types).collect();
-                Ok(ArrayChunked::from_chunks(name, chunks).into_series())
+                let (chunks, dtype) = to_physical_and_dtype(chunks);
+                unsafe {
+                    Ok(
+                        ArrayChunked::from_chunks_and_dtype_unchecked(name, chunks, dtype)
+                            .into_series(),
+                    )
+                }
             }
             ArrowDataType::Boolean => Ok(BooleanChunked::from_chunks(name, chunks).into_series()),
             #[cfg(feature = "dtype-u8")]
             ArrowDataType::UInt8 => Ok(UInt8Chunked::from_chunks(name, chunks).into_series()),
             #[cfg(feature = "dtype-u16")]
             ArrowDataType::UInt16 => Ok(UInt16Chunked::from_chunks(name, chunks).into_series()),
             ArrowDataType::UInt32 => Ok(UInt32Chunked::from_chunks(name, chunks).into_series()),
@@ -317,21 +328,22 @@
                     pe.take_and_forget();
                     s
                 };
                 Ok(s)
             }
             #[cfg(feature = "dtype-struct")]
             ArrowDataType::Struct(logical_fields) => {
+                // We don't have to convert inner types, as that already
+                // happens on `Field: Series` construction
                 let arr = if chunks.len() > 1 {
                     // don't spuriously call this. This triggers a read on memmapped data
                     concatenate_owned_unchecked(&chunks).unwrap() as ArrayRef
                 } else {
                     chunks[0].clone()
                 };
-                let arr = convert_inner_types(&arr);
                 let mut struct_arr =
                     std::borrow::Cow::Borrowed(arr.as_any().downcast_ref::<StructArray>().unwrap());
 
                 if let Some(validity) = struct_arr.validity() {
                     let new_values = struct_arr
                         .values()
                         .iter()
@@ -458,74 +470,150 @@
                 arr.validity().cloned(),
             )) as ArrayRef
         })
         .collect::<Vec<_>>();
     Series::try_from((name, chunks))
 }
 
-fn convert_inner_types(arr: &ArrayRef) -> ArrayRef {
-    match arr.data_type() {
-        ArrowDataType::Utf8 => {
-            let arr = arr.as_any().downcast_ref::<Utf8Array<i32>>().unwrap();
-            Box::from(utf8_to_large_utf8(arr))
+fn convert<F: Fn(&dyn Array) -> ArrayRef>(arr: &[ArrayRef], f: F) -> Vec<ArrayRef> {
+    arr.iter().map(|arr| f(&**arr)).collect()
+}
+
+/// Converts to physical types and bubbles up the correct [`DataType`].
+fn to_physical_and_dtype(arrays: Vec<ArrayRef>) -> (Vec<ArrayRef>, DataType) {
+    match arrays[0].data_type() {
+        ArrowDataType::Utf8 => (
+            convert(&arrays, |arr| {
+                let arr = arr.as_any().downcast_ref::<Utf8Array<i32>>().unwrap();
+                Box::from(utf8_to_large_utf8(arr))
+            }),
+            DataType::Utf8,
+        ),
+        #[allow(unused_variables)]
+        dt @ ArrowDataType::Dictionary(_, _, _) => {
+            feature_gated!("dtype-categorical", {
+                let s = unsafe {
+                    let dt = dt.clone();
+                    Series::try_from_arrow_unchecked("", arrays, &dt)
+                }
+                .unwrap();
+                (s.chunks().clone(), s.dtype().clone())
+            })
         }
         ArrowDataType::List(field) => {
-            let out = cast(&**arr, &ArrowDataType::LargeList(field.clone())).unwrap();
-            convert_inner_types(&out)
+            let out = convert(&arrays, |arr| {
+                cast(arr, &ArrowDataType::LargeList(field.clone())).unwrap()
+            });
+            to_physical_and_dtype(out)
         }
         #[cfg(feature = "dtype-array")]
+        #[allow(unused_variables)]
         ArrowDataType::FixedSizeList(_, size) => {
-            let arr = arr.as_any().downcast_ref::<FixedSizeListArray>().unwrap();
-            let values = convert_inner_types(arr.values());
-            let dtype = FixedSizeListArray::default_datatype(values.data_type().clone(), *size);
-            Box::from(FixedSizeListArray::new(
-                dtype,
-                values,
-                arr.validity().cloned(),
-            ))
+            feature_gated!("dtype-array", {
+                let values = arrays
+                    .iter()
+                    .map(|arr| {
+                        let arr = arr.as_any().downcast_ref::<FixedSizeListArray>().unwrap();
+                        arr.values().clone()
+                    })
+                    .collect::<Vec<_>>();
+
+                let (converted_values, dtype) = to_physical_and_dtype(values);
+
+                let arrays = arrays
+                    .iter()
+                    .zip(converted_values)
+                    .map(|(arr, values)| {
+                        let arr = arr.as_any().downcast_ref::<FixedSizeListArray>().unwrap();
+
+                        let dtype =
+                            FixedSizeListArray::default_datatype(values.data_type().clone(), *size);
+                        Box::from(FixedSizeListArray::new(
+                            dtype,
+                            values,
+                            arr.validity().cloned(),
+                        )) as ArrayRef
+                    })
+                    .collect();
+                (arrays, DataType::Array(Box::new(dtype), *size))
+            })
         }
         ArrowDataType::FixedSizeBinary(_) | ArrowDataType::Binary => {
-            let out = cast(&**arr, &ArrowDataType::LargeBinary).unwrap();
-            convert_inner_types(&out)
+            let out = convert(&arrays, |arr| {
+                cast(arr, &ArrowDataType::LargeBinary).unwrap()
+            });
+            to_physical_and_dtype(out)
         }
         ArrowDataType::LargeList(_) => {
-            let arr = arr.as_any().downcast_ref::<ListArray<i64>>().unwrap();
-            let values = convert_inner_types(arr.values());
-            let dtype = ListArray::<i64>::default_datatype(values.data_type().clone());
-            Box::from(ListArray::<i64>::new(
-                dtype,
-                arr.offsets().clone(),
-                values,
-                arr.validity().cloned(),
-            ))
-        }
-        ArrowDataType::Struct(fields) => {
-            let arr = arr.as_any().downcast_ref::<StructArray>().unwrap();
-            let values = arr
-                .values()
+            let values = arrays
                 .iter()
-                .map(convert_inner_types)
+                .map(|arr| {
+                    let arr = arr.as_any().downcast_ref::<ListArray<i64>>().unwrap();
+                    arr.values().clone()
+                })
                 .collect::<Vec<_>>();
 
-            let fields = values
+            let (converted_values, dtype) = to_physical_and_dtype(values);
+
+            let arrays = arrays
                 .iter()
-                .zip(fields.iter())
-                .map(|(arr, field)| ArrowField::new(&field.name, arr.data_type().clone(), true))
+                .zip(converted_values)
+                .map(|(arr, values)| {
+                    let arr = arr.as_any().downcast_ref::<ListArray<i64>>().unwrap();
+
+                    let dtype = ListArray::<i64>::default_datatype(values.data_type().clone());
+                    Box::from(ListArray::<i64>::new(
+                        dtype,
+                        arr.offsets().clone(),
+                        values,
+                        arr.validity().cloned(),
+                    )) as ArrayRef
+                })
                 .collect();
-            Box::new(StructArray::new(
-                ArrowDataType::Struct(fields),
-                values,
-                arr.validity().cloned(),
-            ))
+            (arrays, DataType::List(Box::new(dtype)))
+        }
+        ArrowDataType::Struct(_fields) => {
+            feature_gated!("dtype-struct", {
+                debug_assert_eq!(arrays.len(), 1);
+                let arr = arrays[0].clone();
+                let arr = arr.as_any().downcast_ref::<StructArray>().unwrap();
+                let (values, dtypes): (Vec<_>, Vec<_>) = arr
+                    .values()
+                    .iter()
+                    .map(|value| {
+                        let mut out = to_physical_and_dtype(vec![value.clone()]);
+                        (out.0.pop().unwrap(), out.1)
+                    })
+                    .unzip();
+
+                let arrow_fields = values
+                    .iter()
+                    .zip(_fields.iter())
+                    .map(|(arr, field)| ArrowField::new(&field.name, arr.data_type().clone(), true))
+                    .collect();
+                let arrow_array = Box::new(StructArray::new(
+                    ArrowDataType::Struct(arrow_fields),
+                    values,
+                    arr.validity().cloned(),
+                )) as ArrayRef;
+                let polars_fields = _fields
+                    .iter()
+                    .zip(dtypes.into_iter())
+                    .map(|(field, dtype)| Field::new(&field.name, dtype))
+                    .collect();
+                (vec![arrow_array], DataType::Struct(polars_fields))
+            })
+        }
+        dt => {
+            let dtype = dt.into();
+            (arrays, dtype)
         }
-        _ => arr.clone(),
     }
 }
 
-// TODO: add types
 impl TryFrom<(&str, Vec<ArrayRef>)> for Series {
     type Error = PolarsError;
 
     fn try_from(name_arr: (&str, Vec<ArrayRef>)) -> PolarsResult<Self> {
         let (name, chunks) = name_arr;
 
         let mut chunks_iter = chunks.iter();
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/array.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/list.rs`

 * *Files 1% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 use crate::chunked_array::ops::explode::ExplodeByOffsets;
 use crate::chunked_array::AsSinglePtr;
 use crate::frame::groupby::*;
 use crate::prelude::*;
 use crate::series::implementations::SeriesWrap;
 use crate::series::IsSorted;
 
-impl private::PrivateSeries for SeriesWrap<ArrayChunked> {
+impl private::PrivateSeries for SeriesWrap<ListChunked> {
     fn compute_len(&mut self) {
         self.0.compute_len()
     }
     fn _field(&self) -> Cow<Field> {
         Cow::Borrowed(self.0.ref_field())
     }
     fn _dtype(&self) -> &DataType {
@@ -42,15 +42,15 @@
     }
 
     fn group_tuples(&self, multithreaded: bool, sorted: bool) -> PolarsResult<GroupsProxy> {
         IntoGroupsProxy::group_tuples(&self.0, multithreaded, sorted)
     }
 }
 
-impl SeriesTrait for SeriesWrap<ArrayChunked> {
+impl SeriesTrait for SeriesWrap<ListChunked> {
     fn rename(&mut self, name: &str) {
         self.0.rename(name);
     }
 
     fn chunk_lengths(&self) -> ChunkIdIter {
         self.0.chunk_id()
     }
@@ -145,15 +145,14 @@
     }
 
     fn get(&self, index: usize) -> PolarsResult<AnyValue> {
         self.0.get_any_value(index)
     }
 
     #[inline]
-    #[cfg(feature = "private")]
     unsafe fn get_unchecked(&self, index: usize) -> AnyValue {
         self.0.get_any_value_unchecked(index)
     }
 
     fn null_count(&self) -> usize {
         self.0.null_count()
     }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/binary.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/binary.rs`

 * *Files 1% similar despite different names*

```diff
@@ -213,15 +213,14 @@
     }
 
     fn get(&self, index: usize) -> PolarsResult<AnyValue> {
         self.0.get_any_value(index)
     }
 
     #[inline]
-    #[cfg(feature = "private")]
     unsafe fn get_unchecked(&self, index: usize) -> AnyValue {
         self.0.get_any_value_unchecked(index)
     }
 
     fn sort_with(&self, options: SortOptions) -> Series {
         ChunkSort::sort_with(&self.0, options).into_series()
     }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/boolean.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/boolean.rs`

 * *Files 1% similar despite different names*

```diff
@@ -236,15 +236,14 @@
     }
 
     fn get(&self, index: usize) -> PolarsResult<AnyValue> {
         self.0.get_any_value(index)
     }
 
     #[inline]
-    #[cfg(feature = "private")]
     unsafe fn get_unchecked(&self, index: usize) -> AnyValue {
         self.0.get_any_value_unchecked(index)
     }
 
     fn sort_with(&self, options: SortOptions) -> Series {
         ChunkSort::sort_with(&self.0, options).into_series()
     }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/categorical.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/categorical.rs`

 * *Files 2% similar despite different names*

```diff
@@ -280,15 +280,14 @@
     }
 
     fn get(&self, index: usize) -> PolarsResult<AnyValue> {
         self.0.get_any_value(index)
     }
 
     #[inline]
-    #[cfg(feature = "private")]
     unsafe fn get_unchecked(&self, index: usize) -> AnyValue {
         self.0.get_any_value_unchecked(index)
     }
 
     fn sort_with(&self, options: SortOptions) -> Series {
         self.0.sort_with(options).into_series()
     }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/dates_time.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/dates_time.rs`

 * *Files 0% similar despite different names*

```diff
@@ -325,15 +325,14 @@
             }
 
             fn get(&self, index: usize) -> PolarsResult<AnyValue> {
                 self.0.get_any_value(index)
             }
 
             #[inline]
-            #[cfg(feature = "private")]
             unsafe fn get_unchecked(&self, index: usize) -> AnyValue {
                 self.0.get_any_value_unchecked(index)
             }
 
             fn sort_with(&self, options: SortOptions) -> Series {
                 self.0.sort_with(options).$into_logical().into_series()
             }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/datetime.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/datetime.rs`

 * *Files 0% similar despite different names*

```diff
@@ -329,15 +329,14 @@
     }
 
     fn get(&self, index: usize) -> PolarsResult<AnyValue> {
         self.0.get_any_value(index)
     }
 
     #[inline]
-    #[cfg(feature = "private")]
     unsafe fn get_unchecked(&self, index: usize) -> AnyValue {
         self.0.get_any_value_unchecked(index)
     }
 
     fn sort_with(&self, options: SortOptions) -> Series {
         self.0
             .sort_with(options)
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/decimal.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/array.rs`

 * *Files 18% similar despite different names*

```diff
@@ -1,169 +1,158 @@
-use super::{private, IntoSeries, SeriesTrait, SeriesWrap, *};
+use std::any::Any;
+use std::borrow::Cow;
+
+use super::{private, IntoSeries, SeriesTrait};
+use crate::chunked_array::comparison::*;
+use crate::chunked_array::ops::explode::ExplodeByOffsets;
+use crate::chunked_array::AsSinglePtr;
+use crate::frame::groupby::*;
 use crate::prelude::*;
+use crate::series::implementations::SeriesWrap;
+use crate::series::IsSorted;
 
-unsafe impl IntoSeries for DecimalChunked {
-    fn into_series(self) -> Series {
-        Series(Arc::new(SeriesWrap(self)))
+impl private::PrivateSeries for SeriesWrap<ArrayChunked> {
+    fn compute_len(&mut self) {
+        self.0.compute_len()
+    }
+    fn _field(&self) -> Cow<Field> {
+        Cow::Borrowed(self.0.ref_field())
+    }
+    fn _dtype(&self) -> &DataType {
+        self.0.ref_field().data_type()
+    }
+    fn explode_by_offsets(&self, offsets: &[i64]) -> Series {
+        self.0.explode_by_offsets(offsets)
     }
-}
-
-impl private::PrivateSeriesNumeric for SeriesWrap<DecimalChunked> {}
 
-impl SeriesWrap<DecimalChunked> {
-    fn apply_logical<F: Fn(&Int128Chunked) -> Int128Chunked>(&self, f: F) -> Series {
-        f(&self.0)
-            .into_decimal_unchecked(self.0.precision(), self.0.scale())
-            .into_series()
+    fn _set_sorted_flag(&mut self, is_sorted: IsSorted) {
+        self.0.set_sorted_flag(is_sorted)
     }
-}
 
-impl private::PrivateSeries for SeriesWrap<DecimalChunked> {
-    fn compute_len(&mut self) {
-        self.0.compute_len()
+    unsafe fn equal_element(&self, idx_self: usize, idx_other: usize, other: &Series) -> bool {
+        self.0.equal_element(idx_self, idx_other, other)
     }
 
-    fn _field(&self) -> Cow<Field> {
-        Cow::Owned(self.0.field())
+    #[cfg(feature = "zip_with")]
+    fn zip_with_same_type(&self, mask: &BooleanChunked, other: &Series) -> PolarsResult<Series> {
+        ChunkZip::zip_with(&self.0, mask, other.as_ref().as_ref()).map(|ca| ca.into_series())
     }
 
-    fn _dtype(&self) -> &DataType {
-        self.0.dtype()
+    unsafe fn agg_list(&self, groups: &GroupsProxy) -> Series {
+        self.0.agg_list(groups)
     }
 
-    fn zip_with_same_type(&self, mask: &BooleanChunked, other: &Series) -> PolarsResult<Series> {
-        Ok(self
-            .0
-            .zip_with(mask, other.as_ref().as_ref())?
-            .into_decimal_unchecked(self.0.precision(), self.0.scale())
-            .into_series())
+    fn group_tuples(&self, multithreaded: bool, sorted: bool) -> PolarsResult<GroupsProxy> {
+        IntoGroupsProxy::group_tuples(&self.0, multithreaded, sorted)
     }
 }
 
-impl SeriesTrait for SeriesWrap<DecimalChunked> {
+impl SeriesTrait for SeriesWrap<ArrayChunked> {
     fn rename(&mut self, name: &str) {
-        self.0.rename(name)
+        self.0.rename(name);
     }
 
     fn chunk_lengths(&self) -> ChunkIdIter {
         self.0.chunk_id()
     }
-
     fn name(&self) -> &str {
         self.0.name()
     }
 
     fn chunks(&self) -> &Vec<ArrayRef> {
         self.0.chunks()
     }
+    fn shrink_to_fit(&mut self) {
+        self.0.shrink_to_fit()
+    }
 
     fn slice(&self, offset: i64, length: usize) -> Series {
-        self.apply_logical(|ca| ca.slice(offset, length))
+        self.0.slice(offset, length).into_series()
     }
 
     fn append(&mut self, other: &Series) -> PolarsResult<()> {
         polars_ensure!(self.0.dtype() == other.dtype(), append);
-        let other = other.decimal()?;
-        self.0.append(&other.0);
-        Ok(())
+        self.0.append(other.as_ref().as_ref())
     }
 
     fn extend(&mut self, other: &Series) -> PolarsResult<()> {
         polars_ensure!(self.0.dtype() == other.dtype(), extend);
-        self.0.extend(other.as_ref().as_ref());
-        Ok(())
+        self.0.extend(other.as_ref().as_ref())
     }
 
     fn filter(&self, filter: &BooleanChunked) -> PolarsResult<Series> {
-        Ok(self
-            .0
-            .filter(filter)?
-            .into_decimal_unchecked(self.0.precision(), self.0.scale())
-            .into_series())
+        ChunkFilter::filter(&self.0, filter).map(|ca| ca.into_series())
     }
 
     #[cfg(feature = "chunked_ids")]
     unsafe fn _take_chunked_unchecked(&self, by: &[ChunkId], sorted: IsSorted) -> Series {
-        let ca = self.0.deref().take_chunked_unchecked(by, sorted);
-        ca.into_decimal_unchecked(self.0.precision(), self.0.scale())
-            .into_series()
+        self.0.take_chunked_unchecked(by, sorted).into_series()
     }
 
     #[cfg(feature = "chunked_ids")]
     unsafe fn _take_opt_chunked_unchecked(&self, by: &[Option<ChunkId>]) -> Series {
-        self.apply_logical(|ca| ca.take_opt_chunked_unchecked(by))
+        self.0.take_opt_chunked_unchecked(by).into_series()
+    }
+
+    fn take(&self, indices: &IdxCa) -> PolarsResult<Series> {
+        let indices = if indices.chunks.len() > 1 {
+            Cow::Owned(indices.rechunk())
+        } else {
+            Cow::Borrowed(indices)
+        };
+        Ok(ChunkTake::take(&self.0, (&*indices).into())?.into_series())
     }
 
     fn take_iter(&self, iter: &mut dyn TakeIterator) -> PolarsResult<Series> {
-        ChunkTake::take(self.0.deref(), iter.into()).map(|ca| {
-            ca.into_decimal_unchecked(self.0.precision(), self.0.scale())
-                .into_series()
-        })
+        Ok(ChunkTake::take(&self.0, iter.into())?.into_series())
     }
 
     unsafe fn take_iter_unchecked(&self, iter: &mut dyn TakeIterator) -> Series {
-        ChunkTake::take_unchecked(self.0.deref(), iter.into())
-            .into_decimal_unchecked(self.0.precision(), self.0.scale())
-            .into_series()
+        ChunkTake::take_unchecked(&self.0, iter.into()).into_series()
     }
 
     unsafe fn take_unchecked(&self, idx: &IdxCa) -> PolarsResult<Series> {
-        let mut out = ChunkTake::take_unchecked(self.0.deref(), idx.into());
-
-        if self.0.is_sorted_ascending_flag()
-            && (idx.is_sorted_ascending_flag() || idx.is_sorted_descending_flag())
-        {
-            out.set_sorted_flag(idx.is_sorted_flag())
-        }
-
-        Ok(out
-            .into_decimal_unchecked(self.0.precision(), self.0.scale())
-            .into_series())
+        let idx = if idx.chunks.len() > 1 {
+            Cow::Owned(idx.rechunk())
+        } else {
+            Cow::Borrowed(idx)
+        };
+        Ok(ChunkTake::take_unchecked(&self.0, (&*idx).into()).into_series())
     }
 
     unsafe fn take_opt_iter_unchecked(&self, iter: &mut dyn TakeIteratorNulls) -> Series {
-        ChunkTake::take_unchecked(self.0.deref(), iter.into())
-            .into_decimal_unchecked(self.0.precision(), self.0.scale())
-            .into_series()
+        ChunkTake::take_unchecked(&self.0, iter.into()).into_series()
     }
 
-    fn take(&self, indices: &IdxCa) -> PolarsResult<Series> {
-        ChunkTake::take(self.0.deref(), indices.into()).map(|ca| {
-            ca.into_decimal_unchecked(self.0.precision(), self.0.scale())
-                .into_series()
-        })
+    #[cfg(feature = "take_opt_iter")]
+    fn take_opt_iter(&self, iter: &mut dyn TakeIteratorNulls) -> PolarsResult<Series> {
+        Ok(ChunkTake::take(&self.0, iter.into())?.into_series())
     }
 
     fn len(&self) -> usize {
         self.0.len()
     }
 
     fn rechunk(&self) -> Series {
-        let ca = self.0.rechunk();
-        ca.into_decimal_unchecked(self.0.precision(), self.0.scale())
-            .into_series()
+        self.0.rechunk().into_series()
     }
 
     fn new_from_index(&self, index: usize, length: usize) -> Series {
-        self.0
-            .new_from_index(index, length)
-            .into_decimal_unchecked(self.0.precision(), self.0.scale())
-            .into_series()
+        ChunkExpandAtIndex::new_from_index(&self.0, index, length).into_series()
     }
 
     fn cast(&self, data_type: &DataType) -> PolarsResult<Series> {
         self.0.cast(data_type)
     }
 
     fn get(&self, index: usize) -> PolarsResult<AnyValue> {
         self.0.get_any_value(index)
     }
 
     #[inline]
-    #[cfg(feature = "private")]
     unsafe fn get_unchecked(&self, index: usize) -> AnyValue {
         self.0.get_any_value_unchecked(index)
     }
 
     fn null_count(&self) -> usize {
         self.0.null_count()
     }
@@ -177,18 +166,40 @@
     }
 
     fn is_not_null(&self) -> BooleanChunked {
         self.0.is_not_null()
     }
 
     fn reverse(&self) -> Series {
-        self.apply_logical(|ca| ca.reverse())
+        ChunkReverse::reverse(&self.0).into_series()
+    }
+
+    fn as_single_ptr(&mut self) -> PolarsResult<usize> {
+        self.0.as_single_ptr()
     }
 
     fn shift(&self, periods: i64) -> Series {
-        self.apply_logical(|ca| ca.shift(periods))
+        ChunkShift::shift(&self.0, periods).into_series()
     }
 
+    fn _sum_as_series(&self) -> Series {
+        ChunkAggSeries::sum_as_series(&self.0)
+    }
+    fn max_as_series(&self) -> Series {
+        ChunkAggSeries::max_as_series(&self.0)
+    }
+    fn min_as_series(&self) -> Series {
+        ChunkAggSeries::min_as_series(&self.0)
+    }
     fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
         Arc::new(SeriesWrap(Clone::clone(&self.0)))
     }
+    fn as_any(&self) -> &dyn Any {
+        &self.0
+    }
+
+    /// Get a hold to self as `Any` trait reference.
+    /// Only implemented for ObjectType
+    fn as_any_mut(&mut self) -> &mut dyn Any {
+        &mut self.0
+    }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/duration.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/duration.rs`

 * *Files 0% similar despite different names*

```diff
@@ -343,15 +343,14 @@
     }
 
     fn get(&self, index: usize) -> PolarsResult<AnyValue> {
         self.0.get_any_value(index)
     }
 
     #[inline]
-    #[cfg(feature = "private")]
     unsafe fn get_unchecked(&self, index: usize) -> AnyValue {
         self.0.get_any_value_unchecked(index)
     }
 
     fn sort_with(&self, options: SortOptions) -> Series {
         self.0
             .sort_with(options)
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/floats.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/floats.rs`

 * *Files 0% similar despite different names*

```diff
@@ -279,15 +279,14 @@
             }
 
             fn get(&self, index: usize) -> PolarsResult<AnyValue> {
                 self.0.get_any_value(index)
             }
 
             #[inline]
-            #[cfg(feature = "private")]
             unsafe fn get_unchecked(&self, index: usize) -> AnyValue {
                 self.0.get_any_value_unchecked(index)
             }
 
             fn sort_with(&self, options: SortOptions) -> Series {
                 ChunkSort::sort_with(&self.0, options).into_series()
             }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/list.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/decimal.rs`

 * *Files 23% similar despite different names*

```diff
@@ -1,159 +1,223 @@
-use std::any::Any;
-use std::borrow::Cow;
-
-use super::{private, IntoSeries, SeriesTrait};
-use crate::chunked_array::comparison::*;
-use crate::chunked_array::ops::explode::ExplodeByOffsets;
-use crate::chunked_array::AsSinglePtr;
-use crate::frame::groupby::*;
+use super::{private, IntoSeries, SeriesTrait, SeriesWrap, *};
 use crate::prelude::*;
-use crate::series::implementations::SeriesWrap;
-use crate::series::IsSorted;
 
-impl private::PrivateSeries for SeriesWrap<ListChunked> {
+unsafe impl IntoSeries for DecimalChunked {
+    fn into_series(self) -> Series {
+        Series(Arc::new(SeriesWrap(self)))
+    }
+}
+
+impl private::PrivateSeriesNumeric for SeriesWrap<DecimalChunked> {}
+
+impl SeriesWrap<DecimalChunked> {
+    fn apply_physical<F: Fn(&Int128Chunked) -> Int128Chunked>(&self, f: F) -> Series {
+        f(&self.0)
+            .into_decimal_unchecked(self.0.precision(), self.0.scale())
+            .into_series()
+    }
+
+    fn agg_helper<F: Fn(&Int128Chunked) -> Series>(&self, f: F) -> Series {
+        let agg_s = f(&self.0);
+        let ca = agg_s.decimal().unwrap();
+        let ca = ca.as_ref().clone();
+        let precision = self.0.precision();
+        let scale = self.0.scale();
+        ca.into_decimal_unchecked(precision, scale).into_series()
+    }
+}
+
+unsafe impl IntoSeries for Int128Chunked {
+    fn into_series(self) -> Series
+    where
+        Self: Sized,
+    {
+        // this is incorrect as it ignores the datatype
+        // the caller must correct this.
+        let mut ca = DecimalChunked::new_logical(self);
+        ca.2 = Some(DataType::Decimal(None, None));
+        ca.into_series()
+    }
+}
+
+impl private::PrivateSeries for SeriesWrap<DecimalChunked> {
     fn compute_len(&mut self) {
         self.0.compute_len()
     }
+
     fn _field(&self) -> Cow<Field> {
-        Cow::Borrowed(self.0.ref_field())
+        Cow::Owned(self.0.field())
     }
+
     fn _dtype(&self) -> &DataType {
-        self.0.ref_field().data_type()
+        self.0.dtype()
     }
-    fn explode_by_offsets(&self, offsets: &[i64]) -> Series {
-        self.0.explode_by_offsets(offsets)
+
+    fn zip_with_same_type(&self, mask: &BooleanChunked, other: &Series) -> PolarsResult<Series> {
+        Ok(self
+            .0
+            .zip_with(mask, other.as_ref().as_ref())?
+            .into_decimal_unchecked(self.0.precision(), self.0.scale())
+            .into_series())
     }
 
-    fn _set_sorted_flag(&mut self, is_sorted: IsSorted) {
-        self.0.set_sorted_flag(is_sorted)
+    unsafe fn agg_sum(&self, groups: &GroupsProxy) -> Series {
+        self.agg_helper(|ca| ca.agg_sum(groups))
     }
 
-    unsafe fn equal_element(&self, idx_self: usize, idx_other: usize, other: &Series) -> bool {
-        self.0.equal_element(idx_self, idx_other, other)
+    unsafe fn agg_min(&self, groups: &GroupsProxy) -> Series {
+        self.agg_helper(|ca| ca.agg_min(groups))
     }
 
-    #[cfg(feature = "zip_with")]
-    fn zip_with_same_type(&self, mask: &BooleanChunked, other: &Series) -> PolarsResult<Series> {
-        ChunkZip::zip_with(&self.0, mask, other.as_ref().as_ref()).map(|ca| ca.into_series())
+    unsafe fn agg_max(&self, groups: &GroupsProxy) -> Series {
+        self.agg_helper(|ca| ca.agg_max(groups))
     }
 
     unsafe fn agg_list(&self, groups: &GroupsProxy) -> Series {
         self.0.agg_list(groups)
     }
 
-    fn group_tuples(&self, multithreaded: bool, sorted: bool) -> PolarsResult<GroupsProxy> {
-        IntoGroupsProxy::group_tuples(&self.0, multithreaded, sorted)
+    fn subtract(&self, rhs: &Series) -> PolarsResult<Series> {
+        let rhs = rhs.decimal()?;
+        ((&self.0) - rhs).map(|ca| ca.into_series())
+    }
+    fn add_to(&self, rhs: &Series) -> PolarsResult<Series> {
+        let rhs = rhs.decimal()?;
+        ((&self.0) + rhs).map(|ca| ca.into_series())
+    }
+    fn multiply(&self, rhs: &Series) -> PolarsResult<Series> {
+        let rhs = rhs.decimal()?;
+        ((&self.0) * rhs).map(|ca| ca.into_series())
+    }
+    fn divide(&self, rhs: &Series) -> PolarsResult<Series> {
+        let rhs = rhs.decimal()?;
+        ((&self.0) / rhs).map(|ca| ca.into_series())
     }
 }
 
-impl SeriesTrait for SeriesWrap<ListChunked> {
+impl SeriesTrait for SeriesWrap<DecimalChunked> {
     fn rename(&mut self, name: &str) {
-        self.0.rename(name);
+        self.0.rename(name)
     }
 
     fn chunk_lengths(&self) -> ChunkIdIter {
         self.0.chunk_id()
     }
+
     fn name(&self) -> &str {
         self.0.name()
     }
 
     fn chunks(&self) -> &Vec<ArrayRef> {
         self.0.chunks()
     }
-    fn shrink_to_fit(&mut self) {
-        self.0.shrink_to_fit()
-    }
 
     fn slice(&self, offset: i64, length: usize) -> Series {
-        self.0.slice(offset, length).into_series()
+        self.apply_physical(|ca| ca.slice(offset, length))
     }
 
     fn append(&mut self, other: &Series) -> PolarsResult<()> {
         polars_ensure!(self.0.dtype() == other.dtype(), append);
-        self.0.append(other.as_ref().as_ref())
+        let other = other.decimal()?;
+        self.0.append(&other.0);
+        Ok(())
     }
 
     fn extend(&mut self, other: &Series) -> PolarsResult<()> {
         polars_ensure!(self.0.dtype() == other.dtype(), extend);
-        self.0.extend(other.as_ref().as_ref())
+        self.0.extend(other.as_ref().as_ref());
+        Ok(())
     }
 
     fn filter(&self, filter: &BooleanChunked) -> PolarsResult<Series> {
-        ChunkFilter::filter(&self.0, filter).map(|ca| ca.into_series())
+        Ok(self
+            .0
+            .filter(filter)?
+            .into_decimal_unchecked(self.0.precision(), self.0.scale())
+            .into_series())
     }
 
     #[cfg(feature = "chunked_ids")]
     unsafe fn _take_chunked_unchecked(&self, by: &[ChunkId], sorted: IsSorted) -> Series {
-        self.0.take_chunked_unchecked(by, sorted).into_series()
+        let ca = self.0.deref().take_chunked_unchecked(by, sorted);
+        ca.into_decimal_unchecked(self.0.precision(), self.0.scale())
+            .into_series()
     }
 
     #[cfg(feature = "chunked_ids")]
     unsafe fn _take_opt_chunked_unchecked(&self, by: &[Option<ChunkId>]) -> Series {
-        self.0.take_opt_chunked_unchecked(by).into_series()
-    }
-
-    fn take(&self, indices: &IdxCa) -> PolarsResult<Series> {
-        let indices = if indices.chunks.len() > 1 {
-            Cow::Owned(indices.rechunk())
-        } else {
-            Cow::Borrowed(indices)
-        };
-        Ok(ChunkTake::take(&self.0, (&*indices).into())?.into_series())
+        self.apply_physical(|ca| ca.take_opt_chunked_unchecked(by))
     }
 
     fn take_iter(&self, iter: &mut dyn TakeIterator) -> PolarsResult<Series> {
-        Ok(ChunkTake::take(&self.0, iter.into())?.into_series())
+        ChunkTake::take(self.0.deref(), iter.into()).map(|ca| {
+            ca.into_decimal_unchecked(self.0.precision(), self.0.scale())
+                .into_series()
+        })
     }
 
     unsafe fn take_iter_unchecked(&self, iter: &mut dyn TakeIterator) -> Series {
-        ChunkTake::take_unchecked(&self.0, iter.into()).into_series()
+        ChunkTake::take_unchecked(self.0.deref(), iter.into())
+            .into_decimal_unchecked(self.0.precision(), self.0.scale())
+            .into_series()
     }
 
     unsafe fn take_unchecked(&self, idx: &IdxCa) -> PolarsResult<Series> {
-        let idx = if idx.chunks.len() > 1 {
-            Cow::Owned(idx.rechunk())
-        } else {
-            Cow::Borrowed(idx)
-        };
-        Ok(ChunkTake::take_unchecked(&self.0, (&*idx).into()).into_series())
+        let mut out = ChunkTake::take_unchecked(self.0.deref(), idx.into());
+
+        if self.0.is_sorted_ascending_flag()
+            && (idx.is_sorted_ascending_flag() || idx.is_sorted_descending_flag())
+        {
+            out.set_sorted_flag(idx.is_sorted_flag())
+        }
+
+        Ok(out
+            .into_decimal_unchecked(self.0.precision(), self.0.scale())
+            .into_series())
     }
 
     unsafe fn take_opt_iter_unchecked(&self, iter: &mut dyn TakeIteratorNulls) -> Series {
-        ChunkTake::take_unchecked(&self.0, iter.into()).into_series()
+        ChunkTake::take_unchecked(self.0.deref(), iter.into())
+            .into_decimal_unchecked(self.0.precision(), self.0.scale())
+            .into_series()
     }
 
-    #[cfg(feature = "take_opt_iter")]
-    fn take_opt_iter(&self, iter: &mut dyn TakeIteratorNulls) -> PolarsResult<Series> {
-        Ok(ChunkTake::take(&self.0, iter.into())?.into_series())
+    fn take(&self, indices: &IdxCa) -> PolarsResult<Series> {
+        ChunkTake::take(self.0.deref(), indices.into()).map(|ca| {
+            ca.into_decimal_unchecked(self.0.precision(), self.0.scale())
+                .into_series()
+        })
     }
 
     fn len(&self) -> usize {
         self.0.len()
     }
 
     fn rechunk(&self) -> Series {
-        self.0.rechunk().into_series()
+        let ca = self.0.rechunk();
+        ca.into_decimal_unchecked(self.0.precision(), self.0.scale())
+            .into_series()
     }
 
     fn new_from_index(&self, index: usize, length: usize) -> Series {
-        ChunkExpandAtIndex::new_from_index(&self.0, index, length).into_series()
+        self.0
+            .new_from_index(index, length)
+            .into_decimal_unchecked(self.0.precision(), self.0.scale())
+            .into_series()
     }
 
     fn cast(&self, data_type: &DataType) -> PolarsResult<Series> {
         self.0.cast(data_type)
     }
 
     fn get(&self, index: usize) -> PolarsResult<AnyValue> {
         self.0.get_any_value(index)
     }
 
     #[inline]
-    #[cfg(feature = "private")]
     unsafe fn get_unchecked(&self, index: usize) -> AnyValue {
         self.0.get_any_value_unchecked(index)
     }
 
     fn null_count(&self) -> usize {
         self.0.null_count()
     }
@@ -167,40 +231,37 @@
     }
 
     fn is_not_null(&self) -> BooleanChunked {
         self.0.is_not_null()
     }
 
     fn reverse(&self) -> Series {
-        ChunkReverse::reverse(&self.0).into_series()
+        self.apply_physical(|ca| ca.reverse())
     }
 
-    fn as_single_ptr(&mut self) -> PolarsResult<usize> {
-        self.0.as_single_ptr()
+    fn shift(&self, periods: i64) -> Series {
+        self.apply_physical(|ca| ca.shift(periods))
     }
 
-    fn shift(&self, periods: i64) -> Series {
-        ChunkShift::shift(&self.0, periods).into_series()
+    fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
+        Arc::new(SeriesWrap(Clone::clone(&self.0)))
     }
 
     fn _sum_as_series(&self) -> Series {
-        ChunkAggSeries::sum_as_series(&self.0)
-    }
-    fn max_as_series(&self) -> Series {
-        ChunkAggSeries::max_as_series(&self.0)
+        self.apply_physical(|ca| {
+            let sum = ca.sum();
+            Int128Chunked::from_slice_options(self.name(), &[sum])
+        })
     }
     fn min_as_series(&self) -> Series {
-        ChunkAggSeries::min_as_series(&self.0)
-    }
-    fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
-        Arc::new(SeriesWrap(Clone::clone(&self.0)))
-    }
-    fn as_any(&self) -> &dyn Any {
-        &self.0
+        self.apply_physical(|ca| {
+            let min = ca.min();
+            Int128Chunked::from_slice_options(self.name(), &[min])
+        })
     }
-
-    /// Get a hold to self as `Any` trait reference.
-    /// Only implemented for ObjectType
-    fn as_any_mut(&mut self) -> &mut dyn Any {
-        &mut self.0
+    fn max_as_series(&self) -> Series {
+        self.apply_physical(|ca| {
+            let max = ca.max();
+            Int128Chunked::from_slice_options(self.name(), &[max])
+        })
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/mod.rs`

 * *Files 0% similar despite different names*

```diff
@@ -371,15 +371,14 @@
             }
 
             fn get(&self, index: usize) -> PolarsResult<AnyValue> {
                 self.0.get_any_value(index)
             }
 
             #[inline]
-            #[cfg(feature = "private")]
             unsafe fn get_unchecked(&self, index: usize) -> AnyValue {
                 self.0.get_any_value_unchecked(index)
             }
 
             fn sort_with(&self, options: SortOptions) -> Series {
                 ChunkSort::sort_with(&self.0, options).into_series()
             }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/null.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/null.rs`

 * *Files 10% similar despite different names*

```diff
@@ -114,15 +114,15 @@
     }
 
     fn has_validity(&self) -> bool {
         true
     }
 
     fn rechunk(&self) -> Series {
-        self.clone().into_series()
+        NullChunked::new(self.name.clone(), self.len()).into_series()
     }
 
     fn cast(&self, data_type: &DataType) -> PolarsResult<Series> {
         Ok(Series::full_null(self.name.as_ref(), self.len(), data_type))
     }
 
     fn null_count(&self) -> usize {
@@ -161,20 +161,24 @@
     }
 
     fn shift(&self, _periods: i64) -> Series {
         self.clone().into_series()
     }
 
     fn append(&mut self, other: &Series) -> PolarsResult<()> {
-        *self = NullChunked::new(self.name.clone(), self.len() + other.len());
+        polars_ensure!(other.dtype() == &DataType::Null, ComputeError: "expected null dtype");
+        // we don't create a new null array to keep probability of aligned chunks higher
+        self.chunks.extend(other.chunks().iter().cloned());
+        self.length += other.len() as IdxSize;
         Ok(())
     }
 
     fn extend(&mut self, other: &Series) -> PolarsResult<()> {
-        self.append(other)
+        *self = NullChunked::new(self.name.clone(), self.len() + other.len());
+        Ok(())
     }
 
     fn clone_inner(&self) -> Arc<dyn SeriesTrait> {
         Arc::new(self.clone())
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/object.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/object.rs`

 * *Files 0% similar despite different names*

```diff
@@ -5,14 +5,15 @@
 
 use crate::chunked_array::object::compare_inner::{IntoPartialEqInner, PartialEqInner};
 use crate::chunked_array::object::PolarsObjectSafe;
 use crate::frame::groupby::{GroupsProxy, IntoGroupsProxy};
 use crate::prelude::*;
 use crate::series::implementations::SeriesWrap;
 use crate::series::private::{PrivateSeries, PrivateSeriesNumeric};
+#[cfg(feature = "chunked_ids")]
 use crate::series::IsSorted;
 
 impl<T: PolarsObject> PrivateSeriesNumeric for SeriesWrap<ObjectChunked<T>> {}
 
 impl<T> PrivateSeries for SeriesWrap<ObjectChunked<T>>
 where
     T: PolarsObject,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/struct_.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/struct_.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/implementations/utf8.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/implementations/utf8.rs`

 * *Files 1% similar despite different names*

```diff
@@ -227,15 +227,14 @@
     }
 
     fn get(&self, index: usize) -> PolarsResult<AnyValue> {
         self.0.get_any_value(index)
     }
 
     #[inline]
-    #[cfg(feature = "private")]
     unsafe fn get_unchecked(&self, index: usize) -> AnyValue {
         self.0.get_any_value_unchecked(index)
     }
 
     fn sort_with(&self, options: SortOptions) -> Series {
         ChunkSort::sort_with(&self.0, options).into_series()
     }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/into.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/into.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/iterator.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/iterator.rs`

 * *Files 6% similar despite different names*

```diff
@@ -55,15 +55,14 @@
         let ca: Utf8Chunked = iter.into_iter().collect();
         ca.into_series()
     }
 }
 
 pub type SeriesPhysIter<'a> = Box<dyn ExactSizeIterator<Item = AnyValue<'a>> + 'a>;
 
-#[cfg(any(feature = "rows", feature = "dtype-struct"))]
 impl Series {
     /// iterate over [`Series`] as [`AnyValue`].
     ///
     /// # Panics
     /// This will panic if the array is not rechunked first.
     pub fn iter(&self) -> SeriesIter<'_> {
         let dtype = self.dtype();
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -7,15 +7,14 @@
 mod comparison;
 mod from;
 pub mod implementations;
 mod into;
 pub(crate) mod iterator;
 pub mod ops;
 mod series_trait;
-#[cfg(feature = "private")]
 pub mod unstable;
 
 use std::borrow::Cow;
 use std::hash::{Hash, Hasher};
 use std::ops::Deref;
 use std::sync::Arc;
 
@@ -171,15 +170,14 @@
                 Series::new(self.name(), [av]).slice(0, 0)
             };
         }
         Series::new_empty(self.name(), self.dtype())
     }
 
     #[doc(hidden)]
-    #[cfg(feature = "private")]
     pub fn _get_inner_mut(&mut self) -> &mut dyn SeriesTrait {
         if Arc::weak_count(&self.0) + Arc::strong_count(&self.0) != 1 {
             self.0 = self.0.clone_inner();
         }
         Arc::get_mut(&mut self.0).expect("implementation error")
     }
 
@@ -346,50 +344,56 @@
             .and_then(|s| s.f64().unwrap().get(0).and_then(T::from))
     }
 
     /// Explode a list Series. This expands every item to a new row..
     pub fn explode(&self) -> PolarsResult<Series> {
         match self.dtype() {
             DataType::List(_) => self.list().unwrap().explode(),
+            #[cfg(feature = "dtype-array")]
+            DataType::Array(_, _) => self.array().unwrap().explode(),
             _ => Ok(self.clone()),
         }
     }
 
     /// Check if float value is NaN (note this is different than missing/ null)
     pub fn is_nan(&self) -> PolarsResult<BooleanChunked> {
         match self.dtype() {
             DataType::Float32 => Ok(self.f32().unwrap().is_nan()),
             DataType::Float64 => Ok(self.f64().unwrap().is_nan()),
+            dt if dt.is_numeric() => Ok(BooleanChunked::full(self.name(), false, self.len())),
             _ => polars_bail!(opq = is_nan, self.dtype()),
         }
     }
 
     /// Check if float value is NaN (note this is different than missing/ null)
     pub fn is_not_nan(&self) -> PolarsResult<BooleanChunked> {
         match self.dtype() {
             DataType::Float32 => Ok(self.f32().unwrap().is_not_nan()),
             DataType::Float64 => Ok(self.f64().unwrap().is_not_nan()),
+            dt if dt.is_numeric() => Ok(BooleanChunked::full(self.name(), true, self.len())),
             _ => polars_bail!(opq = is_not_nan, self.dtype()),
         }
     }
 
-    /// Check if float value is finite
+    /// Check if numeric value is finite
     pub fn is_finite(&self) -> PolarsResult<BooleanChunked> {
         match self.dtype() {
             DataType::Float32 => Ok(self.f32().unwrap().is_finite()),
             DataType::Float64 => Ok(self.f64().unwrap().is_finite()),
+            dt if dt.is_numeric() => Ok(BooleanChunked::full(self.name(), true, self.len())),
             _ => polars_bail!(opq = is_finite, self.dtype()),
         }
     }
 
     /// Check if float value is infinite
     pub fn is_infinite(&self) -> PolarsResult<BooleanChunked> {
         match self.dtype() {
             DataType::Float32 => Ok(self.f32().unwrap().is_infinite()),
             DataType::Float64 => Ok(self.f64().unwrap().is_infinite()),
+            dt if dt.is_numeric() => Ok(BooleanChunked::full(self.name(), false, self.len())),
             _ => polars_bail!(opq = is_infinite, self.dtype()),
         }
     }
 
     /// Create a new ChunkedArray with values from self where the mask evaluates `true` and values
     /// from `other` where the mask evaluates `false`
     #[cfg(feature = "zip_with")]
@@ -863,15 +867,14 @@
             Float32 => a.f32().unwrap().abs().into_series(),
             Float64 => a.f64().unwrap().abs().into_series(),
             dt => polars_bail!(opq = abs, dt),
         };
         out.cast(self.dtype())
     }
 
-    #[cfg(feature = "private")]
     // used for formatting
     pub fn str_value(&self, index: usize) -> PolarsResult<Cow<str>> {
         let out = match self.0.get(index)? {
             AnyValue::Utf8(s) => Cow::Borrowed(s),
             AnyValue::Null => Cow::Borrowed("null"),
             #[cfg(feature = "dtype-categorical")]
             AnyValue::Categorical(idx, rev, arr) => {
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/diff.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/diff.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/downcast.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/downcast.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/ewm.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/ewm.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/moment.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/moment.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/null.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/null.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/pct_change.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/pct_change.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/round.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/round.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/to_list.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/to_list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/ops/unique.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/ops/unique.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/series_trait.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/series_trait.rs`

 * *Files 1% similar despite different names*

```diff
@@ -352,15 +352,14 @@
     /// Get a single value by index. Don't use this operation for loops as a runtime cast is
     /// needed for every iteration.
     ///
     /// This may refer to physical types
     ///
     /// # Safety
     /// Does not do any bounds checking
-    #[cfg(feature = "private")]
     unsafe fn get_unchecked(&self, _index: usize) -> AnyValue {
         invalid_operation_panic!(get_unchecked, self)
     }
 
     fn sort_with(&self, _options: SortOptions) -> Series {
         invalid_operation_panic!(sort_with, self)
     }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/series/unstable.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/series/unstable.rs`

 * *Files 11% similar despite different names*

```diff
@@ -3,15 +3,14 @@
 
 use polars_utils::unwrap::UnwrapUncheckedRelease;
 
 use crate::prelude::*;
 
 /// A wrapper type that should make it a bit more clear that we should not clone Series
 #[derive(Copy, Clone)]
-#[cfg(feature = "private")]
 pub struct UnstableSeries<'a> {
     lifetime: PhantomData<&'a Series>,
     // A series containing a single chunk ArrayRef
     // the ArrayRef will be replaced by amortized_iter
     // use with caution!
     container: *mut Series,
     // the ptr to the inner chunk, this saves some ptr chasing
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/testing.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/testing.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/utils/flatten.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/utils/flatten.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/utils/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/utils/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -10,15 +10,14 @@
 pub use polars_arrow::utils::{TrustMyLength, *};
 use rayon::prelude::*;
 pub use series::*;
 use smartstring::alias::String as SmartString;
 pub use supertype::*;
 pub use {arrow, rayon};
 
-#[cfg(feature = "private")]
 pub use crate::chunked_array::ops::sort::arg_sort_no_nulls;
 use crate::prelude::*;
 use crate::POOL;
 
 #[repr(transparent)]
 pub struct Wrap<T>(pub T);
 
@@ -105,15 +104,14 @@
                 $ca.slice((i * chunk_size) as $ty, len)
             })
             .collect();
         Ok(v)
     }};
 }
 
-#[cfg(feature = "private")]
 pub fn split_ca<T>(ca: &ChunkedArray<T>, n: usize) -> PolarsResult<Vec<ChunkedArray<T>>>
 where
     T: PolarsDataType,
 {
     split_array!(ca, n, i64)
 }
 
@@ -136,15 +134,14 @@
                 };
                 (partition * chunk_size, len)
             })
             .collect_trusted()
     }
 }
 
-#[cfg(feature = "private")]
 #[doc(hidden)]
 pub fn split_series(s: &Series, n: usize) -> PolarsResult<Vec<Series>> {
     split_array!(s, n, i64)
 }
 
 pub fn split_df_as_ref(df: &DataFrame, n: usize) -> PolarsResult<Vec<DataFrame>> {
     let total_len = df.height();
@@ -176,15 +173,14 @@
             out.push(df)
         }
     }
 
     Ok(out)
 }
 
-#[cfg(feature = "private")]
 #[doc(hidden)]
 /// Split a [`DataFrame`] into `n` parts. We take a `&mut` to be able to repartition/align chunks.
 pub fn split_df(df: &mut DataFrame, n: usize) -> PolarsResult<Vec<DataFrame>> {
     if n == 0 || df.height() == 0 {
         return Ok(vec![df.clone()]);
     }
     // make sure that chunks are aligned.
@@ -194,15 +190,14 @@
 
 pub fn slice_slice<T>(vals: &[T], offset: i64, len: usize) -> &[T] {
     let (raw_offset, slice_len) = slice_offsets(offset, len, vals.len());
     &vals[raw_offset..raw_offset + slice_len]
 }
 
 #[inline]
-#[cfg(feature = "private")]
 #[doc(hidden)]
 pub fn slice_offsets(offset: i64, length: usize, array_len: usize) -> (usize, usize) {
     let abs_offset = offset.unsigned_abs() as usize;
 
     // The offset counted from the start of the array
     // negative index
     if offset < 0 {
@@ -519,15 +514,14 @@
     ($($col_name:expr => $slice:expr), + $(,)?) => {
         {
             $crate::prelude::DataFrame::new(vec![$($crate::prelude::Series::new($col_name, $slice),)+])
         }
     }
 }
 
-#[cfg(feature = "private")]
 pub fn get_time_units(tu_l: &TimeUnit, tu_r: &TimeUnit) -> TimeUnit {
     use TimeUnit::*;
     match (tu_l, tu_r) {
         (Nanoseconds, Microseconds) => Microseconds,
         (_, Milliseconds) => Milliseconds,
         _ => *tu_l,
     }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/utils/series.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/utils/series.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-core/src/utils/supertype.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/src/utils/supertype.rs`

 * *Files 0% similar despite different names*

```diff
@@ -1,19 +1,17 @@
 use super::*;
 
 /// Given two datatypes, determine the supertype that both types can safely be cast to
-#[cfg(feature = "private")]
 pub fn try_get_supertype(l: &DataType, r: &DataType) -> PolarsResult<DataType> {
     get_supertype(l, r).ok_or_else(
         || polars_err!(ComputeError: "failed to determine supertype of {} and {}", l, r),
     )
 }
 
 /// Given two datatypes, determine the supertype that both types can safely be cast to
-#[cfg(feature = "private")]
 pub fn get_supertype(l: &DataType, r: &DataType) -> Option<DataType> {
     fn inner(l: &DataType, r: &DataType) -> Option<DataType> {
         use DataType::*;
         if l == r {
             return Some(l.clone());
         }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-algo/Cargo.toml` & `polars_lts_cpu-0.18.1/local_dependencies/polars-algo/Cargo.toml`

 * *Files 24% similar despite different names*

```diff
@@ -1,19 +1,20 @@
 [package]
 name = "polars-algo"
 version= "0.30.0"
 edition = "2021"
 license = "MIT"
 repository = "https://github.com/pola-rs/polars"
 description = "Algorithms built upon Polars primitives"
+resolver = "2"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
-polars-core = { version = "0.30.0", path = "../polars-core", features = ["private", "dtype-categorical", "asof_join"], default-features = false }
+polars-core = { version = "0.30.0", path = "../polars-core", features = ["dtype-categorical", "asof_join"], default-features = false }
 polars-lazy = { version = "0.30.0", path = "../polars-lazy", features = ["asof_join", "concat_str", "strings"] }
 polars-ops = { version = "0.30.0", path = "../polars-ops", features = ["dtype-categorical", "asof_join"], default-features = false }
 
 [package.metadata.docs.rs]
 all-features = true
 # defines the configuration attribute `docsrs`
 rustdoc-args = ["--cfg", "docsrs"]
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-algo/LICENSE` & `polars_lts_cpu-0.18.1/local_dependencies/polars-core/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-algo/src/algo.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-algo/src/algo.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/Cargo.toml` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/Cargo.toml`

 * *Files 1% similar despite different names*

```diff
@@ -2,26 +2,27 @@
 name = "polars-ops"
 version= "0.30.0"
 authors = ["ritchie46 <ritchie46@gmail.com>"]
 edition = "2021"
 license = "MIT"
 repository = "https://github.com/pola-rs/polars"
 description = "More operations on polars data structures"
+resolver = "2"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
 argminmax = { version = "0.6.1", default-features = false, features = ["float"] }
 base64 = { version = "0.21", optional = true }
 either= "1.8"
 hex = { version = "0.4", optional = true }
 jsonpath_lib = { version = "0.3.0", optional = true, git = "https://github.com/ritchie46/jsonpath", branch = "improve_compiled" }
 memchr= "2"
 polars-arrow = { version = "0.30.0", path = "../polars-arrow", default-features = false }
-polars-core = { version = "0.30.0", path = "../polars-core", features = ["private"], default-features = false }
+polars-core = { version = "0.30.0", path = "../polars-core", features = [], default-features = false }
 polars-json = { version = "0.30.0", optional = true, path = "../polars-json", default-features = false }
 polars-utils = { version = "0.30.0", path = "../polars-utils", default-features = false }
 serde = { version = "1", features = ["derive"], optional = true }
 serde_json = { version = "1", optional = true }
 smartstring= { version = "1" }
 
 [features]
@@ -75,17 +76,17 @@
 chunked_ids = ["polars-core/chunked_ids"]
 asof_join = ["polars-core/asof_join"]
 semi_anti_join = ["polars-core/semi_anti_join"]
 list_take = []
 
 [dependencies.arrow]
 package = "arrow2"
-# git = "https://github.com/jorgecarleitao/arrow2"
+git = "https://github.com/jorgecarleitao/arrow2"
 # git = "https://github.com/ritchie46/arrow2"
-# rev = "1491c6e8f4fd100f53c358e4f3ef1536d9e75090"
+rev = "fb5e4d591c7149df590a330365fae55d2370962f"
 # path = "../arrow2"
 # branch = "polars_2023-05-25"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/LICENSE` & `polars_lts_cpu-0.18.1/local_dependencies/polars-utils/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/array/min_max.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/array/min_max.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/array/sum_mean.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/array/sum_mean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/binary/namespace.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/binary/namespace.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/interpolate.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/interpolate.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/list/count.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/list/count.rs`

 * *Files 4% similar despite different names*

```diff
@@ -25,15 +25,15 @@
 }
 
 #[cfg(feature = "list_count")]
 pub fn list_count_match(ca: &ListChunked, value: AnyValue) -> PolarsResult<Series> {
     let value = Series::new("", [value]);
 
     let ca = ca.apply_to_inner(&|s| {
-        ChunkCompare::<&Series>::equal(&s, &value).map(|ca| ca.into_series())
+        ChunkCompare::<&Series>::equal_missing(&s, &value).map(|ca| ca.into_series())
     })?;
     let out = count_boolean_bits(&ca);
     Ok(out.into_series())
 }
 
 pub(super) fn count_boolean_bits(ca: &ListChunked) -> IdxCa {
     let chunks = ca
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/list/hash.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/list/hash.rs`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 use std::hash::Hash;
 
 use polars_core::export::_boost_hash_combine;
 use polars_core::export::ahash::{self};
 use polars_core::export::rayon::prelude::*;
 use polars_core::utils::NoNull;
 use polars_core::POOL;
-use polars_utils::HashSingle;
 
 use super::*;
 
 fn hash_agg<T>(ca: &ChunkedArray<T>, random_state: &ahash::RandomState) -> u64
 where
     T: PolarsIntegerType,
     T::Native: Hash,
@@ -27,15 +26,15 @@
     //  just some large prime
     let null_hash = 2413670057;
 
     ca.downcast_iter().for_each(|arr| {
         for opt_v in arr.iter() {
             match opt_v {
                 Some(v) => {
-                    let r = random_state.hash_single(v);
+                    let r = random_state.hash_one(v);
                     hash_agg = _boost_hash_combine(hash_agg, r);
                 }
                 None => {
                     hash_agg = _boost_hash_combine(hash_agg, null_hash);
                 }
             }
         }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/list/min_max.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/list/min_max.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/list/namespace.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/list/namespace.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/list/sum_mean.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/list/sum_mean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/list/to_struct.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/list/to_struct.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/nan_propagating_aggregate.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/nan_propagating_aggregate.rs`

 * *Files 1% similar despite different names*

```diff
@@ -132,20 +132,21 @@
                 let arr = ca.downcast_iter().next().unwrap();
                 let values = arr.values().as_slice();
                 let offset_iter = groups_slice.iter().map(|[first, len]| (*first, *len));
                 let arr = match arr.validity() {
                     None => _rolling_apply_agg_window_no_nulls::<MaxWindow<_>, _, _>(
                         values,
                         offset_iter,
+                        None,
                     ),
                     Some(validity) => _rolling_apply_agg_window_nulls::<
                         rolling::nulls::MaxWindow<_>,
                         _,
                         _,
-                    >(values, validity, offset_iter),
+                    >(values, validity, offset_iter, None),
                 };
                 ChunkedArray::from_chunks("", vec![arr]).into_series()
             } else {
                 _agg_helper_slice::<T, _>(groups_slice, |[first, len]| {
                     debug_assert!(len <= ca.len() as IdxSize);
                     match len {
                         0 => None,
@@ -203,20 +204,21 @@
                 let arr = ca.downcast_iter().next().unwrap();
                 let values = arr.values().as_slice();
                 let offset_iter = groups_slice.iter().map(|[first, len]| (*first, *len));
                 let arr = match arr.validity() {
                     None => _rolling_apply_agg_window_no_nulls::<MinWindow<_>, _, _>(
                         values,
                         offset_iter,
+                        None,
                     ),
                     Some(validity) => _rolling_apply_agg_window_nulls::<
                         rolling::nulls::MinWindow<_>,
                         _,
                         _,
-                    >(values, validity, offset_iter),
+                    >(values, validity, offset_iter, None),
                 };
                 ChunkedArray::from_chunks("", vec![arr]).into_series()
             } else {
                 _agg_helper_slice::<T, _>(groups_slice, |[first, len]| {
                     debug_assert!(len <= ca.len() as IdxSize);
                     match len {
                         0 => None,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/set.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/set.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/strings/case.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/strings/case.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/strings/json_path.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/strings/json_path.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/strings/justify.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/strings/justify.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/strings/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/strings/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/strings/namespace.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/strings/namespace.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/strings/replace.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/strings/replace.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/chunked_array/top_k.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/chunked_array/top_k.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/frame/join/merge_sorted.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/frame/join/merge_sorted.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/frame/join/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/frame/join/mod.rs`

 * *Files 4% similar despite different names*

```diff
@@ -65,95 +65,83 @@
     /// +--------+----------------------+---------------------+
     /// ```
     fn join<I, S>(
         &self,
         other: &DataFrame,
         left_on: I,
         right_on: I,
-        how: JoinType,
-        suffix: Option<String>,
+        args: JoinArgs,
     ) -> PolarsResult<DataFrame>
     where
         I: IntoIterator<Item = S>,
         S: AsRef<str>,
     {
         let df_left = self.to_df();
         #[cfg(feature = "cross_join")]
-        if let JoinType::Cross = how {
-            return df_left.cross_join(other, suffix.as_deref(), None);
+        if let JoinType::Cross = args.how {
+            return df_left.cross_join(other, args.suffix.as_deref(), None);
         }
         let selected_left = df_left.select_series(left_on)?;
         let selected_right = other.select_series(right_on)?;
-        self._join_impl(
-            other,
-            selected_left,
-            selected_right,
-            how,
-            suffix,
-            None,
-            true,
-            false,
-        )
+        self._join_impl(other, selected_left, selected_right, args, true, false)
     }
 
     #[doc(hidden)]
     #[allow(clippy::too_many_arguments)]
     fn _join_impl(
         &self,
         other: &DataFrame,
         selected_left: Vec<Series>,
         selected_right: Vec<Series>,
-        how: JoinType,
-        suffix: Option<String>,
-        slice: Option<(i64, usize)>,
+        args: JoinArgs,
         _check_rechunk: bool,
         _verbose: bool,
     ) -> PolarsResult<DataFrame> {
         let left_df = self.to_df();
+        args.validation
+            .is_valid_join(&args.how, selected_left.len())?;
 
         #[cfg(feature = "cross_join")]
-        if let JoinType::Cross = how {
-            return left_df.cross_join(other, suffix.as_deref(), slice);
+        if let JoinType::Cross = args.how {
+            return left_df.cross_join(other, args.suffix.as_deref(), args.slice);
         }
 
         #[cfg(feature = "chunked_ids")]
         {
             // a left join create chunked-ids
             // the others not yet.
             // TODO! change this to other join types once they support chunked-id joins
             if _check_rechunk
-                && !(matches!(how, JoinType::Left)
+                && !(matches!(args.how, JoinType::Left)
                     || std::env::var("POLARS_NO_CHUNKED_JOIN").is_ok())
             {
                 let mut left = Cow::Borrowed(left_df);
                 let mut right = Cow::Borrowed(other);
                 if left_df.should_rechunk() {
                     if _verbose {
-                        eprintln!("{:?} join triggered a rechunk of the left dataframe: {} columns are affected", how, left_df.width());
+                        eprintln!("{:?} join triggered a rechunk of the left dataframe: {} columns are affected", args.how, left_df.width());
                     }
 
                     let mut tmp_left = left_df.clone();
                     tmp_left.as_single_chunk_par();
                     left = Cow::Owned(tmp_left);
                 }
                 if other.should_rechunk() {
                     if _verbose {
-                        eprintln!("{:?} join triggered a rechunk of the right dataframe: {} columns are affected", how, other.width());
+                        eprintln!("{:?} join triggered a rechunk of the right dataframe: {} columns are affected", args.how, other.width());
                     }
                     let mut tmp_right = other.clone();
                     tmp_right.as_single_chunk_par();
                     right = Cow::Owned(tmp_right);
                 }
                 return left._join_impl(
                     &right,
                     selected_left,
                     selected_right,
-                    how,
-                    suffix,
-                    slice,
+                    args,
                     false,
                     _verbose,
                 );
             }
         }
 
         polars_ensure!(
@@ -185,29 +173,29 @@
             _check_categorical_src(l.dtype(), r.dtype())?
         }
 
         // Single keys
         if selected_left.len() == 1 {
             let s_left = left_df.column(selected_left[0].name())?;
             let s_right = other.column(selected_right[0].name())?;
-            return match how {
+            return match args.how {
                 JoinType::Inner => {
-                    left_df._inner_join_from_series(other, s_left, s_right, suffix, slice, _verbose)
+                    left_df._inner_join_from_series(other, s_left, s_right, args, _verbose)
                 }
                 JoinType::Left => {
-                    left_df._left_join_from_series(other, s_left, s_right, suffix, slice, _verbose)
-                }
-                JoinType::Outer => {
-                    left_df._outer_join_from_series(other, s_left, s_right, suffix, slice)
+                    left_df._left_join_from_series(other, s_left, s_right, args, _verbose)
                 }
+                JoinType::Outer => left_df._outer_join_from_series(other, s_left, s_right, args),
                 #[cfg(feature = "semi_anti_join")]
-                JoinType::Anti => left_df._semi_anti_join_from_series(s_left, s_right, slice, true),
+                JoinType::Anti => {
+                    left_df._semi_anti_join_from_series(s_left, s_right, args.slice, true)
+                }
                 #[cfg(feature = "semi_anti_join")]
                 JoinType::Semi => {
-                    left_df._semi_anti_join_from_series(s_left, s_right, slice, false)
+                    left_df._semi_anti_join_from_series(s_left, s_right, args.slice, false)
                 }
                 #[cfg(feature = "asof_join")]
                 JoinType::AsOf(options) => {
                     let left_on = selected_left[0].name();
                     let right_on = selected_right[0].name();
 
                     match (options.left_by, options.right_by) {
@@ -215,25 +203,25 @@
                             other,
                             left_on,
                             right_on,
                             left_by,
                             right_by,
                             options.strategy,
                             options.tolerance,
-                            suffix.as_deref(),
-                            slice,
+                            args.suffix.as_deref(),
+                            args.slice,
                         ),
                         (None, None) => left_df._join_asof(
                             other,
                             left_on,
                             right_on,
                             options.strategy,
                             options.tolerance,
-                            suffix,
-                            slice,
+                            args.suffix,
+                            args.slice,
                         ),
                         _ => {
                             panic!("expected by arguments on both sides")
                         }
                     }
                 }
                 JoinType::Cross => {
@@ -254,62 +242,57 @@
         }
         // make sure that we don't have logical types.
         // we don't overwrite the original selected as that might be used to create a column in the new df
         let selected_left_physical = _to_physical_and_bit_repr(&selected_left);
         let selected_right_physical = _to_physical_and_bit_repr(&selected_right);
 
         // multiple keys
-        match how {
+        match args.how {
             JoinType::Inner => {
                 let left = DataFrame::new_no_checks(selected_left_physical);
                 let right = DataFrame::new_no_checks(selected_right_physical);
                 let (mut left, mut right, swap) = det_hash_prone_order!(left, right);
                 let (join_idx_left, join_idx_right) =
                     _inner_join_multiple_keys(&mut left, &mut right, swap);
                 let mut join_idx_left = &*join_idx_left;
                 let mut join_idx_right = &*join_idx_right;
 
-                if let Some((offset, len)) = slice {
+                if let Some((offset, len)) = args.slice {
                     join_idx_left = slice_slice(join_idx_left, offset, len);
                     join_idx_right = slice_slice(join_idx_right, offset, len);
                 }
 
                 let (df_left, df_right) = POOL.join(
                     // safety: join indices are known to be in bounds
                     || unsafe { left_df._create_left_df_from_slice(join_idx_left, false, !swap) },
                     || unsafe {
                         // remove join columns
                         remove_selected(other, &selected_right)
                             ._take_unchecked_slice(join_idx_right, true)
                     },
                 );
-                _finish_join(df_left, df_right, suffix.as_deref())
+                _finish_join(df_left, df_right, args.suffix.as_deref())
             }
             JoinType::Left => {
                 let mut left = DataFrame::new_no_checks(selected_left_physical);
                 let mut right = DataFrame::new_no_checks(selected_right_physical);
                 let ids = _left_join_multiple_keys(&mut left, &mut right, None, None);
 
-                left_df._finish_left_join(
-                    ids,
-                    &remove_selected(other, &selected_right),
-                    suffix,
-                    slice,
-                )
+                left_df._finish_left_join(ids, &remove_selected(other, &selected_right), args)
             }
             JoinType::Outer => {
                 let left = DataFrame::new_no_checks(selected_left_physical);
                 let right = DataFrame::new_no_checks(selected_right_physical);
 
                 let (mut left, mut right, swap) = det_hash_prone_order!(left, right);
                 let opt_join_tuples = _outer_join_multiple_keys(&mut left, &mut right, swap);
 
                 let mut opt_join_tuples = &*opt_join_tuples;
 
-                if let Some((offset, len)) = slice {
+                if let Some((offset, len)) = args.slice {
                     opt_join_tuples = slice_slice(opt_join_tuples, offset, len);
                 }
 
                 // Take the left and right dataframes by join tuples
                 let (df_left, df_right) = POOL.join(
                     || unsafe {
                         remove_selected(left_df, &selected_left).take_opt_iter_unchecked(
@@ -331,33 +314,33 @@
                 for (s_left, s_right) in selected_left.iter().zip(&selected_right) {
                     let mut s = s_left.zip_outer_join_column(s_right, opt_join_tuples);
                     s.rename(s_left.name());
                     keys.push(s)
                 }
                 keys.extend_from_slice(df_left.get_columns());
                 let df_left = DataFrame::new_no_checks(keys);
-                _finish_join(df_left, df_right, suffix.as_deref())
+                _finish_join(df_left, df_right, args.suffix.as_deref())
             }
             #[cfg(feature = "asof_join")]
             JoinType::AsOf(_) => polars_bail!(
                 ComputeError: "asof join not supported for join on multiple keys"
             ),
             #[cfg(feature = "semi_anti_join")]
             JoinType::Anti | JoinType::Semi => {
                 let mut left = DataFrame::new_no_checks(selected_left_physical);
                 let mut right = DataFrame::new_no_checks(selected_right_physical);
 
-                let idx = if matches!(how, JoinType::Anti) {
+                let idx = if matches!(args.how, JoinType::Anti) {
                     _left_anti_multiple_keys(&mut left, &mut right)
                 } else {
                     _left_semi_multiple_keys(&mut left, &mut right)
                 };
                 // Safety:
                 // indices are in bounds
-                Ok(unsafe { left_df._finish_anti_semi_join(&idx, slice) })
+                Ok(unsafe { left_df._finish_anti_semi_join(&idx, args.slice) })
             }
             JoinType::Cross => {
                 unreachable!()
             }
         }
     }
 
@@ -377,15 +360,15 @@
         left_on: I,
         right_on: I,
     ) -> PolarsResult<DataFrame>
     where
         I: IntoIterator<Item = S>,
         S: AsRef<str>,
     {
-        self.join(other, left_on, right_on, JoinType::Inner, None)
+        self.join(other, left_on, right_on, JoinArgs::new(JoinType::Inner))
     }
 
     /// Perform a left join on two DataFrames
     /// # Example
     ///
     /// ```no_run
     /// # use polars_core::prelude::*;
@@ -419,15 +402,15 @@
     /// +-----------------+--------+
     /// ```
     fn left_join<I, S>(&self, other: &DataFrame, left_on: I, right_on: I) -> PolarsResult<DataFrame>
     where
         I: IntoIterator<Item = S>,
         S: AsRef<str>,
     {
-        self.join(other, left_on, right_on, JoinType::Left, None)
+        self.join(other, left_on, right_on, JoinArgs::new(JoinType::Left))
     }
 
     /// Perform an outer join on two DataFrames
     /// # Example
     ///
     /// ```
     /// # use polars_core::prelude::*;
@@ -441,56 +424,55 @@
         left_on: I,
         right_on: I,
     ) -> PolarsResult<DataFrame>
     where
         I: IntoIterator<Item = S>,
         S: AsRef<str>,
     {
-        self.join(other, left_on, right_on, JoinType::Outer, None)
+        self.join(other, left_on, right_on, JoinArgs::new(JoinType::Outer))
     }
 }
 
 trait DataFrameJoinOpsPrivate: IntoDf {
     // hack for a macro
     fn len(&self) -> usize {
         self.to_df().height()
     }
 
     fn _inner_join_from_series(
         &self,
         other: &DataFrame,
         s_left: &Series,
         s_right: &Series,
-        suffix: Option<String>,
-        slice: Option<(i64, usize)>,
+        args: JoinArgs,
         verbose: bool,
     ) -> PolarsResult<DataFrame> {
         let left_df = self.to_df();
         #[cfg(feature = "dtype-categorical")]
         _check_categorical_src(s_left.dtype(), s_right.dtype())?;
         let ((join_tuples_left, join_tuples_right), sorted) =
-            _sort_or_hash_inner(s_left, s_right, verbose);
+            _sort_or_hash_inner(s_left, s_right, verbose, args.validation)?;
 
         let mut join_tuples_left = &*join_tuples_left;
         let mut join_tuples_right = &*join_tuples_right;
 
-        if let Some((offset, len)) = slice {
+        if let Some((offset, len)) = args.slice {
             join_tuples_left = slice_slice(join_tuples_left, offset, len);
             join_tuples_right = slice_slice(join_tuples_right, offset, len);
         }
 
         let (df_left, df_right) = POOL.join(
             // safety: join indices are known to be in bounds
             || unsafe { left_df._create_left_df_from_slice(join_tuples_left, false, sorted) },
             || unsafe {
                 other
                     .drop(s_right.name())
                     .unwrap()
                     ._take_unchecked_slice(join_tuples_right, true)
             },
         );
-        _finish_join(df_left, df_right, suffix.as_deref())
+        _finish_join(df_left, df_right, args.suffix.as_deref())
     }
 }
 
 impl DataFrameJoinOps for DataFrame {}
 impl DataFrameJoinOpsPrivate for DataFrame {}
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/frame/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/frame/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/frame/pivot/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/frame/pivot/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/frame/pivot/positioning.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/frame/pivot/positioning.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/approx_algo/hyperloglogplus.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/approx_algo/hyperloglogplus.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/approx_unique.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/approx_unique.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/arg_min_max.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/arg_min_max.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/floor_divide.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/floor_divide.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/fused.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/fused.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/is_first.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/is_first.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/is_unique.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/is_unique.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/log.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/log.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/rolling.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/rolling.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/search_sorted.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/search_sorted.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/to_dummies.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/to_dummies.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-ops/src/series/ops/various.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-ops/src/series/ops/various.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-json/Cargo.toml` & `polars_lts_cpu-0.18.1/local_dependencies/polars-json/Cargo.toml`

 * *Files 23% similar despite different names*

```diff
@@ -2,14 +2,15 @@
 name = "polars-json"
 version= "0.30.0"
 authors = ["ritchie46 <ritchie46@gmail.com>"]
 edition = "2021"
 license = "MIT"
 repository = "https://github.com/pola-rs/polars"
 description = "JSON related logic for the Polars DataFrame library"
+resolver = "2"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
 ahash= "0.8"
 fallible-streaming-iterator = "0.1"
 hashbrown= { version = "0.13.1", features = ["rayon", "ahash"] }
@@ -18,17 +19,17 @@
 polars-arrow = { version = "0.30.0", path = "../polars-arrow", default-features = false }
 polars-error = { version = "0.30.0", path = "../polars-error" }
 polars-utils = { version = "0.30.0", path = "../polars-utils" }
 simd-json = { version = "0.10", features = ["allow-non-simd", "known-key"] }
 
 [dependencies.arrow]
 package = "arrow2"
-# git = "https://github.com/jorgecarleitao/arrow2"
+git = "https://github.com/jorgecarleitao/arrow2"
 # git = "https://github.com/ritchie46/arrow2"
-# rev = "1491c6e8f4fd100f53c358e4f3ef1536d9e75090"
+rev = "fb5e4d591c7149df590a330365fae55d2370962f"
 # path = "../arrow2"
 # branch = "polars_2023-05-25"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-json/src/json/deserialize.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-json/src/json/deserialize.rs`

 * *Files 2% similar despite different names*

```diff
@@ -374,20 +374,22 @@
         DataType::LargeList(_) => Box::new(deserialize_list(rows, data_type)),
         DataType::LargeBinary => Box::new(deserialize_binary(rows)),
         DataType::Struct(_) => Box::new(deserialize_struct(rows, data_type)),
         _ => todo!(),
     }
 }
 
-/// Deserializes a `json` [`Value`] into an [`Array`] of [`DataType`]
+/// Deserializes a `json` [`Value`][Value] into an [`Array`] of [`DataType`]
 /// This is CPU-bounded.
 /// # Error
 /// This function errors iff either:
-/// * `json` is not a [`Value::Array`]
+/// * `json` is not an [`Array`]
 /// * `data_type` is neither [`DataType::List`] nor [`DataType::LargeList`]
+///
+/// [Value]: simd_json::value::Value
 pub fn deserialize(json: &BorrowedValue, data_type: DataType) -> Result<Box<dyn Array>, Error> {
     match json {
         BorrowedValue::Array(rows) => match data_type {
             DataType::LargeList(inner) => Ok(_deserialize(rows, inner.data_type)),
             _ => todo!("read an Array from a non-Array data type"),
         },
         _ => todo!("read an Array from a non-Array JSON"),
@@ -415,27 +417,27 @@
             )),
             _ => allocate_array(inner),
         },
         _ => todo!(),
     }
 }
 
-/// Deserializes a `json` [`Value`] serialized in Pandas record format into
+/// Deserializes a `json` [`simd_json::value::Value`] serialized in Pandas record format into
 /// a [`Chunk`].
 ///
 /// Uses the `Schema` provided, which can be inferred from arbitrary JSON with
 /// [`infer_records_schema`].
 ///
 /// This is CPU-bounded.
 ///
 /// # Errors
 ///
 /// This function errors iff either:
 ///
-/// * `json` is not a [`Value::Array`]
+/// * `json` is not an [`Array`]
 /// * `data_type` contains any incompatible types:
 ///   * [`DataType::Struct`]
 ///   * [`DataType::Dictionary`]
 ///   * [`DataType::LargeList`]
 pub fn deserialize_records(json: &BorrowedValue, schema: &Schema) -> PolarsResult<Chunk<ArrayRef>> {
     let mut results = schema
         .fields
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-json/src/json/infer_schema.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-json/src/json/infer_schema.rs`

 * *Files 2% similar despite different names*

```diff
@@ -6,28 +6,32 @@
 use simd_json::borrowed::Object;
 use simd_json::{BorrowedValue, StaticNode};
 
 use super::*;
 
 const ITEM_NAME: &str = "item";
 
-/// Infers [`DataType`] from [`Value`].
+/// Infers [`DataType`] from [`Value`][Value].
+///
+/// [Value]: simd_json::value::Value
 pub fn infer(json: &BorrowedValue) -> PolarsResult<DataType> {
     Ok(match json {
         BorrowedValue::Static(StaticNode::Bool(_)) => DataType::Boolean,
         BorrowedValue::Static(StaticNode::U64(_) | StaticNode::I64(_)) => DataType::Int64,
         BorrowedValue::Static(StaticNode::F64(_)) => DataType::Float64,
         BorrowedValue::Static(StaticNode::Null) => DataType::Null,
         BorrowedValue::Array(array) => infer_array(array)?,
         BorrowedValue::String(_) => DataType::LargeUtf8,
         BorrowedValue::Object(inner) => infer_object(inner)?,
     })
 }
 
-/// Infers [`Schema`] from JSON [`Value`] in (pandas-compatible) records format.
+/// Infers [`Schema`] from JSON [`Value`][Value] in (pandas-compatible) records format.
+///
+/// [Value]: simd_json::value::Value
 pub fn infer_records_schema(json: &BorrowedValue) -> PolarsResult<Schema> {
     let outer_array = match json {
         BorrowedValue::Array(array) => Ok(array),
         _ => Err(PolarsError::ComputeError(
             "outer type is not an array".into(),
         )),
     }?;
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-json/src/ndjson/deserialize.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-json/src/ndjson/deserialize.rs`

 * *Files 12% similar despite different names*

```diff
@@ -1,12 +1,15 @@
 use simd_json::BorrowedValue;
 
 use super::*;
 
-/// Deserializes an iterator of rows into an [`Array`] of [`DataType`].
+/// Deserializes an iterator of rows into an [`Array`][Array] of [`DataType`].
+///
+/// [Array]: arrow::array::Array
+///
 /// # Implementation
 /// This function is CPU-bounded.
 /// This function is guaranteed to return an array of length equal to the length
 /// # Errors
 /// This function errors iff any of the rows is not a valid JSON (i.e. the format is not valid NDJSON).
 pub fn deserialize_iter<'a>(
     rows: impl Iterator<Item = &'a str>,
@@ -16,15 +19,17 @@
 ) -> PolarsResult<ArrayRef> {
     let mut buf = String::with_capacity(buf_size + count + 2);
     buf.push('[');
     for row in rows {
         buf.push_str(row);
         buf.push(',')
     }
-    let _ = buf.pop();
+    if buf.len() > 1 {
+        let _ = buf.pop();
+    }
     buf.push(']');
     let slice = unsafe { buf.as_bytes_mut() };
     let out = simd_json::to_borrowed_value(slice)
         .map_err(|e| PolarsError::ComputeError(format!("json parsing error: '{e}'").into()))?;
     if let BorrowedValue::Array(rows) = out {
         Ok(super::super::json::deserialize::_deserialize(
             &rows, data_type,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-json/src/ndjson/file.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-json/src/ndjson/file.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/Cargo.toml` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/Cargo.toml`

 * *Files 22% similar despite different names*

```diff
@@ -1,50 +1,50 @@
 [package]
 name = "polars-time"
 version= "0.30.0"
 authors = ["ritchie46 <ritchie46@gmail.com>"]
 edition = "2021"
 license = "MIT"
 description = "Time related code for the polars dataframe library"
+resolver = "2"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
 atoi = "2.0.0"
 chrono = { version = "0.4", default-features = false, features = ["std"] }
 chrono-tz = { version = "0.8", optional = true }
 now = "0.1"
 once_cell= "1"
 polars-arrow = { version = "0.30.0", path = "../polars-arrow", features = ["compute", "temporal"] }
-polars-core = { version = "0.30.0", path = "../polars-core", default-features = false, features = ["private", "dtype-datetime", "dtype-duration", "dtype-time", "dtype-date"] }
+polars-core = { version = "0.30.0", path = "../polars-core", default-features = false, features = ["dtype-datetime", "dtype-duration", "dtype-time", "dtype-date"] }
 polars-ops = { version = "0.30.0", path = "../polars-ops" }
 polars-utils = { version = "0.30.0", path = "../polars-utils" }
 regex = "1.7.1"
 serde = { version = "1", features = ["derive"], optional = true }
 smartstring= { version = "1" }
 
 [features]
 dtype-date = ["polars-core/dtype-date", "polars-core/temporal"]
 dtype-datetime = ["polars-core/dtype-date", "polars-core/temporal"]
 dtype-time = ["polars-core/dtype-time", "polars-core/temporal"]
 dtype-duration = ["polars-core/dtype-duration", "polars-core/temporal"]
 rolling_window = ["polars-core/rolling_window", "dtype-duration"]
-private = []
 fmt = ["polars-core/fmt"]
 timezones = ["chrono-tz", "dtype-datetime", "polars-core/timezones", "polars-arrow/timezones"]
 
 test = ["dtype-date", "dtype-datetime", "polars-core/fmt"]
 
-default = ["private"]
+default = []
 
 [dependencies.arrow]
 package = "arrow2"
-# git = "https://github.com/jorgecarleitao/arrow2"
+git = "https://github.com/jorgecarleitao/arrow2"
 # git = "https://github.com/ritchie46/arrow2"
-# rev = "1491c6e8f4fd100f53c358e4f3ef1536d9e75090"
+rev = "fb5e4d591c7149df590a330365fae55d2370962f"
 # path = "../arrow2"
 # branch = "polars_2023-05-25"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/LICENSE` & `polars_lts_cpu-0.18.1/local_dependencies/polars-sql/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/date.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/date.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/datetime.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/datetime.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/duration.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/duration.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/kernels.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/kernels.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/rolling_window/floats.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/rolling_window/floats.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/rolling_window/ints.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/rolling_window/ints.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/rolling_window/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/rolling_window/mod.rs`

 * *Files 18% similar despite different names*

```diff
@@ -34,26 +34,29 @@
     pub weights: Option<Vec<f64>>,
     /// Set the labels at the center of the window.
     pub center: bool,
     /// Compute the rolling aggregates with a window defined by a time column
     pub by: Option<String>,
     /// The closed window of that time window if given
     pub closed_window: Option<ClosedWindow>,
+    /// Optional parameters for the rolling function
+    pub fn_params: DynArgs,
 }
 
 #[cfg(feature = "rolling_window")]
 impl Default for RollingOptions {
     fn default() -> Self {
         RollingOptions {
             window_size: Duration::parse("3i"),
             min_periods: 1,
             weights: None,
             center: false,
             by: None,
             closed_window: None,
+            fn_params: None,
         }
     }
 }
 
 #[derive(Clone)]
 #[cfg(feature = "rolling_window")]
 pub struct RollingOptionsImpl<'a> {
@@ -66,14 +69,15 @@
     pub weights: Option<Vec<f64>>,
     /// Set the labels at the center of the window.
     pub center: bool,
     pub by: Option<&'a [i64]>,
     pub tu: Option<TimeUnit>,
     pub tz: Option<&'a TimeZone>,
     pub closed_window: Option<ClosedWindow>,
+    pub fn_params: DynArgs,
 }
 
 #[cfg(feature = "rolling_window")]
 impl From<RollingOptions> for RollingOptionsImpl<'static> {
     fn from(options: RollingOptions) -> Self {
         let window_size = options.window_size;
         assert!(
@@ -86,14 +90,15 @@
             min_periods: options.min_periods,
             weights: options.weights,
             center: options.center,
             by: None,
             tu: None,
             tz: None,
             closed_window: None,
+            fn_params: options.fn_params,
         }
     }
 }
 
 #[cfg(feature = "rolling_window")]
 impl From<RollingOptions> for RollingOptionsFixedWindow {
     fn from(options: RollingOptions) -> Self {
@@ -104,14 +109,15 @@
         );
 
         RollingOptionsFixedWindow {
             window_size: window_size.nanoseconds() as usize,
             min_periods: options.min_periods,
             weights: options.weights,
             center: options.center,
+            fn_params: options.fn_params,
         }
     }
 }
 
 #[cfg(feature = "rolling_window")]
 impl Default for RollingOptionsImpl<'static> {
     fn default() -> Self {
@@ -120,14 +126,15 @@
             min_periods: 1,
             weights: None,
             center: false,
             by: None,
             tu: None,
             tz: None,
             closed_window: None,
+            fn_params: None,
         }
     }
 }
 
 #[cfg(feature = "rolling_window")]
 impl<'a> From<RollingOptionsImpl<'a>> for RollingOptionsFixedWindow {
     fn from(options: RollingOptionsImpl<'a>) -> Self {
@@ -138,14 +145,15 @@
         );
 
         RollingOptionsFixedWindow {
             window_size: window_size.nanoseconds() as usize,
             min_periods: options.min_periods,
             weights: options.weights,
             center: options.center,
+            fn_params: options.fn_params,
         }
     }
 }
 
 #[cfg(not(feature = "rolling_window"))]
 pub trait RollingAgg {}
 
@@ -215,31 +223,33 @@
 }
 
 #[cfg(feature = "rolling_window")]
 #[allow(clippy::type_complexity)]
 fn rolling_agg<T>(
     ca: &ChunkedArray<T>,
     options: RollingOptionsImpl,
-    rolling_agg_fn: &dyn Fn(&[T::Native], usize, usize, bool, Option<&[f64]>) -> ArrayRef,
+    rolling_agg_fn: &dyn Fn(&[T::Native], usize, usize, bool, Option<&[f64]>, DynArgs) -> ArrayRef,
     rolling_agg_fn_nulls: &dyn Fn(
         &PrimitiveArray<T::Native>,
         usize,
         usize,
         bool,
         Option<&[f64]>,
+        DynArgs,
     ) -> ArrayRef,
     rolling_agg_fn_dynamic: Option<
         &dyn Fn(
             &[T::Native],
             Duration,
             Duration,
             &[i64],
             ClosedWindow,
             TimeUnit,
             Option<&TimeZone>,
+            DynArgs,
         ) -> PolarsResult<ArrayRef>,
     >,
 ) -> PolarsResult<Series>
 where
     T: PolarsNumericType,
 {
     if ca.is_empty() {
@@ -256,21 +266,23 @@
         Ok(match ca.null_count() {
             0 => rolling_agg_fn(
                 arr.values().as_slice(),
                 options.window_size,
                 options.min_periods,
                 options.center,
                 options.weights.as_deref(),
+                options.fn_params,
             ),
             _ => rolling_agg_fn_nulls(
                 arr,
                 options.window_size,
                 options.min_periods,
                 options.center,
                 options.weights.as_deref(),
+                options.fn_params,
             ),
         })
     } else {
         if arr.null_count() > 0 {
             panic!("'rolling by' not yet supported for series with null values, consider using 'groupby_rolling'")
         }
         let values = arr.values().as_slice();
@@ -280,11 +292,20 @@
         let closed_window = options.closed_window.expect("closed window  must be set");
         let mut offset = duration;
         offset.negative = true;
         let func = rolling_agg_fn_dynamic.expect(
             "'rolling by' not yet supported for this expression, consider using 'groupby_rolling'",
         );
 
-        func(values, duration, offset, by, closed_window, tu, options.tz)
+        func(
+            values,
+            duration,
+            offset,
+            by,
+            closed_window,
+            tu,
+            options.tz,
+            options.fn_params,
+        )
     }?;
     Series::try_from((ca.name(), arr))
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/no_nulls.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/no_nulls.rs`

 * *Files 5% similar despite different names*

```diff
@@ -5,14 +5,15 @@
 
 use super::*;
 
 // Use an aggregation window that maintains the state
 pub(crate) fn rolling_apply_agg_window<'a, Agg, T, O>(
     values: &'a [T],
     offsets: O,
+    params: DynArgs,
 ) -> PolarsResult<ArrayRef>
 where
     // items (offset, len) -> so offsets are offset, offset + len
     Agg: RollingAggWindowNoNulls<'a, T>,
     O: Iterator<Item = PolarsResult<(IdxSize, IdxSize)>> + TrustedLen,
     T: Debug + IsFloat + NativeType,
 {
@@ -21,15 +22,15 @@
         return Ok(Box::new(PrimitiveArray::new(
             T::PRIMITIVE.into(),
             out.into(),
             None,
         )));
     }
     // start with a dummy index, will be overwritten on first iteration.
-    let mut agg_window = Agg::new(values, 0, 0);
+    let mut agg_window = Agg::new(values, 0, 0, params);
 
     let out = offsets
         .map(|result| {
             result.map(|(start, len)| {
                 let end = start + len;
 
                 if start == end {
@@ -42,22 +43,24 @@
             })
         })
         .collect::<PolarsResult<PrimitiveArray<T>>>()?;
 
     Ok(Box::new(out))
 }
 
+#[allow(clippy::too_many_arguments)]
 pub(crate) fn rolling_min<T>(
     values: &[T],
     period: Duration,
     offset: Duration,
     time: &[i64],
     closed_window: ClosedWindow,
     tu: TimeUnit,
     tz: Option<&TimeZone>,
+    _params: DynArgs,
 ) -> PolarsResult<ArrayRef>
 where
     T: NativeType + PartialOrd + IsFloat + Bounded + NumCast + Mul<Output = T>,
 {
     let offset_iter = match tz {
         #[cfg(feature = "timezones")]
         Some(tz) => groupby_values_iter(
@@ -66,25 +69,27 @@
             time,
             closed_window,
             tu,
             tz.parse::<Tz>().ok(),
         ),
         _ => groupby_values_iter(period, offset, time, closed_window, tu, None),
     };
-    rolling_apply_agg_window::<no_nulls::MinWindow<_>, _, _>(values, offset_iter)
+    rolling_apply_agg_window::<no_nulls::MinWindow<_>, _, _>(values, offset_iter, None)
 }
 
+#[allow(clippy::too_many_arguments)]
 pub(crate) fn rolling_max<T>(
     values: &[T],
     period: Duration,
     offset: Duration,
     time: &[i64],
     closed_window: ClosedWindow,
     tu: TimeUnit,
     tz: Option<&TimeZone>,
+    _params: DynArgs,
 ) -> PolarsResult<ArrayRef>
 where
     T: NativeType + PartialOrd + IsFloat + Bounded + NumCast + Mul<Output = T>,
 {
     let offset_iter = match tz {
         #[cfg(feature = "timezones")]
         Some(tz) => groupby_values_iter(
@@ -93,25 +98,27 @@
             time,
             closed_window,
             tu,
             tz.parse::<Tz>().ok(),
         ),
         _ => groupby_values_iter(period, offset, time, closed_window, tu, None),
     };
-    rolling_apply_agg_window::<no_nulls::MaxWindow<_>, _, _>(values, offset_iter)
+    rolling_apply_agg_window::<no_nulls::MaxWindow<_>, _, _>(values, offset_iter, None)
 }
 
+#[allow(clippy::too_many_arguments)]
 pub(crate) fn rolling_sum<T>(
     values: &[T],
     period: Duration,
     offset: Duration,
     time: &[i64],
     closed_window: ClosedWindow,
     tu: TimeUnit,
     tz: Option<&TimeZone>,
+    _params: DynArgs,
 ) -> PolarsResult<ArrayRef>
 where
     T: NativeType + std::iter::Sum + NumCast + Mul<Output = T> + AddAssign + SubAssign + IsFloat,
 {
     let offset_iter = match tz {
         #[cfg(feature = "timezones")]
         Some(tz) => groupby_values_iter(
@@ -120,25 +127,27 @@
             time,
             closed_window,
             tu,
             tz.parse::<Tz>().ok(),
         ),
         _ => groupby_values_iter(period, offset, time, closed_window, tu, None),
     };
-    rolling_apply_agg_window::<no_nulls::SumWindow<_>, _, _>(values, offset_iter)
+    rolling_apply_agg_window::<no_nulls::SumWindow<_>, _, _>(values, offset_iter, None)
 }
 
+#[allow(clippy::too_many_arguments)]
 pub(crate) fn rolling_mean<T>(
     values: &[T],
     period: Duration,
     offset: Duration,
     time: &[i64],
     closed_window: ClosedWindow,
     tu: TimeUnit,
     tz: Option<&TimeZone>,
+    _params: DynArgs,
 ) -> PolarsResult<ArrayRef>
 where
     T: NativeType + Float + std::iter::Sum<T> + SubAssign + AddAssign + IsFloat,
 {
     let offset_iter = match tz {
         #[cfg(feature = "timezones")]
         Some(tz) => groupby_values_iter(
@@ -147,25 +156,27 @@
             time,
             closed_window,
             tu,
             tz.parse::<Tz>().ok(),
         ),
         _ => groupby_values_iter(period, offset, time, closed_window, tu, None),
     };
-    rolling_apply_agg_window::<no_nulls::MeanWindow<_>, _, _>(values, offset_iter)
+    rolling_apply_agg_window::<no_nulls::MeanWindow<_>, _, _>(values, offset_iter, None)
 }
 
+#[allow(clippy::too_many_arguments)]
 pub(crate) fn rolling_var<T>(
     values: &[T],
     period: Duration,
     offset: Duration,
     time: &[i64],
     closed_window: ClosedWindow,
     tu: TimeUnit,
     tz: Option<&TimeZone>,
+    params: DynArgs,
 ) -> PolarsResult<ArrayRef>
 where
     T: NativeType + Float + std::iter::Sum<T> + SubAssign + AddAssign + IsFloat,
 {
     let offset_iter = match tz {
         #[cfg(feature = "timezones")]
         Some(tz) => groupby_values_iter(
@@ -174,25 +185,27 @@
             time,
             closed_window,
             tu,
             tz.parse::<Tz>().ok(),
         ),
         _ => groupby_values_iter(period, offset, time, closed_window, tu, None),
     };
-    rolling_apply_agg_window::<no_nulls::VarWindow<_>, _, _>(values, offset_iter)
+    rolling_apply_agg_window::<no_nulls::VarWindow<_>, _, _>(values, offset_iter, params)
 }
 
+#[allow(clippy::too_many_arguments)]
 pub(crate) fn rolling_std<T>(
     values: &[T],
     period: Duration,
     offset: Duration,
     time: &[i64],
     closed_window: ClosedWindow,
     tu: TimeUnit,
     tz: Option<&TimeZone>,
+    params: DynArgs,
 ) -> PolarsResult<ArrayRef>
 where
     T: NativeType
         + Float
         + IsFloat
         + std::iter::Sum
         + AddAssign
@@ -211,9 +224,9 @@
             time,
             closed_window,
             tu,
             tz.parse::<Tz>().ok(),
         ),
         _ => groupby_values_iter(period, offset, time, closed_window, tu, None),
     };
-    rolling_apply_agg_window::<no_nulls::StdWindow<_>, _, _>(values, offset_iter)
+    rolling_apply_agg_window::<no_nulls::StdWindow<_>, _, _>(values, offset_iter, params)
 }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/time.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/time.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/utf8/infer.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/utf8/infer.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/utf8/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/utf8/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 pub mod infer;
+use chrono::DateTime;
 mod patterns;
 mod strptime;
 
 use chrono::ParseError;
-pub use patterns::{Pattern, PatternWithOffset};
+pub use patterns::Pattern;
 #[cfg(feature = "dtype-time")]
 use polars_core::chunked_array::temporal::time_to_time64ns;
 
 use super::*;
 #[cfg(feature = "dtype-date")]
 use crate::chunkedarray::date::naive_date_to_date;
 use crate::prelude::utf8::strptime::StrpTimeState;
@@ -246,14 +247,15 @@
     /// Parsing string values and return a [`DatetimeChunked`]
     /// Different from `as_datetime` this function allows matches that not contain the whole string
     /// e.g. "foo-2021-01-01-bar" could match "2021-01-01"
     fn as_datetime_not_exact(
         &self,
         fmt: Option<&str>,
         tu: TimeUnit,
+        tz_aware: bool,
         tz: Option<&TimeZone>,
     ) -> PolarsResult<DatetimeChunked> {
         let utf8_ca = self.as_utf8();
         let fmt = match fmt {
             Some(fmt) => fmt,
             None => sniff_fmt_datetime(utf8_ca)?,
         };
@@ -271,16 +273,20 @@
                 Some(mut s) => {
                     let fmt_len = fmt.len();
 
                     for i in 1..(s.len() - fmt_len) {
                         if s.is_empty() {
                             return None;
                         }
-                        match NaiveDateTime::parse_from_str(s, fmt).map(func) {
-                            Ok(nd) => return Some(nd),
+                        let timestamp = match tz_aware {
+                            true => DateTime::parse_from_str(s, fmt).map(|dt| func(dt.naive_utc())),
+                            false => NaiveDateTime::parse_from_str(s, fmt).map(func),
+                        };
+                        match timestamp {
+                            Ok(ts) => return Some(ts),
                             Err(e) => {
                                 let e: ParseErrorByteCopy = e.into();
                                 match e.0 {
                                     ParseErrorKind::TooLong => {
                                         s = &s[..s.len() - 1];
                                     }
                                     _ => {
@@ -291,17 +297,19 @@
                         }
                     }
                     None
                 }
             })
             .collect_trusted();
         ca.rename(utf8_ca.name());
-        match tz {
+        match (tz_aware, tz) {
+            #[cfg(feature = "timezones")]
+            (false, Some(tz)) => ca.into_datetime(tu, None).replace_time_zone(Some(tz), None),
             #[cfg(feature = "timezones")]
-            Some(tz) => ca.into_datetime(tu, None).replace_time_zone(Some(tz), None),
+            (true, _) => Ok(ca.into_datetime(tu, Some("UTC".to_string()))),
             _ => Ok(ca.into_datetime(tu, None)),
         }
     }
 
     #[cfg(feature = "dtype-date")]
     /// Parsing string values and return a [`DateChunked`]
     fn as_date(&self, fmt: Option<&str>, cache: bool) -> PolarsResult<DateChunked> {
@@ -401,15 +409,14 @@
             TimeUnit::Microseconds => datetime_to_timestamp_us,
             TimeUnit::Milliseconds => datetime_to_timestamp_ms,
         };
 
         if tz_aware {
             #[cfg(feature = "timezones")]
             {
-                use chrono::DateTime;
                 use polars_arrow::export::hashbrown::hash_map::Entry;
                 let mut cache_map = PlHashMap::new();
 
                 let convert = |s: &str| {
                     DateTime::parse_from_str(s, &fmt)
                         .ok()
                         .map(|dt| func(dt.naive_utc()))
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/utf8/patterns.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/utf8/patterns.rs`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,10 @@
 //! Patterns are grouped together by order of month, day, year. This is to prevent
 //! parsing different orders of dates in a single column.
 
-use chrono::FixedOffset;
-
 pub(super) static DATE_D_M_Y: &[&str] = &[
     "%d-%m-%Y", // 31-12-2021
     "%d/%m/%Y", // 31/12/2021
 ];
 
 pub(super) static DATE_Y_M_D: &[&str] = &[
     "%Y/%m/%d", // 2021/12/31
@@ -147,13 +145,7 @@
 pub enum Pattern {
     DateDMY,
     DateYMD,
     DatetimeYMD,
     DatetimeDMY,
     DatetimeYMDZ,
 }
-
-#[derive(Clone)]
-pub struct PatternWithOffset {
-    pub pattern: Pattern,
-    pub offset: Option<FixedOffset>,
-}
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/chunkedarray/utf8/strptime.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/chunkedarray/utf8/strptime.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/date_range.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/date_range.rs`

 * *Files 6% similar despite different names*

```diff
@@ -8,15 +8,14 @@
 use crate::utils::localize_timestamp;
 
 pub fn in_nanoseconds_window(ndt: &NaiveDateTime) -> bool {
     // ~584 year around 1970
     !(ndt.year() > 2554 || ndt.year() < 1386)
 }
 
-#[cfg(feature = "private")]
 #[doc(hidden)]
 pub fn date_range_impl(
     name: &str,
     start: i64,
     stop: i64,
     every: Duration,
     closed: ClosedWindow,
@@ -71,15 +70,14 @@
             stop.timestamp() + stop.timestamp_subsec_millis() as i64,
         ),
         TimeUnit::Milliseconds => (start.timestamp_millis(), stop.timestamp_millis()),
     };
     date_range_impl(name, start, stop, every, closed, tu, tz.as_ref())
 }
 
-#[cfg(feature = "private")]
 #[doc(hidden)]
 pub fn time_range_impl(
     name: &str,
     start: i64,
     stop: i64,
     every: Duration,
     closed: ClosedWindow,
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/groupby/dynamic.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/groupby/dynamic.rs`

 * *Files 1% similar despite different names*

```diff
@@ -751,19 +751,25 @@
         assert_eq!(max, expected);
 
         let var = unsafe { a.agg_var(&groups, 1) };
         let expected = Series::new(
             "",
             [0.0, 8.0, 4.000000000000002, 6.666666666666667, 24.5, 0.0],
         );
-        assert_eq!(var, expected);
+        assert_eq!(
+            (var - expected).abs().unwrap().lt(1e-12).unwrap().all(),
+            true
+        );
 
         let var = unsafe { nulls.agg_var(&groups, 1) };
         let expected = Series::new("", [0.0, 8.0, 8.0, 9.333333333333343, 24.5, 0.0]);
-        assert_eq!(var, expected);
+        assert_eq!(
+            (var - expected).abs().unwrap().lt(1e-12).unwrap().all(),
+            true
+        );
 
         let quantile = unsafe { a.agg_quantile(&groups, 0.5, QuantileInterpolOptions::Linear) };
         let expected = Series::new("", [3.0, 5.0, 5.0, 6.0, 5.5, 1.0]);
         assert_eq!(quantile, expected);
 
         let quantile = unsafe { nulls.agg_quantile(&groups, 0.5, QuantileInterpolOptions::Linear) };
         let expected = Series::new("", [3.0, 5.0, 5.0, 7.0, 5.5, 1.0]);
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/lib.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/lib.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/month_end.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/month_end.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/month_start.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/month_start.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/round.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/round.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/_trait.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/_trait.rs`

 * *Files 1% similar despite different names*

```diff
@@ -11,16 +11,17 @@
         ))
     };
 }
 
 pub trait SeriesOpsTime {
     fn ops_time_dtype(&self) -> &DataType;
 
-    /// Apply a rolling mean to a Series. See:
-    /// [ChunkedArray::rolling_mean](crate::prelude::ChunkWindow::rolling_mean).
+    /// Apply a rolling mean to a Series.
+    ///
+    /// See: [`RollingAgg::rolling_mean`]
     #[cfg(feature = "rolling_window")]
     fn rolling_mean(&self, _options: RollingOptionsImpl) -> PolarsResult<Series> {
         invalid_operation!(self)
     }
     /// Apply a rolling sum to a Series.
     #[cfg(feature = "rolling_window")]
     fn rolling_sum(&self, _options: RollingOptionsImpl) -> PolarsResult<Series> {
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/implementations/floats.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/implementations/floats.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/implementations/integers.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/implementations/integers.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/series/mod.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/series/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/truncate.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/truncate.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/upsample.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/upsample.rs`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 #[cfg(feature = "timezones")]
 use chrono_tz::Tz;
+use polars_core::frame::hash_join::JoinArgs;
 use polars_core::prelude::*;
 use polars_core::utils::ensure_sorted_arg;
 use polars_ops::prelude::*;
 
 use crate::prelude::*;
 #[cfg(feature = "timezones")]
 use crate::utils::unlocalize_timestamp;
@@ -179,16 +180,15 @@
                     )?
                     .into_series()
                     .into_frame();
                     range.join(
                         source,
                         &[index_col_name],
                         &[index_col_name],
-                        JoinType::Left,
-                        None,
+                        JoinArgs::new(JoinType::Left),
                     )
                 }
                 _ => polars_bail!(
                     ComputeError: "cannot determine upsample boundaries: all elements are null"
                 ),
             }
         }
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/utils.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/windows/bounds.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/windows/bounds.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/windows/calendar.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/windows/calendar.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/windows/duration.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/windows/duration.rs`

 * *Files 1% similar despite different names*

```diff
@@ -167,21 +167,22 @@
                     "m" => nsecs += n * NS_MINUTE,
                     "h" => nsecs += n * NS_HOUR,
                     "d" => days += n,
                     "w" => weeks += n,
                     "mo" => {
                         months += n
                     }
+                    "q" => months += n * 3,
                     "y" => months += n * 12,
                     // we will read indexes as nanoseconds
                     "i" => {
                         nsecs += n;
                         parsed_int = true;
                     }
-                    unit => panic!("unit: '{unit}' not supported. Available units are: 'ns', 'us', 'ms', 's', 'm', 'h', 'd', 'w', 'mo', 'y', 'i'"),
+                    unit => panic!("unit: '{unit}' not supported. Available units are: 'ns', 'us', 'ms', 's', 'm', 'h', 'd', 'w', 'q', 'mo', 'y', 'i'"),
                 }
                 unit.clear();
             }
         }
         Duration {
             nsecs: nsecs.abs(),
             days: days.abs(),
@@ -333,38 +334,34 @@
 
     /// Returns the nanoseconds from the `Duration` without the weeks or months part.
     pub fn nanoseconds(&self) -> i64 {
         self.nsecs
     }
 
     /// Estimated duration of the window duration. Not a very good one if months != 0.
-    #[cfg(feature = "private")]
     #[doc(hidden)]
     pub const fn duration_ns(&self) -> i64 {
         self.months * 28 * 24 * 3600 * NANOSECONDS
             + self.weeks * NS_WEEK
             + self.days * NS_DAY
             + self.nsecs
     }
 
-    #[cfg(feature = "private")]
     #[doc(hidden)]
     pub const fn duration_us(&self) -> i64 {
         self.months * 28 * 24 * 3600 * MICROSECONDS
             + (self.weeks * NS_WEEK + self.nsecs + self.days * NS_DAY) / 1000
     }
 
-    #[cfg(feature = "private")]
     #[doc(hidden)]
     pub const fn duration_ms(&self) -> i64 {
         self.months * 28 * 24 * 3600 * MILLISECONDS
             + (self.weeks * NS_WEEK + self.nsecs + self.days * NS_DAY) / 1_000_000
     }
 
-    #[cfg(feature = "private")]
     #[doc(hidden)]
     fn add_month(
         ts: NaiveDateTime,
         n_months: i64,
         negative: bool,
         saturating: bool,
     ) -> PolarsResult<NaiveDateTime> {
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/windows/groupby.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/windows/groupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/windows/test.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/windows/test.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-time/src/windows/window.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-time/src/windows/window.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-error/Cargo.toml` & `polars_lts_cpu-0.18.1/local_dependencies/polars-error/Cargo.toml`

 * *Files 24% similar despite different names*

```diff
@@ -1,26 +1,27 @@
 [package]
 name = "polars-error"
 version = "0.30.0"
 edition = "2021"
 license = "MIT"
 repository = "https://github.com/pola-rs/polars"
 description = "Error definitions for the Polars DataFrame library"
+resolver = "2"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
 regex = { version = "1.6", optional = true }
 thiserror= "^1"
 
 [dependencies.arrow]
 package = "arrow2"
-# git = "https://github.com/jorgecarleitao/arrow2"
+git = "https://github.com/jorgecarleitao/arrow2"
 # git = "https://github.com/ritchie46/arrow2"
-# rev = "1491c6e8f4fd100f53c358e4f3ef1536d9e75090"
+rev = "fb5e4d591c7149df590a330365fae55d2370962f"
 # path = "../arrow2"
 # branch = "polars_2023-05-25"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
```

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-error/LICENSE` & `polars_lts_cpu-0.18.1/local_dependencies/polars-error/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/local_dependencies/polars-error/src/lib.rs` & `polars_lts_cpu-0.18.1/local_dependencies/polars-error/src/lib.rs`

 * *Files 4% similar despite different names*

```diff
@@ -193,14 +193,28 @@
 #[inline]
 #[cold]
 #[must_use]
 pub fn to_compute_err(err: impl Display) -> PolarsError {
     PolarsError::ComputeError(err.to_string().into())
 }
 
+#[macro_export]
+macro_rules! feature_gated {
+    ($feature:expr, $content:expr) => {{
+        #[cfg(feature = $feature)]
+        {
+            $content
+        }
+        #[cfg(not(feature = $feature))]
+        {
+            panic!("activate '{}' feature", $feature)
+        }
+    }};
+}
+
 // Not public, referenced by macros only.
 #[doc(hidden)]
 pub mod __private {
     #[doc(hidden)]
     #[inline]
     #[cold]
     #[must_use]
```

### Comparing `polars_lts_cpu-0.18.0/Cargo.toml` & `polars_lts_cpu-0.18.1/Cargo.toml`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 [package]
 name = "py-polars"
-version = "0.18.0"
+version = "0.18.1"
 edition = "2021"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [workspace]
 # prevents package from thinking it's in the workspace
 [target.'cfg(any(not(target_os = "linux"), use_mimalloc))'.dependencies]
@@ -16,20 +16,20 @@
 [dependencies]
 ahash = "0.8"
 ciborium = "0.2.0"
 lexical-core = "0.8"
 # todo: unfix when compilation problem is solved
 libc = "0.2"
 ndarray = "0.15"
-numpy = "0.18"
+numpy = "0.19"
 once_cell = "1"
 polars-algo = { path = "local_dependencies/polars-algo", default-features = false }
 polars-core = { path = "local_dependencies/polars-core", features = ["python"], default-features = false }
 polars-lazy = { path = "local_dependencies/polars-lazy", features = ["python"], default-features = false }
-pyo3 = { version = "0.18.0", features = ["abi3-py37", "extension-module", "multiple-pymethods"] }
+pyo3 = { version = "0.19", features = ["abi3-py37", "extension-module", "multiple-pymethods"] }
 pyo3-built = { version = "0.4", optional = true }
 serde_json = { version = "1", optional = true }
 smartstring = "1"
 thiserror = "^1.0"
 
 # features are only there to enable building a slim binary for the benchmark in CI
 [features]
@@ -121,15 +121,14 @@
   "lazy",
   "strings",
   "temporal",
   "random",
   "fmt",
   "dtype-full",
   "rows",
-  "private",
   "round_series",
   "is_first",
   "is_unique",
   "dot_product",
   "concat_str",
   "row_hash",
   "reinterpret",
```

### Comparing `polars_lts_cpu-0.18.0/LICENSE` & `polars_lts_cpu-0.18.1/local_dependencies/polars/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/Makefile` & `polars_lts_cpu-0.18.1/Makefile`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/README.md` & `polars_lts_cpu-0.18.1/README.md`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/build.rs` & `polars_lts_cpu-0.18.1/build.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/Makefile` & `polars_lts_cpu-0.18.1/docs/Makefile`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/_templates/autosummary/class.rst` & `polars_lts_cpu-0.18.1/docs/_templates/autosummary/class.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/run_live_docs_server.py` & `polars_lts_cpu-0.18.1/docs/run_live_docs_server.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/_static/css/custom.css` & `polars_lts_cpu-0.18.1/docs/source/_static/css/custom.css`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/conf.py` & `polars_lts_cpu-0.18.1/docs/source/conf.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/api.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/api.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/config.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/config.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/dataframe/modify_select.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/dataframe/modify_select.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/datatypes.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/datatypes.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/expressions/computation.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/expressions/computation.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/expressions/functions.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/expressions/functions.rst`

 * *Files 11% similar despite different names*

```diff
@@ -52,14 +52,15 @@
    repeat
    rolling_corr
    rolling_cov
    select
    std
    struct
    sum
+   sql_expr
    tail
    time
    var
    when
 
 
 **Available in expression namespace:**
```

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/expressions/list.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/expressions/list.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/expressions/modify_select.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/expressions/modify_select.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/expressions/operators.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/expressions/operators.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/expressions/string.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/expressions/string.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/expressions/temporal.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/expressions/temporal.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/functions.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/functions.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/io.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/io.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/lazyframe/modify_select.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/lazyframe/modify_select.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/series/computation.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/series/computation.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/series/descriptive.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/series/descriptive.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/series/list.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/series/list.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/series/modify_select.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/series/modify_select.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/series/string.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/series/string.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/series/temporal.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/series/temporal.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/docs/source/reference/testing.rst` & `polars_lts_cpu-0.18.1/docs/source/reference/testing.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/__init__.py` & `polars_lts_cpu-0.18.1/polars/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -117,14 +117,15 @@
     ones,
     quantile,
     reduce,
     repeat,
     rolling_corr,
     rolling_cov,
     select,
+    sql_expr,
     std,
     struct,
     sum,
     tail,
     time,
     time_range,
     var,
@@ -336,10 +337,13 @@
     "SQLContext",
     # polars.utils
     "build_info",
     "get_idx_type",
     "get_index_type",
     "show_versions",
     "threadpool_size",
+    # selectors
+    "selectors",
+    "sql_expr",
 ]
 
 os.environ["POLARS_ALLOW_EXTENSION"] = "true"
```

### Comparing `polars_lts_cpu-0.18.0/polars/api.py` & `polars_lts_cpu-0.18.1/polars/api.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/config.py` & `polars_lts_cpu-0.18.1/polars/config.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/convert.py` & `polars_lts_cpu-0.18.1/polars/convert.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/dataframe/_html.py` & `polars_lts_cpu-0.18.1/polars/dataframe/_html.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/dataframe/frame.py` & `polars_lts_cpu-0.18.1/polars/dataframe/frame.py`

 * *Files 0% similar despite different names*

```diff
@@ -87,15 +87,15 @@
     iterable_to_pydf,
     numpy_to_pydf,
     pandas_to_pydf,
     sequence_to_pydf,
     series_to_pydf,
 )
 from polars.utils._parse_expr_input import parse_as_expression
-from polars.utils._wrap import wrap_ldf, wrap_s
+from polars.utils._wrap import wrap_expr, wrap_ldf, wrap_s
 from polars.utils.convert import _timedelta_to_pl_duration
 from polars.utils.decorators import deprecated_alias
 from polars.utils.meta import get_index_type
 from polars.utils.various import (
     _prepare_row_count_args,
     _process_null_values,
     find_stacklevel,
@@ -1176,14 +1176,20 @@
         >>> df.schema
         {'foo': Int64, 'bar': Float64, 'ham': Utf8}
 
         """
         return dict(zip(self.columns, self.dtypes))
 
     def __array__(self, dtype: Any = None) -> np.ndarray[Any, Any]:
+        """
+        Numpy __array__ interface protocol.
+
+        Ensures that `np.asarray(pl.DataFrame(..))` works as expected, see
+        https://numpy.org/devdocs/user/basics.interoperability.html#the-array-method.
+        """
         if dtype:
             return self.to_numpy().__array__(dtype)
         else:
             return self.to_numpy().__array__()
 
     def __dataframe__(
         self, nan_as_null: bool = False, allow_copy: bool = True
@@ -1841,16 +1847,19 @@
         foo: int64
         bar: large_string
         ----
         foo: [[1,2,3,4,5,6]]
         bar: [["a","b","c","d","e","f"]]
 
         """
-        record_batches = self._df.to_arrow()
-        return pa.Table.from_batches(record_batches)
+        if self.shape[1]:  # all except 0x0 dataframe
+            record_batches = self._df.to_arrow()
+            return pa.Table.from_batches(record_batches)
+        else:  # 0x0 dataframe, cannot infer schema from batches
+            return pa.table({})
 
     @overload
     def to_dict(self, as_series: Literal[True] = ...) -> dict[str, Series]:
         ...
 
     @overload
     def to_dict(self, as_series: Literal[False]) -> dict[str, list[Any]]:
@@ -4762,34 +4771,41 @@
         period: str | timedelta,
         offset: str | timedelta | None = None,
         closed: ClosedInterval = "right",
         by: IntoExpr | Iterable[IntoExpr] | None = None,
         check_sorted: bool = True,
     ) -> RollingGroupBy:
         """
-        Create rolling groups based on a time column.
-
-        Also works for index values of type Int32 or Int64.
+        Create rolling groups based on a time, Int32, or Int64 column.
 
         Different from a ``dynamic_groupby`` the windows are now determined by the
         individual values and are not of constant intervals. For constant intervals use
-        *groupby_dynamic*
+        *groupby_dynamic*.
+
+        If you have a time series ``<t_0, t_1, ..., t_n>``, then by default the
+        windows created will be
+
+            * (t_0 - period, t_0]
+            * (t_1 - period, t_1]
+            * ...
+            * (t_n - period, t_n]
 
         The `period` and `offset` arguments are created either from a timedelta, or
         by using the following string language:
 
         - 1ns   (1 nanosecond)
         - 1us   (1 microsecond)
         - 1ms   (1 millisecond)
         - 1s    (1 second)
         - 1m    (1 minute)
         - 1h    (1 hour)
         - 1d    (1 day)
         - 1w    (1 week)
         - 1mo   (1 calendar month)
+        - 1q    (1 calendar quarter)
         - 1y    (1 calendar year)
         - 1i    (1 index count)
 
         Or combine them:
         "3d12h4m25s" # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
@@ -4917,14 +4933,15 @@
         - 1ms   (1 millisecond)
         - 1s    (1 second)
         - 1m    (1 minute)
         - 1h    (1 hour)
         - 1d    (1 day)
         - 1w    (1 week)
         - 1mo   (1 calendar month)
+        - 1q    (1 quarter)
         - 1y    (1 calendar year)
         - 1i    (1 index count)
 
         Or combine them:
         "3d12h4m25s" # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
@@ -5224,14 +5241,15 @@
         - 1ms   (1 millisecond)
         - 1s    (1 second)
         - 1m    (1 minute)
         - 1h    (1 hour)
         - 1d    (1 day)
         - 1w    (1 week)
         - 1mo   (1 calendar month)
+        - 1q    (1 calendar quarter)
         - 1y    (1 calendar year)
         - 1i    (1 index count)
 
         Or combine them:
         "3d12h4m25s" # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
@@ -5363,14 +5381,15 @@
                 - 1ms   (1 millisecond)
                 - 1s    (1 second)
                 - 1m    (1 minute)
                 - 1h    (1 hour)
                 - 1d    (1 day)
                 - 1w    (1 week)
                 - 1mo   (1 calendar month)
+                - 1q    (1 calendar quarter)
                 - 1y    (1 calendar year)
                 - 1i    (1 index count)
 
                 Or combine them:
                 "3d12h4m25s" # 3 days, 12 hours, 4 minutes, and 25 seconds
 
                 Suffix with `"_saturating"` to indicate that dates too large for
@@ -5452,14 +5471,15 @@
         other: DataFrame,
         on: str | Expr | Sequence[str | Expr] | None = None,
         how: JoinStrategy = "inner",
         *,
         left_on: str | Expr | Sequence[str | Expr] | None = None,
         right_on: str | Expr | Sequence[str | Expr] | None = None,
         suffix: str = "_right",
+        validate: str = "m:m",
     ) -> DataFrame:
         """
         Join in SQL-like fashion.
 
         Parameters
         ----------
         other
@@ -5470,14 +5490,30 @@
             Join strategy.
         left_on
             Name(s) of the left join column(s).
         right_on
             Name(s) of the right join column(s).
         suffix
             Suffix to append to columns with a duplicate name.
+        validate: {'m:m', 'm:1', '1:m', 'm:m'}
+            Checks if join is of specified type.
+
+                * *many_to_many*
+                    m:m: default, does not result in checks
+                * *one_to_one*
+                    1:1: check if join keys are unique in both left and right datasets
+                * *one_to_many*
+                    1:m: check if join keys are unique in left dataset
+                * *many_to_one*
+                    m:1: check if join keys are unique in right dataset
+
+            .. note::
+
+                - This is currently not supported the streaming engine.
+                - This is only supported when joined by single columns.
 
         Returns
         -------
             Joined DataFrame
 
         See Also
         --------
@@ -5570,14 +5606,15 @@
             .join(
                 other=other.lazy(),
                 left_on=left_on,
                 right_on=right_on,
                 on=on,
                 how=how,
                 suffix=suffix,
+                validate=validate,
             )
             .collect(no_optimization=True)
         )
 
     def apply(
         self,
         function: Callable[[tuple[Any, ...]], Any],
@@ -5908,22 +5945,23 @@
         ]
 
         """
         return wrap_s(self._df.drop_in_place(name))
 
     def clear(self, n: int = 0) -> Self:
         """
-        Create an empty copy of the current DataFrame, with zero to 'n' rows.
+        Create an empty (n=0) or `n`-row null-filled (n>0) copy of the DataFrame.
 
-        Returns a DataFrame with identical schema but no data.
+        Returns a `n`-row null-filled DataFrame with an identical schema.
+        `n` can be greater than the current number of rows in the DataFrame.
 
         Parameters
         ----------
         n
-            Number of (empty) rows to return in the cleared frame.
+            Number of (null-filled) rows to return in the cleared frame.
 
         See Also
         --------
         clone : Cheap deepcopy/clone.
 
         Examples
         --------
@@ -6990,32 +7028,28 @@
         >>> df.lazy()  # doctest: +ELLIPSIS
         <polars.LazyFrame object at ...>
 
         """
         return wrap_ldf(self._df.lazy())
 
     def select(
-        self,
-        exprs: IntoExpr | Iterable[IntoExpr] | None = None,
-        *more_exprs: IntoExpr,
-        **named_exprs: IntoExpr,
+        self, *exprs: IntoExpr | Iterable[IntoExpr], **named_exprs: IntoExpr
     ) -> DataFrame:
         """
         Select columns from this DataFrame.
 
         Parameters
         ----------
-        exprs
-            Column(s) to select. Accepts expression input. Strings are parsed as column
-            names, other non-expression inputs are parsed as literals.
-        *more_exprs
-            Additional columns to select, specified as positional arguments.
+        *exprs
+            Column(s) to select, specified as positional arguments.
+            Accepts expression input. Strings are parsed as column names,
+            other non-expression inputs are parsed as literals.
         **named_exprs
-            Additional columns to select, specified as keyword arguments. The columns
-            will be renamed to the keyword used.
+            Additional columns to select, specified as keyword arguments.
+            The columns will be renamed to the keyword used.
 
         Examples
         --------
         Pass the name of a column to select that column.
 
         >>> df = pl.DataFrame(
         ...     {
@@ -7095,41 +7129,35 @@
         
          {1,0}     
          {0,1}     
          {1,0}     
         
 
         """
-        return (
-            self.lazy()
-            .select(exprs, *more_exprs, **named_exprs)
-            .collect(no_optimization=True)
-        )
+        return self.lazy().select(*exprs, **named_exprs).collect(no_optimization=True)
 
     def with_columns(
         self,
-        exprs: IntoExpr | Iterable[IntoExpr] | None = None,
-        *more_exprs: IntoExpr,
+        *exprs: IntoExpr | Iterable[IntoExpr],
         **named_exprs: IntoExpr,
     ) -> DataFrame:
         """
         Add columns to this DataFrame.
 
         Added columns will replace existing columns with the same name.
 
         Parameters
         ----------
-        exprs
-            Column or columns to add. Accepts expression input. Strings are parsed
-            as column names, other non-expression inputs are parsed as literals.
-        *more_exprs
-            Additional columns to add, specified as positional arguments.
+        *exprs
+            Column(s) to add, specified as positional arguments.
+            Accepts expression input. Strings are parsed as column names, other
+            non-expression inputs are parsed as literals.
         **named_exprs
-            Additional columns to add, specified as keyword arguments. The columns
-            will be renamed to the keyword used.
+            Additional columns to add, specified as keyword arguments.
+            The columns will be renamed to the keyword used.
 
         Returns
         -------
         A new DataFrame with the columns added.
 
         Notes
         -----
@@ -7252,15 +7280,15 @@
          3    10.0  {1,6.0}     
          4    13.0  {1,3.0}     
         
 
         """
         return (
             self.lazy()
-            .with_columns(exprs, *more_exprs, **named_exprs)
+            .with_columns(*exprs, **named_exprs)
             .collect(no_optimization=True)
         )
 
     @overload
     def n_chunks(self, strategy: Literal["first"] = ...) -> int:
         ...
 
@@ -7898,15 +7926,15 @@
         """
         if isinstance(subset, str):
             subset = [F.col(subset)]
         elif isinstance(subset, pl.Expr):
             subset = [subset]
 
         if isinstance(subset, Sequence) and len(subset) == 1:
-            expr = parse_as_expression(subset[0])
+            expr = wrap_expr(parse_as_expression(subset[0]))
         else:
             struct_fields = F.all() if (subset is None) else subset
             expr = F.struct(struct_fields)  # type: ignore[call-overload]
 
         df = self.lazy().select(expr.n_unique()).collect()
         return 0 if df.is_empty() else df.row(0)[0]
```

### Comparing `polars_lts_cpu-0.18.0/polars/dataframe/groupby.py` & `polars_lts_cpu-0.18.1/polars/dataframe/groupby.py`

 * *Files 1% similar despite different names*

```diff
@@ -133,31 +133,29 @@
         group_data = self.df[self._group_indices[self._current_index]]
         self._current_index += 1
 
         return group_name, group_data
 
     def agg(
         self,
-        aggs: IntoExpr | Iterable[IntoExpr] | None = None,
-        *more_aggs: IntoExpr,
+        *aggs: IntoExpr | Iterable[IntoExpr],
         **named_aggs: IntoExpr,
     ) -> DataFrame:
         """
         Compute aggregations for each group of a groupby operation.
 
         Parameters
         ----------
-        aggs
-            Aggregations to compute for each group of the groupby operation.
+        *aggs
+            Aggregations to compute for each group of the groupby operation,
+            specified as positional arguments.
             Accepts expression input. Strings are parsed as column names.
-        *more_aggs
-            Additional aggregations, specified as positional arguments.
         **named_aggs
-            Additional aggregations, specified as keyword arguments. The resulting
-            columns will be renamed to the keyword used.
+            Additional aggregations, specified as keyword arguments.
+            The resulting columns will be renamed to the keyword used.
 
         Examples
         --------
         Compute the sum of a column for each group.
 
         >>> df = pl.DataFrame(
         ...     {
@@ -226,15 +224,15 @@
          b    5      10.0           
         
 
         """
         return (
             self.df.lazy()
             .groupby(self.by, *self.more_by, maintain_order=self.maintain_order)
-            .agg(aggs, *more_aggs, **named_aggs)
+            .agg(*aggs, **named_aggs)
             .collect(no_optimization=True)
         )
 
     def apply(self, function: Callable[[DataFrame], DataFrame]) -> DataFrame:
         """
         Apply a custom/user-defined function (UDF) over the groups as a sub-DataFrame.
 
@@ -820,29 +818,28 @@
         group_data = self.df[self._group_indices[self._current_index]]
         self._current_index += 1
 
         return group_name, group_data
 
     def agg(
         self,
-        aggs: IntoExpr | Iterable[IntoExpr] | None = None,
-        *more_aggs: IntoExpr,
+        *aggs: IntoExpr | Iterable[IntoExpr],
         **named_aggs: IntoExpr,
     ) -> DataFrame:
         return (
             self.df.lazy()
             .groupby_rolling(
                 index_column=self.time_column,
                 period=self.period,
                 offset=self.offset,
                 closed=self.closed,
                 by=self.by,
                 check_sorted=self.check_sorted,
             )
-            .agg(aggs, *more_aggs, **named_aggs)
+            .agg(*aggs, **named_aggs)
             .collect(no_optimization=True)
         )
 
     def apply(
         self,
         function: Callable[[DataFrame], DataFrame],
         schema: SchemaDict | None,
@@ -956,17 +953,17 @@
         truncate: bool,
         include_boundaries: bool,
         closed: ClosedInterval,
         by: IntoExpr | Iterable[IntoExpr] | None,
         start_by: StartBy,
         check_sorted: bool,
     ):
+        every = _timedelta_to_pl_duration(every)
         period = _timedelta_to_pl_duration(period)
         offset = _timedelta_to_pl_duration(offset)
-        every = _timedelta_to_pl_duration(every)
 
         self.df = df
         self.time_column = index_column
         self.every = every
         self.period = period
         self.offset = offset
         self.truncate = truncate
@@ -1022,16 +1019,15 @@
         group_data = self.df[self._group_indices[self._current_index]]
         self._current_index += 1
 
         return group_name, group_data
 
     def agg(
         self,
-        aggs: IntoExpr | Iterable[IntoExpr] | None = None,
-        *more_aggs: IntoExpr,
+        *aggs: IntoExpr | Iterable[IntoExpr],
         **named_aggs: IntoExpr,
     ) -> DataFrame:
         return (
             self.df.lazy()
             .groupby_dynamic(
                 index_column=self.time_column,
                 every=self.every,
@@ -1040,15 +1036,15 @@
                 truncate=self.truncate,
                 include_boundaries=self.include_boundaries,
                 closed=self.closed,
                 by=self.by,
                 start_by=self.start_by,
                 check_sorted=self.check_sorted,
             )
-            .agg(aggs, *more_aggs, **named_aggs)
+            .agg(*aggs, **named_aggs)
             .collect(no_optimization=True)
         )
 
     def apply(
         self,
         function: Callable[[DataFrame], DataFrame],
         schema: SchemaDict | None,
```

### Comparing `polars_lts_cpu-0.18.0/polars/datatypes/__init__.py` & `polars_lts_cpu-0.18.1/polars/datatypes/__init__.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/datatypes/classes.py` & `polars_lts_cpu-0.18.1/polars/datatypes/classes.py`

 * *Files 0% similar despite different names*

```diff
@@ -250,15 +250,15 @@
 
     NOTE: this is an experimental work-in-progress feature and may not work as expected.
     """
 
     precision: int | None
     scale: int
 
-    def __init__(self, precision: int | None, scale: int):
+    def __init__(self, scale: int, precision: int | None = None):
         self.precision = precision
         self.scale = scale
 
     def __repr__(self) -> str:
         return (
             f"{self.__class__.__name__}(precision={self.precision}, scale={self.scale})"
         )
```

### Comparing `polars_lts_cpu-0.18.0/polars/datatypes/constants.py` & `polars_lts_cpu-0.18.1/polars/datatypes/constants.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/datatypes/constructor.py` & `polars_lts_cpu-0.18.1/polars/datatypes/constructor.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/datatypes/convert.py` & `polars_lts_cpu-0.18.1/polars/datatypes/convert.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/dependencies.py` & `polars_lts_cpu-0.18.1/polars/dependencies.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/exceptions.py` & `polars_lts_cpu-0.18.1/polars/exceptions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/expr/array.py` & `polars_lts_cpu-0.18.1/polars/expr/array.py`

 * *Files 9% similar despite different names*

```diff
@@ -83,7 +83,37 @@
         
          3   
          7   
         
 
         """
         return wrap_expr(self._pyexpr.array_sum())
+
+    def unique(self, *, maintain_order: bool = False) -> Expr:
+        """
+        Get the unique/distinct values in the array.
+
+        Parameters
+        ----------
+        maintain_order
+            Maintain order of data. This requires more work.
+
+        Examples
+        --------
+        >>> df = pl.DataFrame(
+        ...     {
+        ...         "a": [[1, 1, 2]],
+        ...     },
+        ...     schema_overrides={"a": pl.Array(width=3, inner=pl.Int64)},
+        ... )
+        >>> df.select(pl.col("a").arr.unique())
+        shape: (1, 1)
+        
+         a         
+         ---       
+         list[i64] 
+        
+         [1, 2]    
+        
+
+        """
+        return wrap_expr(self._pyexpr.array_unique(maintain_order))
```

### Comparing `polars_lts_cpu-0.18.0/polars/expr/binary.py` & `polars_lts_cpu-0.18.1/polars/expr/binary.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/expr/categorical.py` & `polars_lts_cpu-0.18.1/polars/expr/categorical.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/expr/datetime.py` & `polars_lts_cpu-0.18.1/polars/expr/datetime.py`

 * *Files 0% similar despite different names*

```diff
@@ -62,14 +62,15 @@
         - 1m  # 1 minute
         - 1h  # 1 hour
         - 1d  # 1 day
         - 1w  # 1 calendar week
         - 1mo # 1 calendar month
         - 1mo_saturating # same as above, but saturates to the last day of the month
           if the target date does not exist
+        - 1q  # 1 calendar quarter
         - 1y  # 1 calendar year
 
         These strings can be combined:
 
         - 3d12h4m25s # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
@@ -183,14 +184,15 @@
         1ms  # 1 millisecond
         1s   # 1 second
         1m   # 1 minute
         1h   # 1 hour
         1d   # 1 day
         1w   # 1 calendar week
         1mo  # 1 calendar month
+        1q   # 1 calendar quarter
         1y   # 1 calendar year
 
         eg: 3d12h4m25s  # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
         their month should saturate at the largest date (e.g. 2022-02-29 -> 2022-02-28)
         instead of erroring.
@@ -331,15 +333,15 @@
          2023-07-05 07:08:09.101  2022-07-05 07:08:09.101  2022-07-05 04:05:06 
         
         """
         if not isinstance(time, (dt.time, pl.Expr)):
             raise TypeError(
                 f"expected 'time' to be a python time or polars expression, found {time!r}"
             )
-        time = parse_as_expression(time)._pyexpr
+        time = parse_as_expression(time)
         return wrap_expr(self._pyexpr.dt_combine(time, time_unit))
 
     def to_string(self, format: str) -> Expr:
         """
         Convert a Date/Time/Datetime column into a Utf8 column with the given format.
 
         Similar to ``cast(pl.Utf8)``, but this method allows you to customize the
@@ -1798,14 +1800,15 @@
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
             - 1d    (1 day)
             - 1w    (1 week)
             - 1mo   (1 calendar month)
+            - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
         Suffix with `"_saturating"` to indicate that dates too large for
         their month should saturate at the largest date (e.g. 2022-02-29 -> 2022-02-28)
         instead of erroring.
```

### Comparing `polars_lts_cpu-0.18.0/polars/expr/expr.py` & `polars_lts_cpu-0.18.1/polars/expr/expr.py`

 * *Files 2% similar despite different names*

```diff
@@ -51,19 +51,21 @@
 from polars.utils.meta import threadpool_size
 from polars.utils.various import sphinx_accessor
 
 with contextlib.suppress(ImportError):  # Module not available when building docs
     from polars.polars import arg_where as py_arg_where
     from polars.polars import reduce as pyreduce
 
+with contextlib.suppress(ImportError):  # Module not available when building docs
+    from polars.polars import PyExpr
+
 if TYPE_CHECKING:
     import sys
 
     from polars import DataFrame, LazyFrame, Series
-    from polars.polars import PyExpr
     from polars.type_aliases import (
         ApplyStrategy,
         ClosedInterval,
         FillNullStrategy,
         InterpolationMethod,
         IntoExpr,
         NullBehavior,
@@ -187,15 +189,15 @@
     def __pos__(self) -> Expr:
         return F.lit(0) + self
 
     def __pow__(self, power: int | float | Series | Expr) -> Self:
         return self.pow(power)
 
     def __rpow__(self, base: int | float | Expr) -> Expr:
-        return parse_as_expression(base) ** self
+        return self._from_pyexpr(parse_as_expression(base)) ** self
 
     def __sub__(self, other: Any) -> Self:
         return self._from_pyexpr(self._pyexpr - self._to_pyexpr(other))
 
     def __rsub__(self, other: Any) -> Self:
         return self._from_pyexpr(self._to_pyexpr(other) - self._pyexpr)
 
@@ -236,14 +238,29 @@
 
         def function(s: Series) -> Series:  # pragma: no cover
             args = [inp if not isinstance(inp, Expr) else s for inp in inputs]
             return ufunc(*args, **kwargs)
 
         return self.map(function)
 
+    @classmethod
+    def from_json(cls, value: str) -> Self:
+        """
+        Read an expression from a JSON encoded string to construct an Expression.
+
+        Parameters
+        ----------
+        value
+            JSON encoded string value
+
+        """
+        expr = cls.__new__(cls)
+        expr._pyexpr = PyExpr.meta_read_json(value)
+        return expr
+
     def to_physical(self) -> Self:
         """
         Cast to physical representation of the logical dtype.
 
         - :func:`polars.datatypes.Date` -> :func:`polars.datatypes.Int32`
         - :func:`polars.datatypes.Datetime` -> :func:`polars.datatypes.Int64`
         - :func:`polars.datatypes.Time` -> :func:`polars.datatypes.Int64`
@@ -1240,15 +1257,15 @@
          i64  i64  
         
          8    null 
          10   4    
         
 
         """
-        other = parse_as_expression(other)._pyexpr
+        other = parse_as_expression(other)
         return self._from_pyexpr(self._pyexpr.append(other, upcast))
 
     def rechunk(self) -> Self:
         """
         Create a single chunk of memory for this Series.
 
         Examples
@@ -1674,15 +1691,15 @@
          --- 
          i64 
         
          44  
         
 
         """
-        other = parse_as_expression(other)._pyexpr
+        other = parse_as_expression(other)
         return self._from_pyexpr(self._pyexpr.dot(other))
 
     def mode(self) -> Self:
         """
         Compute the most occurring value(s).
 
         Can return multiple Values.
@@ -2045,15 +2062,15 @@
          ---   ---    --- 
          u32   u32    u32 
         
          0     2      4   
         
 
         """
-        element = parse_as_expression(element)._pyexpr
+        element = parse_as_expression(element)
         return self._from_pyexpr(self._pyexpr.search_sorted(element, side))
 
     def sort_by(
         self,
         by: IntoExpr | Iterable[IntoExpr],
         *more_by: IntoExpr,
         descending: bool | Sequence[bool] = False,
@@ -2226,18 +2243,18 @@
          two    99    
         
 
         """
         if isinstance(indices, list) or (
             _check_for_numpy(indices) and isinstance(indices, np.ndarray)
         ):
-            indices_lit = F.lit(pl.Series("", indices, dtype=UInt32))
+            indices_lit = F.lit(pl.Series("", indices, dtype=UInt32))._pyexpr
         else:
             indices_lit = parse_as_expression(indices)  # type: ignore[arg-type]
-        return self._from_pyexpr(self._pyexpr.take(indices_lit._pyexpr))
+        return self._from_pyexpr(self._pyexpr.take(indices_lit))
 
     def shift(self, periods: int = 1) -> Self:
         """
         Shift the values by a given period.
 
         Parameters
         ----------
@@ -2292,15 +2309,15 @@
          a   
          1   
          2   
          3   
         
 
         """
-        fill_value = parse_as_expression(fill_value, str_as_lit=True)._pyexpr
+        fill_value = parse_as_expression(fill_value, str_as_lit=True)
         return self._from_pyexpr(self._pyexpr.shift_and_fill(periods, fill_value))
 
     def fill_null(
         self,
         value: Any | None = None,
         strategy: FillNullStrategy | None = None,
         limit: int | None = None,
@@ -2370,15 +2387,15 @@
         elif strategy not in ("forward", "backward") and limit is not None:
             raise ValueError(
                 "can only specify 'limit' when strategy is set to"
                 " 'backward' or 'forward'"
             )
 
         if value is not None:
-            value = parse_as_expression(value, str_as_lit=True)._pyexpr
+            value = parse_as_expression(value, str_as_lit=True)
             return self._from_pyexpr(self._pyexpr.fill_null(value))
         else:
             return self._from_pyexpr(
                 self._pyexpr.fill_null_with_strategy(strategy, limit)
             )
 
     def fill_nan(self, value: int | float | Expr | None) -> Self:
@@ -2402,15 +2419,15 @@
         
          1.0   4.0  
          null  zero 
          zero  6.0  
         
 
         """
-        fill_value = parse_as_expression(value, str_as_lit=True)._pyexpr
+        fill_value = parse_as_expression(value, str_as_lit=True)
         return self._from_pyexpr(self._pyexpr.fill_nan(fill_value))
 
     def forward_fill(self, limit: int | None = None) -> Self:
         """
         Fill missing values with the latest seen values.
 
         Parameters
@@ -2937,20 +2954,20 @@
         expr
             Column(s) to group by. Accepts expression input. Strings are parsed as
             column names.
         *more_exprs
             Additional columns to group by, specified as positional arguments.
         mapping_strategy: {'group_to_rows', 'join', 'explode'}
             - group_to_rows
-                If the aggregation results in multiple values, assign them back to there
+                If the aggregation results in multiple values, assign them back to their
                 position in the DataFrame. This can only be done if the group yields
-                the same elements before aggregation as after
+                the same elements before aggregation as after.
             - join
                 Join the groups as 'List<group_dtype>' to the row positions.
-                warning: this can be memory intensive
+                warning: this can be memory intensive.
             - explode
                 Don't do any mapping, but simply flatten the group.
                 This only makes sense if the input data is sorted.
 
         Examples
         --------
         Pass the name of a column to compute the expression over that column.
@@ -3165,15 +3182,15 @@
          --- 
          f64 
         
          1.5 
         
 
         """
-        quantile = parse_as_expression(quantile)._pyexpr
+        quantile = parse_as_expression(quantile)
         return self._from_pyexpr(self._pyexpr.quantile(quantile, interpolation))
 
     def filter(self, predicate: Expr) -> Self:
         """
         Filter a single column.
 
         Mostly useful in an aggregation context. If you want to filter on a DataFrame
@@ -3611,15 +3628,15 @@
         
          5   
          6   
          7   
         
 
         """
-        offset = -parse_as_expression(n)
+        offset = -self._from_pyexpr(parse_as_expression(n))
         return self.slice(offset, n)
 
     def limit(self, n: int | Expr = 10) -> Self:
         """
         Get the first `n` rows (alias for :func:`Expr.head`).
 
         Parameters
@@ -4216,15 +4233,15 @@
          1    1.0    1.0        
          2    8.0    2.0        
          4    64.0   16.0       
          8    512.0  512.0      
         
 
         """
-        exponent = parse_as_expression(exponent)._pyexpr
+        exponent = parse_as_expression(exponent)
         return self._from_pyexpr(self._pyexpr.pow(exponent))
 
     def xor(self, other: Any) -> Self:
         """
         Method equivalent of logical exclusive-or operator ``expr ^ other``.
 
         Parameters
@@ -4309,17 +4326,18 @@
         
 
         """
         if isinstance(other, Collection) and not isinstance(other, str):
             if isinstance(other, (Set, FrozenSet)):
                 other = sorted(other)
             other = F.lit(None) if len(other) == 0 else F.lit(pl.Series(other))
+            other = other._pyexpr
         else:
             other = parse_as_expression(other)
-        return self._from_pyexpr(self._pyexpr.is_in(other._pyexpr))
+        return self._from_pyexpr(self._pyexpr.is_in(other))
 
     def repeat_by(self, by: pl.Series | Expr | str | int) -> Self:
         """
         Repeat the elements in this Series as specified in the given expression.
 
         The repeated elements are expanded into a `List`.
 
@@ -4351,15 +4369,15 @@
         
          ["x"]           
          ["y", "y"]      
          ["z", "z", "z"] 
         
 
         """
-        by = parse_as_expression(by)._pyexpr
+        by = parse_as_expression(by)
         return self._from_pyexpr(self._pyexpr.repeat_by(by))
 
     def is_between(
         self,
         lower_bound: IntoExpr,
         upper_bound: IntoExpr,
         closed: ClosedInterval = "both",
@@ -4437,16 +4455,16 @@
          b    true       
          c    true       
          d    false      
          e    false      
         
 
         """
-        lower_bound = parse_as_expression(lower_bound)
-        upper_bound = parse_as_expression(upper_bound)
+        lower_bound = self._from_pyexpr(parse_as_expression(lower_bound))
+        upper_bound = self._from_pyexpr(parse_as_expression(upper_bound))
 
         if closed == "none":
             return (self > lower_bound) & (self < upper_bound)
         elif closed == "both":
             return (self >= lower_bound) & (self <= upper_bound)
         elif closed == "right":
             return (self > lower_bound) & (self <= upper_bound)
@@ -4652,14 +4670,25 @@
         """
         Apply a rolling min (moving min) over the values in this array.
 
         A window of length `window_size` will traverse the array. The values that fill
         this window will (optionally) be multiplied with the weights given by the
         `weight` vector. The resulting values will be aggregated to their sum.
 
+        If you pass a ``by`` column ``<t_0, t_1, ..., t_2>``, then by default the
+        windows will be:
+
+            - [t_0 - window_size, t_0)
+            - [t_1 - window_size, t_1)
+            - ...
+            - [t_n - window_size, t_n)
+
+        Otherwise, the window at a given row will include the row itself, and the
+        `window_size - 1` elements before it.
+
         Parameters
         ----------
         window_size
             The length of the window. Can be a fixed integer size, or a dynamic temporal
             size indicated by a timedelta or the following string language:
 
             - 1ns   (1 nanosecond)
@@ -4667,14 +4696,15 @@
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
             - 1d    (1 day)
             - 1w    (1 week)
             - 1mo   (1 calendar month)
+            - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
@@ -4687,15 +4717,15 @@
             The number of values in the window that should be non-null before computing
             a result. If None, it will be set equal to window size.
         center
             Set the labels at the center of the window
         by
             If the `window_size` is temporal for instance `"5h"` or `"3s"`, you must
             set the column that will be used to determine the windows. This column must
-            be of dtype `{Date, Datetime}`
+            be of dtype Datetime.
         closed : {'left', 'right', 'both', 'none'}
             Define which sides of the temporal interval are closed (inclusive).
 
         Warnings
         --------
         This functionality is experimental and may change without it being considered a
         breaking change.
@@ -4751,14 +4781,25 @@
         """
         Apply a rolling max (moving max) over the values in this array.
 
         A window of length `window_size` will traverse the array. The values that fill
         this window will (optionally) be multiplied with the weights given by the
         `weight` vector. The resulting values will be aggregated to their sum.
 
+        If you pass a ``by`` column ``<t_0, t_1, ..., t_2>``, then by default the
+        windows will be:
+
+            - [t_0 - window_size, t_0)
+            - [t_1 - window_size, t_1)
+            - ...
+            - [t_n - window_size, t_n)
+
+        Otherwise, the window at a given row will include the row itself, and the
+        `window_size - 1` elements before it.
+
         Parameters
         ----------
         window_size
             The length of the window. Can be a fixed integer size, or a dynamic temporal
             size indicated by a timedelta or the following string language:
 
             - 1ns   (1 nanosecond)
@@ -4766,14 +4807,15 @@
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
             - 1d    (1 day)
             - 1w    (1 week)
             - 1mo   (1 calendar month)
+            - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
@@ -4786,15 +4828,15 @@
             The number of values in the window that should be non-null before computing
             a result. If None, it will be set equal to window size.
         center
             Set the labels at the center of the window
         by
             If the `window_size` is temporal, for instance `"5h"` or `"3s"`, you must
             set the column that will be used to determine the windows. This column must
-            be of dtype `{Date, Datetime}`
+            be of dtype Datetime.
         closed : {'left', 'right', 'both', 'none'}
             Define which sides of the temporal interval are closed (inclusive).
 
         Warnings
         --------
         This functionality is experimental and may change without it being considered a
         breaking change.
@@ -4850,14 +4892,25 @@
         """
         Apply a rolling mean (moving mean) over the values in this array.
 
         A window of length `window_size` will traverse the array. The values that fill
         this window will (optionally) be multiplied with the weights given by the
         `weight` vector. The resulting values will be aggregated to their sum.
 
+        If you pass a ``by`` column ``<t_0, t_1, ..., t_2>``, then by default the
+        windows will be:
+
+            - [t_0 - window_size, t_0)
+            - [t_1 - window_size, t_1)
+            - ...
+            - [t_n - window_size, t_n)
+
+        Otherwise, the window at a given row will include the row itself, and the
+        `window_size - 1` elements before it.
+
         Parameters
         ----------
         window_size
             The length of the window. Can be a fixed integer size, or a dynamic temporal
             size indicated by a timedelta or the following string language:
 
             - 1ns   (1 nanosecond)
@@ -4865,14 +4918,15 @@
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
             - 1d    (1 day)
             - 1w    (1 week)
             - 1mo   (1 calendar month)
+            - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
@@ -4885,15 +4939,15 @@
             The number of values in the window that should be non-null before computing
             a result. If None, it will be set equal to window size.
         center
             Set the labels at the center of the window
         by
             If the `window_size` is temporal for instance `"5h"` or `"3s"`, you must
             set the column that will be used to determine the windows. This column must
-            be of dtype `{Date, Datetime}`
+            be of dtype Datetime.
         closed : {'left', 'right', 'both', 'none'}
             Define which sides of the temporal interval are closed (inclusive).
 
         Warnings
         --------
         This functionality is experimental and may change without it being considered a
         breaking change.
@@ -4949,14 +5003,25 @@
         """
         Apply a rolling sum (moving sum) over the values in this array.
 
         A window of length `window_size` will traverse the array. The values that fill
         this window will (optionally) be multiplied with the weights given by the
         `weight` vector. The resulting values will be aggregated to their sum.
 
+        If you pass a ``by`` column ``<t_0, t_1, ..., t_2>``, then by default the
+        windows will be:
+
+            - [t_0 - window_size, t_0)
+            - [t_1 - window_size, t_1)
+            - ...
+            - [t_n - window_size, t_n)
+
+        Otherwise, the window at a given row will include the row itself, and the
+        `window_size - 1` elements before it.
+
         Parameters
         ----------
         window_size
             The length of the window. Can be a fixed integer size, or a dynamic temporal
             size indicated by a timedelta or the following string language:
 
             - 1ns   (1 nanosecond)
@@ -4964,14 +5029,15 @@
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
             - 1d    (1 day)
             - 1w    (1 week)
             - 1mo   (1 calendar month)
+            - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
@@ -5040,22 +5106,34 @@
         window_size: int | timedelta | str,
         weights: list[float] | None = None,
         min_periods: int | None = None,
         *,
         center: bool = False,
         by: str | None = None,
         closed: ClosedInterval = "left",
+        ddof: int = 1,
     ) -> Self:
         """
         Compute a rolling standard deviation.
 
         A window of length `window_size` will traverse the array. The values that fill
         this window will (optionally) be multiplied with the weights given by the
         `weight` vector. The resulting values will be aggregated to their sum.
 
+        If you pass a ``by`` column ``<t_0, t_1, ..., t_2>``, then by default the
+        windows will be:
+
+            - [t_0 - window_size, t_0)
+            - [t_1 - window_size, t_1)
+            - ...
+            - [t_n - window_size, t_n)
+
+        Otherwise, the window at a given row will include the row itself, and the
+        `window_size - 1` elements before it.
+
         Parameters
         ----------
         window_size
             The length of the window. Can be a fixed integer size, or a dynamic temporal
             size indicated by a timedelta or the following string language:
 
             - 1ns   (1 nanosecond)
@@ -5063,14 +5141,15 @@
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
             - 1d    (1 day)
             - 1w    (1 week)
             - 1mo   (1 calendar month)
+            - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
@@ -5083,17 +5162,19 @@
             The number of values in the window that should be non-null before computing
             a result. If None, it will be set equal to window size.
         center
             Set the labels at the center of the window
         by
             If the `window_size` is temporal for instance `"5h"` or `"3s"`, you must
             set the column that will be used to determine the windows. This column must
-            be of dtype `{Date, Datetime}`
+            be of dtype Datetime.
         closed : {'left', 'right', 'both', 'none'}
             Define which sides of the temporal interval are closed (inclusive).
+        ddof
+            "Delta Degrees of Freedom": The divisor for a length N window is N - ddof
 
         Warnings
         --------
         This functionality is experimental and may change without it being considered a
         breaking change.
 
         Notes
@@ -5126,35 +5207,47 @@
 
         """
         window_size, min_periods = _prepare_rolling_window_args(
             window_size, min_periods
         )
         return self._from_pyexpr(
             self._pyexpr.rolling_std(
-                window_size, weights, min_periods, center, by, closed
+                window_size, weights, min_periods, center, by, closed, ddof
             )
         )
 
     def rolling_var(
         self,
         window_size: int | timedelta | str,
         weights: list[float] | None = None,
         min_periods: int | None = None,
         *,
         center: bool = False,
         by: str | None = None,
         closed: ClosedInterval = "left",
+        ddof: int = 1,
     ) -> Self:
         """
         Compute a rolling variance.
 
         A window of length `window_size` will traverse the array. The values that fill
         this window will (optionally) be multiplied with the weights given by the
         `weight` vector. The resulting values will be aggregated to their sum.
 
+        If you pass a ``by`` column ``<t_0, t_1, ..., t_2>``, then by default the
+        windows will be:
+
+            - [t_0 - window_size, t_0)
+            - [t_1 - window_size, t_1)
+            - ...
+            - [t_n - window_size, t_n)
+
+        Otherwise, the window at a given row will include the row itself, and the
+        `window_size - 1` elements before it.
+
         Parameters
         ----------
         window_size
             The length of the window. Can be a fixed integer size, or a dynamic temporal
             size indicated by a timedelta or the following string language:
 
             - 1ns   (1 nanosecond)
@@ -5162,14 +5255,15 @@
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
             - 1d    (1 day)
             - 1w    (1 week)
             - 1mo   (1 calendar month)
+            - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
@@ -5182,17 +5276,19 @@
             The number of values in the window that should be non-null before computing
             a result. If None, it will be set equal to window size.
         center
             Set the labels at the center of the window
         by
             If the `window_size` is temporal for instance `"5h"` or `"3s"`, you must
             set the column that will be used to determine the windows. This column must
-            be of dtype `{Date, Datetime}`
+            be of dtype Datetime.
         closed : {'left', 'right', 'both', 'none'}
             Define which sides of the temporal interval are closed (inclusive).
+        ddof
+            "Delta Degrees of Freedom": The divisor for a length N window is N - ddof
 
         Warnings
         --------
         This functionality is experimental and may change without it being considered a
         breaking change.
 
         Notes
@@ -5225,15 +5321,21 @@
 
         """
         window_size, min_periods = _prepare_rolling_window_args(
             window_size, min_periods
         )
         return self._from_pyexpr(
             self._pyexpr.rolling_var(
-                window_size, weights, min_periods, center, by, closed
+                window_size,
+                weights,
+                min_periods,
+                center,
+                by,
+                closed,
+                ddof,
             )
         )
 
     def rolling_median(
         self,
         window_size: int | timedelta | str,
         weights: list[float] | None = None,
@@ -5242,14 +5344,25 @@
         center: bool = False,
         by: str | None = None,
         closed: ClosedInterval = "left",
     ) -> Self:
         """
         Compute a rolling median.
 
+        If you pass a ``by`` column ``<t_0, t_1, ..., t_2>``, then by default the
+        windows will be:
+
+            - [t_0 - window_size, t_0)
+            - [t_1 - window_size, t_1)
+            - ...
+            - [t_n - window_size, t_n)
+
+        Otherwise, the window at a given row will include the row itself, and the
+        `window_size - 1` elements before it.
+
         Parameters
         ----------
         window_size
             The length of the window. Can be a fixed integer size, or a dynamic temporal
             size indicated by a timedelta or the following string language:
 
             - 1ns   (1 nanosecond)
@@ -5257,14 +5370,15 @@
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
             - 1d    (1 day)
             - 1w    (1 week)
             - 1mo   (1 calendar month)
+            - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
@@ -5277,15 +5391,15 @@
             The number of values in the window that should be non-null before computing
             a result. If None, it will be set equal to window size.
         center
             Set the labels at the center of the window
         by
             If the `window_size` is temporal for instance `"5h"` or `"3s"`, you must
             set the column that will be used to determine the windows. This column must
-            be of dtype `{Date, Datetime}`
+            be of dtype Datetime.
         closed : {'left', 'right', 'both', 'none'}
             Define which sides of the temporal interval are closed (inclusive).
 
         Warnings
         --------
         This functionality is experimental and may change without it being considered a
         breaking change.
@@ -5339,14 +5453,25 @@
         center: bool = False,
         by: str | None = None,
         closed: ClosedInterval = "left",
     ) -> Self:
         """
         Compute a rolling quantile.
 
+        If you pass a ``by`` column ``<t_0, t_1, ..., t_2>``, then by default the
+        windows will be:
+
+            - [t_0 - window_size, t_0)
+            - [t_1 - window_size, t_1)
+            - ...
+            - [t_n - window_size, t_n)
+
+        Otherwise, the window at a given row will include the row itself, and the
+        `window_size - 1` elements before it.
+
         Parameters
         ----------
         quantile
             Quantile between 0.0 and 1.0.
         interpolation : {'nearest', 'higher', 'lower', 'midpoint', 'linear'}
             Interpolation method.
         window_size
@@ -5358,14 +5483,15 @@
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
             - 1d    (1 day)
             - 1w    (1 week)
             - 1mo   (1 calendar month)
+            - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
@@ -5378,15 +5504,15 @@
             The number of values in the window that should be non-null before computing
             a result. If None, it will be set equal to window size.
         center
             Set the labels at the center of the window
         by
             If the `window_size` is temporal for instance `"5h"` or `"3s"`, you must
             set the column that will be used to determine the windows. This column must
-            be of dtype `{Date, Datetime}`
+            be of dtype Datetime.
         closed : {'left', 'right', 'both', 'none'}
             Define which sides of the temporal interval are closed (inclusive).
 
         Warnings
         --------
         This functionality is experimental and may change without it being considered a
         breaking change.
@@ -5453,14 +5579,17 @@
         Prefer:
 
             * rolling_min
             * rolling_max
             * rolling_mean
             * rolling_sum
 
+        The window at a given row will include the row itself and the `window_size - 1`
+        elements before it.
+
         Parameters
         ----------
         function
             Aggregation function
         window_size
             The length of the window.
         weights
@@ -5506,21 +5635,45 @@
             )
         )
 
     def rolling_skew(self, window_size: int, *, bias: bool = True) -> Self:
         """
         Compute a rolling skew.
 
+        The window at a given row includes the row itself and the
+        `window_size - 1` elements before it.
+
         Parameters
         ----------
         window_size
             Integer size of the rolling window.
         bias
             If False, the calculations are corrected for statistical bias.
 
+        Examples
+        --------
+        >>> df = pl.DataFrame({"a": [1, 4, 2, 9]})
+        >>> df.select(pl.col("a").rolling_skew(3))
+        shape: (4, 1)
+        
+         a        
+         ---      
+         f64      
+        
+         null     
+         null     
+         0.381802 
+         0.47033  
+        
+
+        Note how the values match the following:
+
+        >>> pl.Series([1, 4, 2]).skew(), pl.Series([4, 2, 9]).skew()
+        (0.38180177416060584, 0.47033046033698594)
+
         """
         return self._from_pyexpr(self._pyexpr.rolling_skew(window_size, bias))
 
     def abs(self) -> Self:
         """
         Compute absolute values.
```

### Comparing `polars_lts_cpu-0.18.0/polars/expr/list.py` & `polars_lts_cpu-0.18.1/polars/expr/list.py`

 * *Files 0% similar despite different names*

```diff
@@ -291,15 +291,15 @@
         
          3    
          null 
          1    
         
 
         """
-        index = parse_as_expression(index)._pyexpr
+        index = parse_as_expression(index)
         return wrap_expr(self._pyexpr.list_get(index))
 
     def take(
         self,
         index: Expr | Series | list[int] | list[list[int]],
         *,
         null_on_oob: bool = False,
@@ -319,15 +319,15 @@
             True -> set as null
             False -> raise an error
             Note that defaulting to raising an error is much cheaper
 
         """
         if isinstance(index, list):
             index = pl.Series(index)
-        index = parse_as_expression(index)._pyexpr
+        index = parse_as_expression(index)
         return wrap_expr(self._pyexpr.list_take(index, null_on_oob))
 
     def first(self) -> Expr:
         """
         Get the first value of the sublists.
 
         Examples
@@ -397,15 +397,15 @@
         
          true  
          false 
          true  
         
 
         """
-        item = parse_as_expression(item, str_as_lit=True)._pyexpr
+        item = parse_as_expression(item, str_as_lit=True)
         return wrap_expr(self._pyexpr.list_contains(item))
 
     def join(self, separator: str) -> Expr:
         """
         Join all string items in a sublist and place a separator between them.
 
         This errors if inner type of list `!= Utf8`.
@@ -589,16 +589,16 @@
         Series: 'a' [list[i64]]
         [
             [2, 3]
             [2, 1]
         ]
 
         """
-        offset = parse_as_expression(offset)._pyexpr
-        length = parse_as_expression(length)._pyexpr
+        offset = parse_as_expression(offset)
+        length = parse_as_expression(length)
         return wrap_expr(self._pyexpr.list_slice(offset, length))
 
     def head(self, n: int | str | Expr = 5) -> Expr:
         """
         Slice the first `n` values of every sublist.
 
         Parameters
@@ -637,15 +637,15 @@
         Series: 'a' [list[i64]]
         [
             [3, 4]
             [2, 1]
         ]
 
         """
-        n = parse_as_expression(n)._pyexpr
+        n = parse_as_expression(n)
         return wrap_expr(self._pyexpr.list_tail(n))
 
     def explode(self) -> Expr:
         """
         Returns a column with a separate row for every list element.
 
         Returns
@@ -700,15 +700,15 @@
          0              
          2              
          1              
          0              
         
 
         """
-        element = parse_as_expression(element, str_as_lit=True)._pyexpr
+        element = parse_as_expression(element, str_as_lit=True)
         return wrap_expr(self._pyexpr.list_count_match(element))
 
     @deprecated_alias(name_generator="fields")
     def to_struct(
         self,
         n_field_strategy: ToStructStrategy = "first_non_null",
         fields: Sequence[str] | Callable[[int], str] | None = None,
```

### Comparing `polars_lts_cpu-0.18.0/polars/expr/meta.py` & `polars_lts_cpu-0.18.1/polars/expr/meta.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,14 +1,19 @@
 from __future__ import annotations
 
-from typing import TYPE_CHECKING
+from io import BytesIO, StringIO
+from pathlib import Path
+from typing import TYPE_CHECKING, overload
 
 from polars.utils._wrap import wrap_expr
+from polars.utils.various import normalise_filepath
 
 if TYPE_CHECKING:
+    from io import IOBase
+
     from polars import Expr
 
 
 class ExprMetaNameSpace:
     """Namespace for expressions on a meta level."""
 
     _accessor = "meta"
@@ -64,7 +69,50 @@
     def root_names(self) -> list[str]:
         """Get a list with the root column name."""
         return self._pyexpr.meta_root_names()
 
     def undo_aliases(self) -> Expr:
         """Undo any renaming operation like ``alias`` or ``keep_name``."""
         return wrap_expr(self._pyexpr.meta_undo_aliases())
+
+    def _as_selector(self) -> Expr:
+        """Turn this expression in a selector."""
+        return wrap_expr(self._pyexpr._meta_as_selector())
+
+    def _selector_add(self, other: Expr) -> Expr:
+        """Add selectors."""
+        return wrap_expr(self._pyexpr._meta_selector_add(other._pyexpr))
+
+    def _selector_sub(self, other: Expr) -> Expr:
+        """Subtract selectors."""
+        return wrap_expr(self._pyexpr._meta_selector_sub(other._pyexpr))
+
+    def _selector_and(self, other: Expr) -> Expr:
+        """& selectors."""
+        return wrap_expr(self._pyexpr._meta_selector_and(other._pyexpr))
+
+    @overload
+    def write_json(self, file: None = ...) -> str:
+        ...
+
+    @overload
+    def write_json(self, file: IOBase | str | Path) -> None:
+        ...
+
+    def write_json(self, file: IOBase | str | Path | None = None) -> str | None:
+        """Write expression to json."""
+        if isinstance(file, (str, Path)):
+            file = normalise_filepath(file)
+        to_string_io = (file is not None) and isinstance(file, StringIO)
+        if file is None or to_string_io:
+            with BytesIO() as buf:
+                self._pyexpr.meta_write_json(buf)
+                json_bytes = buf.getvalue()
+
+            json_str = json_bytes.decode("utf8")
+            if to_string_io:
+                file.write(json_str)  # type: ignore[union-attr]
+            else:
+                return json_str
+        else:
+            self._pyexpr.meta_write_json(file)
+        return None
```

### Comparing `polars_lts_cpu-0.18.0/polars/expr/string.py` & `polars_lts_cpu-0.18.1/polars/expr/string.py`

 * *Files 2% similar despite different names*

```diff
@@ -47,14 +47,18 @@
             for the full specification. Example: ``"%Y-%m-%d"``.
             If set to None (default), the format is inferred from the data.
         strict
             Raise an error if any conversion fails.
         exact
             Require an exact format match. If False, allow the format to match anywhere
             in the target string.
+
+            .. note::
+                Using ``exact=False`` introduces a performance penalty - cleaning your
+                data beforehand will almost certainly be more performant.
         cache
             Use a cache of unique, converted dates to apply the conversion.
 
         Examples
         --------
         >>> s = pl.Series(["2020/01/01", "2020/02/01", "2020/03/01"])
         >>> s.str.to_date()
@@ -99,14 +103,18 @@
         time_zone
             Time zone for the resulting Datetime column.
         strict
             Raise an error if any conversion fails.
         exact
             Require an exact format match. If False, allow the format to match anywhere
             in the target string.
+
+            .. note::
+                Using ``exact=False`` introduces a performance penalty - cleaning your
+                data beforehand will almost certainly be more performant.
         cache
             Use a cache of unique, converted datetimes to apply the conversion.
         utc
             Parse time zone aware datetimes as UTC. This may be useful if you have data
             with mixed offsets.
 
             .. deprecated:: 0.18.0
@@ -210,14 +218,18 @@
             for the full specification. Example: ``"%Y-%m-%d %H:%M:%S"``.
             If set to None (default), the format is inferred from the data.
         strict
             Raise an error if any conversion fails.
         exact
             Require an exact format match. If False, allow the format to match anywhere
             in the target string. Conversion to the Time type is always exact.
+
+            .. note::
+                Using ``exact=False`` introduces a performance penalty - cleaning your
+                data beforehand will almost certainly be more performant.
         cache
             Use a cache of unique, converted dates to apply the datetime conversion.
         utc
             Parse time zone aware datetimes as UTC. This may be useful if you have data
             with mixed offsets.
 
             .. deprecated:: 0.18.0
@@ -295,22 +307,22 @@
             raise ValueError("dtype should be of type {Date, Datetime, Time}")
 
     def to_decimal(
         self,
         inference_length: int = 100,
     ) -> Expr:
         """
-        Convert a Utf8 column into a Date column.
+        Convert a Utf8 column into a Decimal column.
 
         This method infers the needed parameters ``precision`` and ``scale``.
 
         Parameters
         ----------
         inference_length
-            Number of elements to parse to determine the `precision` and `scale`
+            Number of elements to parse to determine the `precision` and `scale`.
 
         Examples
         --------
         >>> df = pl.DataFrame(
         ...     {
         ...         "numbers": [
         ...             "40.12",
@@ -321,27 +333,27 @@
         ...             "143.09",
         ...             "143.9",
         ...         ]
         ...     }
         ... )
         >>> df.select(pl.col("numbers").str.to_decimal())
         shape: (7, 1)
-        
-         numbers      
-         ---          
-         decimal[8,2] 
-        
-         40.12        
-         3420.13      
-         120134.19    
-         3212.98      
-         12.9         
-         143.09       
-         143.9        
-        
+        
+         numbers    
+         ---        
+         decimal[2] 
+        
+         40.12      
+         3420.13    
+         120134.19  
+         3212.98    
+         12.9       
+         143.09     
+         143.9      
+        
 
         """
         return wrap_expr(self._pyexpr.str_to_decimal(inference_length))
 
     def lengths(self) -> Expr:
         """
         Get length of the strings as UInt32 (as number of bytes).
@@ -780,15 +792,15 @@
 
         See Also
         --------
         starts_with : Check if string values start with a substring.
         ends_with : Check if string values end with a substring.
 
         """
-        pattern = parse_as_expression(pattern, str_as_lit=True)._pyexpr
+        pattern = parse_as_expression(pattern, str_as_lit=True)
         return wrap_expr(self._pyexpr.str_contains(pattern, literal, strict))
 
     def ends_with(self, suffix: str | Expr) -> Expr:
         """
         Check if string values end with a substring.
 
         Parameters
@@ -827,15 +839,15 @@
 
         See Also
         --------
         contains : Check if string contains a substring that matches a regex.
         starts_with : Check if string values start with a substring.
 
         """
-        suffix = parse_as_expression(suffix, str_as_lit=True)._pyexpr
+        suffix = parse_as_expression(suffix, str_as_lit=True)
         return wrap_expr(self._pyexpr.str_ends_with(suffix))
 
     def starts_with(self, prefix: str | Expr) -> Expr:
         """
         Check if string values start with a substring.
 
         Parameters
@@ -874,15 +886,15 @@
 
         See Also
         --------
         contains : Check if string contains a substring that matches a regex.
         ends_with : Check if string values end with a substring.
 
         """
-        prefix = parse_as_expression(prefix, str_as_lit=True)._pyexpr
+        prefix = parse_as_expression(prefix, str_as_lit=True)
         return wrap_expr(self._pyexpr.str_starts_with(prefix))
 
     def json_extract(self, dtype: PolarsDataType | None = None) -> Expr:
         """
         Parse string values as JSON.
 
         Throw errors if encounter invalid JSON strings.
@@ -1178,15 +1190,15 @@
          list[str]      
         
          ["123", "45"]  
          ["678", "910"] 
         
 
         '''
-        pattern = parse_as_expression(pattern, str_as_lit=True)._pyexpr
+        pattern = parse_as_expression(pattern, str_as_lit=True)
         return wrap_expr(self._pyexpr.str_extract_all(pattern))
 
     def count_match(self, pattern: str) -> Expr:
         r"""
         Count all successive non-overlapping regex matches.
 
         Parameters
@@ -1454,16 +1466,16 @@
          i64  str    
         
          1    123ABC 
          2    abc456 
         
 
         """
-        pattern = parse_as_expression(pattern, str_as_lit=True)._pyexpr
-        value = parse_as_expression(value, str_as_lit=True)._pyexpr
+        pattern = parse_as_expression(pattern, str_as_lit=True)
+        value = parse_as_expression(value, str_as_lit=True)
         return wrap_expr(self._pyexpr.str_replace_n(pattern, value, literal, n))
 
     def replace_all(
         self, pattern: str | Expr, value: str | Expr, *, literal: bool = False
     ) -> Expr:
         """
         Replace all matching regex/literal substrings with a new string value.
@@ -1493,16 +1505,16 @@
          i64  str     
         
          1    -bc-bc  
          2    123-123 
         
 
         """
-        pattern = parse_as_expression(pattern, str_as_lit=True)._pyexpr
-        value = parse_as_expression(value, str_as_lit=True)._pyexpr
+        pattern = parse_as_expression(pattern, str_as_lit=True)
+        value = parse_as_expression(value, str_as_lit=True)
         return wrap_expr(self._pyexpr.str_replace_all(pattern, value, literal))
 
     def slice(self, offset: int, length: int | None = None) -> Expr:
         """
         Create subslices of the string values of a Utf8 Series.
 
         Parameters
```

### Comparing `polars_lts_cpu-0.18.0/polars/expr/struct.py` & `polars_lts_cpu-0.18.1/polars/expr/struct.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/functions/__init__.py` & `polars_lts_cpu-0.18.1/polars/functions/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -43,14 +43,15 @@
     min,
     n_unique,
     quantile,
     reduce,
     rolling_corr,
     rolling_cov,
     select,
+    sql_expr,
     std,
     sum,
     tail,
     var,
 )
 from polars.functions.range import arange, date_range, time_range
 from polars.functions.repeat import ones, repeat, zeros
@@ -114,8 +115,9 @@
     "struct",
     "sum",
     "tail",
     "time",
     "var",
     # polars.functions.whenthen
     "when",
+    "sql_expr",
 ]
```

### Comparing `polars_lts_cpu-0.18.0/polars/functions/as_datatype.py` & `polars_lts_cpu-0.18.1/polars/functions/as_datatype.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,19 +1,21 @@
 from __future__ import annotations
 
 import contextlib
+import warnings
 from typing import TYPE_CHECKING, Iterable, overload
 
 from polars import functions as F
 from polars.datatypes import Date, Struct, Time
 from polars.utils._parse_expr_input import (
     parse_as_expression,
     parse_as_list_of_expressions,
 )
 from polars.utils._wrap import wrap_expr
+from polars.utils.various import find_stacklevel
 
 with contextlib.suppress(ImportError):  # Module not available when building docs
     import polars.polars as plr
 
 
 if TYPE_CHECKING:
     import sys
@@ -57,26 +59,26 @@
         column or literal, ranging from 0-999999.
 
     Returns
     -------
     Expr of type `pl.Datetime`
 
     """
-    year_expr = parse_as_expression(year)._pyexpr
-    month_expr = parse_as_expression(month)._pyexpr
-    day_expr = parse_as_expression(day)._pyexpr
+    year_expr = parse_as_expression(year)
+    month_expr = parse_as_expression(month)
+    day_expr = parse_as_expression(day)
 
     if hour is not None:
-        hour = parse_as_expression(hour)._pyexpr
+        hour = parse_as_expression(hour)
     if minute is not None:
-        minute = parse_as_expression(minute)._pyexpr
+        minute = parse_as_expression(minute)
     if second is not None:
-        second = parse_as_expression(second)._pyexpr
+        second = parse_as_expression(second)
     if microsecond is not None:
-        microsecond = parse_as_expression(microsecond)._pyexpr
+        microsecond = parse_as_expression(microsecond)
 
     return wrap_expr(
         plr.datetime(
             year_expr,
             month_expr,
             day_expr,
             hour,
@@ -199,29 +201,29 @@
     
      2022-01-08 00:00:00  2022-01-02 00:00:00  2022-01-01 00:00:01  2022-01-01 00:00:00.001  2022-01-01 01:00:00 
      2022-01-16 00:00:00  2022-01-04 00:00:00  2022-01-02 00:00:02  2022-01-02 00:00:00.002  2022-01-02 02:00:00 
     
 
     """  # noqa: W505
     if hours is not None:
-        hours = parse_as_expression(hours)._pyexpr
+        hours = parse_as_expression(hours)
     if minutes is not None:
-        minutes = parse_as_expression(minutes)._pyexpr
+        minutes = parse_as_expression(minutes)
     if seconds is not None:
-        seconds = parse_as_expression(seconds)._pyexpr
+        seconds = parse_as_expression(seconds)
     if milliseconds is not None:
-        milliseconds = parse_as_expression(milliseconds)._pyexpr
+        milliseconds = parse_as_expression(milliseconds)
     if microseconds is not None:
-        microseconds = parse_as_expression(microseconds)._pyexpr
+        microseconds = parse_as_expression(microseconds)
     if nanoseconds is not None:
-        nanoseconds = parse_as_expression(nanoseconds)._pyexpr
+        nanoseconds = parse_as_expression(nanoseconds)
     if days is not None:
-        days = parse_as_expression(days)._pyexpr
+        days = parse_as_expression(days)
     if weeks is not None:
-        weeks = parse_as_expression(weeks)._pyexpr
+        weeks = parse_as_expression(weeks)
 
     return wrap_expr(
         plr.duration(
             days,
             seconds,
             nanoseconds,
             microseconds,
@@ -274,69 +276,63 @@
     """
     exprs = parse_as_list_of_expressions(exprs, *more_exprs)
     return wrap_expr(plr.concat_list(exprs))
 
 
 @overload
 def struct(
-    exprs: IntoExpr | Iterable[IntoExpr] = ...,
-    *more_exprs: IntoExpr,
-    eager: Literal[False] = ...,
+    *exprs: IntoExpr | Iterable[IntoExpr],
     schema: SchemaDict | None = ...,
+    eager: Literal[False] = ...,
     **named_exprs: IntoExpr,
 ) -> Expr:
     ...
 
 
 @overload
 def struct(
-    exprs: IntoExpr | Iterable[IntoExpr] = ...,
-    *more_exprs: IntoExpr,
-    eager: Literal[True],
+    *exprs: IntoExpr | Iterable[IntoExpr],
     schema: SchemaDict | None = ...,
+    eager: Literal[True],
     **named_exprs: IntoExpr,
 ) -> Series:
     ...
 
 
 @overload
 def struct(
-    exprs: IntoExpr | Iterable[IntoExpr] = ...,
-    *more_exprs: IntoExpr,
-    eager: bool,
+    *exprs: IntoExpr | Iterable[IntoExpr],
     schema: SchemaDict | None = ...,
+    eager: bool,
     **named_exprs: IntoExpr,
 ) -> Expr | Series:
     ...
 
 
 def struct(
-    exprs: IntoExpr | Iterable[IntoExpr] = None,
-    *more_exprs: IntoExpr,
-    eager: bool = False,
+    *exprs: IntoExpr | Iterable[IntoExpr],
     schema: SchemaDict | None = None,
+    eager: bool = False,
     **named_exprs: IntoExpr,
 ) -> Expr | Series:
     """
     Collect columns into a struct column.
 
     Parameters
     ----------
-    exprs
-        Column(s) to collect into a struct column. Accepts expression input. Strings are
-        parsed as column names, other non-expression inputs are parsed as literals.
-    *more_exprs
-        Additional columns to collect into the struct column, specified as positional
-        arguments.
-    eager
-        Evaluate immediately and return a ``Series``. If set to ``False`` (default),
-        return an expression instead.
+    *exprs
+        Column(s) to collect into a struct column, specified as positional arguments.
+        Accepts expression input. Strings are parsed as column names,
+        other non-expression inputs are parsed as literals.
     schema
         Optional schema that explicitly defines the struct field dtypes. If no columns
         or expressions are provided, schema keys are used to define columns.
+    eager
+        Evaluate immediately and return a ``Series``. If set to ``False`` (default),
+        return an expression instead.
     **named_exprs
         Additional columns to collect into the struct column, specified as keyword
         arguments. The columns will be renamed to the keyword used.
 
     Examples
     --------
     Collect all columns of a dataframe into a struct by passing ``pl.all()``.
@@ -376,16 +372,27 @@
 
     Use keyword arguments to easily name each struct field.
 
     >>> df.select(pl.struct(p="int", q="bool").alias("my_struct")).schema
     {'my_struct': Struct([Field('p', Int64), Field('q', Boolean)])}
 
     """
-    exprs = parse_as_list_of_expressions(exprs, *more_exprs, **named_exprs)  # type: ignore[arg-type]
-    expr = wrap_expr(plr.as_struct(exprs))
+    if "exprs" in named_exprs:
+        warnings.warn(
+            "passing expressions to `struct` using the keyword argument `exprs` is"
+            " deprecated. Use positional syntax instead.",
+            DeprecationWarning,
+            stacklevel=find_stacklevel(),
+        )
+        first_input = named_exprs.pop("exprs")
+        pyexprs = parse_as_list_of_expressions(first_input, *exprs, **named_exprs)
+    else:
+        pyexprs = parse_as_list_of_expressions(*exprs, **named_exprs)
+
+    expr = wrap_expr(plr.as_struct(pyexprs))
 
     if schema:
         if not exprs:
             # no columns or expressions provided; create one from schema keys
             expr = wrap_expr(
                 plr.as_struct(parse_as_list_of_expressions(list(schema.keys())))
             )
@@ -495,14 +502,14 @@
         raise ValueError("number of placeholders should equal the number of arguments")
 
     exprs = []
 
     arguments = iter(args)
     for i, s in enumerate(f_string.split("{}")):
         if i > 0:
-            e = parse_as_expression(next(arguments))
+            e = wrap_expr(parse_as_expression(next(arguments)))
             exprs.append(e)
 
         if len(s) > 0:
             exprs.append(F.lit(s))
 
     return concat_str(exprs, separator="")
```

### Comparing `polars_lts_cpu-0.18.0/polars/functions/eager.py` & `polars_lts_cpu-0.18.1/polars/functions/eager.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 from functools import reduce
 from itertools import chain
 from typing import TYPE_CHECKING, Iterable, List, Sequence, cast
 
 import polars._reexport as pl
 from polars import functions as F
 from polars.type_aliases import FrameType
-from polars.utils._wrap import wrap_df, wrap_ldf, wrap_s
+from polars.utils._wrap import wrap_df, wrap_expr, wrap_ldf, wrap_s
 from polars.utils.various import ordered_unique
 
 with contextlib.suppress(ImportError):  # Module not available when building docs
     import polars.polars as plr
 
 if TYPE_CHECKING:
     import sys
@@ -183,17 +183,15 @@
     elif isinstance(first, pl.Series):
         if how == "vertical":
             out = wrap_s(plr.concat_series(elems))
         else:
             raise ValueError("'Series' only allows {'vertical'} concat strategy.")
 
     elif isinstance(first, pl.Expr):
-        out = first
-        for e in elems[1:]:
-            out = out.append(e)
+        return wrap_expr(plr.concat_expr([e._pyexpr for e in elems], rechunk))
     else:
         raise ValueError(f"did not expect type: {type(first)} in 'pl.concat'.")
 
     if rechunk:
         return out.rechunk()
     return out
```

### Comparing `polars_lts_cpu-0.18.0/polars/functions/lazy.py` & `polars_lts_cpu-0.18.1/polars/functions/lazy.py`

 * *Files 0% similar despite different names*

```diff
@@ -1354,18 +1354,18 @@
     """
     if not more_exprs:
         if isinstance(exprs, pl.Series):
             return exprs.cumsum()
         elif isinstance(exprs, str):
             return col(exprs).cumsum()
 
-    exprs = parse_as_list_of_expressions(exprs, *more_exprs)
+    pyexprs = parse_as_list_of_expressions(exprs, *more_exprs)
+    exprs_wrapped = [wrap_expr(e) for e in pyexprs]
 
     # (Expr): use u32 as that will not cast to float as eagerly
-    exprs_wrapped = [wrap_expr(e) for e in exprs]
     return cumfold(lit(0).cast(UInt32), lambda a, b: a + b, exprs_wrapped).alias(
         "cumsum"
     )
 
 
 def corr(
     a: str | Expr,
@@ -1711,15 +1711,15 @@
      ---  --- 
      i64  i64 
     
      3    2   
     
     """
     # in case of pl.col("*")
-    acc = parse_as_expression(acc, str_as_lit=True)._pyexpr
+    acc = parse_as_expression(acc, str_as_lit=True)
     if isinstance(exprs, pl.Expr):
         exprs = [exprs]
 
     exprs = parse_as_list_of_expressions(exprs)
     return wrap_expr(plr.fold(acc, function, exprs))
 
 
@@ -1852,15 +1852,15 @@
      {2,5,10}  
      {3,7,13}  
      {4,9,16}  
     
 
     """  # noqa: W505
     # in case of pl.col("*")
-    acc = parse_as_expression(acc, str_as_lit=True)._pyexpr
+    acc = parse_as_expression(acc, str_as_lit=True)
     if isinstance(exprs, pl.Expr):
         exprs = [exprs]
 
     exprs = parse_as_list_of_expressions(exprs)
     return wrap_expr(plr.cumfold(acc, function, exprs, include_init))
 
 
@@ -2006,17 +2006,17 @@
     """
     if not more_exprs:
         if isinstance(exprs, pl.Series):
             return exprs.any()
         elif isinstance(exprs, str):
             return col(exprs).any()
 
-    exprs = parse_as_list_of_expressions(exprs, *more_exprs)
+    pyexprs = parse_as_list_of_expressions(exprs, *more_exprs)
+    exprs_wrapped = [wrap_expr(e) for e in pyexprs]
 
-    exprs_wrapped = [wrap_expr(e) for e in exprs]
     return fold(
         lit(False), lambda a, b: a.cast(bool) | b.cast(bool), exprs_wrapped
     ).alias("any")
 
 
 @overload
 def all(exprs: Series) -> bool:  # type: ignore[misc]
@@ -2095,17 +2095,17 @@
         if exprs is None:
             return col("*")
         elif isinstance(exprs, pl.Series):
             return exprs.all()
         elif isinstance(exprs, str):
             return col(exprs).all()
 
-    exprs = parse_as_list_of_expressions(exprs, *more_exprs)
+    pyexprs = parse_as_list_of_expressions(exprs, *more_exprs)
+    exprs_wrapped = [wrap_expr(e) for e in pyexprs]
 
-    exprs_wrapped = [wrap_expr(e) for e in exprs]
     return fold(
         lit(True), lambda a, b: a.cast(bool) & b.cast(bool), exprs_wrapped
     ).alias("all")
 
 
 def exclude(
     columns: str | PolarsDataType | Iterable[str] | Iterable[PolarsDataType],
@@ -2343,33 +2343,29 @@
 
     # wrap the pydataframes into dataframe
     result = [wrap_df(pydf) for pydf in out]
 
     return result
 
 
-def select(
-    exprs: IntoExpr | Iterable[IntoExpr] | None = None,
-    *more_exprs: IntoExpr,
-    **named_exprs: IntoExpr,
-) -> DataFrame:
+def select(*exprs: IntoExpr | Iterable[IntoExpr], **named_exprs: IntoExpr) -> DataFrame:
     """
     Run polars expressions without a context.
 
     This is syntactic sugar for running ``df.select`` on an empty DataFrame.
 
     Parameters
     ----------
-    exprs
-        Expression or expressions to run.
-    *more_exprs
-        Additional expressions to run, specified as positional arguments.
+    *exprs
+        Column(s) to select, specified as positional arguments.
+        Accepts expression input. Strings are parsed as column names,
+        other non-expression inputs are parsed as literals.
     **named_exprs
-        Additional expressions to run, specified as keyword arguments. The expressions
-        will be renamed to the keyword used.
+        Additional columns to select, specified as keyword arguments.
+        The columns will be renamed to the keyword used.
 
     Returns
     -------
     DataFrame
 
     Examples
     --------
@@ -2384,15 +2380,15 @@
     
      1   
      2   
      1   
     
 
     """
-    return pl.DataFrame().select(exprs, *more_exprs, **named_exprs)
+    return pl.DataFrame().select(*exprs, **named_exprs)
 
 
 @overload
 def arg_where(condition: Expr | Series, *, eager: Literal[False] = ...) -> Expr:
     ...
 
 
@@ -2442,15 +2438,15 @@
         if not isinstance(condition, pl.Series):
             raise ValueError(
                 "expected 'Series' in 'arg_where' if 'eager=True', got"
                 f" {type(condition)}"
             )
         return condition.to_frame().select(arg_where(col(condition.name))).to_series()
     else:
-        condition = parse_as_expression(condition)._pyexpr
+        condition = parse_as_expression(condition)
         return wrap_expr(plr.arg_where(condition))
 
 
 def coalesce(exprs: IntoExpr | Iterable[IntoExpr], *more_exprs: IntoExpr) -> Expr:
     """
     Folds the columns from left to right, keeping the first non-null value.
 
@@ -2583,14 +2579,17 @@
     window_size: int,
     min_periods: int | None = None,
     ddof: int = 1,
 ) -> Expr:
     """
     Compute the rolling covariance between two columns/ expressions.
 
+    The window at a given row includes the row itself and the
+    `window_size - 1` elements before it.
+
     Parameters
     ----------
     a
         Column name or Expression.
     b
         Column name or Expression.
     window_size
@@ -2621,14 +2620,17 @@
     window_size: int,
     min_periods: int | None = None,
     ddof: int = 1,
 ) -> Expr:
     """
     Compute the rolling correlation between two columns/ expressions.
 
+    The window at a given row includes the row itself and the
+    `window_size - 1` elements before it.
+
     Parameters
     ----------
     a
         Column name or Expression.
     b
         Column name or Expression.
     window_size
@@ -2646,7 +2648,33 @@
     if isinstance(a, str):
         a = col(a)
     if isinstance(b, str):
         b = col(b)
     return wrap_expr(
         plr.rolling_corr(a._pyexpr, b._pyexpr, window_size, min_periods, ddof)
     )
+
+
+def sql_expr(sql: str) -> Expr:
+    """
+    Parse a SQL expression to a polars expression.
+
+    Parameters
+    ----------
+    sql
+        SQL expression
+
+    Examples
+    --------
+    >>> df = pl.DataFrame({"a": [2, 1]})
+    >>> expr = pl.sql_expr("MAX(a)")
+    >>> df.select(expr)
+    shape: (1, 1)
+    
+     a   
+     --- 
+     i64 
+    
+     2   
+    
+    """
+    return wrap_expr(plr.sql_expr(sql))
```

### Comparing `polars_lts_cpu-0.18.0/polars/functions/range.py` & `polars_lts_cpu-0.18.1/polars/functions/range.py`

 * *Files 2% similar despite different names*

```diff
@@ -120,16 +120,16 @@
      list[i64] 
     
      [1, 2]    
      [2, 3]    
     
 
     """
-    start = parse_as_expression(start)._pyexpr
-    end = parse_as_expression(end)._pyexpr
+    start = parse_as_expression(start)
+    end = parse_as_expression(end)
     range_expr = wrap_expr(plr.arange(start, end, step))
 
     if dtype is not None and dtype != Int64:
         range_expr = range_expr.cast(dtype)
     if not eager:
         return range_expr
     else:
@@ -323,17 +323,20 @@
         interval = interval.replace(" ", "")
 
     if (
         not eager
         or isinstance(start, (str, pl.Expr))
         or isinstance(end, (str, pl.Expr))
     ):
-        start = parse_as_expression(start)._pyexpr
-        end = parse_as_expression(end)._pyexpr
-        return wrap_expr(plr.date_range_lazy(start, end, interval, closed, time_zone))
+        start = parse_as_expression(start)
+        end = parse_as_expression(end)
+        expr = wrap_expr(plr.date_range_lazy(start, end, interval, closed, time_zone))
+        if name is not None:
+            expr = expr.alias(name)
+        return expr
 
     start, start_is_date = _ensure_datetime(start)
     end, end_is_date = _ensure_datetime(end)
 
     if start.tzinfo is not None or time_zone is not None:
         if start.tzinfo != end.tzinfo:
             raise ValueError(
@@ -366,14 +369,16 @@
     if (
         start_is_date
         and end_is_date
         and not _interval_granularity(interval).endswith(("h", "m", "s"))
     ):
         dt_range = dt_range.cast(Date)
 
+    if name is not None:
+        dt_range = dt_range.alias(name)
     return dt_range
 
 
 def _ensure_datetime(value: date | datetime) -> tuple[datetime, bool]:
     is_date_type = False
     if not isinstance(value, datetime):
         value = datetime(value.year, value.month, value.day)
@@ -527,20 +532,22 @@
     default_end = time(23, 59, 59, 999999)
     if (
         not eager
         or isinstance(start, (str, pl.Expr))
         or isinstance(end, (str, pl.Expr))
     ):
         start_expr = (
-            F.lit(default_start) if start is None else parse_as_expression(start)
-        )._pyexpr
+            F.lit(default_start)._pyexpr
+            if start is None
+            else parse_as_expression(start)
+        )
 
         end_expr = (
-            F.lit(default_end) if end is None else parse_as_expression(end)
-        )._pyexpr
+            F.lit(default_end)._pyexpr if end is None else parse_as_expression(end)
+        )
 
         tm_expr = wrap_expr(plr.time_range_lazy(start_expr, end_expr, interval, closed))
         if name is not None:
             tm_expr = tm_expr.alias(name)
         return tm_expr
     else:
         tm_srs = wrap_s(
```

### Comparing `polars_lts_cpu-0.18.0/polars/functions/repeat.py` & `polars_lts_cpu-0.18.1/polars/functions/repeat.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/functions/whenthen.py` & `polars_lts_cpu-0.18.1/polars/functions/whenthen.py`

 * *Files 5% similar despite different names*

```diff
@@ -89,15 +89,15 @@
      1    3    null 
      3    4    1    
      4    0    1    
     
 
 
     """
-    expr = parse_as_expression(expr)._pyexpr
+    expr = parse_as_expression(expr)
     pywhen = _when(expr)
     return When(pywhen)
 
 
 class When:
     """Utility class. See the `when` function."""
 
@@ -109,40 +109,40 @@
         Values to return in case of the predicate being `True`.
 
         See Also
         --------
         pl.when : Documentation for `when, then, otherwise`
 
         """
-        expr = parse_as_expression(expr, str_as_lit=True)._pyexpr
+        expr = parse_as_expression(expr, str_as_lit=True)
         pywhenthen = self._pywhen.then(expr)
         return WhenThen(pywhenthen)
 
 
 class WhenThen:
     """Utility class. See the `when` function."""
 
     def __init__(self, pywhenthen: Any):
         self._pywhenthen = pywhenthen
 
     def when(self, predicate: IntoExpr) -> WhenThenThen:
         """Start another "when, then, otherwise" layer."""
-        predicate = parse_as_expression(predicate)._pyexpr
+        predicate = parse_as_expression(predicate)
         return WhenThenThen(self._pywhenthen.when(predicate))
 
     def otherwise(self, expr: IntoExpr) -> Expr:
         """
         Values to return in case of the predicate being `False`.
 
         See Also
         --------
         pl.when : Documentation for `when, then, otherwise`
 
         """
-        expr = parse_as_expression(expr, str_as_lit=True)._pyexpr
+        expr = parse_as_expression(expr, str_as_lit=True)
         return wrap_expr(self._pywhenthen.otherwise(expr))
 
     @typing.no_type_check
     def __getattr__(self, item) -> Expr:
         expr = self.otherwise(None)  # noqa: F841
         return eval(f"expr.{item}")
 
@@ -151,38 +151,38 @@
     """Utility class. See the `when` function."""
 
     def __init__(self, pywhenthenthen: Any):
         self.pywhenthenthen = pywhenthenthen
 
     def when(self, predicate: IntoExpr) -> WhenThenThen:
         """Start another "when, then, otherwise" layer."""
-        predicate = parse_as_expression(predicate)._pyexpr
+        predicate = parse_as_expression(predicate)
         return WhenThenThen(self.pywhenthenthen.when(predicate))
 
     def then(self, expr: IntoExpr) -> WhenThenThen:
         """
         Values to return in case of the predicate being `True`.
 
         See Also
         --------
         pl.when : Documentation for `when, then, otherwise`
 
         """
-        expr = parse_as_expression(expr, str_as_lit=True)._pyexpr
+        expr = parse_as_expression(expr, str_as_lit=True)
         return WhenThenThen(self.pywhenthenthen.then(expr))
 
     def otherwise(self, expr: IntoExpr) -> Expr:
         """
         Values to return in case of the predicate being `False`.
 
         See Also
         --------
         pl.when : Documentation for `when, then, otherwise`
 
         """
-        expr = parse_as_expression(expr, str_as_lit=True)._pyexpr
+        expr = parse_as_expression(expr, str_as_lit=True)
         return wrap_expr(self.pywhenthenthen.otherwise(expr))
 
     @typing.no_type_check
     def __getattr__(self, item) -> Expr:
         expr = self.otherwise(None)  # noqa: F841
         return eval(f"expr.{item}")
```

### Comparing `polars_lts_cpu-0.18.0/polars/io/__init__.py` & `polars_lts_cpu-0.18.1/polars/io/__init__.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/io/_utils.py` & `polars_lts_cpu-0.18.1/polars/io/_utils.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/io/avro.py` & `polars_lts_cpu-0.18.1/polars/io/avro.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/io/csv/_utils.py` & `polars_lts_cpu-0.18.1/polars/io/csv/_utils.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/io/csv/batched_reader.py` & `polars_lts_cpu-0.18.1/polars/io/csv/batched_reader.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/io/csv/functions.py` & `polars_lts_cpu-0.18.1/polars/io/csv/functions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/io/database.py` & `polars_lts_cpu-0.18.1/polars/io/database.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/io/delta.py` & `polars_lts_cpu-0.18.1/polars/io/delta.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/io/excel/_write_utils.py` & `polars_lts_cpu-0.18.1/polars/io/excel/_write_utils.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/io/excel/functions.py` & `polars_lts_cpu-0.18.1/polars/io/excel/functions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/io/ipc/anonymous_scan.py` & `polars_lts_cpu-0.18.1/polars/io/ipc/anonymous_scan.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/io/ipc/functions.py` & `polars_lts_cpu-0.18.1/polars/io/ipc/functions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/io/ndjson.py` & `polars_lts_cpu-0.18.1/polars/io/ndjson.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/io/parquet/anonymous_scan.py` & `polars_lts_cpu-0.18.1/polars/io/parquet/anonymous_scan.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/io/parquet/functions.py` & `polars_lts_cpu-0.18.1/polars/io/parquet/functions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/io/pyarrow_dataset/anonymous_scan.py` & `polars_lts_cpu-0.18.1/polars/io/pyarrow_dataset/anonymous_scan.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/io/pyarrow_dataset/functions.py` & `polars_lts_cpu-0.18.1/polars/io/pyarrow_dataset/functions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/lazyframe/frame.py` & `polars_lts_cpu-0.18.1/polars/lazyframe/frame.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 from __future__ import annotations
 
 import contextlib
 import os
 import typing
+import warnings
 from datetime import date, datetime, time, timedelta
 from io import BytesIO, StringIO
 from pathlib import Path
 from typing import (
     TYPE_CHECKING,
     Any,
     Callable,
@@ -54,14 +55,15 @@
 )
 from polars.utils._wrap import wrap_df, wrap_expr
 from polars.utils.convert import _timedelta_to_pl_duration
 from polars.utils.various import (
     _in_notebook,
     _prepare_row_count_args,
     _process_null_values,
+    find_stacklevel,
     normalise_filepath,
 )
 
 with contextlib.suppress(ImportError):  # Module not available when building docs
     from polars.polars import PyLazyFrame
 
 
@@ -1916,37 +1918,32 @@
          3    8    c   
         
 
         """
         if isinstance(predicate, list):
             predicate = pl.Series(predicate)
 
-        return self._from_pyldf(
-            self._ldf.filter(parse_as_expression(predicate)._pyexpr)
-        )
+        predicate = parse_as_expression(predicate)
+        return self._from_pyldf(self._ldf.filter(predicate))
 
     def select(
-        self,
-        exprs: IntoExpr | Iterable[IntoExpr] | None = None,
-        *more_exprs: IntoExpr,
-        **named_exprs: IntoExpr,
+        self, *exprs: IntoExpr | Iterable[IntoExpr], **named_exprs: IntoExpr
     ) -> Self:
         """
         Select columns from this LazyFrame.
 
         Parameters
         ----------
-        exprs
-            Column(s) to select. Accepts expression input. Strings are parsed as column
-            names, other non-expression inputs are parsed as literals.
-        *more_exprs
-            Additional columns to select, specified as positional arguments.
+        *exprs
+            Column(s) to select, specified as positional arguments.
+            Accepts expression input. Strings are parsed as column names,
+            other non-expression inputs are parsed as literals.
         **named_exprs
-            Additional columns to select, specified as keyword arguments. The columns
-            will be renamed to the keyword used.
+            Additional columns to select, specified as keyword arguments.
+            The columns will be renamed to the keyword used.
 
         Examples
         --------
         Pass the name of a column to select that column.
 
         >>> lf = pl.LazyFrame(
         ...     {
@@ -2028,24 +2025,33 @@
         
          {1,0}     
          {0,1}     
          {1,0}     
         
 
         """
-        if exprs is None and not named_exprs:
-            raise ValueError("Expected at least one of 'exprs' or '**named_exprs'")
-
         structify = bool(int(os.environ.get("POLARS_AUTO_STRUCTIFY", 0)))
 
-        exprs = parse_as_list_of_expressions(
-            exprs, *more_exprs, **named_exprs, structify=structify
-        )
+        if "exprs" in named_exprs:
+            warnings.warn(
+                "passing expressions to `select` using the keyword argument `exprs` is"
+                " deprecated. Use positional syntax instead.",
+                DeprecationWarning,
+                stacklevel=find_stacklevel(),
+            )
+            first_input = named_exprs.pop("exprs")
+            pyexprs = parse_as_list_of_expressions(
+                first_input, *exprs, **named_exprs, __structify=structify
+            )
+        else:
+            pyexprs = parse_as_list_of_expressions(
+                *exprs, **named_exprs, __structify=structify
+            )
 
-        return self._from_pyldf(self._ldf.select(exprs))
+        return self._from_pyldf(self._ldf.select(pyexprs))
 
     def groupby(
         self,
         by: IntoExpr | Iterable[IntoExpr],
         *more_by: IntoExpr,
         maintain_order: bool = False,
     ) -> LazyGroupBy:
@@ -2148,34 +2154,41 @@
         period: str | timedelta,
         offset: str | timedelta | None = None,
         closed: ClosedInterval = "right",
         by: IntoExpr | Iterable[IntoExpr] | None = None,
         check_sorted: bool = True,
     ) -> LazyGroupBy:
         """
-        Create rolling groups based on a time column.
-
-        Also works for index values of type Int32 or Int64.
+        Create rolling groups based on a time, Int32, or Int64 column.
 
         Different from a ``dynamic_groupby`` the windows are now determined by the
         individual values and are not of constant intervals. For constant intervals
         use *groupby_dynamic*.
 
+        If you have a time series ``<t_0, t_1, ..., t_n>``, then by default the
+        windows created will be
+
+            * (t_0 - period, t_0]
+            * (t_1 - period, t_1]
+            * ...
+            * (t_n - period, t_n]
+
         The `period` and `offset` arguments are created either from a timedelta, or
         by using the following string language:
 
         - 1ns   (1 nanosecond)
         - 1us   (1 microsecond)
         - 1ms   (1 millisecond)
         - 1s    (1 second)
         - 1m    (1 minute)
         - 1h    (1 hour)
         - 1d    (1 day)
         - 1w    (1 week)
         - 1mo   (1 calendar month)
+        - 1q    (1 calendar quarter)
         - 1y    (1 calendar year)
         - 1i    (1 index count)
 
         Or combine them:
         "3d12h4m25s" # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
@@ -2263,15 +2276,15 @@
          2020-01-01 16:45:09  15     3      7     
          2020-01-02 18:12:48  24     3      9     
          2020-01-03 19:45:32  11     2      9     
          2020-01-08 23:16:43  1      1      1     
         
 
         """
-        index_column = parse_as_expression(index_column)._pyexpr
+        index_column = parse_as_expression(index_column)
         if offset is None:
             offset = f"-{_timedelta_to_pl_duration(period)}"
 
         pyexprs_by = parse_as_list_of_expressions(by)
         period = _timedelta_to_pl_duration(period)
         offset = _timedelta_to_pl_duration(offset)
 
@@ -2316,14 +2329,15 @@
         - 1ms   (1 millisecond)
         - 1s    (1 second)
         - 1m    (1 minute)
         - 1h    (1 hour)
         - 1d    (1 day)
         - 1w    (1 week)
         - 1mo   (1 calendar month)
+        - 1q    (1 calendar quarter)
         - 1y    (1 calendar year)
         - 1i    (1 index count)
 
         Or combine them:
         "3d12h4m25s" # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
@@ -2575,15 +2589,15 @@
         
          0                3                0    ["A", "B", "B"] 
          2                5                2    ["B", "B", "C"] 
          4                7                4    ["C"]           
         
 
         """  # noqa: W505
-        index_column = parse_as_expression(index_column)._pyexpr
+        index_column = parse_as_expression(index_column)
         if offset is None:
             offset = f"-{_timedelta_to_pl_duration(every)}" if period is None else "0ns"
 
         if period is None:
             period = every
 
         period = _timedelta_to_pl_duration(period)
@@ -2674,14 +2688,15 @@
                 - 1ms   (1 millisecond)
                 - 1s    (1 second)
                 - 1m    (1 minute)
                 - 1h    (1 hour)
                 - 1d    (1 day)
                 - 1w    (1 week)
                 - 1mo   (1 calendar month)
+                - 1q    (1 calendar quarter)
                 - 1y    (1 calendar year)
                 - 1i    (1 index count)
 
                 Or combine them:
                 "3d12h4m25s" # 3 days, 12 hours, 4 minutes, and 25 seconds
 
                 Suffix with `"_saturating"` to indicate that dates too large for
@@ -2792,14 +2807,15 @@
         other: LazyFrame,
         on: str | Expr | Sequence[str | Expr] | None = None,
         how: JoinStrategy = "inner",
         *,
         left_on: str | Expr | Sequence[str | Expr] | None = None,
         right_on: str | Expr | Sequence[str | Expr] | None = None,
         suffix: str = "_right",
+        validate: str = "m:m",
         allow_parallel: bool = True,
         force_parallel: bool = False,
     ) -> Self:
         """
         Add a join operation to the Logical Plan.
 
         Parameters
@@ -2813,14 +2829,30 @@
             Join strategy.
         left_on
             Join column of the left DataFrame.
         right_on
             Join column of the right DataFrame.
         suffix
             Suffix to append to columns with a duplicate name.
+        validate: {'m:m', 'm:1', '1:m', 'm:m'}
+            Checks if join is of specified type.
+
+                * *many_to_many*
+                    m:m: default, does not result in checks
+                * *one_to_one*
+                    1:1: check if join keys are unique in both left and right datasets
+                * *one_to_many*
+                    1:m: check if join keys are unique in left dataset
+                * *many_to_one*
+                    m:1: check if join keys are unique in right dataset
+
+            .. note::
+
+                - This is currently not supported the streaming engine.
+                - This is only supported when joined by single columns.
         allow_parallel
             Allow the physical plan to optionally evaluate the computation of both
             DataFrames up to the join in parallel.
         force_parallel
             Force the physical plan to evaluate the computation of both DataFrames up to
             the join in parallel.
 
@@ -2901,15 +2933,22 @@
             raise TypeError(
                 f"Expected 'other' join table to be a LazyFrame, not a {type(other).__name__}"
             )
 
         if how == "cross":
             return self._from_pyldf(
                 self._ldf.join(
-                    other._ldf, [], [], allow_parallel, force_parallel, how, suffix
+                    other._ldf,
+                    [],
+                    [],
+                    allow_parallel,
+                    force_parallel,
+                    how,
+                    suffix,
+                    validate,
                 )
             )
 
         if on is not None:
             pyexprs = parse_as_list_of_expressions(on)
             pyexprs_left = pyexprs
             pyexprs_right = pyexprs
@@ -2924,38 +2963,37 @@
                 other._ldf,
                 pyexprs_left,
                 pyexprs_right,
                 allow_parallel,
                 force_parallel,
                 how,
                 suffix,
+                validate,
             )
         )
 
     def with_columns(
         self,
-        exprs: IntoExpr | Iterable[IntoExpr] | None = None,
-        *more_exprs: IntoExpr,
+        *exprs: IntoExpr | Iterable[IntoExpr],
         **named_exprs: IntoExpr,
     ) -> Self:
         """
         Add columns to this DataFrame.
 
         Added columns will replace existing columns with the same name.
 
         Parameters
         ----------
-        exprs
-            Column or columns to add. Accepts expression input. Strings are parsed
-            as column names, other non-expression inputs are parsed as literals.
-        *more_exprs
-            Additional columns to add, specified as positional arguments.
+        *exprs
+            Column(s) to add, specified as positional arguments.
+            Accepts expression input. Strings are parsed as column names, other
+            non-expression inputs are parsed as literals.
         **named_exprs
-            Additional columns to add, specified as keyword arguments. The columns
-            will be renamed to the keyword used.
+            Additional columns to add, specified as keyword arguments.
+            The columns will be renamed to the keyword used.
 
         Returns
         -------
         A new LazyFrame with the columns added.
 
         Notes
         -----
@@ -3076,24 +3114,33 @@
          1    0.5   {null,null} 
          2    4.0   {1,3.5}     
          3    10.0  {1,6.0}     
          4    13.0  {1,3.0}     
         
 
         """
-        if exprs is None and not named_exprs:
-            raise ValueError("Expected at least one of 'exprs' or '**named_exprs'")
-
         structify = bool(int(os.environ.get("POLARS_AUTO_STRUCTIFY", 0)))
 
-        exprs = parse_as_list_of_expressions(
-            exprs, *more_exprs, **named_exprs, structify=structify
-        )
+        if "exprs" in named_exprs:
+            warnings.warn(
+                "passing expressions to `with_columns` using the keyword argument"
+                " `exprs` is deprecated. Use positional syntax instead.",
+                DeprecationWarning,
+                stacklevel=find_stacklevel(),
+            )
+            first_input = named_exprs.pop("exprs")
+            pyexprs = parse_as_list_of_expressions(
+                first_input, *exprs, **named_exprs, __structify=structify
+            )
+        else:
+            pyexprs = parse_as_list_of_expressions(
+                *exprs, **named_exprs, __structify=structify
+            )
 
-        return self._from_pyldf(self._ldf.with_columns(exprs))
+        return self._from_pyldf(self._ldf.with_columns(pyexprs))
 
     @typing.no_type_check
     def with_context(self, other: Self | list[Self]) -> Self:
         """
         Add an external context to the computation graph.
 
         This allows expressions to also access columns from DataFrames
@@ -4138,15 +4185,15 @@
          ---  --- 
          f64  f64 
         
          3.0  1.0 
         
 
         """
-        quantile = parse_as_expression(quantile)._pyexpr
+        quantile = parse_as_expression(quantile)
         return self._from_pyldf(self._ldf.quantile(quantile, interpolation))
 
     def explode(
         self,
         columns: str | Sequence[str] | Expr | Sequence[Expr],
         *more_columns: str | Expr,
     ) -> Self:
@@ -4632,14 +4679,15 @@
             Columns that are sorted
         more_columns
             Additional columns that are sorted, specified as positional arguments.
         descending
             Whether the columns are sorted in descending order.
         """
         columns = parse_as_list_of_expressions(column, *more_columns)
+
         return self.with_columns(
             [wrap_expr(e).set_sorted(descending=descending) for e in columns]
         )
 
     def update(
         self,
         other: LazyFrame,
```

### Comparing `polars_lts_cpu-0.18.0/polars/lazyframe/groupby.py` & `polars_lts_cpu-0.18.1/polars/lazyframe/groupby.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,16 @@
 from __future__ import annotations
 
+import warnings
 from typing import TYPE_CHECKING, Callable, Iterable
 
 from polars import functions as F
 from polars.utils._parse_expr_input import parse_as_list_of_expressions
 from polars.utils._wrap import wrap_ldf
+from polars.utils.various import find_stacklevel
 
 if TYPE_CHECKING:
     from polars import DataFrame, LazyFrame
     from polars.polars import PyLazyGroupBy
     from polars.type_aliases import IntoExpr, RollingInterpolationMethod, SchemaDict
 
 
@@ -20,31 +22,29 @@
     """
 
     def __init__(self, lgb: PyLazyGroupBy) -> None:
         self.lgb = lgb
 
     def agg(
         self,
-        aggs: IntoExpr | Iterable[IntoExpr] | None = None,
-        *more_aggs: IntoExpr,
+        *aggs: IntoExpr | Iterable[IntoExpr],
         **named_aggs: IntoExpr,
     ) -> LazyFrame:
         """
         Compute aggregations for each group of a groupby operation.
 
         Parameters
         ----------
-        aggs
-            Aggregations to compute for each group of the groupby operation.
+        *aggs
+            Aggregations to compute for each group of the groupby operation,
+            specified as positional arguments.
             Accepts expression input. Strings are parsed as column names.
-        *more_aggs
-            Additional aggregations, specified as positional arguments.
         **named_aggs
-            Additional aggregations, specified as keyword arguments. The resulting
-            columns will be renamed to the keyword used.
+            Additional aggregations, specified as keyword arguments.
+            The resulting columns will be renamed to the keyword used.
 
         Examples
         --------
         Compute the sum of a column for each group.
 
         >>> ldf = pl.DataFrame(
         ...     {
@@ -112,24 +112,34 @@
         
          a    2      17.0           
          c    3      1.0            
          b    5      10.0           
         
 
         """
-        if isinstance(aggs, dict):
+        if aggs and isinstance(aggs[0], dict):
             raise ValueError(
-                f"'aggs' argument should be one or multiple expressions, got: '{aggs}'."
+                "specifying aggregations as a dictionary is not supported."
+                " Try unpacking the dictionary to take advantage of the keyword syntax"
+                " of the `agg` method."
             )
-        if aggs is None and not named_aggs:
-            raise ValueError("Expected at least one of 'aggs' or '**named_aggs'")
 
-        exprs = parse_as_list_of_expressions(aggs, *more_aggs, **named_aggs)  # type: ignore[arg-type]
+        if "aggs" in named_aggs:
+            warnings.warn(
+                "passing expressions to `agg` using the keyword argument `aggs` is"
+                " deprecated. Use positional syntax instead.",
+                DeprecationWarning,
+                stacklevel=find_stacklevel(),
+            )
+            first_input = named_aggs.pop("aggs")
+            pyexprs = parse_as_list_of_expressions(first_input, *aggs, **named_aggs)
+        else:
+            pyexprs = parse_as_list_of_expressions(*aggs, **named_aggs)
 
-        return wrap_ldf(self.lgb.agg(exprs))
+        return wrap_ldf(self.lgb.agg(pyexprs))
 
     def apply(
         self,
         function: Callable[[DataFrame], DataFrame],
         schema: SchemaDict | None,
     ) -> LazyFrame:
         """
```

### Comparing `polars_lts_cpu-0.18.0/polars/series/_numpy.py` & `polars_lts_cpu-0.18.1/polars/series/_numpy.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/series/array.py` & `polars_lts_cpu-0.18.1/polars/series/array.py`

 * *Files 19% similar despite different names*

```diff
@@ -74,7 +74,36 @@
          i64 
         
          3   
          7   
         
 
         """
+
+    def unique(self, *, maintain_order: bool = False) -> Series:
+        """
+        Get the unique/distinct values in the array.
+
+        Parameters
+        ----------
+        maintain_order
+            Maintain order of data. This requires more work.
+
+        Examples
+        --------
+        >>> df = pl.DataFrame(
+        ...     {
+        ...         "a": [[1, 1, 2]],
+        ...     },
+        ...     schema_overrides={"a": pl.Array(width=3, inner=pl.Int64)},
+        ... )
+        >>> df.select(pl.col("a").arr.unique())
+        shape: (1, 1)
+        
+         a         
+         ---       
+         list[i64] 
+        
+         [1, 2]    
+        
+
+        """
```

### Comparing `polars_lts_cpu-0.18.0/polars/series/binary.py` & `polars_lts_cpu-0.18.1/polars/series/binary.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/series/categorical.py` & `polars_lts_cpu-0.18.1/polars/series/categorical.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/series/datetime.py` & `polars_lts_cpu-0.18.1/polars/series/datetime.py`

 * *Files 1% similar despite different names*

```diff
@@ -1487,14 +1487,15 @@
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
             - 1d    (1 day)
             - 1w    (1 week)
             - 1mo   (1 calendar month)
+            - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
@@ -1584,14 +1585,15 @@
         - 1ms # 1 millisecond
         - 1s  # 1 second
         - 1m  # 1 minute
         - 1h  # 1 hour
         - 1d  # 1 day
         - 1w  # 1 calendar week
         - 1mo # 1 calendar month
+        - 1q  # 1 calendar quarter
         - 1y  # 1 calendar year
 
         These strings can be combined:
 
         - 3d12h4m25s # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
@@ -1690,14 +1692,15 @@
         1ms # 1 millisecond
         1s  # 1 second
         1m  # 1 minute
         1h  # 1 hour
         1d  # 1 day
         1w  # 1 calendar week
         1mo # 1 calendar month
+        1q  # 1 calendar quarter
         1y  # 1 calendar year
 
         3d12h4m25s # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
         their month should saturate at the largest date (e.g. 2022-02-29 -> 2022-02-28)
         instead of erroring.
```

### Comparing `polars_lts_cpu-0.18.0/polars/series/list.py` & `polars_lts_cpu-0.18.1/polars/series/list.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/series/series.py` & `polars_lts_cpu-0.18.1/polars/series/series.py`

 * *Files 2% similar despite different names*

```diff
@@ -24,14 +24,15 @@
 from polars.datatypes import (
     FLOAT_DTYPES,
     INTEGER_DTYPES,
     NUMERIC_DTYPES,
     SIGNED_INTEGER_DTYPES,
     TEMPORAL_DTYPES,
     UNSIGNED_INTEGER_DTYPES,
+    Array,
     Boolean,
     Categorical,
     Date,
     Datetime,
     Decimal,
     Duration,
     Float32,
@@ -1067,14 +1068,20 @@
         elif isinstance(key, (list, tuple)):
             s = self._from_pyseries(sequence_to_pyseries("", key, dtype=UInt32))
             self.__setitem__(s, value)
         else:
             raise ValueError(f'cannot use "{key}" for indexing')
 
     def __array__(self, dtype: Any = None) -> np.ndarray[Any, Any]:
+        """
+        Numpy __array__ interface protocol.
+
+        Ensures that `np.asarray(pl.Series(..))` works as expected, see
+        https://numpy.org/devdocs/user/basics.interoperability.html#the-array-method.
+        """
         if not dtype and self.dtype == Utf8 and not self.has_validity():
             dtype = np.dtype("U")
         if dtype:
             return self.to_numpy().__array__(dtype)
         else:
             return self.to_numpy().__array__()
 
@@ -3390,23 +3397,33 @@
                 tp = f"datetime64[{self._s.time_unit()}]"
             return arr.astype(tp)
 
         def raise_no_zero_copy() -> None:
             if zero_copy_only:
                 raise ValueError("Cannot return a zero-copy array")
 
+        if self.dtype == Array:
+            np_array = self.explode().to_numpy(
+                zero_copy_only=zero_copy_only,
+                writable=writable,
+                use_pyarrow=use_pyarrow,
+            )
+            np_array.shape = (self.len(), self.dtype.width)  # type: ignore[union-attr]
+            return np_array
+
         if (
             use_pyarrow
             and _PYARROW_AVAILABLE
             and self.dtype != Object
             and not self.is_temporal(excluding=Time)
         ):
             return self.to_arrow().to_numpy(
                 *args, zero_copy_only=zero_copy_only, writable=writable
             )
+
         elif self.dtype == Time:
             raise_no_zero_copy()
             # note: there is no native numpy "time" dtype
             return np.array(self.to_list(), dtype="object")
         else:
             if not self.has_validity():
                 if self.is_temporal():
@@ -4374,14 +4391,17 @@
         """
         Apply a rolling min (moving min) over the values in this array.
 
         A window of length `window_size` will traverse the array. The values that fill
         this window will (optionally) be multiplied with the weights given by the
         `weight` vector. The resulting values will be aggregated to their sum.
 
+        The window at a given row will include the row itself and the `window_size - 1`
+        elements before it.
+
         Parameters
         ----------
         window_size
             The length of the window.
         weights
             An optional slice with the same length as the window that will be multiplied
             elementwise with the values in the window.
@@ -4427,14 +4447,17 @@
         """
         Apply a rolling max (moving max) over the values in this array.
 
         A window of length `window_size` will traverse the array. The values that fill
         this window will (optionally) be multiplied with the weights given by the
         `weight` vector. The resulting values will be aggregated to their sum.
 
+        The window at a given row will include the row itself and the `window_size - 1`
+        elements before it.
+
         Parameters
         ----------
         window_size
             The length of the window.
         weights
             An optional slice with the same length as the window that will be multiplied
             elementwise with the values in the window.
@@ -4480,14 +4503,17 @@
         """
         Apply a rolling mean (moving mean) over the values in this array.
 
         A window of length `window_size` will traverse the array. The values that fill
         this window will (optionally) be multiplied with the weights given by the
         `weight` vector. The resulting values will be aggregated to their sum.
 
+        The window at a given row will include the row itself and the `window_size - 1`
+        elements before it.
+
         Parameters
         ----------
         window_size
             The length of the window.
         weights
             An optional slice with the same length as the window that will be multiplied
             elementwise with the values in the window.
@@ -4533,14 +4559,17 @@
         """
         Apply a rolling sum (moving sum) over the values in this array.
 
         A window of length `window_size` will traverse the array. The values that fill
         this window will (optionally) be multiplied with the weights given by the
         `weight` vector. The resulting values will be aggregated to their sum.
 
+        The window at a given row will include the row itself and the `window_size - 1`
+        elements before it.
+
         Parameters
         ----------
         window_size
             The length of the window.
         weights
             An optional slice with the same length of the window that will be multiplied
             elementwise with the values in the window.
@@ -4578,34 +4607,40 @@
     def rolling_std(
         self,
         window_size: int,
         weights: list[float] | None = None,
         min_periods: int | None = None,
         *,
         center: bool = False,
+        ddof: int = 1,
     ) -> Series:
         """
         Compute a rolling std dev.
 
         A window of length `window_size` will traverse the array. The values that fill
         this window will (optionally) be multiplied with the weights given by the
         `weight` vector. The resulting values will be aggregated to their sum.
 
+        The window at a given row will include the row itself and the `window_size - 1`
+        elements before it.
+
         Parameters
         ----------
         window_size
             The length of the window.
         weights
             An optional slice with the same length as the window that will be multiplied
             elementwise with the values in the window.
         min_periods
             The number of values in the window that should be non-null before computing
             a result. If None, it will be set equal to window size.
         center
             Set the labels at the center of the window
+        ddof
+            "Delta Degrees of Freedom": The divisor for a length N window is N - ddof
 
         Examples
         --------
         >>> s = pl.Series("a", [1.0, 2.0, 3.0, 4.0, 6.0, 8.0])
         >>> s.rolling_std(window_size=3)
         shape: (6,)
         Series: 'a' [f64]
@@ -4619,47 +4654,53 @@
         ]
 
         """
         return (
             self.to_frame()
             .select(
                 F.col(self.name).rolling_std(
-                    window_size, weights, min_periods, center=center
+                    window_size, weights, min_periods, center=center, ddof=ddof
                 )
             )
             .to_series()
         )
 
     def rolling_var(
         self,
         window_size: int,
         weights: list[float] | None = None,
         min_periods: int | None = None,
         *,
         center: bool = False,
+        ddof: int = 1,
     ) -> Series:
         """
         Compute a rolling variance.
 
         A window of length `window_size` will traverse the array. The values that fill
         this window will (optionally) be multiplied with the weights given by the
         `weight` vector. The resulting values will be aggregated to their sum.
 
+        The window at a given row will include the row itself and the `window_size - 1`
+        elements before it.
+
         Parameters
         ----------
         window_size
             The length of the window.
         weights
             An optional slice with the same length as the window that will be multiplied
             elementwise with the values in the window.
         min_periods
             The number of values in the window that should be non-null before computing
             a result. If None, it will be set equal to window size.
         center
             Set the labels at the center of the window
+        ddof
+            "Delta Degrees of Freedom": The divisor for a length N window is N - ddof
 
         Examples
         --------
         >>> s = pl.Series("a", [1.0, 2.0, 3.0, 4.0, 6.0, 8.0])
         >>> s.rolling_var(window_size=3)
         shape: (6,)
         Series: 'a' [f64]
@@ -4673,15 +4714,15 @@
         ]
 
         """
         return (
             self.to_frame()
             .select(
                 F.col(self.name).rolling_var(
-                    window_size, weights, min_periods, center=center
+                    window_size, weights, min_periods, center=center, ddof=ddof
                 )
             )
             .to_series()
         )
 
     def rolling_apply(
         self,
@@ -4698,14 +4739,17 @@
         Prefer the specific rolling window functions over this one, as they are faster:
 
             * rolling_min
             * rolling_max
             * rolling_mean
             * rolling_sum
 
+        The window at a given row will include the row itself and the `window_size - 1`
+        elements before it.
+
         Parameters
         ----------
         function
             Aggregation function
         window_size
             The length of the window.
         weights
@@ -4754,14 +4798,17 @@
             elementwise with the values in the window.
         min_periods
             The number of values in the window that should be non-null before computing
             a result. If None, it will be set equal to window size.
         center
             Set the labels at the center of the window
 
+        The window at a given row will include the row itself and the `window_size - 1`
+        elements before it.
+
         Examples
         --------
         >>> s = pl.Series("a", [1.0, 2.0, 3.0, 4.0, 6.0, 8.0])
         >>> s.rolling_median(window_size=3)
         shape: (6,)
         Series: 'a' [f64]
         [
@@ -4796,14 +4843,17 @@
         min_periods: int | None = None,
         *,
         center: bool = False,
     ) -> Series:
         """
         Compute a rolling quantile.
 
+        The window at a given row will include the row itself and the `window_size - 1`
+        elements before it.
+
         Parameters
         ----------
         quantile
             Quantile between 0.0 and 1.0.
         interpolation : {'nearest', 'higher', 'lower', 'midpoint', 'linear'}
             Interpolation method.
         window_size
@@ -4862,36 +4912,41 @@
             .to_series()
         )
 
     def rolling_skew(self, window_size: int, *, bias: bool = True) -> Series:
         """
         Compute a rolling skew.
 
+        The window at a given row includes the row itself and the
+        `window_size - 1` elements before it.
+
         Parameters
         ----------
         window_size
             Integer size of the rolling window.
         bias
             If False, the calculations are corrected for statistical bias.
 
         Examples
         --------
-        >>> s = pl.Series("a", [1.0, 2.0, 3.0, 4.0, 6.0, 8.0])
-        >>> s.rolling_skew(window_size=3)
-        shape: (6,)
-        Series: 'a' [f64]
+        >>> pl.Series([1, 4, 2, 9]).rolling_skew(3)
+        shape: (4,)
+        Series: '' [f64]
         [
-                null
-                null
-                0.0
-                0.0
-                0.381802
-                0.0
+            null
+            null
+            0.381802
+            0.47033
         ]
 
+        Note how the values match
+
+        >>> pl.Series([1, 4, 2]).skew(), pl.Series([4, 2, 9]).skew()
+        (0.38180177416060584, 0.47033046033698594)
+
         """
 
     @deprecated_alias(frac="fraction")
     def sample(
         self,
         n: int | None = None,
         *,
```

### Comparing `polars_lts_cpu-0.18.0/polars/series/string.py` & `polars_lts_cpu-0.18.1/polars/series/string.py`

 * *Files 2% similar despite different names*

```diff
@@ -48,14 +48,18 @@
             for the full specification. Example: ``"%Y-%m-%d"``.
             If set to None (default), the format is inferred from the data.
         strict
             Raise an error if any conversion fails.
         exact
             Require an exact format match. If False, allow the format to match anywhere
             in the target string.
+
+            .. note::
+                Using ``exact=False`` introduces a performance penalty - cleaning your
+                data beforehand will almost certainly be more performant.
         cache
             Use a cache of unique, converted dates to apply the conversion.
 
         Examples
         --------
         >>> s = pl.Series(["2020/01/01", "2020/02/01", "2020/03/01"])
         >>> s.str.to_date()
@@ -98,14 +102,18 @@
         time_zone
             Time zone for the resulting Datetime column.
         strict
             Raise an error if any conversion fails.
         exact
             Require an exact format match. If False, allow the format to match anywhere
             in the target string.
+
+            .. note::
+                Using ``exact=False`` introduces a performance penalty - cleaning your
+                data beforehand will almost certainly be more performant.
         cache
             Use a cache of unique, converted datetimes to apply the conversion.
         utc
             Parse time zone aware datetimes as UTC. This may be useful if you have data
             with mixed offsets.
 
             .. deprecated:: 0.18.0
@@ -186,14 +194,18 @@
             for the full specification. Example: ``"%Y-%m-%d %H:%M:%S"``.
             If set to None (default), the format is inferred from the data.
         strict
             Raise an error if any conversion fails.
         exact
             Require an exact format match. If False, allow the format to match anywhere
             in the target string. Conversion to the Time type is always exact.
+
+            .. note::
+                Using ``exact=False`` introduces a performance penalty - cleaning your
+                data beforehand will almost certainly be more performant.
         cache
             Use a cache of unique, converted dates to apply the datetime conversion.
         utc
             Parse time zone aware datetimes as UTC. This may be useful if you have data
             with mixed offsets.
 
             .. deprecated:: 0.18.0
@@ -291,15 +303,15 @@
         Examples
         --------
         >>> s = pl.Series(
         ...     ["40.12", "3420.13", "120134.19", "3212.98", "12.90", "143.09", "143.9"]
         ... )
         >>> s.str.to_decimal()
         shape: (7,)
-        Series: '' [decimal[8,2]]
+        Series: '' [decimal[2]]
         [
             40.12
             3420.13
             120134.19
             3212.98
             12.9
             143.09
```

### Comparing `polars_lts_cpu-0.18.0/polars/series/struct.py` & `polars_lts_cpu-0.18.1/polars/series/struct.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/series/utils.py` & `polars_lts_cpu-0.18.1/polars/series/utils.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/slice.py` & `polars_lts_cpu-0.18.1/polars/slice.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/sql/context.py` & `polars_lts_cpu-0.18.1/polars/sql/context.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/string_cache.py` & `polars_lts_cpu-0.18.1/polars/string_cache.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/testing/_private.py` & `polars_lts_cpu-0.18.1/polars/testing/_private.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/testing/asserts.py` & `polars_lts_cpu-0.18.1/polars/testing/asserts.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/testing/parametric/__init__.py` & `polars_lts_cpu-0.18.1/polars/testing/parametric/__init__.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/testing/parametric/primitives.py` & `polars_lts_cpu-0.18.1/polars/testing/parametric/primitives.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/testing/parametric/profiles.py` & `polars_lts_cpu-0.18.1/polars/testing/parametric/profiles.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/testing/parametric/strategies.py` & `polars_lts_cpu-0.18.1/polars/testing/parametric/strategies.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/type_aliases.py` & `polars_lts_cpu-0.18.1/polars/type_aliases.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/utils/__init__.py` & `polars_lts_cpu-0.18.1/polars/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/utils/_construction.py` & `polars_lts_cpu-0.18.1/polars/utils/_construction.py`

 * *Files 0% similar despite different names*

```diff
@@ -551,15 +551,15 @@
     elif dtype:
         return pa.array(values, from_pandas=nan_to_null)
     else:
         # Pandas Series is actually a Pandas DataFrame when the original dataframe
         # contains duplicated columns and a duplicated column is requested with df["a"].
         raise ValueError(
             "Duplicate column names found: "
-            + f"{str(values.columns.tolist())}"  # type: ignore[union-attr]
+            + f"{values.columns.tolist()!s}"  # type: ignore[union-attr]
         )
 
 
 def pandas_to_pyseries(
     name: str, values: pd.Series | pd.DatetimeIndex, nan_to_null: bool = True
 ) -> PySeries:
     """Construct a PySeries from a pandas Series or DatetimeIndex."""
```

### Comparing `polars_lts_cpu-0.18.0/polars/utils/_parse_expr_input.py` & `polars_lts_cpu-0.18.1/polars/utils/_parse_expr_input.py`

 * *Files 6% similar despite different names*

```diff
@@ -10,89 +10,93 @@
 if TYPE_CHECKING:
     from polars import Expr
     from polars.polars import PyExpr
     from polars.type_aliases import IntoExpr
 
 
 def parse_as_list_of_expressions(
-    inputs: IntoExpr | Iterable[IntoExpr] | None = None,
-    *more_inputs: IntoExpr,
-    structify: bool = False,
+    *inputs: IntoExpr | Iterable[IntoExpr],
+    __structify: bool = False,
     **named_inputs: IntoExpr,
 ) -> list[PyExpr]:
     """
     Parse multiple inputs into a list of expressions.
 
     Parameters
     ----------
-    inputs
-        Inputs to be parsed as expressions.
-    *more_inputs
-        Additional inputs to be parsed as expressions, specified as positional
-        arguments.
+    *inputs
+        Inputs to be parsed as expressions, specified as positional arguments.
     **named_inputs
         Additional inputs to be parsed as expressions, specified as keyword arguments.
         The expressions will be renamed to the keyword used.
-    structify
+    __structify
         Convert multi-column expressions to a single struct expression.
 
     """
-    exprs = _parse_regular_inputs(inputs, more_inputs, structify=structify)
-
+    exprs = _parse_regular_inputs(inputs, structify=__structify)
     if named_inputs:
-        named_exprs = _parse_named_inputs(named_inputs, structify=structify)
+        named_exprs = _parse_named_inputs(named_inputs, structify=__structify)
         exprs.extend(named_exprs)
 
     return exprs
 
 
 def _parse_regular_inputs(
-    inputs: IntoExpr | Iterable[IntoExpr] | None,
-    more_inputs: tuple[IntoExpr, ...],
+    inputs: tuple[IntoExpr | Iterable[IntoExpr], ...],
+    *,
     structify: bool = False,
 ) -> list[PyExpr]:
-    inputs = _inputs_to_list(inputs)
-    if more_inputs:
-        inputs.extend(more_inputs)
-    return [parse_as_expression(e, structify=structify)._pyexpr for e in inputs]
+    if not inputs:
+        return []
+
+    input_list = _first_input_to_list(inputs[0])
+    input_list.extend(inputs[1:])  # type: ignore[arg-type]
+    return [parse_as_expression(e, structify=structify) for e in input_list]
 
 
-def _inputs_to_list(inputs: IntoExpr | Iterable[IntoExpr] | None) -> list[IntoExpr]:
+def _first_input_to_list(
+    inputs: IntoExpr | Iterable[IntoExpr] | None,
+) -> list[IntoExpr]:
     if inputs is None:
         return []
     elif not isinstance(inputs, Iterable) or isinstance(inputs, (str, pl.Series)):
         return [inputs]
     else:
         return list(inputs)
 
 
 def _parse_named_inputs(
-    named_inputs: dict[str, IntoExpr], structify: bool = False
+    named_inputs: dict[str, IntoExpr], *, structify: bool = False
 ) -> Iterable[PyExpr]:
     return (
-        parse_as_expression(input, structify=structify).alias(name)._pyexpr
+        parse_as_expression(input, structify=structify).alias(name)
         for name, input in named_inputs.items()
     )
 
 
 def parse_as_expression(
-    input: IntoExpr, *, str_as_lit: bool = False, structify: bool = False
-) -> Expr:
+    input: IntoExpr,
+    *,
+    str_as_lit: bool = False,
+    structify: bool = False,
+) -> PyExpr | Expr:
     """
     Parse a single input into an expression.
 
     Parameters
     ----------
     input
         The input to be parsed as an expression.
     str_as_lit
         Interpret string input as a string literal. If set to ``False`` (default),
         strings are parsed as column names.
     structify
         Convert multi-column expressions to a single struct expression.
+    wrap
+        Return an ``Expr`` object rather than a ``PyExpr`` object.
 
     """
     if isinstance(input, pl.Expr):
         expr = input
     elif isinstance(input, str) and not str_as_lit:
         expr = F.col(input)
         structify = False
@@ -112,15 +116,15 @@
             f"did not expect value {input!r} of type {type(input)}, maybe disambiguate with"
             " pl.lit or pl.col"
         )
 
     if structify:
         expr = _structify_expression(expr)
 
-    return expr
+    return expr._pyexpr
 
 
 def _structify_expression(expr: Expr) -> Expr:
     unaliased_expr = expr.meta.undo_aliases()
     if unaliased_expr.meta.has_multiple_outputs():
         try:
             expr_name = expr.meta.output_name()
```

### Comparing `polars_lts_cpu-0.18.0/polars/utils/_scan.py` & `polars_lts_cpu-0.18.1/polars/utils/_scan.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/utils/_wrap.py` & `polars_lts_cpu-0.18.1/polars/utils/_wrap.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/utils/build_info.py` & `polars_lts_cpu-0.18.1/polars/utils/build_info.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/utils/convert.py` & `polars_lts_cpu-0.18.1/polars/utils/convert.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/utils/decorators.py` & `polars_lts_cpu-0.18.1/polars/utils/decorators.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/utils/meta.py` & `polars_lts_cpu-0.18.1/polars/utils/meta.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/utils/polars_version.py` & `polars_lts_cpu-0.18.1/polars/utils/polars_version.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/utils/show_versions.py` & `polars_lts_cpu-0.18.1/polars/utils/show_versions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/polars/utils/various.py` & `polars_lts_cpu-0.18.1/polars/utils/various.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/pyproject.toml` & `polars_lts_cpu-0.18.1/pyproject.toml`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 [build-system]
-requires = ["maturin>=0.14,<0.15"]
+requires = ["maturin>=1.0,<1.1"]
 build-backend = "maturin"
 
 [project]
 name = "polars-lts-cpu"
 description = "Blazingly fast DataFrame library"
 readme = "README.md"
 authors = [
```

### Comparing `polars_lts_cpu-0.18.0/requirements-dev.txt` & `polars_lts_cpu-0.18.1/requirements-dev.txt`

 * *Files 16% similar despite different names*

```diff
@@ -15,14 +15,14 @@
 xlsx2csv
 XlsxWriter
 adbc_driver_sqlite; python_version >= '3.9' and platform_system != 'Windows'
 connectorx==0.3.2a5; python_version >= '3.8'  # Latest full release is broken - unpin when 0.3.2 released
 
 # Tooling
 hypothesis==6.75.1
-maturin==0.14.10
+maturin==1.0.1
 pytest==7.3.0
-pytest-cov==4.0.0
-pytest-xdist==3.2.0
+pytest-cov==4.1.0
+pytest-xdist==3.3.1
 
 # Stub files
 pandas-stubs==1.2.0.62
```

### Comparing `polars_lts_cpu-0.18.0/scripts/check_stacklevels.py` & `polars_lts_cpu-0.18.1/scripts/check_stacklevels.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/apply/dataframe.rs` & `polars_lts_cpu-0.18.1/src/apply/dataframe.rs`

 * *Files 16% similar despite different names*

```diff
@@ -36,25 +36,25 @@
         let iter = iters.iter_mut().map(|it| Wrap(it.next().unwrap()));
         let arg = (PyTuple::new(py, iter),);
         let out = lambda.call1(arg)?;
 
         if out.is_none() {
             null_count += 1;
             continue;
-        } else if out.is_instance_of::<PyBool>().unwrap() {
+        } else if out.is_instance_of::<PyBool>() {
             let first_value = out.extract::<bool>().ok();
             return Ok((
                 PySeries::new(
                     apply_lambda_with_bool_out_type(df, py, lambda, null_count, first_value)
                         .into_series(),
                 )
                 .into_py(py),
                 false,
             ));
-        } else if out.is_instance_of::<PyFloat>().unwrap() {
+        } else if out.is_instance_of::<PyFloat>() {
             let first_value = out.extract::<f64>().ok();
 
             return Ok((
                 PySeries::new(
                     apply_lambda_with_primitive_out_type::<Float64Type>(
                         df,
                         py,
@@ -63,15 +63,15 @@
                         first_value,
                     )
                     .into_series(),
                 )
                 .into_py(py),
                 false,
             ));
-        } else if out.is_instance_of::<PyInt>().unwrap() {
+        } else if out.is_instance_of::<PyInt>() {
             let first_value = out.extract::<i64>().ok();
             return Ok((
                 PySeries::new(
                     apply_lambda_with_primitive_out_type::<Int64Type>(
                         df,
                         py,
                         lambda,
@@ -79,15 +79,15 @@
                         first_value,
                     )
                     .into_series(),
                 )
                 .into_py(py),
                 false,
             ));
-        } else if out.is_instance_of::<PyString>().unwrap() {
+        } else if out.is_instance_of::<PyString>() {
             let first_value = out.extract::<&str>().ok();
             return Ok((
                 PySeries::new(
                     apply_lambda_with_utf8_out_type(df, py, lambda, null_count, first_value)
                         .into_series(),
                 )
                 .into_py(py),
@@ -118,17 +118,15 @@
                         inference_size,
                     )
                     .map_err(PyPolarsErr::from)?,
                 )
                 .into_py(py),
                 true,
             ));
-        } else if out.is_instance_of::<PyList>().unwrap()
-            || out.is_instance_of::<PyTuple>().unwrap()
-        {
+        } else if out.is_instance_of::<PyList>() || out.is_instance_of::<PyTuple>() {
             return Err(PyPolarsErr::Other(
                 "A list output type is invalid. Do you mean to create polars List Series?\
 Then return a Series object."
                     .into(),
             )
             .into());
         } else {
@@ -263,53 +261,58 @@
     let mut row_buf = Row::default();
 
     let skip = 1;
     let mut iters = get_iters_skip(df, init_null_count + skip);
     let mut row_iter = ((init_null_count + skip)..df.height()).map(|_| {
         let iter = iters.iter_mut().map(|it| Wrap(it.next().unwrap()));
         let tpl = (PyTuple::new(py, iter),);
-        match lambda.call1(tpl) {
-            Ok(val) => {
-                match val.downcast::<PyTuple>().ok() {
-                    Some(tuple) => {
-                        row_buf.0.clear();
-                        for v in tuple {
-                            let v = v.extract::<Wrap<AnyValue>>().unwrap().0;
-                            row_buf.0.push(v);
-                        }
-                        let ptr = &row_buf as *const Row;
-                        // Safety:
-                        // we know that row constructor of polars dataframe does not keep a reference
-                        // to the row. Before we mutate the row buf again, the reference is dropped.
-                        // we only cannot prove it to the compiler.
-                        // we still to this because it save a Vec allocation in a hot loop.
-                        unsafe { &*ptr }
-                    }
-                    None => &null_row,
-                }
+
+        let return_val = lambda.call1(tpl).map_err(|e| polars_err!(ComputeError: format!("{e}")))?;
+        if return_val.is_none() {
+            Ok(&null_row)
+        } else {
+            let tuple = return_val.downcast::<PyTuple>().map_err(|_| polars_err!(ComputeError: format!("expected tuple, got {}", return_val.get_type().name().unwrap())))?;
+            row_buf.0.clear();
+            for v in tuple {
+                let v = v.extract::<Wrap<AnyValue>>().unwrap().0;
+                row_buf.0.push(v);
             }
-            Err(e) => panic!("python function failed {e}"),
+            let ptr = &row_buf as *const Row;
+            // Safety:
+            // we know that row constructor of polars dataframe does not keep a reference
+            // to the row. Before we mutate the row buf again, the reference is dropped.
+            // we only cannot prove it to the compiler.
+            // we still to this because it save a Vec allocation in a hot loop.
+            Ok(unsafe { &*ptr })
         }
     });
 
     // first rows for schema inference
     let mut buf = Vec::with_capacity(inference_size);
     buf.push(first_value);
-    buf.extend((&mut row_iter).take(inference_size).cloned());
+    for v in (&mut row_iter).take(inference_size) {
+        buf.push(v?.clone());
+    }
+
     let schema = rows_to_schema_first_non_null(&buf, Some(50));
 
     if init_null_count > 0 {
         // Safety: we know the iterators size
         let iter = unsafe {
             (0..init_null_count)
-                .map(|_| &null_row)
-                .chain(buf.iter())
+                .map(|_| Ok(&null_row))
+                .chain(buf.iter().map(Ok))
                 .chain(row_iter)
                 .trust_my_length(df.height())
         };
-        DataFrame::from_rows_iter_and_schema(iter, &schema)
+        DataFrame::try_from_rows_iter_and_schema(iter, &schema)
     } else {
         // Safety: we know the iterators size
-        let iter = unsafe { buf.iter().chain(row_iter).trust_my_length(df.height()) };
-        DataFrame::from_rows_iter_and_schema(iter, &schema)
+        let iter = unsafe {
+            buf.iter()
+                .map(Ok)
+                .chain(row_iter)
+                .trust_my_length(df.height())
+        };
+        DataFrame::try_from_rows_iter_and_schema(iter, &schema)
     }
 }
```

### Comparing `polars_lts_cpu-0.18.0/src/apply/lazy.rs` & `polars_lts_cpu-0.18.1/src/apply/lazy.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/apply/mod.rs` & `polars_lts_cpu-0.18.1/src/apply/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/apply/series.rs` & `polars_lts_cpu-0.18.1/src/apply/series.rs`

 * *Files 1% similar despite different names*

```diff
@@ -13,42 +13,42 @@
 fn infer_and_finish<'a, A: ApplyLambda<'a>>(
     applyer: &'a A,
     py: Python,
     lambda: &'a PyAny,
     out: &'a PyAny,
     null_count: usize,
 ) -> PyResult<PySeries> {
-    if out.is_instance_of::<PyBool>().unwrap() {
+    if out.is_instance_of::<PyBool>() {
         let first_value = out.extract::<bool>().unwrap();
         applyer
             .apply_lambda_with_bool_out_type(py, lambda, null_count, Some(first_value))
             .map(|ca| ca.into_series().into())
-    } else if out.is_instance_of::<PyFloat>().unwrap() {
+    } else if out.is_instance_of::<PyFloat>() {
         let first_value = out.extract::<f64>().unwrap();
         applyer
             .apply_lambda_with_primitive_out_type::<Float64Type>(
                 py,
                 lambda,
                 null_count,
                 Some(first_value),
             )
             .map(|ca| ca.into_series().into())
-    } else if out.is_instance_of::<PyString>().unwrap() {
+    } else if out.is_instance_of::<PyString>() {
         let first_value = out.extract::<&str>().unwrap();
         applyer
             .apply_lambda_with_utf8_out_type(py, lambda, null_count, Some(first_value))
             .map(|ca| ca.into_series().into())
     } else if out.hasattr("_s")? {
         let py_pyseries = out.getattr("_s").unwrap();
         let series = py_pyseries.extract::<PySeries>().unwrap().series;
         let dt = series.dtype();
         applyer
             .apply_lambda_with_list_out_type(py, lambda.to_object(py), null_count, &series, dt)
             .map(|ca| ca.into_series().into())
-    } else if out.is_instance_of::<PyList>().unwrap() || out.is_instance_of::<PyTuple>().unwrap() {
+    } else if out.is_instance_of::<PyList>() || out.is_instance_of::<PyTuple>() {
         let series = SERIES.call1(py, (out,))?;
         let py_pyseries = series.getattr(py, "_s").unwrap();
         let series = py_pyseries.extract::<PySeries>(py).unwrap().series;
 
         // empty dtype is incorrect use anyvalues.
         if series.is_empty() {
             let av = out.extract::<Wrap<AnyValue>>()?;
@@ -80,15 +80,15 @@
             Err(_) => {
                 let av = out.extract::<Wrap<AnyValue>>()?;
                 applyer
                     .apply_extract_any_values(py, lambda, null_count, av.0)
                     .map(|s| s.into())
             }
         }
-    } else if out.is_instance_of::<PyDict>().unwrap() {
+    } else if out.is_instance_of::<PyDict>() {
         let first = out.extract::<Wrap<AnyValue<'_>>>()?;
         applyer.apply_to_struct(py, lambda, null_count, first.0)
     }
     // this succeeds for numpy ints as well, where checking if it is pyint fails
     // we do this later in the chain so that we don't extract integers from string chars.
     else if out.extract::<i64>().is_ok() {
         let first_value = out.extract::<i64>().unwrap();
```

### Comparing `polars_lts_cpu-0.18.0/src/arrow_interop/to_py.rs` & `polars_lts_cpu-0.18.1/src/arrow_interop/to_py.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/arrow_interop/to_rust.rs` & `polars_lts_cpu-0.18.1/src/arrow_interop/to_rust.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/batched_csv.rs` & `polars_lts_cpu-0.18.1/src/batched_csv.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/conversion.rs` & `polars_lts_cpu-0.18.1/src/conversion.rs`

 * *Files 1% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 use polars::frame::NullStrategy;
 #[cfg(feature = "avro")]
 use polars::io::avro::AvroCompression;
 #[cfg(feature = "ipc")]
 use polars::io::ipc::IpcCompression;
 use polars::prelude::AnyValue;
 use polars::series::ops::NullBehavior;
+use polars_core::frame::hash_join::JoinValidation;
 use polars_core::frame::row::any_values_to_dtype;
 use polars_core::prelude::QuantileInterpolOptions;
 use polars_core::utils::arrow::types::NativeType;
 use polars_lazy::prelude::*;
 use pyo3::basic::CompareOp;
 use pyo3::conversion::{FromPyObject, IntoPy};
 use pyo3::exceptions::{PyTypeError, PyValueError};
@@ -293,15 +294,15 @@
             DataType::UInt32 => pl.getattr("UInt32").unwrap().into(),
             DataType::UInt64 => pl.getattr("UInt64").unwrap().into(),
             DataType::Float32 => pl.getattr("Float32").unwrap().into(),
             DataType::Float64 => pl.getattr("Float64").unwrap().into(),
             DataType::Decimal(precision, scale) => pl
                 .getattr("Decimal")
                 .unwrap()
-                .call1((*precision, *scale))
+                .call1((*scale, *precision))
                 .unwrap()
                 .into(),
             DataType::Boolean => pl.getattr("Boolean").unwrap().into(),
             DataType::Utf8 => pl.getattr("Utf8").unwrap().into(),
             DataType::Binary => pl.getattr("Binary").unwrap().into(),
             DataType::Array(inner, size) => {
                 let inner = Wrap(*inner.clone()).to_object(py);
@@ -380,20 +381,22 @@
                     "Time" => DataType::Time,
                     "Duration" => DataType::Duration(TimeUnit::Microseconds),
                     "Decimal" => DataType::Decimal(None, None), // "none" scale => "infer"
                     "Float32" => DataType::Float32,
                     "Float64" => DataType::Float64,
                     #[cfg(feature = "object")]
                     "Object" => DataType::Object(OBJECT_NAME),
+                    "Array" => DataType::Array(Box::new(DataType::Null), 0),
                     "List" => DataType::List(Box::new(DataType::Null)),
+                    "Struct" => DataType::Struct(vec![]),
                     "Null" => DataType::Null,
                     "Unknown" => DataType::Unknown,
                     dt => {
                         return Err(PyValueError::new_err(format!(
-                            "{dt} is not a correct polars DataType.",
+                            "{dt} is not a recognised polars DataType.",
                         )))
                     }
                 }
             }
             "Duration" => {
                 let time_unit = ob.getattr("time_unit").unwrap();
                 let time_unit = time_unit.extract::<Wrap<TimeUnit>>()?.0;
@@ -430,15 +433,15 @@
                     .into_iter()
                     .map(|f| f.0)
                     .collect::<Vec<Field>>();
                 DataType::Struct(fields)
             }
             dt => {
                 return Err(PyTypeError::new_err(format!(
-                    "A {dt} object is not a correct polars DataType. \
+                    "A {dt} object is not a recognised polars DataType. \
                     Hint: use the class without instantiating it.",
                 )))
             }
         };
         Ok(Wrap(dtype))
     }
 }
@@ -657,40 +660,40 @@
         // choose "us" as that is python's default unit
         Ok(AnyValue::Datetime(v, TimeUnit::Microseconds, &None).into())
     })
 }
 
 impl<'s> FromPyObject<'s> for Wrap<AnyValue<'s>> {
     fn extract(ob: &'s PyAny) -> PyResult<Self> {
-        if ob.is_instance_of::<PyBool>()? {
+        if ob.is_instance_of::<PyBool>() {
             Ok(AnyValue::Boolean(ob.extract::<bool>().unwrap()).into())
         } else if let Ok(value) = ob.extract::<i64>() {
             Ok(AnyValue::Int64(value).into())
-        } else if ob.is_instance_of::<PyFloat>()? {
+        } else if ob.is_instance_of::<PyFloat>() {
             let value = ob.extract::<f64>().unwrap();
             Ok(AnyValue::Float64(value).into())
-        } else if ob.is_instance_of::<PyString>()? {
+        } else if ob.is_instance_of::<PyString>() {
             let value = ob.extract::<&'s str>().unwrap();
             Ok(AnyValue::Utf8(value).into())
         } else if ob.is_none() {
             Ok(AnyValue::Null.into())
-        } else if ob.is_instance_of::<PyDict>()? {
+        } else if ob.is_instance_of::<PyDict>() {
             let dict = ob.downcast::<PyDict>().unwrap();
             let len = dict.len();
             let mut keys = Vec::with_capacity(len);
             let mut vals = Vec::with_capacity(len);
             for (k, v) in dict.into_iter() {
                 let key = k.extract::<&str>()?;
                 let val = v.extract::<Wrap<AnyValue>>()?.0;
                 let dtype = DataType::from(&val);
                 keys.push(Field::new(key, dtype));
                 vals.push(val)
             }
             Ok(Wrap(AnyValue::StructOwned(Box::new((vals, keys)))))
-        } else if ob.is_instance_of::<PyList>()? || ob.is_instance_of::<PyTuple>()? {
+        } else if ob.is_instance_of::<PyList>() || ob.is_instance_of::<PyTuple>() {
             materialize_list(ob)
         } else if let Ok(value) = ob.extract::<u64>() {
             Ok(AnyValue::UInt64(value).into())
         } else if ob.hasattr("_s")? {
             let py_pyseries = ob.getattr("_s").unwrap();
             let series = py_pyseries.extract::<PySeries>().unwrap().series;
             Ok(Wrap(AnyValue::List(series)))
@@ -1261,14 +1264,31 @@
                 )))
             }
         };
         Ok(Wrap(parsed))
     }
 }
 
+impl FromPyObject<'_> for Wrap<JoinValidation> {
+    fn extract(ob: &PyAny) -> PyResult<Self> {
+        let parsed = match ob.extract::<&str>()? {
+            "1:1" => JoinValidation::OneToOne,
+            "1:m" => JoinValidation::OneToMany,
+            "m:m" => JoinValidation::ManyToMany,
+            "m:1" => JoinValidation::ManyToOne,
+            v => {
+                return Err(PyValueError::new_err(format!(
+                    "validate must be one of {{'m:m', 'm:1', '1:m', '1:1'}}, got {v}",
+                )))
+            }
+        };
+        Ok(Wrap(parsed))
+    }
+}
+
 pub(crate) fn parse_fill_null_strategy(
     strategy: &str,
     limit: FillNullLimit,
 ) -> PyResult<FillNullStrategy> {
     let parsed = match strategy {
         "forward" => FillNullStrategy::Forward(limit),
         "backward" => FillNullStrategy::Backward(limit),
```

### Comparing `polars_lts_cpu-0.18.0/src/dataframe.rs` & `polars_lts_cpu-0.18.1/src/dataframe.rs`

 * *Files 1% similar despite different names*

```diff
@@ -495,15 +495,15 @@
     #[staticmethod]
     pub fn read_dict(py: Python, dict: &PyDict) -> PyResult<Self> {
         let cols = dict
             .into_iter()
             .map(|(key, val)| {
                 let name = key.extract::<&str>()?;
 
-                let s = if val.is_instance_of::<PyDict>()? {
+                let s = if val.is_instance_of::<PyDict>() {
                     let df = Self::read_dict(py, val.extract::<&PyDict>()?)?;
                     df.df.into_struct(name).into_series()
                 } else {
                     let obj = py_modules::SERIES.call1(py, (name, val))?;
 
                     let pyseries_obj = obj.getattr(py, "_s")?;
                     let pyseries = pyseries_obj.extract::<PySeries>(py)?;
@@ -1253,20 +1253,22 @@
     pub fn null_count(&self) -> Self {
         let df = self.df.null_count();
         df.into()
     }
 
     #[pyo3(signature = (lambda, output_type, inference_size))]
     pub fn apply(
-        &self,
+        &mut self,
         lambda: &PyAny,
         output_type: Option<Wrap<DataType>>,
         inference_size: usize,
     ) -> PyResult<(PyObject, bool)> {
         Python::with_gil(|py| {
+            // needed for series iter
+            self.df.as_single_chunk_par();
             let df = &self.df;
 
             let output_type = output_type.map(|dt| dt.0);
             let out = match output_type {
                 Some(DataType::Int32) => {
                     apply_lambda_with_primitive_out_type::<Int32Type>(df, py, lambda, 0, None)
                         .into_series()
```

### Comparing `polars_lts_cpu-0.18.0/src/datatypes.rs` & `polars_lts_cpu-0.18.1/src/datatypes.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/error.rs` & `polars_lts_cpu-0.18.1/src/error.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/expr/binary.rs` & `polars_lts_cpu-0.18.1/src/expr/binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/expr/datetime.rs` & `polars_lts_cpu-0.18.1/src/expr/datetime.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/expr/general.rs` & `polars_lts_cpu-0.18.1/src/expr/general.rs`

 * *Files 5% similar despite different names*

```diff
@@ -1,18 +1,21 @@
+use std::any::Any;
+
 use polars::lazy::dsl;
 use polars::prelude::*;
 use polars::series::ops::NullBehavior;
 use polars_core::prelude::QuantileInterpolOptions;
 use polars_core::series::IsSorted;
 use pyo3::class::basic::CompareOp;
 use pyo3::prelude::*;
 use pyo3::types::{PyBytes, PyFloat};
 
 use crate::apply::lazy::{call_lambda_with_series, map_single};
 use crate::conversion::{parse_fill_null_strategy, Wrap};
+use crate::error::PyPolarsErr;
 use crate::series::PySeries;
 use crate::utils::reinterpret;
 use crate::PyExpr;
 
 #[pymethods]
 impl PyExpr {
     fn __richcmp__(&self, other: Self, op: CompareOp) -> Self {
@@ -72,48 +75,31 @@
     }
     fn lt(&self, other: Self) -> Self {
         self.clone().inner.lt(other.inner).into()
     }
 
     fn __getstate__(&self, py: Python) -> PyResult<PyObject> {
         // Used in pickle/pickling
-        #[cfg(feature = "json")]
-        {
-            let s = serde_json::to_string(&self.inner).unwrap();
-            Ok(PyBytes::new(py, s.as_bytes()).to_object(py))
-        }
-        #[cfg(not(feature = "json"))]
-        {
-            panic!("activate 'json' feature")
-        }
+        let mut writer: Vec<u8> = vec![];
+        ciborium::ser::into_writer(&self.inner, &mut writer)
+            .map_err(|e| PyPolarsErr::Other(format!("{}", e)))?;
+
+        Ok(PyBytes::new(py, &writer).to_object(py))
     }
 
     fn __setstate__(&mut self, py: Python, state: PyObject) -> PyResult<()> {
         // Used in pickle/pickling
-        #[cfg(feature = "json")]
         match state.extract::<&PyBytes>(py) {
             Ok(s) => {
-                // Safety
-                // we skipped the serializing/deserializing of the static in lifetime in `DataType`
-                // so we actually don't have a lifetime at all when serializing.
-
-                // PyBytes still has a lifetime. Bit its ok, because we drop it immediately
-                // in this scope
-                let s = unsafe { std::mem::transmute::<&'_ PyBytes, &'static PyBytes>(s) };
-                self.inner = serde_json::from_slice(s.as_bytes()).unwrap();
-
+                self.inner = ciborium::de::from_reader(s.as_bytes())
+                    .map_err(|e| PyPolarsErr::Other(format!("{}", e)))?;
                 Ok(())
             }
             Err(e) => Err(e),
         }
-
-        #[cfg(not(feature = "json"))]
-        {
-            panic!("activate 'json' feature")
-        }
     }
 
     fn alias(&self, name: &str) -> Self {
         self.clone().inner.alias(name).into()
     }
     fn is_not(&self) -> Self {
         self.clone().inner.not().into()
@@ -551,14 +537,15 @@
         center: bool,
     ) -> Self {
         let options = RollingOptionsFixedWindow {
             window_size,
             weights,
             min_periods,
             center,
+            ..Default::default()
         };
         // get the pypolars module
         // do the import outside of the function.
         let pypolars = PyModule::import(py, "polars").unwrap().to_object(py);
 
         let function = move |s: &Series| {
             Python::with_gil(|py| {
@@ -567,15 +554,15 @@
                 match out.getattr(py, "_s") {
                     Ok(pyseries) => {
                         let pyseries = pyseries.extract::<PySeries>(py).unwrap();
                         pyseries.series
                     }
                     Err(_) => {
                         let obj = out;
-                        let is_float = obj.as_ref(py).is_instance_of::<PyFloat>().unwrap();
+                        let is_float = obj.as_ref(py).is_instance_of::<PyFloat>();
 
                         let dtype = s.dtype();
 
                         use DataType::*;
                         let result = match dtype {
                             UInt8 => {
                                 if is_float {
@@ -748,14 +735,15 @@
         let options = RollingOptions {
             window_size: Duration::parse(window_size),
             weights,
             min_periods,
             center,
             by,
             closed_window: closed.map(|c| c.0),
+            ..Default::default()
         };
         self.inner.clone().rolling_sum(options).into()
     }
 
     #[pyo3(signature = (window_size, weights, min_periods, center, by, closed))]
     fn rolling_min(
         &self,
@@ -769,14 +757,15 @@
         let options = RollingOptions {
             window_size: Duration::parse(window_size),
             weights,
             min_periods,
             center,
             by,
             closed_window: closed.map(|c| c.0),
+            ..Default::default()
         };
         self.inner.clone().rolling_min(options).into()
     }
 
     #[pyo3(signature = (window_size, weights, min_periods, center, by, closed))]
     fn rolling_max(
         &self,
@@ -790,14 +779,15 @@
         let options = RollingOptions {
             window_size: Duration::parse(window_size),
             weights,
             min_periods,
             center,
             by,
             closed_window: closed.map(|c| c.0),
+            ..Default::default()
         };
         self.inner.clone().rolling_max(options).into()
     }
 
     #[pyo3(signature = (window_size, weights, min_periods, center, by, closed))]
     fn rolling_mean(
         &self,
@@ -811,58 +801,65 @@
         let options = RollingOptions {
             window_size: Duration::parse(window_size),
             weights,
             min_periods,
             center,
             by,
             closed_window: closed.map(|c| c.0),
+            ..Default::default()
         };
 
         self.inner.clone().rolling_mean(options).into()
     }
 
-    #[pyo3(signature = (window_size, weights, min_periods, center, by, closed))]
+    #[pyo3(signature = (window_size, weights, min_periods, center, by, closed, ddof))]
+    #[allow(clippy::too_many_arguments)]
     fn rolling_std(
         &self,
         window_size: &str,
         weights: Option<Vec<f64>>,
         min_periods: usize,
         center: bool,
         by: Option<String>,
         closed: Option<Wrap<ClosedWindow>>,
+        ddof: u8,
     ) -> Self {
         let options = RollingOptions {
             window_size: Duration::parse(window_size),
             weights,
             min_periods,
             center,
             by,
             closed_window: closed.map(|c| c.0),
+            fn_params: Some(Arc::new(RollingVarParams { ddof }) as Arc<dyn Any + Send + Sync>),
         };
 
         self.inner.clone().rolling_std(options).into()
     }
 
-    #[pyo3(signature = (window_size, weights, min_periods, center, by, closed))]
+    #[pyo3(signature = (window_size, weights, min_periods, center, by, closed, ddof))]
+    #[allow(clippy::too_many_arguments)]
     fn rolling_var(
         &self,
         window_size: &str,
         weights: Option<Vec<f64>>,
         min_periods: usize,
         center: bool,
         by: Option<String>,
         closed: Option<Wrap<ClosedWindow>>,
+        ddof: u8,
     ) -> Self {
         let options = RollingOptions {
             window_size: Duration::parse(window_size),
             weights,
             min_periods,
             center,
             by,
             closed_window: closed.map(|c| c.0),
+            fn_params: Some(Arc::new(RollingVarParams { ddof }) as Arc<dyn Any + Send + Sync>),
         };
 
         self.inner.clone().rolling_var(options).into()
     }
 
     #[pyo3(signature = (window_size, weights, min_periods, center, by, closed))]
     fn rolling_median(
@@ -877,14 +874,15 @@
         let options = RollingOptions {
             window_size: Duration::parse(window_size),
             weights,
             min_periods,
             center,
             by,
             closed_window: closed.map(|c| c.0),
+            ..Default::default()
         };
         self.inner.clone().rolling_median(options).into()
     }
 
     #[pyo3(signature = (quantile, interpolation, window_size, weights, min_periods, center, by, closed))]
     #[allow(clippy::too_many_arguments)]
     fn rolling_quantile(
@@ -901,14 +899,15 @@
         let options = RollingOptions {
             window_size: Duration::parse(window_size),
             weights,
             min_periods,
             center,
             by,
             closed_window: closed.map(|c| c.0),
+            ..Default::default()
         };
 
         self.inner
             .clone()
             .rolling_quantile(quantile, interpolation.0, options)
             .into()
     }
```

### Comparing `polars_lts_cpu-0.18.0/src/expr/list.rs` & `polars_lts_cpu-0.18.1/src/expr/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/expr/mod.rs` & `polars_lts_cpu-0.18.1/src/expr/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/expr/string.rs` & `polars_lts_cpu-0.18.1/src/expr/string.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/file.rs` & `polars_lts_cpu-0.18.1/src/file.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/functions/eager.rs` & `polars_lts_cpu-0.18.1/src/functions/eager.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/functions/io.rs` & `polars_lts_cpu-0.18.1/src/functions/io.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/functions/lazy.rs` & `polars_lts_cpu-0.18.1/src/functions/lazy.rs`

 * *Files 3% similar despite different names*

```diff
@@ -225,14 +225,21 @@
         .collect::<PyResult<Vec<_>>>()?;
 
     let lf = dsl::functions::diag_concat_lf(lfs, rechunk, parallel).map_err(PyPolarsErr::from)?;
     Ok(lf.into())
 }
 
 #[pyfunction]
+pub fn concat_expr(e: Vec<PyExpr>, rechunk: bool) -> PyResult<PyExpr> {
+    let e = e.to_exprs();
+    let e = dsl::functions::concat_expr(e, rechunk).map_err(PyPolarsErr::from)?;
+    Ok(e.into())
+}
+
+#[pyfunction]
 pub fn dtype_cols(dtypes: Vec<Wrap<DataType>>) -> PyResult<PyExpr> {
     let dtypes = vec_extract_wrapped(dtypes);
     Ok(dsl::dtype_cols(dtypes).into())
 }
 
 #[allow(clippy::too_many_arguments)]
 #[pyfunction]
@@ -285,15 +292,15 @@
 #[pyfunction]
 pub fn last() -> PyExpr {
     dsl::last().into()
 }
 
 #[pyfunction]
 pub fn lit(value: &PyAny, allow_object: bool) -> PyResult<PyExpr> {
-    if let Ok(true) = value.is_instance_of::<PyBool>() {
+    if value.is_instance_of::<PyBool>() {
         let val = value.extract::<bool>().unwrap();
         Ok(dsl::lit(val).into())
     } else if let Ok(int) = value.downcast::<PyInt>() {
         match int.extract::<i64>() {
             Ok(val) => {
                 if val >= 0 && val < i32::MAX as i64 || val <= 0 && val > i32::MIN as i64 {
                     Ok(dsl::lit(val as i32).into())
@@ -441,7 +448,14 @@
     closed: Wrap<ClosedWindow>,
 ) -> PyExpr {
     let start = start.inner;
     let end = end.inner;
     let every = Duration::parse(every);
     dsl::functions::time_range(start, end, every, closed.0).into()
 }
+
+#[pyfunction]
+#[cfg(feature = "sql")]
+pub fn sql_expr(sql: &str) -> PyResult<PyExpr> {
+    let expr = polars::sql::sql_expr(sql).map_err(PyPolarsErr::from)?;
+    Ok(expr.into())
+}
```

### Comparing `polars_lts_cpu-0.18.0/src/functions/meta.rs` & `polars_lts_cpu-0.18.1/src/functions/meta.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/functions/whenthen.rs` & `polars_lts_cpu-0.18.1/src/functions/whenthen.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/lazyframe.rs` & `polars_lts_cpu-0.18.1/src/lazyframe.rs`

 * *Files 1% similar despite different names*

```diff
@@ -10,14 +10,15 @@
 use polars::lazy::frame::LazyJsonLineReader;
 use polars::lazy::frame::{AllowedOptimizations, LazyFrame};
 use polars::lazy::prelude::col;
 use polars::prelude::{ClosedWindow, CsvEncoding, DataFrame, Field, JoinType, Schema};
 use polars::time::*;
 use polars_core::cloud;
 use polars_core::frame::explode::MeltArgs;
+use polars_core::frame::hash_join::JoinValidation;
 use polars_core::frame::UniqueKeepStrategy;
 use polars_core::prelude::*;
 use pyo3::exceptions::PyValueError;
 use pyo3::prelude::*;
 use pyo3::types::{PyBytes, PyDict, PyList};
 
 use crate::arrow_interop::to_rust::pyarrow_schema_to_rust;
@@ -623,14 +624,15 @@
         other: Self,
         left_on: Vec<PyExpr>,
         right_on: Vec<PyExpr>,
         allow_parallel: bool,
         force_parallel: bool,
         how: Wrap<JoinType>,
         suffix: String,
+        validate: Wrap<JoinValidation>,
     ) -> PyResult<Self> {
         let ldf = self.ldf.clone();
         let other = other.ldf;
         let left_on = left_on
             .into_iter()
             .map(|pyexpr| pyexpr.inner)
             .collect::<Vec<_>>();
@@ -643,14 +645,15 @@
             .join_builder()
             .with(other)
             .left_on(left_on)
             .right_on(right_on)
             .allow_parallel(allow_parallel)
             .force_parallel(force_parallel)
             .how(how.0)
+            .validate(validate.0)
             .suffix(suffix)
             .finish()
             .into())
     }
 
     fn with_column(&mut self, expr: PyExpr) -> Self {
         let ldf = self.ldf.clone();
```

### Comparing `polars_lts_cpu-0.18.0/src/lazygroupby.rs` & `polars_lts_cpu-0.18.1/src/lazygroupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/lib.rs` & `polars_lts_cpu-0.18.1/src/lib.rs`

 * *Files 1% similar despite different names*

```diff
@@ -123,14 +123,16 @@
         .unwrap();
     m.add_wrapped(wrap_pyfunction!(functions::lazy::date_range_lazy))
         .unwrap();
     m.add_wrapped(wrap_pyfunction!(functions::lazy::datetime))
         .unwrap();
     m.add_wrapped(wrap_pyfunction!(functions::lazy::diag_concat_lf))
         .unwrap();
+    m.add_wrapped(wrap_pyfunction!(functions::lazy::concat_expr))
+        .unwrap();
     m.add_wrapped(wrap_pyfunction!(functions::lazy::dtype_cols))
         .unwrap();
     m.add_wrapped(wrap_pyfunction!(functions::lazy::duration))
         .unwrap();
     m.add_wrapped(wrap_pyfunction!(functions::lazy::first))
         .unwrap();
     m.add_wrapped(wrap_pyfunction!(functions::lazy::fold))
@@ -160,14 +162,18 @@
     m.add_wrapped(wrap_pyfunction!(functions::lazy::sum_exprs))
         .unwrap();
     m.add_wrapped(wrap_pyfunction!(functions::lazy::time_range_lazy))
         .unwrap();
     m.add_wrapped(wrap_pyfunction!(functions::whenthen::when))
         .unwrap();
 
+    #[cfg(feature = "sql")]
+    m.add_wrapped(wrap_pyfunction!(functions::lazy::sql_expr))
+        .unwrap();
+
     // Functions - I/O
     #[cfg(feature = "ipc")]
     m.add_wrapped(wrap_pyfunction!(functions::io::read_ipc_schema))
         .unwrap();
     #[cfg(feature = "parquet")]
     m.add_wrapped(wrap_pyfunction!(functions::io::read_parquet_schema))
         .unwrap();
```

### Comparing `polars_lts_cpu-0.18.0/src/object.rs` & `polars_lts_cpu-0.18.1/src/object.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/series/aggregation.rs` & `polars_lts_cpu-0.18.1/src/series/aggregation.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/series/arithmetic.rs` & `polars_lts_cpu-0.18.1/src/series/arithmetic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/series/comparison.rs` & `polars_lts_cpu-0.18.1/src/series/comparison.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/series/construction.rs` & `polars_lts_cpu-0.18.1/src/series/construction.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/series/export.rs` & `polars_lts_cpu-0.18.1/src/series/export.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/series/mod.rs` & `polars_lts_cpu-0.18.1/src/series/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/series/numpy_ufunc.rs` & `polars_lts_cpu-0.18.1/src/series/numpy_ufunc.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/series/set_at_idx.rs` & `polars_lts_cpu-0.18.1/src/series/set_at_idx.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/sql.rs` & `polars_lts_cpu-0.18.1/src/sql.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/src/utils.rs` & `polars_lts_cpu-0.18.1/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/README.md` & `polars_lts_cpu-0.18.1/tests/README.md`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/benchmark/groupby-datagen.R` & `polars_lts_cpu-0.18.1/tests/benchmark/groupby-datagen.R`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/benchmark/run_h2oai_benchmark.py` & `polars_lts_cpu-0.18.1/tests/benchmark/run_h2oai_benchmark.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/benchmark/test_release.py` & `polars_lts_cpu-0.18.1/tests/benchmark/test_release.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/docs/run_doctest.py` & `polars_lts_cpu-0.18.1/tests/docs/run_doctest.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/parametric/test_dataframe.py` & `polars_lts_cpu-0.18.1/tests/parametric/test_dataframe.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/parametric/test_lazyframe.py` & `polars_lts_cpu-0.18.1/tests/parametric/test_lazyframe.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/parametric/test_series.py` & `polars_lts_cpu-0.18.1/tests/parametric/test_series.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/parametric/test_testing.py` & `polars_lts_cpu-0.18.1/tests/parametric/test_testing.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/conftest.py` & `polars_lts_cpu-0.18.1/tests/unit/conftest.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/datatypes/test_array.py` & `polars_lts_cpu-0.18.1/tests/unit/datatypes/test_array.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/datatypes/test_bool.py` & `polars_lts_cpu-0.18.1/tests/unit/datatypes/test_bool.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/datatypes/test_categorical.py` & `polars_lts_cpu-0.18.1/tests/unit/datatypes/test_categorical.py`

 * *Files 3% similar despite different names*

```diff
@@ -389,7 +389,16 @@
         {
             "colB": ["1", "2", "3", "4", "5", "5", "5", "5"],
         }
     ).with_columns([pl.col("colB").cast(pl.Categorical)])
 
     filtered = df.to_arrow().filter([True, False, True, True, False, True, True, True])
     assert pl.from_arrow(filtered).select(pl.col("colB").n_unique()).item() == 4
+
+
+def test_construct_with_null() -> None:
+    # Example from https://github.com/pola-rs/polars/issues/7188
+    df = pl.from_dicts([{"A": None}, {"A": "foo"}], schema={"A": pl.Categorical})
+    assert df.to_series().to_list() == [None, "foo"]
+
+    s = pl.Series([{"struct_A": None}], dtype=pl.Struct({"struct_A": pl.Categorical}))
+    assert s.to_list() == [{"struct_A": None}]
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/datatypes/test_duration.py` & `polars_lts_cpu-0.18.1/tests/unit/datatypes/test_duration.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/datatypes/test_list.py` & `polars_lts_cpu-0.18.1/tests/unit/datatypes/test_list.py`

 * *Files 1% similar despite different names*

```diff
@@ -411,7 +411,19 @@
 
 
 def test_list_null_list_categorical_cast() -> None:
     expected = pl.List(pl.Categorical)
     s = pl.Series([[]], dtype=pl.List(pl.Null)).cast(expected)
     assert s.dtype == expected
     assert s.to_list() == [[]]
+
+
+def test_struct_with_nulls_as_list() -> None:
+    df = pl.DataFrame([[{"a": 1, "b": 2}], [{"c": 3, "d": None}]])
+    assert df.select(pl.concat_list(pl.all()).alias("as_list")).to_dict(False) == {
+        "as_list": [
+            [
+                {"a": 1, "b": 2, "c": None, "d": None},
+                {"a": None, "b": None, "c": 3, "d": None},
+            ]
+        ]
+    }
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/datatypes/test_object.py` & `polars_lts_cpu-0.18.1/tests/unit/datatypes/test_object.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/datatypes/test_struct.py` & `polars_lts_cpu-0.18.1/tests/unit/datatypes/test_struct.py`

 * *Files 1% similar despite different names*

```diff
@@ -832,17 +832,18 @@
         }
     )
 
     df.select("numerical", "struct").unique().sort("numerical")
 
 
 def test_struct_is_in() -> None:
+    # The dtype casts below test that struct is_in upcasts dtypes.
     s1 = (
         pl.DataFrame({"x": [4, 3, 4, 9], "y": [0, 4, 6, 2]})
-        .select(pl.struct(["x", "y"]))
+        .select(pl.struct(schema={"x": pl.Int8, "y": pl.Float32}))
         .to_series()
     )
     s2 = (
         pl.DataFrame({"x": [4, 3, 5, 9], "y": [0, 7, 6, 2]})
         .select(pl.struct(["x", "y"]))
         .to_series()
     )
@@ -899,7 +900,13 @@
                 {"val": 0, "counts": 1},
                 {"val": 1, "counts": 1},
                 {"val": 2, "counts": 1},
                 {"val": 3, "counts": 1},
             ]
         ],
     }
+
+
+def test_struct_null_count_strict_cast() -> None:
+    s = pl.Series([{"a": None}]).cast(pl.Struct({"a": pl.Categorical}))
+    assert s.dtype == pl.Struct([pl.Field("a", pl.Categorical)])
+    assert s.to_list() == [{"a": None}]
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/datatypes/test_temporal.py` & `polars_lts_cpu-0.18.1/tests/unit/datatypes/test_temporal.py`

 * *Files 1% similar despite different names*

```diff
@@ -2691,7 +2691,49 @@
         time(15, 10, 20, 123456),
         time(23, 59, 59, 999999),
     ],
 )
 def test_pytime_conversion(tm: time) -> None:
     s = pl.Series("tm", [tm])
     assert s.to_list() == [tm]
+
+
+@pytest.mark.parametrize(
+    ("input_df", "expected_grouped_df"),
+    [
+        (
+            (
+                pl.DataFrame(
+                    {
+                        "dt": [
+                            datetime(2021, 12, 31, 0, 0, 0),
+                            datetime(2022, 1, 1, 0, 0, 1),
+                            datetime(2022, 3, 31, 0, 0, 1),
+                            datetime(2022, 4, 1, 0, 0, 1),
+                        ]
+                    }
+                )
+            ),
+            pl.DataFrame(
+                {
+                    "dt": [
+                        datetime(2021, 10, 1),
+                        datetime(2022, 1, 1),
+                        datetime(2022, 4, 1),
+                    ],
+                    "num_points": [1, 2, 1],
+                },
+                schema={"dt": pl.Datetime, "num_points": pl.UInt32},
+            ).sort("dt"),
+        )
+    ],
+)
+def test_groupby_dynamic(
+    input_df: pl.DataFrame, expected_grouped_df: pl.DataFrame
+) -> None:
+    result = (
+        input_df.sort("dt")
+        .groupby_dynamic("dt", every="1q")
+        .agg(pl.col("dt").count().alias("num_points"))
+        .sort("dt")
+    )
+    assert_frame_equal(result, expected_grouped_df)
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/functions/test_as_datatype.py` & `polars_lts_cpu-0.18.1/tests/unit/functions/test_as_datatype.py`

 * *Files 1% similar despite different names*

```diff
@@ -452,7 +452,18 @@
 
 
 def test_format() -> None:
     df = pl.DataFrame({"a": ["a", "b", "c"], "b": [1, 2, 3]})
 
     out = df.select([pl.format("foo_{}_bar_{}", pl.col("a"), "b").alias("fmt")])
     assert out["fmt"].to_list() == ["foo_a_bar_1", "foo_b_bar_2", "foo_c_bar_3"]
+
+
+def test_struct_deprecation_exprs_keyword() -> None:
+    with pytest.deprecated_call():
+        result = pl.select(pl.struct(exprs=1.0))
+
+    expected = pl.DataFrame(
+        {"literal": [{"literal": 1.0}]},
+        schema={"literal": pl.Struct({"literal": pl.Float64})},
+    )
+    assert_frame_equal(result, expected)
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/functions/test_functions.py` & `polars_lts_cpu-0.18.1/tests/unit/functions/test_functions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/functions/test_range.py` & `polars_lts_cpu-0.18.1/tests/unit/functions/test_range.py`

 * *Files 2% similar despite different names*

```diff
@@ -540,7 +540,28 @@
 def test_time_range_name() -> None:
     expected_name = "time"
     result_eager = pl.time_range(time(10), time(12), eager=True)
     assert result_eager.name == expected_name
 
     result_lazy = pl.select(pl.time_range(time(10), time(12), eager=False)).to_series()
     assert result_lazy.name == expected_name
+
+
+def test_deprecated_name_arg() -> None:
+    name = "x"
+    with pytest.deprecated_call():
+        result_lazy = pl.date_range(date(2023, 1, 1), date(2023, 1, 3), name=name)
+        assert result_lazy.meta.output_name() == name
+
+    with pytest.deprecated_call():
+        result_eager = pl.date_range(
+            date(2023, 1, 1), date(2023, 1, 3), name=name, eager=True
+        )
+        assert result_eager.name == name
+
+    with pytest.deprecated_call():
+        result_lazy = pl.time_range(time(10), time(12), name=name)
+        assert result_lazy.meta.output_name() == name
+
+    with pytest.deprecated_call():
+        result_eager = pl.time_range(time(10), time(12), name=name, eager=True)
+        assert result_eager.name == name
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/functions/test_repeat.py` & `polars_lts_cpu-0.18.1/tests/unit/functions/test_repeat.py`

 * *Files 26% similar despite different names*

```diff
@@ -52,14 +52,38 @@
 def test_repeat_expr_input_lazy() -> None:
     df = pl.DataFrame({"a": [3, 2, 1]})
     result = df.select(pl.repeat(1, n=pl.col("a"))).to_series()
     expected = pl.Series("repeat", [1, 1, 1], dtype=pl.Int32)
     assert_series_equal(result, expected)
 
 
+def test_repeat_n_zero() -> None:
+    assert pl.repeat(1, n=0, eager=True).len() == 0
+
+
+@pytest.mark.parametrize(
+    "n",
+    [1.5, 2.0, date(1971, 1, 2), "hello"],
+)
+def test_repeat_n_non_integer(n: Any) -> None:
+    with pytest.raises(pl.SchemaError, match="expected expression of dtype 'integer'"):
+        pl.repeat(1, n=pl.lit(n), eager=True)
+
+
+def test_repeat_n_empty() -> None:
+    df = pl.DataFrame(schema={"a": pl.Int32})
+    with pytest.raises(pl.ComputeError, match="index 0 is out of bounds"):
+        df.select(pl.repeat(1, n=pl.col("a")))
+
+
+def test_repeat_n_negative() -> None:
+    with pytest.raises(pl.ComputeError, match="could not parse value '-1' as a size"):
+        pl.repeat(1, n=-1, eager=True)
+
+
 @pytest.mark.parametrize(
     ("n", "dtype", "expected_dtype"),
     [
         (3, None, pl.Float64),
         (2, pl.UInt8, pl.UInt8),
         (0, pl.Int32, pl.Int32),
     ],
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/files/delta-table/_delta_log/00000000000000000000.json` & `polars_lts_cpu-0.18.1/tests/unit/io/files/delta-table/_delta_log/00000000000000000000.json`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/files/delta-table/_delta_log/00000000000000000001.json` & `polars_lts_cpu-0.18.1/tests/unit/io/files/delta-table/_delta_log/00000000000000000001.json`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/files/delta-table/part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet` & `polars_lts_cpu-0.18.1/tests/unit/io/files/delta-table/part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/files/delta-table/part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet` & `polars_lts_cpu-0.18.1/tests/unit/io/files/delta-table/part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/files/example.xlsx` & `polars_lts_cpu-0.18.1/tests/unit/io/files/example.xlsx`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/files/foods1.ipc` & `polars_lts_cpu-0.18.1/tests/unit/io/files/foods1.ipc`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/files/foods1.ndjson` & `polars_lts_cpu-0.18.1/tests/unit/io/files/foods1.ndjson`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/files/foods1.parquet` & `polars_lts_cpu-0.18.1/tests/unit/io/files/foods1.parquet`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/files/foods2.ipc` & `polars_lts_cpu-0.18.1/tests/unit/io/files/foods2.ipc`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/files/foods2.ndjson` & `polars_lts_cpu-0.18.1/tests/unit/io/files/foods2.ndjson`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/files/foods2.parquet` & `polars_lts_cpu-0.18.1/tests/unit/io/files/foods2.parquet`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/files/small.parquet` & `polars_lts_cpu-0.18.1/tests/unit/io/files/small.parquet`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/test_avro.py` & `polars_lts_cpu-0.18.1/tests/unit/io/test_avro.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,22 +1,23 @@
 from __future__ import annotations
 
 import io
-from pathlib import Path
 from typing import TYPE_CHECKING
 
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
-from polars.testing._tempdir import TemporaryDirectory
 
 if TYPE_CHECKING:
+    from pathlib import Path
+
     from polars.type_aliases import AvroCompression
 
+
 COMPRESSIONS = ["uncompressed", "snappy", "deflate"]
 
 
 @pytest.fixture()
 def example_df() -> pl.DataFrame:
     return pl.DataFrame({"i64": [1, 2], "f64": [0.1, 0.2], "utf8": ["a", "b"]})
 
@@ -29,19 +30,22 @@
 
     read_df = pl.read_avro(buf)
     assert_frame_equal(example_df, read_df)
 
 
 @pytest.mark.write_disk()
 @pytest.mark.parametrize("compression", COMPRESSIONS)
-def test_from_to_file(example_df: pl.DataFrame, compression: AvroCompression) -> None:
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "small.avro"
-        example_df.write_avro(file_path, compression=compression)
-        df_read = pl.read_avro(file_path)
+def test_from_to_file(
+    example_df: pl.DataFrame, compression: AvroCompression, tmp_path: Path
+) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
+    file_path = tmp_path / "small.avro"
+    example_df.write_avro(file_path, compression=compression)
+    df_read = pl.read_avro(file_path)
 
     assert_frame_equal(example_df, df_read)
 
 
 def test_select_columns() -> None:
     df = pl.DataFrame({"a": [1, 2, 3], "b": [True, False, True], "c": ["a", "b", "c"]})
     expected = pl.DataFrame({"b": [True, False, True], "c": ["a", "b", "c"]})
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/test_csv.py` & `polars_lts_cpu-0.18.1/tests/unit/io/test_csv.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,31 +2,31 @@
 
 import gzip
 import io
 import textwrap
 import typing
 import zlib
 from datetime import date, datetime, time, timedelta, timezone
-from pathlib import Path
 from typing import TYPE_CHECKING
 
 import numpy as np
 import pytest
 
 import polars as pl
 from polars.exceptions import ComputeError, NoDataError
 from polars.testing import (
     assert_frame_equal,
     assert_frame_equal_local_categoricals,
     assert_series_equal,
 )
-from polars.testing._tempdir import TemporaryDirectory
 from polars.utils.various import normalise_filepath
 
 if TYPE_CHECKING:
+    from pathlib import Path
+
     from polars.type_aliases import TimeUnit
 
 
 @pytest.fixture()
 def foods_file_path(io_files_path: Path) -> Path:
     return io_files_path / "foods1.csv"
 
@@ -56,21 +56,22 @@
     )
     assert_frame_equal_local_categoricals(df, read_df)
     with pytest.raises(AssertionError):
         assert_frame_equal_local_categoricals(df.select(["time", "cat"]), read_df)
 
 
 @pytest.mark.write_disk()
-def test_to_from_file(df_no_lists: pl.DataFrame) -> None:
+def test_to_from_file(df_no_lists: pl.DataFrame, tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     df = df_no_lists.drop("strings_nulls")
 
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "small.csv"
-        df.write_csv(file_path)
-        read_df = pl.read_csv(file_path, try_parse_dates=True)
+    file_path = tmp_path / "small.csv"
+    df.write_csv(file_path)
+    read_df = pl.read_csv(file_path, try_parse_dates=True)
 
     read_df = read_df.with_columns(
         [pl.col("cat").cast(pl.Categorical), pl.col("time").cast(pl.Time)]
     )
     assert_frame_equal_local_categoricals(df, read_df)
 
 
@@ -363,41 +364,42 @@
     assert df.shape == (2, 3)
     assert df.rows() == [("", 5.55, 333), ("", -5.0, 666)]
     assert not buf.closed
     assert buf.read() == bts
 
 
 @pytest.mark.write_disk()
-def test_read_csv_encoding() -> None:
+def test_read_csv_encoding(tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     bts = (
         b"Value1,Value2,Value3,Value4,Region\n"
         b"-30,7.5,2578,1,\xa5x\xa5_\n-32,7.97,3006,1,\xa5x\xa4\xa4\n"
         b"-31,8,3242,2,\xb7s\xa6\xcb\n-33,7.97,3300,3,\xb0\xaa\xb6\xaf\n"
         b"-20,7.91,3384,4,\xac\xfc\xb0\xea\n"
     )
 
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "encoding.csv"
-        with open(file_path, "wb") as f:
-            f.write(bts)
-
-        file_str = str(file_path)
-        bytesio = io.BytesIO(bts)
-
-        for use_pyarrow in (False, True):
-            bytesio.seek(0)
-            for file in [file_path, file_str, bts, bytesio]:
-                assert_series_equal(
-                    pl.read_csv(
-                        file,  # type: ignore[arg-type]
-                        encoding="big5",
-                        use_pyarrow=use_pyarrow,
-                    ).get_column("Region"),
-                    pl.Series("Region", ["", "", "", "", ""]),
-                )
+    file_path = tmp_path / "encoding.csv"
+    with open(file_path, "wb") as f:
+        f.write(bts)
+
+    file_str = str(file_path)
+    bytesio = io.BytesIO(bts)
+
+    for use_pyarrow in (False, True):
+        bytesio.seek(0)
+        for file in [file_path, file_str, bts, bytesio]:
+            assert_series_equal(
+                pl.read_csv(
+                    file,  # type: ignore[arg-type]
+                    encoding="big5",
+                    use_pyarrow=use_pyarrow,
+                ).get_column("Region"),
+                pl.Series("Region", ["", "", "", "", ""]),
+            )
 
 
 def test_column_rename_and_dtype_overwrite() -> None:
     csv = textwrap.dedent(
         """\
         a,b,c
         1,2,3
@@ -780,23 +782,24 @@
     df.write_csv(f)
     f.seek(0)
     df_read = pl.read_csv(f)
     assert_frame_equal(df_read, df)
 
 
 @pytest.mark.write_disk()
-def test_glob_csv(df_no_lists: pl.DataFrame) -> None:
+def test_glob_csv(df_no_lists: pl.DataFrame, tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     df = df_no_lists.drop("strings_nulls")
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "small.csv"
-        df.write_csv(file_path)
-
-        path_glob = Path(temp_dir) / "small*.csv"
-        assert pl.scan_csv(path_glob).collect().shape == (3, 11)
-        assert pl.read_csv(path_glob).shape == (3, 11)
+    file_path = tmp_path / "small.csv"
+    df.write_csv(file_path)
+
+    path_glob = tmp_path / "small*.csv"
+    assert pl.scan_csv(path_glob).collect().shape == (3, 11)
+    assert pl.read_csv(path_glob).shape == (3, 11)
 
 
 def test_csv_whitespace_delimiter_at_start_do_not_skip() -> None:
     csv = "\t\t\t\t0\t1"
     assert pl.read_csv(csv.encode(), separator="\t", has_header=False).to_dict(
         False
     ) == {
@@ -1234,21 +1237,23 @@
     # the lines at the end have larger rows as the numbers increase
     N = 5_000
     csv = "\n".join(str(x) for x in range(N))
     assert pl.read_csv(io.StringIO(csv), n_rows=N).height == 4999
 
 
 @pytest.mark.write_disk()
-def test_csv_scan_categorical() -> None:
+def test_csv_scan_categorical(tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     N = 5_000
     df = pl.DataFrame({"x": ["A"] * N})
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "test_csv_scan_categorical.csv"
-        df.write_csv(file_path)
-        result = pl.scan_csv(file_path, dtypes={"x": pl.Categorical}).collect()
+
+    file_path = tmp_path / "test_csv_scan_categorical.csv"
+    df.write_csv(file_path)
+    result = pl.scan_csv(file_path, dtypes={"x": pl.Categorical}).collect()
 
     assert result["x"].dtype == pl.Categorical
 
 
 def test_read_csv_chunked() -> None:
     """Check that row count is properly functioning."""
     N = 10_000
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/test_database.py` & `polars_lts_cpu-0.18.1/tests/unit/io/test_database.py`

 * *Files 5% similar despite different names*

```diff
@@ -5,17 +5,18 @@
 from datetime import date
 from typing import TYPE_CHECKING
 
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
-from polars.testing._tempdir import TemporaryDirectory
 
 if TYPE_CHECKING:
+    from pathlib import Path
+
     from polars.type_aliases import (
         DbReadEngine,
         DbWriteEngine,
         DbWriteMode,
     )
 
 
@@ -100,27 +101,29 @@
         ),
     ],
 )
 def test_read_database(
     engine: DbReadEngine,
     expected_dtypes: dict[str, pl.DataType],
     expected_dates: list[date | str],
+    tmp_path: Path,
 ) -> None:
-    with TemporaryDirectory(prefix=f"pl_{engine}_") as tmpdir_name:
-        test_db = os.path.join(tmpdir_name, "test.db")
-        create_temp_sqlite_db(test_db)
+    tmp_path.mkdir(exist_ok=True)
 
-        df = pl.read_database(
-            connection_uri=f"sqlite:///{test_db}",
-            query="SELECT * FROM test_data",
-            engine=engine,
-        )
-        assert df.schema == expected_dtypes
-        assert df.shape == (2, 4)
-        assert df["date"].to_list() == expected_dates
+    test_db = str(tmp_path / "test.db")
+    create_temp_sqlite_db(test_db)
+
+    df = pl.read_database(
+        connection_uri=f"sqlite:///{test_db}",
+        query="SELECT * FROM test_data",
+        engine=engine,
+    )
+    assert df.schema == expected_dtypes
+    assert df.shape == (2, 4)
+    assert df["date"].to_list() == expected_dates
 
 
 @pytest.mark.parametrize(
     ("engine", "query", "database", "err"),
     [
         pytest.param(
             "not_engine",
@@ -142,26 +145,22 @@
             "mysql",
             "ADBC does not currently support this database.",
             id="Unavailable database for adbc.",
         ),
     ],
 )
 def test_read_database_exceptions(
-    engine: DbReadEngine, query: str, database: str, err: str
+    engine: DbReadEngine, query: str, database: str, err: str, tmp_path: Path
 ) -> None:
-    with TemporaryDirectory() as tmpdir_name:
-        test_db = os.path.join(tmpdir_name, "test.db")
-        create_temp_sqlite_db(test_db)
-
-        with pytest.raises(ValueError, match=err):
-            pl.read_database(
-                connection_uri=f"{database}:///{test_db}",
-                query=query,
-                engine=engine,
-            )
+    with pytest.raises(ValueError, match=err):
+        pl.read_database(
+            connection_uri=f"{database}://test",
+            query=query,
+            engine=engine,
+        )
 
 
 @pytest.mark.write_disk()
 @pytest.mark.parametrize(
     ("engine", "mode"),
     [
         pytest.param(
@@ -181,32 +180,33 @@
                 sys.version_info < (3, 9) or sys.platform == "win32",
                 reason="adbc_driver_sqlite not available below Python 3.9 / on Windows",
             ),
         ),
     ],
 )
 def test_write_database(
-    engine: DbWriteEngine, mode: DbWriteMode, sample_df: pl.DataFrame
+    engine: DbWriteEngine, mode: DbWriteMode, sample_df: pl.DataFrame, tmp_path: Path
 ) -> None:
-    with TemporaryDirectory() as tmpdir_name:
-        test_db = os.path.join(tmpdir_name, "test.db")
+    tmp_path.mkdir(exist_ok=True)
+
+    test_db = str(tmp_path / "test.db")
 
+    sample_df.write_database(
+        table_name="test_data",
+        connection_uri=f"sqlite:///{test_db}",
+        if_exists="replace",
+        engine=engine,
+    )
+
+    if mode == "append":
         sample_df.write_database(
             table_name="test_data",
             connection_uri=f"sqlite:///{test_db}",
-            if_exists="replace",
+            if_exists="append",
             engine=engine,
         )
+        sample_df = pl.concat([sample_df, sample_df])
 
-        if mode == "append":
-            sample_df.write_database(
-                table_name="test_data",
-                connection_uri=f"sqlite:///{test_db}",
-                if_exists="append",
-                engine=engine,
-            )
-            sample_df = pl.concat([sample_df, sample_df])
-
-        result = pl.read_database("SELECT * FROM test_data", f"sqlite:///{test_db}")
+    result = pl.read_database("SELECT * FROM test_data", f"sqlite:///{test_db}")
 
     sample_df = sample_df.with_columns(pl.col("date").cast(pl.Utf8))
     assert_frame_equal(sample_df, result)
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/test_delta.py` & `polars_lts_cpu-0.18.1/tests/unit/io/test_delta.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/test_excel.py` & `polars_lts_cpu-0.18.1/tests/unit/io/test_excel.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/test_ipc.py` & `polars_lts_cpu-0.18.1/tests/unit/io/test_ipc.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,22 +1,21 @@
 from __future__ import annotations
 
 import io
-import sys
-from pathlib import Path
 from typing import TYPE_CHECKING
 
 import pandas as pd
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal, assert_frame_equal_local_categoricals
-from polars.testing._tempdir import TemporaryDirectory
 
 if TYPE_CHECKING:
+    from pathlib import Path
+
     from polars.type_aliases import IpcCompression
 
 COMPRESSIONS = ["uncompressed", "lz4", "zstd"]
 
 
 @pytest.mark.parametrize("compression", COMPRESSIONS)
 def test_from_to_buffer(df: pl.DataFrame, compression: IpcCompression) -> None:
@@ -28,48 +27,39 @@
     buf2 = io.BytesIO()
     df.write_ipc(buf2, compression=compression)
     buf2.seek(0)
     read_df = pl.read_ipc(buf2, use_pyarrow=False)
     assert_frame_equal_local_categoricals(df, read_df)
 
 
-@pytest.mark.parametrize(
-    "compression",
-    [
-        pytest.param(
-            "uncompressed",
-            marks=pytest.mark.xfail(
-                sys.platform == "win32", reason="Does not work on Windows"
-            ),
-        ),
-        "lz4",
-        "zstd",
-    ],
-)
-@pytest.mark.parametrize("path_type", [str, Path])
+@pytest.mark.parametrize("compression", COMPRESSIONS)
+@pytest.mark.parametrize("path_as_string", [True, False])
 @pytest.mark.write_disk()
 def test_from_to_file(
-    df: pl.DataFrame, compression: IpcCompression, path_type: type[str] | type[Path]
+    df: pl.DataFrame,
+    compression: IpcCompression,
+    path_as_string: bool,
+    tmp_path: Path,
 ) -> None:
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "small.ipc"
-        file_path_cast = path_type(file_path)
-        df.write_ipc(file_path_cast, compression=compression)
-        df_read = pl.read_ipc(file_path_cast, use_pyarrow=False)
+    tmp_path.mkdir(exist_ok=True)
+    file_path = tmp_path / "small.ipc"
+    if path_as_string:
+        file_path = str(file_path)  # type: ignore[assignment]
+    df.write_ipc(file_path, compression=compression)
+    df_read = pl.read_ipc(file_path, use_pyarrow=False)
 
     assert_frame_equal_local_categoricals(df, df_read)
 
 
 @pytest.mark.write_disk()
-@pytest.mark.xfail(sys.platform == "win32", reason="Does not work on Windows")
-def test_select_columns_from_file(df: pl.DataFrame) -> None:
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "small.ipc"
-        df.write_ipc(file_path)
-        df_read = pl.read_ipc(file_path, columns=["bools"])
+def test_select_columns_from_file(df: pl.DataFrame, tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+    file_path = tmp_path / "small.ipc"
+    df.write_ipc(file_path)
+    df_read = pl.read_ipc(file_path, columns=["bools"])
 
     assert df_read.columns == ["bools"]
 
 
 def test_select_columns_from_buffer() -> None:
     df = pl.DataFrame({"a": [1, 2, 3], "b": [True, False, True], "c": ["a", "b", "c"]})
     expected = pl.DataFrame({"b": [True, False, True], "c": ["a", "b", "c"]})
@@ -116,25 +106,28 @@
 
     expected = {"a": pl.Int64, "b": pl.Utf8, "c": pl.Boolean}
     assert pl.read_ipc_schema(f) == expected
 
 
 @pytest.mark.write_disk()
 @pytest.mark.parametrize("compression", COMPRESSIONS)
-@pytest.mark.parametrize("path_type", [str, Path])
+@pytest.mark.parametrize("path_as_string", [True, False])
 def test_ipc_schema_from_file(
     df_no_lists: pl.DataFrame,
     compression: IpcCompression,
-    path_type: type[str] | type[Path],
+    path_as_string: bool,
+    tmp_path: Path,
 ) -> None:
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "small.ipc"
-        file_path_cast = path_type(file_path)
-        df_no_lists.write_ipc(file_path_cast, compression=compression)
-        schema = pl.read_ipc_schema(file_path_cast)
+    tmp_path.mkdir(exist_ok=True)
+
+    file_path = tmp_path / "small.ipc"
+    if path_as_string:
+        file_path = str(file_path)  # type: ignore[assignment]
+    df_no_lists.write_ipc(file_path, compression=compression)
+    schema = pl.read_ipc_schema(file_path)
 
     expected = {
         "bools": pl.Boolean,
         "bools_nulls": pl.Boolean,
         "int": pl.Int64,
         "int_nulls": pl.Int64,
         "floats": pl.Float64,
@@ -163,24 +156,23 @@
 
     columns = ["colc", "colb", "cola"]
     # read file into polars; the specified column order is no longer respected
     assert pl.read_ipc(f, columns=columns).columns == columns
 
 
 @pytest.mark.write_disk()
-@pytest.mark.xfail(sys.platform == "win32", reason="Does not work on Windows")
-def test_glob_ipc(df: pl.DataFrame) -> None:
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "small.ipc"
-        df.write_ipc(file_path)
+def test_glob_ipc(df: pl.DataFrame, tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+    file_path = tmp_path / "small.ipc"
+    df.write_ipc(file_path)
 
-        file_path_glob = Path(temp_dir) / "small*.ipc"
+    file_path_glob = tmp_path / "small*.ipc"
 
-        result_scan = pl.scan_ipc(file_path_glob).collect()
-        result_read = pl.read_ipc(file_path_glob, use_pyarrow=False)
+    result_scan = pl.scan_ipc(file_path_glob).collect()
+    result_read = pl.read_ipc(file_path_glob, use_pyarrow=False)
 
     for result in [result_scan, result_read]:
         assert_frame_equal_local_categoricals(result, df)
 
 
 def test_from_float16() -> None:
     # Create a feather file with a 16-bit floating point column
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/test_json.py` & `polars_lts_cpu-0.18.1/tests/unit/io/test_json.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,34 +1,37 @@
 from __future__ import annotations
 
 import io
 import json
-from pathlib import Path
+from typing import TYPE_CHECKING
 
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal, assert_frame_equal_local_categoricals
-from polars.testing._tempdir import TemporaryDirectory
+
+if TYPE_CHECKING:
+    from pathlib import Path
 
 
 @pytest.mark.parametrize("buf", [io.BytesIO(), io.StringIO()])
 def test_to_from_buffer(df: pl.DataFrame, buf: io.IOBase) -> None:
     df.write_json(buf)
     buf.seek(0)
     read_df = pl.read_json(buf)
     assert_frame_equal_local_categoricals(df, read_df)
 
 
 @pytest.mark.write_disk()
-def test_to_from_file(df: pl.DataFrame) -> None:
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "small.json"
-        df.write_json(file_path)
-        out = pl.read_json(file_path)
+def test_to_from_file(df: pl.DataFrame, tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
+    file_path = tmp_path / "small.json"
+    df.write_json(file_path)
+    out = pl.read_json(file_path)
 
     assert_frame_equal_local_categoricals(df, out)
 
 
 def test_write_json_to_string() -> None:
     # Tests if it runs if no arg given
     df = pl.DataFrame({"a": [1, 2, 3]})
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/test_lazy_csv.py` & `polars_lts_cpu-0.18.1/tests/unit/io/test_lazy_csv.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,18 +1,20 @@
 from __future__ import annotations
 
-from pathlib import Path
+from typing import TYPE_CHECKING
 
 import numpy as np
 import pytest
 
 import polars as pl
 from polars.exceptions import PolarsPanicError
 from polars.testing import assert_frame_equal
-from polars.testing._tempdir import TemporaryDirectory
+
+if TYPE_CHECKING:
+    from pathlib import Path
 
 
 @pytest.fixture()
 def foods_file_path(io_files_path: Path) -> Path:
     return io_files_path / "foods1.csv"
 
 
@@ -29,25 +31,26 @@
 def test_scan_empty_csv(io_files_path: Path) -> None:
     with pytest.raises(Exception) as excinfo:
         pl.scan_csv(io_files_path / "empty.csv").collect()
     assert "empty csv" in str(excinfo.value)
 
 
 @pytest.mark.write_disk()
-def test_invalid_utf8() -> None:
+def test_invalid_utf8(tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     np.random.seed(1)
     bts = bytes(np.random.randint(0, 255, 200))
 
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "nonutf8.csv"
-        with open(file_path, "wb") as f:
-            f.write(bts)
+    file_path = tmp_path / "nonutf8.csv"
+    with open(file_path, "wb") as f:
+        f.write(bts)
 
-        a = pl.read_csv(file_path, has_header=False, encoding="utf8-lossy")
-        b = pl.scan_csv(file_path, has_header=False, encoding="utf8-lossy").collect()
+    a = pl.read_csv(file_path, has_header=False, encoding="utf8-lossy")
+    b = pl.scan_csv(file_path, has_header=False, encoding="utf8-lossy").collect()
 
     assert_frame_equal(a, b)
 
 
 def test_row_count(foods_file_path: Path) -> None:
     df = pl.read_csv(foods_file_path, row_count_name="row_count")
     assert df["row_count"].to_list() == list(range(27))
@@ -180,35 +183,36 @@
 
 def test_scan_slice_streaming(foods_file_path: Path) -> None:
     df = pl.scan_csv(foods_file_path).head(5).collect(streaming=True)
     assert df.shape == (5, 4)
 
 
 @pytest.mark.write_disk()
-def test_glob_skip_rows() -> None:
-    with TemporaryDirectory() as temp_dir:
-        for i in range(2):
-            file_path = Path(temp_dir) / f"test_{i}.csv"
-            with open(file_path, "w") as f:
-                f.write(
-                    f"""
+def test_glob_skip_rows(tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
+    for i in range(2):
+        file_path = tmp_path / f"test_{i}.csv"
+        with open(file_path, "w") as f:
+            f.write(
+                f"""
 metadata goes here
 file number {i}
 foo,bar,baz
 1,2,3
 4,5,6
 7,8,9
-        """
-                )
-        file_path = Path(temp_dir) / "*.csv"
-        assert pl.read_csv(file_path, skip_rows=2).to_dict(False) == {
-            "foo": [1, 4, 7, 1, 4, 7],
-            "bar": [2, 5, 8, 2, 5, 8],
-            "baz": [3, 6, 9, 3, 6, 9],
-        }
+    """
+            )
+    file_path = tmp_path / "*.csv"
+    assert pl.read_csv(file_path, skip_rows=2).to_dict(False) == {
+        "foo": [1, 4, 7, 1, 4, 7],
+        "bar": [2, 5, 8, 2, 5, 8],
+        "baz": [3, 6, 9, 3, 6, 9],
+    }
 
 
 def test_glob_n_rows(io_files_path: Path) -> None:
     file_path = io_files_path / "foods*.csv"
     df = pl.scan_csv(file_path, n_rows=40).collect()
 
     # 27 rows from foods1.csv and 13 from foods2.csv
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/test_lazy_ipc.py` & `polars_lts_cpu-0.18.1/tests/unit/io/test_lazy_ipc.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/test_lazy_json.py` & `polars_lts_cpu-0.18.1/tests/unit/io/test_lazy_json.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,16 +1,18 @@
 from __future__ import annotations
 
-from pathlib import Path
+from typing import TYPE_CHECKING
 
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
-from polars.testing._tempdir import TemporaryDirectory
+
+if TYPE_CHECKING:
+    from pathlib import Path
 
 
 @pytest.fixture()
 def foods_ndjson_path(io_files_path: Path) -> Path:
     return io_files_path / "foods1.ndjson"
 
 
@@ -33,34 +35,36 @@
         .collect()
     )
 
     assert df["foo"].to_list() == [10, 16, 21, 23, 24, 30, 35]
 
 
 @pytest.mark.write_disk()
-def test_scan_with_projection() -> None:
+def test_scan_with_projection(tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     json = r"""
 {"text": "\"hello", "id": 1}
 {"text": "\n{\n\t\t\"inner\": \"json\n}\n", "id": 10}
 {"id": 0, "text":"\"","date":"2013-08-03 15:17:23"}
 {"id": 1, "text":"\"123\"","date":"2009-05-19 21:07:53"}
 {"id": 2, "text":"/....","date":"2009-05-19 21:07:53"}
 {"id": 3, "text":"\n\n..","date":"2"}
 {"id": 4, "text":"\"'/\n...","date":"2009-05-19 21:07:53"}
 {"id": 5, "text":".h\"h1hh\\21hi1e2emm...","date":"2009-05-19 21:07:53"}
 {"id": 6, "text":"xxxx....","date":"2009-05-19 21:07:53"}
 {"id": 7, "text":".\"quoted text\".","date":"2009-05-19 21:07:53"}
 """
     json_bytes = bytes(json, "utf-8")
 
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "escape_chars.json"
-        with open(file_path, "wb") as f:
-            f.write(json_bytes)
-        actual = pl.scan_ndjson(file_path).select(["id", "text"]).collect()
+    file_path = tmp_path / "escape_chars.json"
+    with open(file_path, "wb") as f:
+        f.write(json_bytes)
+    actual = pl.scan_ndjson(file_path).select(["id", "text"]).collect()
+
     expected = pl.DataFrame(
         {
             "id": [1, 10, 0, 1, 2, 3, 4, 5, 6, 7],
             "text": [
                 '"hello',
                 '\n{\n\t\t"inner": "json\n}\n',
                 '"',
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/test_lazy_parquet.py` & `polars_lts_cpu-0.18.1/tests/unit/io/test_lazy_parquet.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 from __future__ import annotations
 
-from pathlib import Path
 from typing import TYPE_CHECKING, Any
 
 import pandas as pd
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
-from polars.testing._tempdir import TemporaryDirectory
 
 if TYPE_CHECKING:
+    from pathlib import Path
+
     from polars.type_aliases import ParallelStrategy
 
 
 @pytest.fixture()
 def parquet_file_path(io_files_path: Path) -> Path:
     return io_files_path / "small.parquet"
 
@@ -48,15 +48,17 @@
         .collect()
     )
 
     assert df["foo"].to_list() == [10, 16, 21, 23, 24, 30, 35]
 
 
 @pytest.mark.write_disk()
-def test_categorical_parquet_statistics() -> None:
+def test_categorical_parquet_statistics(tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     df = pl.DataFrame(
         {
             "book": [
                 "bookA",
                 "bookA",
                 "bookB",
                 "bookA",
@@ -66,298 +68,302 @@
                 "bookC",
             ],
             "transaction_id": [1, 2, 3, 4, 5, 6, 7, 8],
             "user": ["bob", "bob", "bob", "tim", "lucy", "lucy", "lucy", "lucy"],
         }
     ).with_columns(pl.col("book").cast(pl.Categorical))
 
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "books.parquet"
-        df.write_parquet(file_path, statistics=True)
-
-        parallel_options: list[ParallelStrategy] = [
-            "auto",
-            "columns",
-            "row_groups",
-            "none",
-        ]
-        for par in parallel_options:
-            df = (
-                pl.scan_parquet(file_path, parallel=par)
-                .filter(pl.col("book") == "bookA")
-                .collect()
-            )
-        assert df.shape == (4, 3)
+    file_path = tmp_path / "books.parquet"
+    df.write_parquet(file_path, statistics=True)
+
+    parallel_options: list[ParallelStrategy] = [
+        "auto",
+        "columns",
+        "row_groups",
+        "none",
+    ]
+    for par in parallel_options:
+        df = (
+            pl.scan_parquet(file_path, parallel=par)
+            .filter(pl.col("book") == "bookA")
+            .collect()
+        )
+    assert df.shape == (4, 3)
 
 
 @pytest.mark.write_disk()
-def test_null_parquet() -> None:
+def test_null_parquet(tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     df = pl.DataFrame([pl.Series("foo", [], dtype=pl.Int8)])
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "null.parquet"
-        df.write_parquet(file_path)
-        out = pl.read_parquet(file_path)
+    file_path = tmp_path / "null.parquet"
+    df.write_parquet(file_path)
+    out = pl.read_parquet(file_path)
     assert_frame_equal(out, df)
 
 
 @pytest.mark.write_disk()
-def test_parquet_eq_stats() -> None:
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "stats.parquet"
-
-        df1 = pd.DataFrame({"a": [None, 1, None, 2, 3, 3, 4, 4, 5, 5]})
-        df1.to_parquet(file_path, engine="pyarrow")
-        df = pl.scan_parquet(file_path).filter(pl.col("a") == 4).collect()
-        assert df["a"].to_list() == [4.0, 4.0]
+def test_parquet_eq_stats(tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
 
-        assert (
-            pl.scan_parquet(file_path)
-            .filter(pl.col("a") == 2)
-            .select(pl.col("a").sum())
-        ).collect()[0, "a"] == 2.0
-
-        assert pl.scan_parquet(file_path).filter(pl.col("a") == 5).collect().shape == (
-            2,
-            1,
-        )
+    file_path = tmp_path / "stats.parquet"
+
+    df1 = pd.DataFrame({"a": [None, 1, None, 2, 3, 3, 4, 4, 5, 5]})
+    df1.to_parquet(file_path, engine="pyarrow")
+    df = pl.scan_parquet(file_path).filter(pl.col("a") == 4).collect()
+    assert df["a"].to_list() == [4.0, 4.0]
+
+    assert (
+        pl.scan_parquet(file_path).filter(pl.col("a") == 2).select(pl.col("a").sum())
+    ).collect()[0, "a"] == 2.0
+
+    assert pl.scan_parquet(file_path).filter(pl.col("a") == 5).collect().shape == (
+        2,
+        1,
+    )
 
 
 @pytest.mark.write_disk()
-def test_parquet_is_in_stats() -> None:
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "stats.parquet"
-
-        df1 = pd.DataFrame({"a": [None, 1, None, 2, 3, 3, 4, 4, 5, 5]})
-        df1.to_parquet(file_path, engine="pyarrow")
-        df = pl.scan_parquet(file_path).filter(pl.col("a").is_in([5])).collect()
-        assert df["a"].to_list() == [5.0, 5.0]
+def test_parquet_is_in_stats(tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
 
-        assert (
-            pl.scan_parquet(file_path)
-            .filter(pl.col("a").is_in([5]))
-            .select(pl.col("a").sum())
-        ).collect()[0, "a"] == 10.0
+    file_path = tmp_path / "stats.parquet"
 
-        assert (
-            pl.scan_parquet(file_path)
-            .filter(pl.col("a").is_in([1, 2, 3]))
-            .select(pl.col("a").sum())
-        ).collect()[0, "a"] == 9.0
+    df1 = pd.DataFrame({"a": [None, 1, None, 2, 3, 3, 4, 4, 5, 5]})
+    df1.to_parquet(file_path, engine="pyarrow")
+    df = pl.scan_parquet(file_path).filter(pl.col("a").is_in([5])).collect()
+    assert df["a"].to_list() == [5.0, 5.0]
 
-        assert (
-            pl.scan_parquet(file_path)
-            .filter(pl.col("a").is_in([1, 2, 3]))
-            .select(pl.col("a").sum())
-        ).collect()[0, "a"] == 9.0
+    assert (
+        pl.scan_parquet(file_path)
+        .filter(pl.col("a").is_in([5]))
+        .select(pl.col("a").sum())
+    ).collect()[0, "a"] == 10.0
 
-        assert (
-            pl.scan_parquet(file_path)
-            .filter(pl.col("a").is_in([5]))
-            .select(pl.col("a").sum())
-        ).collect()[0, "a"] == 10.0
-
-        assert pl.scan_parquet(file_path).filter(
-            pl.col("a").is_in([1, 2, 3, 4, 5])
-        ).collect().shape == (8, 1)
+    assert (
+        pl.scan_parquet(file_path)
+        .filter(pl.col("a").is_in([1, 2, 3]))
+        .select(pl.col("a").sum())
+    ).collect()[0, "a"] == 9.0
+
+    assert (
+        pl.scan_parquet(file_path)
+        .filter(pl.col("a").is_in([1, 2, 3]))
+        .select(pl.col("a").sum())
+    ).collect()[0, "a"] == 9.0
+
+    assert (
+        pl.scan_parquet(file_path)
+        .filter(pl.col("a").is_in([5]))
+        .select(pl.col("a").sum())
+    ).collect()[0, "a"] == 10.0
+
+    assert pl.scan_parquet(file_path).filter(
+        pl.col("a").is_in([1, 2, 3, 4, 5])
+    ).collect().shape == (8, 1)
 
 
 @pytest.mark.write_disk()
-def test_parquet_stats() -> None:
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "binary_stats.parquet"
+def test_parquet_stats(tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
 
-        df1 = pd.DataFrame({"a": [None, 1, None, 2, 3, 3, 4, 4, 5, 5]})
-        df1.to_parquet(file_path, engine="pyarrow")
-        df = (
-            pl.scan_parquet(file_path)
-            .filter(pl.col("a").is_not_null() & (pl.col("a") > 4))
-            .collect()
-        )
-        assert df["a"].to_list() == [5.0, 5.0]
+    file_path = tmp_path / "binary_stats.parquet"
+
+    df1 = pd.DataFrame({"a": [None, 1, None, 2, 3, 3, 4, 4, 5, 5]})
+    df1.to_parquet(file_path, engine="pyarrow")
+    df = (
+        pl.scan_parquet(file_path)
+        .filter(pl.col("a").is_not_null() & (pl.col("a") > 4))
+        .collect()
+    )
+    assert df["a"].to_list() == [5.0, 5.0]
+
+    assert (
+        pl.scan_parquet(file_path).filter(pl.col("a") > 4).select(pl.col("a").sum())
+    ).collect()[0, "a"] == 10.0
 
-        assert (
-            pl.scan_parquet(file_path).filter(pl.col("a") > 4).select(pl.col("a").sum())
-        ).collect()[0, "a"] == 10.0
-
-        assert (
-            pl.scan_parquet(file_path).filter(pl.col("a") < 4).select(pl.col("a").sum())
-        ).collect()[0, "a"] == 9.0
-
-        assert (
-            pl.scan_parquet(file_path).filter(pl.col("a") < 4).select(pl.col("a").sum())
-        ).collect()[0, "a"] == 9.0
-
-        assert (
-            pl.scan_parquet(file_path).filter(pl.col("a") > 4).select(pl.col("a").sum())
-        ).collect()[0, "a"] == 10.0
-        assert pl.scan_parquet(file_path).filter(
-            (pl.col("a") * 10) > 5.0
-        ).collect().shape == (8, 1)
+    assert (
+        pl.scan_parquet(file_path).filter(pl.col("a") < 4).select(pl.col("a").sum())
+    ).collect()[0, "a"] == 9.0
+
+    assert (
+        pl.scan_parquet(file_path).filter(pl.col("a") < 4).select(pl.col("a").sum())
+    ).collect()[0, "a"] == 9.0
+
+    assert (
+        pl.scan_parquet(file_path).filter(pl.col("a") > 4).select(pl.col("a").sum())
+    ).collect()[0, "a"] == 10.0
+    assert pl.scan_parquet(file_path).filter(
+        (pl.col("a") * 10) > 5.0
+    ).collect().shape == (8, 1)
 
 
 def test_row_count_schema(parquet_file_path: Path) -> None:
     assert (
         pl.scan_parquet(str(parquet_file_path), row_count_name="id")
         .select(["id", "b"])
         .collect()
     ).dtypes == [pl.UInt32, pl.Utf8]
 
 
 @pytest.mark.write_disk()
-def test_parquet_eq_statistics(monkeypatch: Any, capfd: Any) -> None:
+def test_parquet_eq_statistics(monkeypatch: Any, capfd: Any, tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     monkeypatch.setenv("POLARS_VERBOSE", "1")
 
     df = pl.DataFrame({"idx": pl.arange(100, 200, eager=True)}).with_columns(
         (pl.col("idx") // 25).alias("part")
     )
     df = pl.concat(df.partition_by("part", as_dict=False), rechunk=False)
     assert df.n_chunks("all") == [4, 4]
 
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "stats.parquet"
-        df.write_parquet(file_path, statistics=True, use_pyarrow=False)
-
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "stats.parquet"
-        df.write_parquet(file_path, statistics=True, use_pyarrow=False)
-
-        for pred in [
-            pl.col("idx") == 50,
-            pl.col("idx") == 150,
-            pl.col("idx") == 210,
-        ]:
-            result = pl.scan_parquet(file_path).filter(pred).collect()
-            assert_frame_equal(result, df.filter(pred))
+    file_path = tmp_path / "stats.parquet"
+    df.write_parquet(file_path, statistics=True, use_pyarrow=False)
+
+    file_path = tmp_path / "stats.parquet"
+    df.write_parquet(file_path, statistics=True, use_pyarrow=False)
+
+    for pred in [
+        pl.col("idx") == 50,
+        pl.col("idx") == 150,
+        pl.col("idx") == 210,
+    ]:
+        result = pl.scan_parquet(file_path).filter(pred).collect()
+        assert_frame_equal(result, df.filter(pred))
 
     captured = capfd.readouterr().err
     assert (
         "parquet file must be read, statistics not sufficient for predicate."
         in captured
     )
     assert (
         "parquet file can be skipped, the statistics were sufficient"
         " to apply the predicate." in captured
     )
 
 
 @pytest.mark.write_disk()
-def test_parquet_is_in_statistics(monkeypatch: Any, capfd: Any) -> None:
+def test_parquet_is_in_statistics(monkeypatch: Any, capfd: Any, tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     monkeypatch.setenv("POLARS_VERBOSE", "1")
 
     df = pl.DataFrame({"idx": pl.arange(0, 100, eager=True)}).with_columns(
         (pl.col("idx") // 25).alias("part")
     )
     df = pl.concat(df.partition_by("part", as_dict=False), rechunk=False)
     assert df.n_chunks("all") == [4, 4]
 
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "stats.parquet"
-        df.write_parquet(file_path, statistics=True, use_pyarrow=False)
-
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "stats.parquet"
-        df.write_parquet(file_path, statistics=True, use_pyarrow=False)
-
-        for pred in [
-            pl.col("idx").is_in([150, 200, 300]),
-            pl.col("idx").is_in([5, 250, 350]),
-        ]:
-            result = pl.scan_parquet(file_path).filter(pred).collect()
-            assert_frame_equal(result, df.filter(pred))
+    file_path = tmp_path / "stats.parquet"
+    df.write_parquet(file_path, statistics=True, use_pyarrow=False)
+
+    file_path = tmp_path / "stats.parquet"
+    df.write_parquet(file_path, statistics=True, use_pyarrow=False)
+
+    for pred in [
+        pl.col("idx").is_in([150, 200, 300]),
+        pl.col("idx").is_in([5, 250, 350]),
+    ]:
+        result = pl.scan_parquet(file_path).filter(pred).collect()
+        assert_frame_equal(result, df.filter(pred))
 
     captured = capfd.readouterr().err
     assert (
         "parquet file must be read, statistics not sufficient for predicate."
         in captured
     )
     assert (
         "parquet file can be skipped, the statistics were sufficient"
         " to apply the predicate." in captured
     )
 
 
 @pytest.mark.write_disk()
-def test_parquet_statistics(monkeypatch: Any, capfd: Any) -> None:
+def test_parquet_statistics(monkeypatch: Any, capfd: Any, tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     monkeypatch.setenv("POLARS_VERBOSE", "1")
 
     df = pl.DataFrame({"idx": pl.arange(0, 100, eager=True)}).with_columns(
         (pl.col("idx") // 25).alias("part")
     )
     df = pl.concat(df.partition_by("part", as_dict=False), rechunk=False)
     assert df.n_chunks("all") == [4, 4]
 
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "stats.parquet"
-        df.write_parquet(file_path, statistics=True, use_pyarrow=False)
-
-        for pred in [
-            pl.col("idx") < 50,
-            pl.col("idx") > 50,
-            pl.col("idx").null_count() != 0,
-            pl.col("idx").null_count() == 0,
-            pl.col("idx").min() == pl.col("part").null_count(),
-        ]:
-            result = pl.scan_parquet(file_path).filter(pred).collect()
-            assert_frame_equal(result, df.filter(pred))
+    file_path = tmp_path / "stats.parquet"
+    df.write_parquet(file_path, statistics=True, use_pyarrow=False)
+
+    for pred in [
+        pl.col("idx") < 50,
+        pl.col("idx") > 50,
+        pl.col("idx").null_count() != 0,
+        pl.col("idx").null_count() == 0,
+        pl.col("idx").min() == pl.col("part").null_count(),
+    ]:
+        result = pl.scan_parquet(file_path).filter(pred).collect()
+        assert_frame_equal(result, df.filter(pred))
 
     captured = capfd.readouterr().err
     assert (
         "parquet file must be read, statistics not sufficient for predicate."
         in captured
     )
     assert (
         "parquet file can be skipped, the statistics were sufficient"
         " to apply the predicate." in captured
     )
 
 
 @pytest.mark.write_disk()
-def test_streaming_categorical() -> None:
+def test_streaming_categorical(tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     df = pl.DataFrame(
         [
             pl.Series("name", ["Bob", "Alice", "Bob"], pl.Categorical),
             pl.Series("amount", [100, 200, 300]),
         ]
     )
 
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "categorical.parquet"
-        df.write_parquet(file_path)
-
-        with pl.StringCache():
-            result = (
-                pl.scan_parquet(file_path)
-                .groupby("name")
-                .agg(pl.col("amount").sum())
-                .collect()
-                .sort("name")
-            )
-            expected = pl.DataFrame(
-                {"name": ["Bob", "Alice"], "amount": [400, 200]},
-                schema_overrides={"name": pl.Categorical},
-            )
-            assert_frame_equal(result, expected)
+    file_path = tmp_path / "categorical.parquet"
+    df.write_parquet(file_path)
+
+    with pl.StringCache():
+        result = (
+            pl.scan_parquet(file_path)
+            .groupby("name")
+            .agg(pl.col("amount").sum())
+            .collect()
+            .sort("name")
+        )
+        expected = pl.DataFrame(
+            {"name": ["Bob", "Alice"], "amount": [400, 200]},
+            schema_overrides={"name": pl.Categorical},
+        )
+        assert_frame_equal(result, expected)
 
 
 @pytest.mark.write_disk()
-def test_parquet_struct_categorical() -> None:
+def test_parquet_struct_categorical(tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     df = pl.DataFrame(
         [
             pl.Series("a", ["bob"], pl.Categorical),
             pl.Series("b", ["foo"], pl.Categorical),
         ]
     )
 
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "categorical.parquet"
-        df.write_parquet(file_path)
-
-        with pl.StringCache():
-            out = pl.read_parquet(file_path).select(pl.col("b").value_counts())
-        assert out.to_dict(False) == {"b": [{"b": "foo", "counts": 1}]}
+    file_path = tmp_path / "categorical.parquet"
+    df.write_parquet(file_path)
+
+    with pl.StringCache():
+        out = pl.read_parquet(file_path).select(pl.col("b").value_counts())
+    assert out.to_dict(False) == {"b": [{"b": "foo", "counts": 1}]}
 
 
 def test_glob_n_rows(io_files_path: Path) -> None:
     file_path = io_files_path / "foods*.parquet"
     df = pl.scan_parquet(file_path, n_rows=40).collect()
 
     # 27 rows from foods1.parquet and 13 from foods2.parquet
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/test_other.py` & `polars_lts_cpu-0.18.1/tests/unit/io/test_other.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/test_parquet.py` & `polars_lts_cpu-0.18.1/tests/unit/io/test_parquet.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,28 +1,29 @@
 from __future__ import annotations
 
 import io
 import typing
-from pathlib import Path
 from typing import TYPE_CHECKING
 
 import numpy as np
 import pandas as pd
 import pyarrow as pa
 import pyarrow.dataset as ds
 import pyarrow.parquet as pq
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal, assert_frame_equal_local_categoricals
-from polars.testing._tempdir import TemporaryDirectory
 
 if TYPE_CHECKING:
+    from pathlib import Path
+
     from polars.type_aliases import ParquetCompression
 
+
 COMPRESSIONS = [
     "lz4",
     "uncompressed",
     "snappy",
     "gzip",
     # "lzo",  # LZO compression currently not supported by Arrow backend
     "brotli",
@@ -65,40 +66,44 @@
     # Invalid parquet file as writing failed.
     with pytest.raises(pl.ArrowError):
         _ = pl.read_parquet(buf)
 
 
 @pytest.mark.write_disk()
 @pytest.mark.parametrize("compression", COMPRESSIONS)
-def test_to_from_file(df: pl.DataFrame, compression: ParquetCompression) -> None:
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "small.avro"
-        df.write_parquet(file_path, compression=compression)
-        read_df = pl.read_parquet(file_path)
-        assert_frame_equal_local_categoricals(df, read_df)
+def test_to_from_file(
+    df: pl.DataFrame, compression: ParquetCompression, tmp_path: Path
+) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
+    file_path = tmp_path / "small.avro"
+    df.write_parquet(file_path, compression=compression)
+    read_df = pl.read_parquet(file_path)
+    assert_frame_equal_local_categoricals(df, read_df)
 
 
 @pytest.mark.write_disk()
-def test_to_from_file_lzo(df: pl.DataFrame) -> None:
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "small.avro"
+def test_to_from_file_lzo(df: pl.DataFrame, tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
 
-        # Writing lzo compressed parquet files is not supported for now.
-        with pytest.raises(pl.ArrowError):
-            df.write_parquet(file_path, compression="lzo", use_pyarrow=False)
-        # Invalid parquet file as writing failed.
-        with pytest.raises(pl.ArrowError):
-            _ = pl.read_parquet(file_path)
+    file_path = tmp_path / "small.avro"
 
-        # Writing lzo compressed parquet files is not supported for now.
-        with pytest.raises(OSError):
-            df.write_parquet(file_path, compression="lzo", use_pyarrow=True)
-        # Invalid parquet file as writing failed.
-        with pytest.raises(FileNotFoundError):
-            _ = pl.read_parquet(file_path)
+    # Writing lzo compressed parquet files is not supported for now.
+    with pytest.raises(pl.ArrowError):
+        df.write_parquet(file_path, compression="lzo", use_pyarrow=False)
+    # Invalid parquet file as writing failed.
+    with pytest.raises(pl.ArrowError):
+        _ = pl.read_parquet(file_path)
+
+    # Writing lzo compressed parquet files is not supported for now.
+    with pytest.raises(OSError):
+        df.write_parquet(file_path, compression="lzo", use_pyarrow=True)
+    # Invalid parquet file as writing failed.
+    with pytest.raises(FileNotFoundError):
+        _ = pl.read_parquet(file_path)
 
 
 def test_select_columns() -> None:
     df = pl.DataFrame({"a": [1, 2, 3], "b": [True, False, True], "c": ["a", "b", "c"]})
     expected = pl.DataFrame({"b": [True, False, True], "c": ["a", "b", "c"]})
 
     f = io.BytesIO()
@@ -157,35 +162,33 @@
     read = pl.read_parquet(f, use_pyarrow=True)
     assert read.columns == ["a"]
     assert isinstance(read.dtypes[0], pl.datatypes.List)
     assert isinstance(read.dtypes[0].inner, pl.datatypes.Struct)
 
 
 @pytest.mark.write_disk()
-def test_glob_parquet(df: pl.DataFrame) -> None:
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "small.parquet"
-        df.write_parquet(file_path)
-
-        path_glob = Path(temp_dir) / "small*.parquet"
-        assert pl.read_parquet(path_glob).shape == (3, 16)
-        assert pl.scan_parquet(path_glob).collect().shape == (3, 16)
+def test_glob_parquet(df: pl.DataFrame, tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+    file_path = tmp_path / "small.parquet"
+    df.write_parquet(file_path)
+
+    path_glob = tmp_path / "small*.parquet"
+    assert pl.read_parquet(path_glob).shape == (3, 16)
+    assert pl.scan_parquet(path_glob).collect().shape == (3, 16)
 
 
 @pytest.mark.write_disk()
-def test_streaming_parquet_glob_5900(df: pl.DataFrame) -> None:
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "small.parquet"
-        df.write_parquet(file_path)
-
-        path_glob = Path(temp_dir) / "small*.parquet"
-        result = (
-            pl.scan_parquet(path_glob).select(pl.all().first()).collect(streaming=True)
-        )
-        assert result.shape == (1, 16)
+def test_streaming_parquet_glob_5900(df: pl.DataFrame, tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+    file_path = tmp_path / "small.parquet"
+    df.write_parquet(file_path)
+
+    path_glob = tmp_path / "small*.parquet"
+    result = pl.scan_parquet(path_glob).select(pl.all().first()).collect(streaming=True)
+    assert result.shape == (1, 16)
 
 
 def test_chunked_round_trip() -> None:
     df1 = pl.DataFrame(
         {
             "a": [1] * 2,
             "l": [[1] for j in range(0, 2)],
@@ -203,23 +206,24 @@
     f = io.BytesIO()
     df.write_parquet(f)
     f.seek(0)
     assert_frame_equal(pl.read_parquet(f), df)
 
 
 @pytest.mark.write_disk()
-def test_lazy_self_join_file_cache_prop_3979(df: pl.DataFrame) -> None:
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "small.parquet"
-        df.write_parquet(file_path)
-
-        a = pl.scan_parquet(file_path)
-        b = pl.DataFrame({"a": [1]}).lazy()
-        assert a.join(b, how="cross").collect().shape == (3, 17)
-        assert b.join(a, how="cross").collect().shape == (3, 17)
+def test_lazy_self_join_file_cache_prop_3979(df: pl.DataFrame, tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
+    file_path = tmp_path / "small.parquet"
+    df.write_parquet(file_path)
+
+    a = pl.scan_parquet(file_path)
+    b = pl.DataFrame({"a": [1]}).lazy()
+    assert a.join(b, how="cross").collect().shape == (3, 17)
+    assert b.join(a, how="cross").collect().shape == (3, 17)
 
 
 def test_recursive_logical_type() -> None:
     df = pl.DataFrame({"str": ["A", "B", "A", "B", "C"], "group": [1, 1, 2, 1, 2]})
     df = df.with_columns(pl.col("str").cast(pl.Categorical))
 
     df_groups = df.groupby("group").agg([pl.col("str").alias("cat_list")])
@@ -352,81 +356,83 @@
         pq.write_table(table, f, compression="snappy")
         f.seek(0)
         read = pl.read_parquet(f)
         assert_frame_equal(read, df)
 
 
 @pytest.mark.write_disk()
-def test_sink_parquet(io_files_path: Path) -> None:
+def test_sink_parquet(io_files_path: Path, tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     file = io_files_path / "small.parquet"
 
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "sink.parquet"
+    file_path = tmp_path / "sink.parquet"
 
-        df_scanned = pl.scan_parquet(file)
-        df_scanned.sink_parquet(file_path)
+    df_scanned = pl.scan_parquet(file)
+    df_scanned.sink_parquet(file_path)
 
-        with pl.StringCache():
-            result = pl.read_parquet(file_path)
-            df_read = pl.read_parquet(file)
-            assert_frame_equal(result, df_read)
+    with pl.StringCache():
+        result = pl.read_parquet(file_path)
+        df_read = pl.read_parquet(file)
+        assert_frame_equal(result, df_read)
 
 
 @pytest.mark.write_disk()
-def test_sink_ipc(io_files_path: Path) -> None:
+def test_sink_ipc(io_files_path: Path, tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     file = io_files_path / "small.parquet"
 
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "sink.ipc"
+    file_path = tmp_path / "sink.ipc"
 
-        df_scanned = pl.scan_parquet(file)
-        df_scanned.sink_ipc(file_path)
+    df_scanned = pl.scan_parquet(file)
+    df_scanned.sink_ipc(file_path)
 
-        with pl.StringCache():
-            result = pl.read_ipc(file_path)
-            df_read = pl.read_parquet(file)
-            assert_frame_equal(result, df_read)
+    with pl.StringCache():
+        result = pl.read_ipc(file_path)
+        df_read = pl.read_parquet(file)
+        assert_frame_equal(result, df_read)
 
 
 @pytest.mark.write_disk()
-def test_fetch_union() -> None:
+def test_fetch_union(tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     df1 = pl.DataFrame({"a": [0, 1, 2], "b": [1, 2, 3]})
     df2 = pl.DataFrame({"a": [3, 4, 5], "b": [4, 5, 6]})
 
-    with TemporaryDirectory() as temp_dir:
-        file_path_1 = Path(temp_dir) / "df_fetch_1.parquet"
-        file_path_2 = Path(temp_dir) / "df_fetch_2.parquet"
-        file_path_glob = Path(temp_dir) / "df_fetch_*.parquet"
+    file_path_1 = tmp_path / "df_fetch_1.parquet"
+    file_path_2 = tmp_path / "df_fetch_2.parquet"
+    file_path_glob = tmp_path / "df_fetch_*.parquet"
 
-        df1.write_parquet(file_path_1)
-        df2.write_parquet(file_path_2)
+    df1.write_parquet(file_path_1)
+    df2.write_parquet(file_path_2)
 
-        result_one = pl.scan_parquet(file_path_1).fetch(1)
-        result_glob = pl.scan_parquet(file_path_glob).fetch(1)
+    result_one = pl.scan_parquet(file_path_1).fetch(1)
+    result_glob = pl.scan_parquet(file_path_glob).fetch(1)
 
     expected = pl.DataFrame({"a": [0], "b": [1]})
     assert_frame_equal(result_one, expected)
 
     expected = pl.DataFrame({"a": [0, 3], "b": [1, 4]})
     assert_frame_equal(result_glob, expected)
 
 
 @pytest.mark.slow()
 @typing.no_type_check
-def test_struct_pyarrow_dataset_5796() -> None:
+def test_struct_pyarrow_dataset_5796(tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+
     num_rows = 2**17 + 1
 
-    df = pl.from_records(
-        [dict(id=i, nested=dict(a=i)) for i in range(num_rows)]  # noqa: C408
-    )
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "out.parquet"
-        df.write_parquet(file_path, use_pyarrow=True)
-        tbl = ds.dataset(file_path).to_table()
-        result = pl.from_arrow(tbl)
+    df = pl.from_records([{"id": i, "nested": {"a": i}} for i in range(num_rows)])
+    file_path = tmp_path / "out.parquet"
+    df.write_parquet(file_path, use_pyarrow=True)
+    tbl = ds.dataset(file_path).to_table()
+    result = pl.from_arrow(tbl)
 
     assert_frame_equal(result, df)
 
 
 @pytest.mark.slow()
 @pytest.mark.parametrize("case", [1048576, 1048577])
 def test_parquet_chunks_545(case: int) -> None:
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/test_pickle.py` & `polars_lts_cpu-0.18.1/tests/unit/io/test_pickle.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/io/test_pyarrow_dataset.py` & `polars_lts_cpu-0.18.1/tests/unit/io/test_pyarrow_dataset.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,120 +1,128 @@
 from __future__ import annotations
 
 import typing
 from datetime import date, datetime, time
-from pathlib import Path
+from typing import TYPE_CHECKING
 
 import pyarrow.dataset as ds
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
-from polars.testing._tempdir import TemporaryDirectory
+
+if TYPE_CHECKING:
+    from pathlib import Path
 
 
 @typing.no_type_check
 def helper_dataset_test(file_path: Path, query) -> None:
     dset = ds.dataset(file_path, format="ipc")
 
     expected = query(pl.scan_ipc(file_path))
     out = query(pl.scan_pyarrow_dataset(dset))
     assert_frame_equal(out, expected)
 
 
 @pytest.mark.write_disk()
-def test_dataset(df: pl.DataFrame) -> None:
-    with TemporaryDirectory() as temp_dir:
-        file_path = Path(temp_dir) / "small.ipc"
-        df.write_ipc(file_path)
-
-        helper_dataset_test(
-            file_path,
-            lambda lf: lf.filter("bools").select(["bools", "floats", "date"]).collect(),
-        )
-        helper_dataset_test(
-            file_path,
-            lambda lf: lf.filter(~pl.col("bools"))
-            .select(["bools", "floats", "date"])
-            .collect(),
-        )
-        helper_dataset_test(
-            file_path,
-            lambda lf: lf.filter(pl.col("int_nulls").is_null())
-            .select(["bools", "floats", "date"])
-            .collect(),
-        )
-        helper_dataset_test(
-            file_path,
-            lambda lf: lf.filter(pl.col("int_nulls").is_not_null())
-            .select(["bools", "floats", "date"])
-            .collect(),
-        )
-        helper_dataset_test(
-            file_path,
-            lambda lf: lf.filter(pl.col("int_nulls").is_not_null() == pl.col("bools"))
-            .select(["bools", "floats", "date"])
-            .collect(),
-        )
-        # this equality on a column with nulls fails as pyarrow has different
-        # handling kleene logic. We leave it for now and document it in the function.
-        helper_dataset_test(
-            file_path,
-            lambda lf: lf.filter(pl.col("int") == 10)
-            .select(["bools", "floats", "int_nulls"])
-            .collect(),
-        )
-        helper_dataset_test(
-            file_path,
-            lambda lf: lf.filter(pl.col("int") != 10)
-            .select(["bools", "floats", "int_nulls"])
-            .collect(),
-        )
-        # this predicate is not supported by pyarrow
-        # check if we still do it on our side
-        helper_dataset_test(
-            file_path,
-            lambda lf: lf.filter(pl.col("floats").sum().over("date") == 10)
-            .select(["bools", "floats", "date"])
-            .collect(),
-        )
-
-        # temporal types
-        helper_dataset_test(
-            file_path,
-            lambda lf: lf.filter(pl.col("date") < date(1972, 1, 1))
-            .select(["bools", "floats", "date"])
-            .collect(),
-        )
-        helper_dataset_test(
-            file_path,
-            lambda lf: lf.filter(pl.col("datetime") > datetime(1970, 1, 1, second=13))
-            .select(["bools", "floats", "date"])
-            .collect(),
-        )
-        # not yet supported in pyarrow
-        helper_dataset_test(
-            file_path,
-            lambda lf: lf.filter(pl.col("time") >= time(microsecond=100))
-            .select(["bools", "time", "date"])
-            .collect(),
-        )
-
-        # pushdown is_in
-        helper_dataset_test(
-            file_path,
-            lambda lf: lf.filter(pl.col("int").is_in([1, 3, 20]))
-            .select(["bools", "floats", "date"])
-            .collect(),
-        )
-        helper_dataset_test(
-            file_path,
-            lambda lf: lf.filter(pl.col("int").is_in(list(range(120))))
-            .select(["bools", "floats", "date"])
-            .collect(),
-        )
-        helper_dataset_test(
-            file_path,
-            lambda lf: lf.filter(pl.col("cat").is_in([]))
-            .select(["bools", "floats", "date"])
-            .collect(),
-        )
+def test_dataset(df: pl.DataFrame, tmp_path: Path) -> None:
+    file_path = tmp_path / "small.ipc"
+    df.write_ipc(file_path)
+
+    helper_dataset_test(
+        file_path,
+        lambda lf: lf.filter("bools").select(["bools", "floats", "date"]).collect(),
+    )
+    helper_dataset_test(
+        file_path,
+        lambda lf: lf.filter(~pl.col("bools"))
+        .select(["bools", "floats", "date"])
+        .collect(),
+    )
+    helper_dataset_test(
+        file_path,
+        lambda lf: lf.filter(pl.col("int_nulls").is_null())
+        .select(["bools", "floats", "date"])
+        .collect(),
+    )
+    helper_dataset_test(
+        file_path,
+        lambda lf: lf.filter(pl.col("int_nulls").is_not_null())
+        .select(["bools", "floats", "date"])
+        .collect(),
+    )
+    helper_dataset_test(
+        file_path,
+        lambda lf: lf.filter(pl.col("int_nulls").is_not_null() == pl.col("bools"))
+        .select(["bools", "floats", "date"])
+        .collect(),
+    )
+    # this equality on a column with nulls fails as pyarrow has different
+    # handling kleene logic. We leave it for now and document it in the function.
+    helper_dataset_test(
+        file_path,
+        lambda lf: lf.filter(pl.col("int") == 10)
+        .select(["bools", "floats", "int_nulls"])
+        .collect(),
+    )
+    helper_dataset_test(
+        file_path,
+        lambda lf: lf.filter(pl.col("int") != 10)
+        .select(["bools", "floats", "int_nulls"])
+        .collect(),
+    )
+    # this predicate is not supported by pyarrow
+    # check if we still do it on our side
+    helper_dataset_test(
+        file_path,
+        lambda lf: lf.filter(pl.col("floats").sum().over("date") == 10)
+        .select(["bools", "floats", "date"])
+        .collect(),
+    )
+
+    # temporal types
+    helper_dataset_test(
+        file_path,
+        lambda lf: lf.filter(pl.col("date") < date(1972, 1, 1))
+        .select(["bools", "floats", "date"])
+        .collect(),
+    )
+    helper_dataset_test(
+        file_path,
+        lambda lf: lf.filter(pl.col("datetime") > datetime(1970, 1, 1, second=13))
+        .select(["bools", "floats", "date"])
+        .collect(),
+    )
+    # not yet supported in pyarrow
+    helper_dataset_test(
+        file_path,
+        lambda lf: lf.filter(pl.col("time") >= time(microsecond=100))
+        .select(["bools", "time", "date"])
+        .collect(),
+    )
+
+    # pushdown is_in
+    helper_dataset_test(
+        file_path,
+        lambda lf: lf.filter(pl.col("int").is_in([1, 3, 20]))
+        .select(["bools", "floats", "date"])
+        .collect(),
+    )
+    helper_dataset_test(
+        file_path,
+        lambda lf: lf.filter(pl.col("int").is_in(list(range(120))))
+        .select(["bools", "floats", "date"])
+        .collect(),
+    )
+    helper_dataset_test(
+        file_path,
+        lambda lf: lf.filter(pl.col("cat").is_in([]))
+        .select(["bools", "floats", "date"])
+        .collect(),
+    )
+    # direct filter
+    helper_dataset_test(
+        file_path,
+        lambda lf: lf.filter(pl.Series([True, False, True]))
+        .select(["bools", "floats", "date"])
+        .collect(),
+    )
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/namespaces/test_binary.py` & `polars_lts_cpu-0.18.1/tests/unit/namespaces/test_binary.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/namespaces/test_categorical.py` & `polars_lts_cpu-0.18.1/tests/unit/namespaces/test_categorical.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/namespaces/test_datetime.py` & `polars_lts_cpu-0.18.1/tests/unit/namespaces/test_datetime.py`

 * *Files 1% similar despite different names*

```diff
@@ -536,14 +536,26 @@
 def test_negative_offset_by_err_msg_8464() -> None:
     with pytest.raises(
         ComputeError, match=r"cannot advance '2022-03-30 00:00:00' by -1 month\(s\)"
     ):
         pl.Series([datetime(2022, 3, 30)]).dt.offset_by("-1mo")
 
 
+def test_offset_by_truncate_sorted_flag() -> None:
+    s = pl.Series([datetime(2001, 1, 1), datetime(2001, 1, 2)])
+    s = s.set_sorted()
+
+    assert s.flags["SORTED_ASC"]
+    s1 = s.dt.offset_by("1d")
+    assert s1.to_list() == [datetime(2001, 1, 2), datetime(2001, 1, 3)]
+    assert s1.flags["SORTED_ASC"]
+    s2 = s1.dt.truncate("1mo")
+    assert s2.flags["SORTED_ASC"]
+
+
 @pytest.mark.parametrize(
     ("duration", "input_date", "expected"),
     [
         ("1mo_saturating", date(2018, 1, 31), date(2018, 2, 28)),
         ("1y_saturating", date(2024, 2, 29), date(2025, 2, 28)),
         ("1y1mo_saturating", date(2024, 1, 30), date(2025, 2, 28)),
     ],
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/namespaces/test_list.py` & `polars_lts_cpu-0.18.1/tests/unit/namespaces/test_list.py`

 * *Files 1% similar despite different names*

```diff
@@ -444,7 +444,13 @@
     ).to_dict(False) == {"a": [None]}
 
 
 def test_list_tail_underflow_9087() -> None:
     assert pl.Series([["a", "b", "c"]]).list.tail(pl.lit(1, pl.UInt32)).to_list() == [
         ["c"]
     ]
+
+
+def test_list_count_match_boolean_nulls_9141() -> None:
+    a = pl.DataFrame({"a": [[True, None, False]]})
+
+    assert a.select(pl.col("a").list.count_match(True))["a"].to_list() == [1]
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/namespaces/test_meta.py` & `polars_lts_cpu-0.18.1/tests/unit/namespaces/test_meta.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/namespaces/test_string.py` & `polars_lts_cpu-0.18.1/tests/unit/namespaces/test_string.py`

 * *Files 0% similar despite different names*

```diff
@@ -62,17 +62,17 @@
 
     assert_series_equal(hex_encoded.str.decode("hex"), expected)
     assert_series_equal(base64_encoded.str.decode("base64"), expected)
 
 
 def test_str_decode_exception() -> None:
     s = pl.Series(["not a valid", "626172", None])
-    with pytest.raises(Exception):
+    with pytest.raises(pl.ComputeError):
         s.str.decode(encoding="hex")
-    with pytest.raises(Exception):
+    with pytest.raises(pl.ComputeError):
         s.str.decode(encoding="base64")
     with pytest.raises(ValueError):
         s.str.decode("utf8")  # type: ignore[arg-type]
 
 
 def test_hex_decode_return_dtype() -> None:
     data = {"a": ["68656c6c6f", "776f726c64"]}
@@ -262,14 +262,19 @@
     assert_series_equal(s.str.json_extract(None), expected)
     assert_series_equal(s.str.json_extract(dtype2), expected)
 
     expected = pl.Series([{"a": 1}, None, {"a": 2}])
     dtype2 = pl.Struct([pl.Field("a", pl.Int64)])
     assert_series_equal(s.str.json_extract(dtype2), expected)
 
+    s = pl.Series([], dtype=pl.Utf8)
+    expected = pl.Series([], dtype=pl.List(pl.Int64))
+    dtype = pl.List(pl.Int64)
+    assert_series_equal(s.str.json_extract(dtype), expected)
+
 
 def test_json_extract_lazy_expr() -> None:
     dtype = pl.Struct([pl.Field("a", pl.Int64), pl.Field("b", pl.Boolean)])
     ldf = (
         pl.DataFrame({"json": ['{"a": 1, "b": true}', None, '{"a": 2, "b": false}']})
         .lazy()
         .select(pl.col("json").str.json_extract(dtype))
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/namespaces/test_strptime.py` & `polars_lts_cpu-0.18.1/tests/unit/namespaces/test_strptime.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,22 +1,23 @@
 """
 Module for testing ``.str.strptime`` of the string namespace.
 
 This method gets its own module due to its complexity.
 """
 from __future__ import annotations
 
+import contextlib
 import sys
 from datetime import date, datetime, time, timedelta, timezone
 from typing import TYPE_CHECKING
 
 import pytest
 
 import polars as pl
-from polars.exceptions import ArrowError, ComputeError
+from polars.exceptions import ArrowError, ComputeError, TimeZoneAwareConstructorWarning
 from polars.testing import assert_series_equal
 
 if sys.version_info >= (3, 9):
     from zoneinfo import ZoneInfo
 else:
     # Import from submodule due to typing issue with backports.zoneinfo package:
     # https://github.com/pganssle/zoneinfo/issues/125
@@ -126,18 +127,77 @@
     result = s.str.to_date(format, strict=False, exact=False)
     expected = pl.Series(
         "a",
         [date(2022, 1, 16), date(2022, 1, 17), date(2022, 1, 18), date(2022, 1, 19)],
     )
     assert_series_equal(result, expected)
 
-    with pytest.raises(Exception):
+    with pytest.raises(pl.ComputeError):
         s.str.to_date(format, strict=True, exact=True)
 
 
+@pytest.mark.parametrize(
+    ("offset", "time_zone", "tzinfo", "format"),
+    [
+        ("+01:00", "UTC", timezone(timedelta(hours=1)), "%Y-%m-%dT%H:%M%z"),
+        ("", None, None, "%Y-%m-%dT%H:%M"),
+    ],
+)
+def test_to_datetime_non_exact_strptime(
+    offset: str, time_zone: str | None, tzinfo: timezone | None, format: str
+) -> None:
+    msg = "Series with UTC time zone"
+    context_manager: contextlib.AbstractContextManager[pytest.WarningsRecorder | None]
+    if offset:
+        context_manager = pytest.warns(TimeZoneAwareConstructorWarning, match=msg)
+    else:
+        context_manager = contextlib.nullcontext()
+
+    s = pl.Series(
+        "a",
+        [
+            f"2022-01-16T00:00{offset}",
+            f"2022-01-17T00:00{offset}",
+            f"foo2022-01-18T00:00{offset}",
+            f"b2022-01-19T00:00{offset}ar",
+        ],
+    )
+
+    result = s.str.to_datetime(format, strict=False, exact=True)
+    with context_manager:
+        expected = pl.Series(
+            "a",
+            [
+                datetime(2022, 1, 16, tzinfo=tzinfo),
+                datetime(2022, 1, 17, tzinfo=tzinfo),
+                None,
+                None,
+            ],
+        )
+    assert_series_equal(result, expected)
+    assert result.dtype == pl.Datetime("us", time_zone)
+
+    result = s.str.to_datetime(format, strict=False, exact=False)
+    with context_manager:
+        expected = pl.Series(
+            "a",
+            [
+                datetime(2022, 1, 16, tzinfo=tzinfo),
+                datetime(2022, 1, 17, tzinfo=tzinfo),
+                datetime(2022, 1, 18, tzinfo=tzinfo),
+                datetime(2022, 1, 19, tzinfo=tzinfo),
+            ],
+        )
+    assert_series_equal(result, expected)
+    assert result.dtype == pl.Datetime("us", time_zone)
+
+    with pytest.raises(pl.ComputeError):
+        s.str.to_datetime(format, strict=True, exact=True)
+
+
 def test_to_datetime_dates_datetimes() -> None:
     s = pl.Series("date", ["2021-04-22", "2022-01-04 00:00:00"])
     assert s.str.to_datetime().to_list() == [
         datetime(2021, 4, 22, 0, 0),
         datetime(2022, 1, 4, 0, 0),
     ]
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/namespaces/test_struct.py` & `polars_lts_cpu-0.18.1/tests/unit/namespaces/test_struct.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_aggregations.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_aggregations.py`

 * *Files 3% similar despite different names*

```diff
@@ -254,7 +254,14 @@
 
     # but not during a window function as the groups cannot be mapped back
     with pytest.raises(
         pl.InvalidOperationError,
         match=r"'implode' followed by an aggregation is not allowed",
     ):
         df.lazy().select(pl.col("type").implode().list.head(1).over("type")).collect()
+
+
+def test_mapped_literal_to_literal_9217() -> None:
+    df = pl.DataFrame({"unique_id": ["a", "b"]})
+    assert df.groupby(True).agg(
+        pl.struct(pl.lit("unique_id").alias("unique_id"))
+    ).to_dict(False) == {"literal": [True], "unique_id": [{"unique_id": "unique_id"}]}
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_apply.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_apply.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,17 @@
 from __future__ import annotations
 
 import json
+import typing
 from datetime import date, datetime, timedelta
 from functools import reduce
 from typing import Sequence, no_type_check
 
 import numpy as np
+import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
 
 
 def test_apply_none() -> None:
     df = pl.DataFrame(
@@ -334,7 +336,29 @@
     df = pl.DataFrame({"a": [""]})
     payload = datetime(2001, 1, 1)
     assert df.select(
         pl.col("a").apply(lambda _: payload, return_dtype=pl.Datetime),
     )[
         "a"
     ].to_list() == [payload]
+
+
+def test_err_df_apply_return_type() -> None:
+    df = pl.DataFrame({"a": [[1, 2], [2, 3]], "b": [[4, 5], [6, 7]]})
+
+    @typing.no_type_check
+    def cmb(row):
+        res = [x + y for x, y in zip(row[0], row[1])]
+        return [res]
+
+    with pytest.raises(pl.ComputeError, match="expected tuple, got list"):
+        df.apply(cmb)
+
+
+def test_apply_shifted_chunks() -> None:
+    df = pl.DataFrame(pl.Series("texts", ["test", "test123", "tests"]))
+    assert df.select(
+        pl.col("texts"), pl.col("texts").shift(1).alias("texts_shifted")
+    ).apply(lambda x: x).to_dict(False) == {
+        "column_0": ["test", "test123", "tests"],
+        "column_1": [None, "test", "test123"],
+    }
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_arithmetic.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_arithmetic.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_comparison.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_comparison.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_drop.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_drop.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_explode.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_explode.py`

 * *Files 1% similar despite different names*

```diff
@@ -298,7 +298,18 @@
     assert out["cats"].to_list() == ["Value1", "Value2", "Value1"]
 
 
 def test_explode_inner_null() -> None:
     expected = pl.DataFrame({"A": [None, None]}, schema={"A": pl.Null})
     out = pl.DataFrame({"A": [[], []]}, schema={"A": pl.List(pl.Null)}).explode("A")
     assert_frame_equal(out, expected)
+
+
+def test_explode_array() -> None:
+    out = pl.DataFrame(
+        {"a": [[1, 2], [2, 3]], "b": [1, 2]},
+        schema_overrides={"a": pl.Array(2, inner=pl.Int64)},
+    ).explode("a")
+
+    expected = pl.DataFrame({"a": [1, 2, 2, 3], "b": [1, 1, 2, 2]})
+
+    assert_frame_equal(out, expected)
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_filter.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_filter.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_folds.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_folds.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_groupby.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_groupby.py`

 * *Files 2% similar despite different names*

```diff
@@ -128,14 +128,21 @@
     assert df.groupby("a").agg(["b", "c"]).columns == expected
     # Multiple aggregations as positional arguments
     assert df.groupby("a").agg("b", "c").columns == expected
     # Multiple aggregations as keyword arguments
     assert df.groupby("a").agg(q="b", r="c").columns == ["a", "q", "r"]
 
 
+def test_groupby_empty() -> None:
+    df = pl.DataFrame({"a": [1, 1, 2]})
+    result = df.groupby("a").agg()
+    expected = pl.DataFrame({"a": [1, 2]})
+    assert_frame_equal(result, expected, check_row_order=False)
+
+
 def test_groupby_iteration() -> None:
     df = pl.DataFrame(
         {
             "foo": ["a", "b", "a", "b", "b", "c"],
             "bar": [1, 2, 3, 4, 5, 6],
             "baz": [6, 5, 4, 3, 2, 1],
         }
@@ -359,32 +366,39 @@
         (timedelta(seconds=10), "100s"),
     ],
 )
 @pytest.mark.parametrize("time_zone", [None, "Asia/Kathmandu"])
 def test_groupby_dynamic_overlapping_groups_flat_apply_multiple_5038(
     every: str | timedelta, period: str | timedelta, time_zone: str | None
 ) -> None:
-    assert (
-        pl.DataFrame(
-            {
-                "a": [
-                    datetime(2021, 1, 1) + timedelta(seconds=2**i) for i in range(10)
-                ],
-                "b": [float(i) for i in range(10)],
-            }
+    res = (
+        (
+            pl.DataFrame(
+                {
+                    "a": [
+                        datetime(2021, 1, 1) + timedelta(seconds=2**i)
+                        for i in range(10)
+                    ],
+                    "b": [float(i) for i in range(10)],
+                }
+            )
+            .with_columns(pl.col("a").dt.replace_time_zone(time_zone))
+            .lazy()
+            .set_sorted("a")
+            .groupby_dynamic("a", every=every, period=period)
+            .agg([pl.col("b").var().sqrt().alias("corr")])
         )
-        .with_columns(pl.col("a").dt.replace_time_zone(time_zone))
-        .lazy()
-        .set_sorted("a")
-        .groupby_dynamic("a", every=every, period=period)
-        .agg([pl.col("b").var().sqrt().alias("corr")])
-    ).collect().sum().to_dict(False) == pytest.approx(
-        {"a": [None], "corr": [6.988674024215477]}
+        .collect()
+        .sum()
+        .to_dict(False)
     )
 
+    assert res["corr"] == pytest.approx([6.988674024215477])
+    assert res["a"] == [None]
+
 
 def test_take_in_groupby() -> None:
     df = pl.DataFrame({"group": [1, 1, 1, 2, 2, 2], "values": [10, 200, 3, 40, 500, 6]})
     assert df.groupby("group").agg(
         pl.col("values").take(1) - pl.col("values").take(2)
     ).sort("group").to_dict(False) == {"group": [1, 2], "values": [197, 494]}
 
@@ -832,7 +846,17 @@
             ["18", "18"],
             ["34"],
             ["44"],
             ["12"],
             [None, None, None],
         ],
     }
+
+
+def test_groupby_agg_deprecation_aggs_keyword() -> None:
+    df = pl.DataFrame({"a": [1, 1, 2], "b": [3, 4, 5]})
+
+    with pytest.deprecated_call():
+        result = df.groupby("a", maintain_order=True).agg(aggs="b")
+
+    expected = pl.DataFrame({"a": [1, 2], "b": [[3, 4], [5]]})
+    assert_frame_equal(result, expected)
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_groupby_rolling.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_groupby_rolling.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_is_in.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_is_in.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_join.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_join.py`

 * *Files 3% similar despite different names*

```diff
@@ -565,7 +565,27 @@
     df1 = pl.DataFrame({"id": [1], "vals": [[]]}, schema=schema)
     df2 = pl.DataFrame({"id": [2, 3], "vals": [[], [4]]}, schema=schema)
     assert df1.join(df2, on="id", how="outer").to_dict(False) == {
         "id": [2, 3, 1],
         "vals": [None, None, []],
         "vals_right": [[], [4.0], None],
     }
+
+
+def test_join_validation() -> None:
+    a = pl.DataFrame({"a": [1, 1, 1, 2]})
+
+    b = pl.DataFrame({"a": [2]})
+
+    assert a.join(b, on="a", validate="m:m")["a"].to_list() == [2]
+    assert a.join(b, on="a", validate="m:1")["a"].to_list() == [2]
+    # swap the tables
+    assert b.join(a, on="a", validate="1:m")["a"].to_list() == [2]
+
+    with pytest.raises(pl.ComputeError):
+        a.join(b, on="a", validate="1:m")
+    with pytest.raises(pl.ComputeError):
+        a.join(b, on="a", validate="1:1")
+    with pytest.raises(pl.ComputeError):
+        b.join(a, on="a", validate="m:1")
+    with pytest.raises(pl.ComputeError):
+        b.join(a, on="a", validate="1:1")
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_join_asof.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_join_asof.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_melt.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_melt.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_pivot.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_pivot.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_rolling.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_rolling.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,14 +2,15 @@
 
 import sys
 import typing
 from datetime import date, datetime, timedelta
 from typing import TYPE_CHECKING
 
 import pytest
+from numpy import nan
 
 if sys.version_info >= (3, 9):
     from zoneinfo import ZoneInfo
 else:
     # Import from submodule due to typing issue with backports.zoneinfo package:
     # https://github.com/pganssle/zoneinfo/issues/125
     from backports.zoneinfo._zoneinfo import ZoneInfo
@@ -386,27 +387,27 @@
         0.6309038567106234,
         0.0,
     ]
 
 
 def test_rolling_var_numerical_stability_5197() -> None:
     s = pl.Series([*[1.2] * 4, *[3.3] * 7])
-    assert s.to_frame("a").with_columns(pl.col("a").rolling_var(5))[:, 0].to_list() == [
-        None,
-        None,
-        None,
-        None,
-        0.882,
-        1.3229999999999997,
-        1.3229999999999997,
-        0.8819999999999983,
-        0.0,
-        0.0,
-        0.0,
-    ]
+    res = s.to_frame("a").with_columns(pl.col("a").rolling_var(5))[:, 0].to_list()
+    assert res[4:] == pytest.approx(
+        [
+            0.882,
+            1.3229999999999997,
+            1.3229999999999997,
+            0.8819999999999983,
+            0.0,
+            0.0,
+            0.0,
+        ]
+    )
+    assert res[:4] == [None] * 4
 
 
 @typing.no_type_check
 def test_dynamic_groupby_timezone_awareness() -> None:
     df = pl.DataFrame(
         (
             pl.date_range(
@@ -634,18 +635,26 @@
         "sum_value": [3, 6, 5, 3],
     }
 
 
 def test_rolling_cov_corr() -> None:
     df = pl.DataFrame({"x": [3, 3, 3, 5, 8], "y": [3, 4, 4, 4, 8]})
 
-    assert (
-        str(
-            df.select(
-                [
-                    pl.rolling_cov("x", "y", window_size=3).alias("cov"),
-                    pl.rolling_corr("x", "y", window_size=3).alias("corr"),
-                ]
-            ).to_dict(False)
-        )
-        == "{'cov': [None, None, 0.0, 0.0, 5.333333333333336], 'corr': [None, None, nan, nan, 0.9176629354822473]}"
-    )
+    res = df.select(
+        [
+            pl.rolling_cov("x", "y", window_size=3).alias("cov"),
+            pl.rolling_corr("x", "y", window_size=3).alias("corr"),
+        ]
+    ).to_dict(False)
+    assert res["cov"][2:] == pytest.approx([0.0, 0.0, 5.333333333333336])
+    assert res["corr"][2:] == pytest.approx([nan, nan, 0.9176629354822473], nan_ok=True)
+    assert res["cov"][:2] == [None] * 2
+    assert res["corr"][:2] == [None] * 2
+
+
+def test_rolling_window_size_9160() -> None:
+    assert pl.Series([1, 5]).rolling_apply(
+        lambda x: sum(x), window_size=2, min_periods=1
+    ).to_list() == [1, 6]
+    assert pl.Series([1]).rolling_apply(
+        lambda x: sum(x), window_size=2, min_periods=1
+    ).to_list() == [1]
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_sort.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_sort.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_statistics.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_statistics.py`

 * *Files 3% similar despite different names*

```diff
@@ -99,7 +99,13 @@
     df = pl.DataFrame({"A": [timedelta(days=0), timedelta(days=1)]})
     assert df.select(pl.col("A").median()).to_dict(False) == {
         "A": [timedelta(seconds=43200)]
     }
     assert df.select(pl.col("A").quantile(0.5, interpolation="linear")).to_dict(
         False
     ) == {"A": [timedelta(seconds=43200)]}
+
+
+def test_correlation_cast_supertype() -> None:
+    df = pl.DataFrame({"a": [1, 8, 3], "b": [4.0, 5.0, 2.0]})
+    df = df.with_columns(pl.col("b"))
+    assert df.select(pl.corr("a", "b")).to_dict(False) == {"a": [0.5447047794019223]}
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_transpose.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_transpose.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_unique.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_unique.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/operations/test_window.py` & `polars_lts_cpu-0.18.1/tests/unit/operations/test_window.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/streaming/test_ooc.py` & `polars_lts_cpu-0.18.1/tests/unit/streaming/test_ooc.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/streaming/test_streaming.py` & `polars_lts_cpu-0.18.1/tests/unit/streaming/test_streaming.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_api.py` & `polars_lts_cpu-0.18.1/tests/unit/test_api.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_arity.py` & `polars_lts_cpu-0.18.1/tests/unit/test_arity.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_cfg.py` & `polars_lts_cpu-0.18.1/tests/unit/test_cfg.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_constructors.py` & `polars_lts_cpu-0.18.1/tests/unit/test_constructors.py`

 * *Files 0% similar despite different names*

```diff
@@ -212,45 +212,45 @@
         trades = [TradeClass(**dict(zip(columns, values))) for values in raw_data]
 
         for DF in (pl.DataFrame, pl.from_records):
             df = DF(data=trades)  # type: ignore[operator]
             assert df.schema == {
                 "timestamp": pl.Datetime("us"),
                 "ticker": pl.Utf8,
-                "price": pl.Decimal(None, 1),
+                "price": pl.Decimal(1),
                 "size": pl.Int64,
             }
             assert df.rows() == raw_data
 
             # partial dtypes override
             df = DF(  # type: ignore[operator]
                 data=trades,
                 schema_overrides={"timestamp": pl.Datetime("ms"), "size": pl.Int32},
             )
             assert df.schema == {
                 "timestamp": pl.Datetime("ms"),
                 "ticker": pl.Utf8,
-                "price": pl.Decimal(None, 1),
+                "price": pl.Decimal(1),
                 "size": pl.Int32,
             }
 
         # in conjunction with full 'columns' override (rename/downcast)
         df = pl.DataFrame(
             data=trades,
             schema=[
                 ("ts", pl.Datetime("ms")),
                 ("tk", pl.Categorical),
-                ("pc", pl.Decimal(None, 1)),
+                ("pc", pl.Decimal(1)),
                 ("sz", pl.UInt16),
             ],
         )
         assert df.schema == {
             "ts": pl.Datetime("ms"),
             "tk": pl.Categorical,
-            "pc": pl.Decimal(None, 1),
+            "pc": pl.Decimal(1),
             "sz": pl.UInt16,
         }
         assert df.rows() == raw_data
 
         # cover a miscellaneous edge-case when detecting the annotations
         assert type_hints(obj=type(None)) == {}
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_cse.py` & `polars_lts_cpu-0.18.1/tests/unit/test_cse.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_datatypes.py` & `polars_lts_cpu-0.18.1/tests/unit/test_datatypes.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 from __future__ import annotations
 
 import pickle
+import typing
 from datetime import datetime, timedelta
 
 import pytest
 
 import polars as pl
 from polars import datatypes
 from polars.datatypes import (
@@ -113,7 +114,53 @@
             pl.Struct({"name": pl.Utf8, "ids": pl.List(pl.UInt32)}),
             "Struct([Field('name', Utf8), Field('ids', List(UInt32))])",
         ),
     ],
 )
 def test_repr(dtype: pl.PolarsDataType, representation: str) -> None:
     assert repr(dtype) == representation
+
+
+@typing.no_type_check
+def test_conversion_dtype() -> None:
+    df = (
+        pl.DataFrame(
+            {
+                "id_column": [1, 2, 3, 4],
+                "some_column": ["a", "b", "c", "d"],
+                "some_partition_column": [
+                    "partition_1",
+                    "partition_2",
+                    "partition_1",
+                    "partition_2",
+                ],
+            }
+        )
+        .select(
+            [
+                pl.struct(
+                    [pl.col("id_column"), pl.col("some_column").cast(pl.Categorical)]
+                ).alias("struct"),
+                pl.col("some_partition_column"),
+            ]
+        )
+        .groupby(["some_partition_column"], maintain_order=True)
+        .agg([pl.col(["struct"])])
+    )
+
+    df = pl.from_arrow(df.to_arrow())
+    # the assertion is not the real test
+    # this tests if dtype as bubbled up correctly in conversion
+    # if not we would UB
+    assert df.to_dict(False) == {
+        "some_partition_column": ["partition_1", "partition_2"],
+        "struct": [
+            [
+                {"id_column": 1, "some_column": "a"},
+                {"id_column": 3, "some_column": "c"},
+            ],
+            [
+                {"id_column": 2, "some_column": "b"},
+                {"id_column": 4, "some_column": "d"},
+            ],
+        ],
+    }
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_df.py` & `polars_lts_cpu-0.18.1/tests/unit/test_df.py`

 * *Files 2% similar despite different names*

```diff
@@ -213,15 +213,15 @@
     record_batches = tbl.to_batches(max_chunksize=1)
     expected_schema = {
         "a": pl.Datetime("ms"),
         "b": pl.Datetime("ms"),
         "c": pl.Datetime("us"),
         "d": pl.Datetime("ns"),
         "e": pl.Int32,
-        "decimal1": pl.Decimal(2, 1),
+        "decimal1": pl.Decimal(1, 2),
     }
     expected_data = [
         (
             datetime(1970, 1, 1, 0, 0, 1),
             datetime(1970, 1, 1, 0, 0, 0, 1000),
             datetime(1970, 1, 1, 0, 0, 0, 1),
             datetime(1970, 1, 1, 0, 0),
@@ -2141,18 +2141,18 @@
     )
     expected = {"foo": pl.Int64, "bar": pl.Float64, "ham": pl.Utf8}
     assert df.schema == expected
 
 
 def test_df_schema_unique() -> None:
     df = pl.DataFrame({"a": [1, 2], "b": [3, 4]})
-    with pytest.raises(Exception):
+    with pytest.raises(pl.DuplicateError):
         df.columns = ["a", "a"]
 
-    with pytest.raises(Exception):
+    with pytest.raises(pl.DuplicateError):
         df.rename({"b": "a"})
 
 
 def test_cleared() -> None:
     df = pl.DataFrame(
         {"a": [1, 2], "b": [True, False]}, schema_overrides={"a": pl.UInt32}
     )
@@ -3107,153 +3107,14 @@
     assert (
         pl.DataFrame({"a": [1, 1, 3], "b": [1, 2, 3]})
         .with_columns([pl.col("a").set_sorted()])
         .unique(subset="a", keep="last")
     ).to_dict(False) == {"a": [1, 3], "b": [2, 3]}
 
 
-def test_with_columns() -> None:
-    import datetime
-
-    df = pl.DataFrame(
-        {
-            "a": [1, 2, 3, 4],
-            "b": [0.5, 4, 10, 13],
-            "c": [True, True, False, True],
-        }
-    )
-    srs_named = pl.Series("f", [3, 2, 1, 0])
-    srs_unnamed = pl.Series(values=[3, 2, 1, 0])
-
-    expected = pl.DataFrame(
-        {
-            "a": [1, 2, 3, 4],
-            "b": [0.5, 4, 10, 13],
-            "c": [True, True, False, True],
-            "d": [0.5, 8.0, 30.0, 52.0],
-            "e": [False, False, True, False],
-            "f": [3, 2, 1, 0],
-            "g": True,
-            "h": pl.Series(values=[1, 1, 1, 1], dtype=pl.Int32),
-            "i": 3.2,
-            "j": [1, 2, 3, 4],
-            "k": pl.Series(values=[None, None, None, None], dtype=pl.Null),
-            "l": datetime.datetime(2001, 1, 1, 0, 0),
-        }
-    )
-
-    # as exprs list
-    dx = df.with_columns(
-        [
-            (pl.col("a") * pl.col("b")).alias("d"),
-            ~pl.col("c").alias("e"),
-            srs_named,
-            pl.lit(True).alias("g"),
-            pl.lit(1).alias("h"),
-            pl.lit(3.2).alias("i"),
-            pl.col("a").alias("j"),
-            pl.lit(None).alias("k"),
-            pl.lit(datetime.datetime(2001, 1, 1, 0, 0)).alias("l"),
-        ]
-    )
-    assert_frame_equal(dx, expected)
-
-    # as positional arguments
-    dx = df.with_columns(
-        (pl.col("a") * pl.col("b")).alias("d"),
-        ~pl.col("c").alias("e"),
-        srs_named,
-        pl.lit(True).alias("g"),
-        pl.lit(1).alias("h"),
-        pl.lit(3.2).alias("i"),
-        pl.col("a").alias("j"),
-        pl.lit(None).alias("k"),
-        pl.lit(datetime.datetime(2001, 1, 1, 0, 0)).alias("l"),
-    )
-    assert_frame_equal(dx, expected)
-
-    # as keyword arguments
-    dx = df.with_columns(
-        d=pl.col("a") * pl.col("b"),
-        e=~pl.col("c"),
-        f=srs_unnamed,
-        g=True,
-        h=1,
-        i=3.2,
-        j="a",  # Note: string interpreted as column name, resolves to `pl.col("a")`
-        k=None,
-        l=datetime.datetime(2001, 1, 1, 0, 0),
-    )
-    assert_frame_equal(dx, expected)
-
-    # mixed
-    dx = df.with_columns(
-        [(pl.col("a") * pl.col("b")).alias("d")],
-        ~pl.col("c").alias("e"),
-        f=srs_unnamed,
-        g=True,
-        h=1,
-        i=3.2,
-        j="a",  # Note: string interpreted as column name, resolves to `pl.col("a")`
-        k=None,
-        l=datetime.datetime(2001, 1, 1, 0, 0),
-    )
-    assert_frame_equal(dx, expected)
-
-    # automatically upconvert multi-output expressions to struct
-    with pl.Config() as cfg:
-        cfg.set_auto_structify(True)
-
-        ldf = (
-            pl.DataFrame({"x1": [1, 2, 6], "x2": [1, 2, 3]})
-            .lazy()
-            .with_columns(
-                pl.col(["x1", "x2"]).pct_change().alias("pct_change"),
-                maxes=pl.all().max().suffix("_max"),
-                xcols=pl.col("^x.*$"),
-            )
-        )
-        # 
-        #  x1   x2   pct_change   maxes      xcols     
-        #  ---  ---  ---          ---        ---       
-        #  i64  i64  struct[2]    struct[2]  struct[2] 
-        # 
-        #  1    1    {null,null}  {6,3}      {1,1}     
-        #  2    2    {1.0,1.0}    {6,3}      {2,2}     
-        #  6    3    {2.0,0.5}    {6,3}      {6,3}     
-        # 
-        assert ldf.collect().to_dicts() == [
-            {
-                "x1": 1,
-                "x2": 1,
-                "pct_change": {"x1": None, "x2": None},
-                "maxes": {"x1_max": 6, "x2_max": 3},
-                "xcols": {"x1": 1, "x2": 1},
-            },
-            {
-                "x1": 2,
-                "x2": 2,
-                "pct_change": {"x1": 1.0, "x2": 1.0},
-                "maxes": {"x1_max": 6, "x2_max": 3},
-                "xcols": {"x1": 2, "x2": 2},
-            },
-            {
-                "x1": 6,
-                "x2": 3,
-                "pct_change": {"x1": 2.0, "x2": 0.5},
-                "maxes": {"x1_max": 6, "x2_max": 3},
-                "xcols": {"x1": 6, "x2": 3},
-            },
-        ]
-
-    # require at least one of exprs / **named_exprs
-    with pytest.raises(ValueError):
-        _ = ldf.with_columns()
-
-
 def test_len_compute(df: pl.DataFrame) -> None:
     df = df.with_columns(pl.struct(["list_bool", "cat"]).alias("struct"))
     filtered = df.filter(pl.col("bools"))
     for col in filtered.columns:
         assert len(filtered[col]) == 1
 
     taken = df[[1, 2], :]
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_empty.py` & `polars_lts_cpu-0.18.1/tests/unit/test_empty.py`

 * *Files 8% similar despite different names*

```diff
@@ -56,7 +56,17 @@
     assert out.height == 0
 
 
 def test_empty_sort_by_args() -> None:
     df = pl.DataFrame([1, 2, 3])
     with pytest.raises(pl.InvalidOperationError):
         df.select(pl.all().sort_by([]))
+
+
+def test_empty_9137() -> None:
+    out = (
+        pl.DataFrame({"id": [], "value": []})
+        .groupby("id")
+        .agg(pl.col("value").pow(2).mean())
+    )
+    assert out.shape == (0, 2)
+    assert out.dtypes == [pl.Float32, pl.Float32]
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_errors.py` & `polars_lts_cpu-0.18.1/tests/unit/test_errors.py`

 * *Files 2% similar despite different names*

```diff
@@ -258,16 +258,14 @@
                 strategy="backward",
             )
         )
 
 
 def test_is_nan_on_non_boolean() -> None:
     with pytest.raises(pl.InvalidOperationError):
-        pl.Series([1, 2, 3]).fill_nan(0)
-    with pytest.raises(pl.InvalidOperationError):
         pl.Series(["1", "2", "3"]).fill_nan("2")  # type: ignore[arg-type]
 
 
 def test_window_expression_different_group_length() -> None:
     try:
         pl.DataFrame({"groups": ["a", "a", "b", "a", "b"]}).select(
             [pl.col("groups").apply(lambda _: pl.Series([1, 2])).over("groups")]
@@ -581,16 +579,15 @@
     with pytest.raises(KeyError, match=r"('x', 'y')"):
         df["x", "y"]
 
 
 def test_invalid_groupby_arg() -> None:
     df = pl.DataFrame({"a": [1]})
     with pytest.raises(
-        ValueError,
-        match=r"'aggs' argument should be one or multiple expressions, got: '{'a': 'sum'}'",
+        ValueError, match="specifying aggregations as a dictionary is not supported"
     ):
         df.groupby(1).agg({"a": "sum"})
 
 
 def test_no_sorted_err() -> None:
     df = pl.DataFrame(
         {
@@ -647,7 +644,18 @@
 
 def test_overflow_msg() -> None:
     with pytest.raises(
         pl.ComputeError,
         match=r"could not append value: 2147483648 of type: i64 to the builder",
     ):
         pl.DataFrame([[2**31]], [("a", pl.Int32)], orient="row")
+
+
+def test_sort_by_err_9259() -> None:
+    df = pl.DataFrame(
+        {"a": [1, 1, 1], "b": [3, 2, 1], "c": [1, 1, 2]},
+        schema={"a": pl.Float32, "b": pl.Float32, "c": pl.Float32},
+    )
+    with pytest.raises(pl.ComputeError):
+        df.lazy().groupby("c").agg(
+            [pl.col("a").sort_by(pl.col("b").filter(pl.col("b") > 100)).sum()]
+        ).collect()
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_expr_multi_cols.py` & `polars_lts_cpu-0.18.1/tests/unit/test_expr_multi_cols.py`

 * *Files 4% similar despite different names*

```diff
@@ -77,7 +77,24 @@
                 pl.col("col2").append(pl.col("other")),
                 pl.col("col1").append(pl.col("other")).keep_name(),
                 pl.col("col1").append(pl.col("other")).prefix("prefix_"),
                 pl.col("col1").append(pl.col("other")).suffix("_suffix"),
             ]
         )
     ).columns == ["col2", "col1", "prefix_col1", "col1_suffix"]
+
+
+def test_multiple_columns_length_9137() -> None:
+    df = pl.DataFrame(
+        {
+            "a": [1, 1],
+            "b": ["c", "d"],
+        }
+    )
+
+    # list is larger than groups
+    cmp_list = ["a", "b", "c"]
+
+    assert df.groupby("a").agg(pl.col("b").is_in(cmp_list)).to_dict(False) == {
+        "a": [1],
+        "b": [[True, False]],
+    }
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_exprs.py` & `polars_lts_cpu-0.18.1/tests/unit/test_exprs.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_fmt.py` & `polars_lts_cpu-0.18.1/tests/unit/test_fmt.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_interchange.py` & `polars_lts_cpu-0.18.1/tests/unit/test_interchange.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_interop.py` & `polars_lts_cpu-0.18.1/tests/unit/test_interop.py`

 * *Files 4% similar despite different names*

```diff
@@ -216,14 +216,31 @@
 
     assert arw.shape == tbl.shape
     assert arw.schema.names == tbl.schema.names
     for c1, c2 in zip(arw.columns, tbl.columns):
         assert c1.to_pylist() == c2.to_pylist()
 
 
+def test_arrow_empty_dataframe() -> None:
+    # 0x0 dataframe
+    df = pl.DataFrame({})
+    tbl = pa.table({})
+    assert df.to_arrow() == tbl
+    df2 = cast(pl.DataFrame, pl.from_arrow(df.to_arrow()))
+    assert_frame_equal(df2, df)
+
+    # 0 row dataframe
+    df = pl.DataFrame({}, schema={"a": pl.Int32})
+    tbl = pa.Table.from_batches([], pa.schema([pa.field("a", pa.int32())]))
+    assert df.to_arrow() == tbl
+    df2 = cast(pl.DataFrame, pl.from_arrow(df.to_arrow()))
+    assert df2.schema == {"a": pl.Int32}
+    assert df2.shape == (0, 1)
+
+
 def test_arrow_dict_to_polars() -> None:
     pa_dict = pa.DictionaryArray.from_arrays(
         indices=np.array([0, 1, 2, 3, 1, 0, 2, 3, 3, 2]),
         dictionary=np.array(["AAA", "BBB", "CCC", "DDD"]),
     ).cast(pa.large_utf8())
 
     s = pl.Series(
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_lazy.py` & `polars_lts_cpu-0.18.1/tests/unit/test_lazy.py`

 * *Files 2% similar despite different names*

```diff
@@ -660,49 +660,14 @@
 
 def test_backward_fill() -> None:
     ldf = pl.LazyFrame({"a": [1.0, None, 3.0]})
     col_a_backward_fill = ldf.select([pl.col("a").backward_fill()]).collect()["a"]
     assert_series_equal(col_a_backward_fill, pl.Series("a", [1, 3, 3]).cast(pl.Float64))
 
 
-def test_select_by_col_list(fruits_cars: pl.DataFrame) -> None:
-    ldf = fruits_cars.lazy()
-    result = ldf.select(pl.col(["A", "B"]).sum())
-    expected = pl.LazyFrame({"A": 15, "B": 15})
-    assert_frame_equal(result, expected)
-
-
-def test_select_args_kwargs() -> None:
-    ldf = pl.LazyFrame({"foo": [1, 2], "bar": [3, 4], "ham": ["a", "b"]})
-
-    # Single column name
-    result = ldf.select("foo")
-    expected = pl.LazyFrame({"foo": [1, 2]})
-    assert_frame_equal(result, expected)
-
-    # Column names as list
-    result = ldf.select(["foo", "bar"])
-    expected = pl.LazyFrame({"foo": [1, 2], "bar": [3, 4]})
-    assert_frame_equal(result, expected)
-
-    # Column names as positional arguments
-    result, expected = ldf.select("foo", "bar", "ham"), ldf
-    assert_frame_equal(result, expected)
-
-    # Keyword arguments
-    result = ldf.select(oof="foo")
-    expected = pl.LazyFrame({"oof": [1, 2]})
-    assert_frame_equal(result, expected)
-
-    # Mixed
-    result = ldf.select(["bar"], "foo", oof="foo")
-    expected = pl.LazyFrame({"bar": [3, 4], "foo": [1, 2], "oof": [1, 2]})
-    assert_frame_equal(result, expected)
-
-
 def test_rolling(fruits_cars: pl.DataFrame) -> None:
     ldf = fruits_cars.lazy()
     out = ldf.select(
         [
             pl.col("A").rolling_min(3, min_periods=1).alias("1"),
             pl.col("A").rolling_min(3).alias("1b"),
             pl.col("A").rolling_mean(3, min_periods=1).alias("2"),
@@ -923,22 +888,14 @@
 
 
 def test_with_column_renamed(fruits_cars: pl.DataFrame) -> None:
     res = fruits_cars.lazy().rename({"A": "C"}).collect()
     assert res.columns[0] == "C"
 
 
-def test_with_columns_single_series() -> None:
-    ldf = pl.LazyFrame({"a": [1, 2]})
-    result = ldf.with_columns(pl.Series("b", [3, 4]))
-
-    expected = pl.DataFrame({"a": [1, 2], "b": [3, 4]})
-    assert_frame_equal(result.collect(), expected)
-
-
 def test_reverse() -> None:
     out = pl.LazyFrame({"a": [1, 2], "b": [3, 4]}).reverse()
     expected = pl.DataFrame({"a": [2, 1], "b": [4, 3]})
     assert_frame_equal(out.collect(), expected)
 
 
 def test_limit(fruits_cars: pl.DataFrame) -> None:
@@ -1137,15 +1094,15 @@
             "manager_id": [None, 100, 101],
         }
     ).lazy()
 
     out = (
         ldf.join(other=ldf, left_on="manager_id", right_on="employee_id", how="left")
         .select(
-            exprs=[
+            [
                 pl.col("employee_id"),
                 pl.col("employee_name"),
                 pl.col("employee_name_right").alias("manager_name"),
             ]
         )
         .fetch()
     )
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_polars_import.py` & `polars_lts_cpu-0.18.1/tests/unit/test_polars_import.py`

 * *Files 9% similar despite different names*

```diff
@@ -38,15 +38,15 @@
         .reverse()
         .select("import", "own_time", "cumulative_time")
     )
 
 
 @pytest.mark.skipif(sys.platform == "win32", reason="Unreliable on Windows")
 def test_polars_import() -> None:
-    # note: take the fastest of three runs to reduce noise.
+    # note: take the fastest of several runs to reduce noise.
     df_import = _import_timings_as_frame(best_of=3)
 
     with pl.Config() as cfg:
         # get a complete view of what's going on in case of failure
         cfg.set_tbl_rows(250)
         cfg.set_fmt_str_lengths(100)
         cfg.set_tbl_hide_dataframe_shape()
@@ -57,12 +57,13 @@
         ]
         for mod in lazy_modules:
             not_imported = not df_import["import"].str.starts_with(mod).any()
             if_err = f"lazy-loading regression: found {mod!r} at import time"
             assert not_imported, f"{if_err}\n{df_import}"
 
         # ensure that we do not have an import speed regression.
-        total_import_time = df_import["cumulative_time"].max()
-        assert isinstance(total_import_time, int)
+        polars_import = df_import.filter(pl.col("import").str.strip() == "polars")
+        polars_import_time = polars_import["cumulative_time"].item()
+        assert isinstance(polars_import_time, int)
 
-        if_err = f"Possible import speed regression; took {total_import_time//1_000}ms"
-        assert total_import_time < 200_000, f"{if_err}\n{df_import}"
+        if_err = f"Possible import speed regression; took {polars_import_time//1_000}ms"
+        assert polars_import_time < 200_000, f"{if_err}\n{df_import}"
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_predicates.py` & `polars_lts_cpu-0.18.1/tests/unit/test_predicates.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_projections.py` & `polars_lts_cpu-0.18.1/tests/unit/test_projections.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_queries.py` & `polars_lts_cpu-0.18.1/tests/unit/test_queries.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_rows.py` & `polars_lts_cpu-0.18.1/tests/unit/test_rows.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_schema.py` & `polars_lts_cpu-0.18.1/tests/unit/test_schema.py`

 * *Files 1% similar despite different names*

```diff
@@ -449,7 +449,13 @@
 
 def test_list_null_constructor_schema() -> None:
     expected = pl.List(pl.Null)
     assert pl.Series([[]]).dtype == expected
     assert pl.Series([[]], dtype=pl.List).dtype == expected
     assert pl.DataFrame({"a": [[]]}).dtypes[0] == expected
     assert pl.DataFrame(schema={"a": pl.List}).dtypes[0] == expected
+
+
+def test_schema_ne_missing_9256() -> None:
+    df = pl.DataFrame({"a": [0, 1, None], "b": [True, False, True]})
+
+    assert df.select(pl.col("a").ne_missing(0).or_(pl.col("b")))["a"].all()
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_serde.py` & `polars_lts_cpu-0.18.1/tests/unit/test_serde.py`

 * *Files 10% similar despite different names*

```diff
@@ -86,7 +86,15 @@
     assert_frame_equal(pickle.loads(s).collect(), pl.DataFrame({"a": [1, 3, 4]}))
 
 
 def test_deser_empty_list() -> None:
     s = pickle.loads(pickle.dumps(pl.Series([[[42.0]], []])))
     assert s.dtype == pl.List(pl.List(pl.Float64))
     assert s.to_list() == [[[42.0]], []]
+
+
+def test_expression_json() -> None:
+    e = pl.col("foo").sum().over("bar")
+    json = e.meta.write_json()
+
+    round_tripped = pl.Expr.from_json(json)
+    assert round_tripped.meta == e
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_series.py` & `polars_lts_cpu-0.18.1/tests/unit/test_series.py`

 * *Files 0% similar despite different names*

```diff
@@ -490,15 +490,15 @@
 
     s = pl.Series("bool", [True, None, False])
     assert not s.is_numeric()
 
     s = pl.Series("s", ["testing..."])
     assert s.is_utf8()
 
-    s = pl.Series("s", [], dtype=pl.Decimal(20, 15))
+    s = pl.Series("s", [], dtype=pl.Decimal(scale=15, precision=20))
     assert not s.is_float()
     assert s.is_numeric()
     assert s.is_empty()
 
     s = pl.Series("s", [], dtype=pl.Datetime("ms", time_zone="UTC"))
     assert s.is_temporal()
 
@@ -1025,14 +1025,17 @@
     assert_series_equal(a.rolling_min(2), pl.Series("a", [None, 1, 2, 2, 1]))
     assert_series_equal(a.rolling_max(2), pl.Series("a", [None, 2, 3, 3, 2]))
     assert_series_equal(a.rolling_sum(2), pl.Series("a", [None, 3, 5, 5, 3]))
     assert_series_equal(a.rolling_mean(2), pl.Series("a", [None, 1.5, 2.5, 2.5, 1.5]))
 
     assert a.rolling_std(2).to_list()[1] == pytest.approx(0.7071067811865476)
     assert a.rolling_var(2).to_list()[1] == pytest.approx(0.5)
+    assert a.rolling_std(2, ddof=0).to_list()[1] == pytest.approx(0.5)
+    assert a.rolling_var(2, ddof=0).to_list()[1] == pytest.approx(0.25)
+
     assert_series_equal(
         a.rolling_median(4), pl.Series("a", [None, None, None, 2, 2], dtype=Float64)
     )
     assert_series_equal(
         a.rolling_quantile(0, "nearest", 3),
         pl.Series("a", [None, None, 1, 2, 1], dtype=Float64),
     )
@@ -1819,15 +1822,15 @@
 
     assert len(s.sample(n=2, seed=0)) == 2
     assert len(s.sample(fraction=0.4, seed=0)) == 2
 
     assert len(s.sample(n=2, with_replacement=True, seed=0)) == 2
 
     # on a series of length 5, you cannot sample more than 5 items
-    with pytest.raises(Exception):
+    with pytest.raises(pl.ShapeError):
         s.sample(n=10, with_replacement=False, seed=0)
     # unless you use with_replacement=True
     assert len(s.sample(n=10, with_replacement=True, seed=0)) == 10
 
 
 def test_peak_max_peak_min() -> None:
     s = pl.Series("a", [4, 1, 3, 2, 5])
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_single.py` & `polars_lts_cpu-0.18.1/tests/unit/test_single.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_sql.py` & `polars_lts_cpu-0.18.1/tests/unit/test_sql.py`

 * *Files 1% similar despite different names*

```diff
@@ -230,7 +230,14 @@
             _lf4 = pl.LazyFrame({"a": [4, 5, 6], "c": ["v", "w", "x"]})
             ctx.register_globals(n=2)
             assert ctx.tables() == ["_lf1", "_lf2", "_lf3", "_lf4"]
 
         assert ctx.tables() == ["_lf1", "_lf2"]
 
     assert ctx.tables() == []
+
+
+def test_sql_expr() -> None:
+    df = pl.DataFrame({"a": [1, 2, 3], "b": [4, None, 6]})
+    sql_expr = pl.sql_expr("MIN(a)")
+    expected = pl.DataFrame({"a": [1]})
+    assert df.select(sql_expr).frame_equal(expected)
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/test_testing.py` & `polars_lts_cpu-0.18.1/tests/unit/test_testing.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/tests/unit/utils/test_parse_expr_input.py` & `polars_lts_cpu-0.18.1/tests/unit/utils/test_parse_expr_input.py`

 * *Files 17% similar despite different names*

```diff
@@ -3,87 +3,88 @@
 from datetime import date
 from typing import Any
 
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
-from polars.utils._parse_expr_input import _inputs_to_list, parse_as_expression
+from polars.utils._parse_expr_input import _first_input_to_list, parse_as_expression
+from polars.utils._wrap import wrap_expr
 
 
 def assert_expr_equal(result: pl.Expr, expected: pl.Expr) -> None:
     """
     Evaluate the given expressions in a simple context to assert equality.
 
     WARNING: This is not a fully featured function - it's just to evaluate the tests in
     this module. Do not use it elsewhere.
     """
     df = pl.DataFrame({"a": [1, 2], "b": [3, 4]})
     assert_frame_equal(df.select(result), df.select(expected))
 
 
 @pytest.mark.parametrize("input", [None, []])
-def test_inputs_to_list_empty(input: Any) -> None:
-    assert _inputs_to_list(input) == []
+def test_first_input_to_list_empty(input: Any) -> None:
+    assert _first_input_to_list(input) == []
 
 
 @pytest.mark.parametrize(
     "input",
     [5, 2.0, "a", pl.Series([1, 2, 3]), pl.lit(4)],
 )
-def test_inputs_to_list_single(input: Any) -> None:
-    assert _inputs_to_list(input) == [input]
+def test_first_input_to_list_single(input: Any) -> None:
+    assert _first_input_to_list(input) == [input]
 
 
 @pytest.mark.parametrize(
     "input",
     [[5], ["a", "b"], (1, 2, 3), ["a", 5, 3.2]],
 )
-def test_inputs_to_list_multiple(input: Any) -> None:
-    assert _inputs_to_list(input) == list(input)
+def test_first_input_to_list_multiple(input: Any) -> None:
+    assert _first_input_to_list(input) == list(input)
 
 
 @pytest.mark.parametrize("input", [5, 2.0, pl.Series([1, 2, 3]), date(2022, 1, 1)])
 def test_parse_as_expression_lit(input: Any) -> None:
-    result = parse_as_expression(input)
+    result = wrap_expr(parse_as_expression(input))
     expected = pl.lit(input)
     assert_expr_equal(result, expected)
 
 
 def test_parse_as_expression_col() -> None:
-    result = parse_as_expression("a")
+    result = wrap_expr(parse_as_expression("a"))
     expected = pl.col("a")
     assert_expr_equal(result, expected)
 
 
 @pytest.mark.parametrize("input", [pl.lit(4), pl.col("a")])
 def test_parse_as_expression_expr(input: pl.Expr) -> None:
-    result = parse_as_expression(input)
+    result = wrap_expr(parse_as_expression(input))
     expected = input
     assert_expr_equal(result, expected)
 
 
 @pytest.mark.parametrize(
     "input", [pl.when(True).then(1), pl.when(True).then(1).when(False).then(0)]
 )
 def test_parse_as_expression_whenthen(input: Any) -> None:
-    result = parse_as_expression(input)
+    result = wrap_expr(parse_as_expression(input))
     expected = input.otherwise(None)
     assert_expr_equal(result, expected)
 
 
 def test_parse_as_expression_list() -> None:
-    result = parse_as_expression([1, 2, 3])
+    result = wrap_expr(parse_as_expression([1, 2, 3]))
     expected = pl.lit(pl.Series([[1, 2, 3]]))
     assert_expr_equal(result, expected)
 
 
 def test_parse_as_expression_str_as_lit() -> None:
-    result = parse_as_expression("a", str_as_lit=True)
+    result = wrap_expr(parse_as_expression("a", str_as_lit=True))
     expected = pl.lit("a")
     assert_expr_equal(result, expected)
 
 
 def test_parse_as_expression_structify() -> None:
-    result = parse_as_expression(pl.col("a", "b"), structify=True)
+    result = wrap_expr(parse_as_expression(pl.col("a", "b"), structify=True))
     expected = pl.struct("a", "b")
     assert_expr_equal(result, expected)
```

### Comparing `polars_lts_cpu-0.18.0/tests/unit/utils/test_utils.py` & `polars_lts_cpu-0.18.1/tests/unit/utils/test_utils.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.0/Cargo.lock` & `polars_lts_cpu-0.18.1/Cargo.lock`

 * *Files 1% similar despite different names*

```diff
@@ -47,14 +47,20 @@
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "94fb8275041c72129eb51b7d0322c29b8387a0386127718b096429201a5d6ece"
 dependencies = [
  "alloc-no-stdlib",
 ]
 
 [[package]]
+name = "android-tzdata"
+version = "0.1.1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "e999941b234f3131b00bc13c22d06e8c5ff726d1b6318ac7eb276997bbb4fef0"
+
+[[package]]
 name = "android_system_properties"
 version = "0.1.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "819e7219dbd41043ac279b19830f2efc897156490d7fd6ea916720117ee66311"
 dependencies = [
  "libc",
 ]
@@ -82,17 +88,16 @@
 dependencies = [
  "planus",
  "serde",
 ]
 
 [[package]]
 name = "arrow2"
-version = "0.17.2"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "15ae0428d69ab31d7b2adad22a752d6f11fef2e901d2262d0cad4f5cb08b7093"
+version = "0.17.1"
+source = "git+https://github.com/jorgecarleitao/arrow2?rev=fb5e4d591c7149df590a330365fae55d2370962f#fb5e4d591c7149df590a330365fae55d2370962f"
 dependencies = [
  "ahash",
  "arrow-format",
  "avro-schema",
  "base64",
  "bytemuck",
  "chrono",
@@ -134,26 +139,26 @@
 name = "async-stream-impl"
 version = "0.3.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "16e62a023e7c117e27523144c5d2459f4397fcc3cab0085af8e2224f643a0193"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 2.0.16",
+ "syn 2.0.18",
 ]
 
 [[package]]
 name = "async-trait"
 version = "0.1.68"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "b9ccdd8f2a161be9bd5c023df56f1b2a0bd1d83872ae53b71a84a12c9bf6e842"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 2.0.16",
+ "syn 2.0.18",
 ]
 
 [[package]]
 name = "atoi"
 version = "2.0.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "f28d99ec8bfea296261ca1af174f24225171fea9664ba9003cbebee704810528"
@@ -179,17 +184,17 @@
  "serde",
  "serde_json",
  "snap",
 ]
 
 [[package]]
 name = "base64"
-version = "0.21.1"
+version = "0.21.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "3f1e31e207a6b8fb791a38ea3105e6cb541f55e4d029902d3039a4ad07cc4105"
+checksum = "604178f6c5c21f02dc555784810edfb88d34ac2c73b2eae109655649ee73ce3d"
 
 [[package]]
 name = "bitflags"
 version = "1.3.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "bef38d45163c2f1dde094a7dfd33ccf595c92905c8f8f4fdc18d06fb1037718a"
 
@@ -244,15 +249,15 @@
 name = "bytemuck_derive"
 version = "1.4.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "fdde5c9cd29ebd706ce1b35600920a33550e402fc998a2e53ad3b42c3c47a192"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 2.0.16",
+ "syn 2.0.18",
 ]
 
 [[package]]
 name = "bytes"
 version = "1.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "89b2fd2a0dcf38d7971e2194b6b6eebab45ae01067456a7fd93d5547a61b70be"
@@ -282,21 +287,21 @@
 name = "cfg-if"
 version = "1.0.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "baf1de4339761588bc0619e3cbc0120ee582ebb74b53b4efbf79117bd2da40fd"
 
 [[package]]
 name = "chrono"
-version = "0.4.24"
+version = "0.4.26"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4e3c5919066adf22df73762e50cffcde3a758f2a848b113b586d1f86728b673b"
+checksum = "ec837a71355b28f6556dbd569b37b3f363091c0bd4b2e735674521b4c5fd9bc5"
 dependencies = [
+ "android-tzdata",
  "iana-time-zone",
  "js-sys",
- "num-integer",
  "num-traits",
  "serde",
  "time",
  "wasm-bindgen",
  "winapi",
 ]
 
@@ -347,17 +352,17 @@
 dependencies = [
  "ciborium-io",
  "half",
 ]
 
 [[package]]
 name = "comfy-table"
-version = "6.1.4"
+version = "6.2.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "6e7b787b0dc42e8111badfdbe4c3059158ccb2db8780352fa1b01e8ccf45cc4d"
+checksum = "7e959d788268e3bf9d35ace83e81b124190378e4c91c9067524675e33394b8ba"
 dependencies = [
  "crossterm",
  "strum",
  "strum_macros",
  "unicode-width",
 ]
 
@@ -417,15 +422,15 @@
 version = "0.9.14"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "46bd5f3f85273295a9d14aedfb86f6aadbff6d8f5295c4a9edb08e819dcf5695"
 dependencies = [
  "autocfg",
  "cfg-if",
  "crossbeam-utils",
- "memoffset",
+ "memoffset 0.8.0",
  "scopeguard",
 ]
 
 [[package]]
 name = "crossbeam-queue"
 version = "0.3.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
@@ -442,17 +447,17 @@
 checksum = "3c063cd8cc95f5c377ed0d4b49a4b21f632396ff690e8470c29b3359b346984b"
 dependencies = [
  "cfg-if",
 ]
 
 [[package]]
 name = "crossterm"
-version = "0.25.0"
+version = "0.26.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e64e6c0fbe2c17357405f7c758c1ef960fce08bdfb2c03d88d2a18d7e09c4b67"
+checksum = "a84cda67535339806297f1b331d6dd6320470d2a0fe65381e79ee9e156dd3d13"
 dependencies = [
  "bitflags",
  "crossterm_winapi",
  "libc",
  "mio",
  "parking_lot 0.12.1",
  "signal-hook",
@@ -597,15 +602,15 @@
 name = "futures-macro"
 version = "0.3.28"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "89ca545a94061b6365f2c7355b4b32bd20df3ff95f02da9329b34ccc3bd6ee72"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 2.0.16",
+ "syn 2.0.18",
 ]
 
 [[package]]
 name = "futures-sink"
 version = "0.3.28"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "f43be4fe21a13b9781a69afa4985b0f6ee0e1afab2c6f454a8cf30e2b2237b6e"
@@ -651,15 +656,15 @@
 name = "ghost"
 version = "0.1.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "e77ac7b51b8e6313251737fcef4b1c01a2ea102bde68415b62c0ee9268fec357"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 2.0.16",
+ "syn 2.0.18",
 ]
 
 [[package]]
 name = "git2"
 version = "0.16.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "ccf7f68c2995f392c49fffb4f95ae2c873297830eb25c6bc4c114ce8f4562acc"
@@ -1020,20 +1025,17 @@
 dependencies = [
  "autocfg",
  "scopeguard",
 ]
 
 [[package]]
 name = "log"
-version = "0.4.17"
+version = "0.4.18"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "abb12e687cfb44aa40f41fc3978ef76448f9b6038cad6aef4259d3c095a2382e"
-dependencies = [
- "cfg-if",
-]
+checksum = "518ef76f2f87365916b142844c16d8fefd85039bc5699050210a7778ee1cd1de"
 
 [[package]]
 name = "lz4"
 version = "1.24.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "7e9e2dd86df36ce760a60f6ff6ad526f7ba1f14ba0356f8254fb6905e6494df1"
 dependencies = [
@@ -1082,14 +1084,23 @@
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "d61c719bcfbcf5d62b3a09efa6088de8c54bc0bfcd3ea7ae39fcc186108b8de1"
 dependencies = [
  "autocfg",
 ]
 
 [[package]]
+name = "memoffset"
+version = "0.9.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "5a634b1c61a95585bd15607c6ab0c4e5b226e695ff2800ba0cdccddf208c406c"
+dependencies = [
+ "autocfg",
+]
+
+[[package]]
 name = "mimalloc"
 version = "0.1.37"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "4e2894987a3459f3ffb755608bd82188f8ed00d0ae077f1edea29c068d639d98"
 dependencies = [
  "libmimalloc-sys",
 ]
@@ -1101,22 +1112,22 @@
 checksum = "e7810e0be55b428ada41041c41f32c9f1a42817901b4ccf45fa3d4b6561e74c7"
 dependencies = [
  "adler",
 ]
 
 [[package]]
 name = "mio"
-version = "0.8.6"
+version = "0.8.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5b9d9a46eff5b4ff64b45a9e316a6d1e0bc719ef429cbec4dc630684212bfdf9"
+checksum = "927a765cd3fc26206e66b296465fa9d3e5ab003e651c1b3c060e7956d96b19d2"
 dependencies = [
  "libc",
  "log",
  "wasi 0.11.0+wasi-snapshot-preview1",
- "windows-sys 0.45.0",
+ "windows-sys 0.48.0",
 ]
 
 [[package]]
 name = "multiversion"
 version = "0.7.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "8cda45dade5144c2c929bf2ed6c24bebbba784e9198df049ec87d722b9462bd1"
@@ -1205,32 +1216,32 @@
 dependencies = [
  "hermit-abi",
  "libc",
 ]
 
 [[package]]
 name = "numpy"
-version = "0.18.0"
+version = "0.19.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "96b0fee4571867d318651c24f4a570c3f18408cf95f16ccb576b3ce85496a46e"
+checksum = "437213adf41bbccf4aeae535fbfcdad0f6fed241e1ae182ebe97fa1f3ce19389"
 dependencies = [
  "libc",
  "ndarray",
  "num-complex",
  "num-integer",
  "num-traits",
  "pyo3",
  "rustc-hash",
 ]
 
 [[package]]
 name = "once_cell"
-version = "1.17.1"
+version = "1.17.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "b7e5500299e16ebb147ae15a00a942af264cf3688f47923b8fc2cd5858f23ad3"
+checksum = "9670a07f94779e00908f3e686eab508878ebb390ba6e604d3a284c00e8d0487b"
 
 [[package]]
 name = "parking_lot"
 version = "0.11.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "7d17b78036a60663b797adeaee46f5c9dfebb86948d1255007a1d6be0271ff99"
 dependencies = [
@@ -1411,14 +1422,15 @@
 name = "polars-arrow"
 version = "0.30.0"
 dependencies = [
  "arrow2",
  "atoi",
  "chrono",
  "chrono-tz",
+ "ethnum",
  "hashbrown 0.13.2",
  "multiversion",
  "num-traits",
  "polars-error",
  "serde",
  "thiserror",
 ]
@@ -1657,24 +1669,24 @@
 name = "ppv-lite86"
 version = "0.2.17"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "5b40af805b3121feab8a3c29f04d8ad262fa8e0561883e7653e024ae4479e6de"
 
 [[package]]
 name = "proc-macro2"
-version = "1.0.58"
+version = "1.0.59"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "fa1fb82fc0c281dd9671101b66b771ebbe1eaf967b96ac8740dcba4b70005ca8"
+checksum = "6aeca18b86b413c660b781aa319e4e2648a3e6f9eadc9b47e9038e6fe9f3451b"
 dependencies = [
  "unicode-ident",
 ]
 
 [[package]]
 name = "py-polars"
-version = "0.18.0"
+version = "0.18.1"
 dependencies = [
  "ahash",
  "built",
  "ciborium",
  "jemallocator",
  "lexical-core",
  "libc",
@@ -1691,84 +1703,84 @@
  "serde_json",
  "smartstring",
  "thiserror",
 ]
 
 [[package]]
 name = "pyo3"
-version = "0.18.3"
+version = "0.19.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e3b1ac5b3731ba34fdaa9785f8d74d17448cd18f30cf19e0c7e7b1fdb5272109"
+checksum = "cffef52f74ec3b1a1baf295d9b8fcc3070327aefc39a6d00656b13c1d0b8885c"
 dependencies = [
  "cfg-if",
  "indoc",
  "inventory",
  "libc",
- "memoffset",
+ "memoffset 0.9.0",
  "parking_lot 0.12.1",
  "pyo3-build-config",
  "pyo3-ffi",
  "pyo3-macros",
  "unindent",
 ]
 
 [[package]]
 name = "pyo3-build-config"
-version = "0.18.3"
+version = "0.19.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "9cb946f5ac61bb61a5014924910d936ebd2b23b705f7a4a3c40b05c720b079a3"
+checksum = "713eccf888fb05f1a96eb78c0dbc51907fee42b3377272dc902eb38985f418d5"
 dependencies = [
  "once_cell",
  "target-lexicon",
 ]
 
 [[package]]
 name = "pyo3-built"
 version = "0.4.7"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "be6d574e0f8cab2cdd1eeeb640cbf845c974519fa9e9b62fa9c08ecece0ca5de"
 
 [[package]]
 name = "pyo3-ffi"
-version = "0.18.3"
+version = "0.19.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "fd4d7c5337821916ea2a1d21d1092e8443cf34879e53a0ac653fbb98f44ff65c"
+checksum = "5b2ecbdcfb01cbbf56e179ce969a048fd7305a66d4cdf3303e0da09d69afe4c3"
 dependencies = [
  "libc",
  "pyo3-build-config",
 ]
 
 [[package]]
 name = "pyo3-macros"
-version = "0.18.3"
+version = "0.19.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "a9d39c55dab3fc5a4b25bbd1ac10a2da452c4aca13bb450f22818a002e29648d"
+checksum = "b78fdc0899f2ea781c463679b20cb08af9247febc8d052de941951024cd8aea0"
 dependencies = [
  "proc-macro2",
  "pyo3-macros-backend",
  "quote",
  "syn 1.0.109",
 ]
 
 [[package]]
 name = "pyo3-macros-backend"
-version = "0.18.3"
+version = "0.19.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "97daff08a4c48320587b5224cc98d609e3c27b6d437315bd40b605c98eeb5918"
+checksum = "60da7b84f1227c3e2fe7593505de274dcf4c8928b4e0a1c23d551a14e4e80a0f"
 dependencies = [
  "proc-macro2",
  "quote",
  "syn 1.0.109",
 ]
 
 [[package]]
 name = "quote"
-version = "1.0.27"
+version = "1.0.28"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "8f4f29d145265ec1c483c7c654450edde0bfe043d3938d6972630663356d9500"
+checksum = "1b9ab9c7eadfd8df19006f1cf1a4aed13540ed5cbc047010ece5826e10825488"
 dependencies = [
  "proc-macro2",
 ]
 
 [[package]]
 name = "rand"
 version = "0.8.5"
@@ -1844,17 +1856,17 @@
 checksum = "fb5a58c1855b4b6819d59012155603f0b22ad30cad752600aadfcb695265519a"
 dependencies = [
  "bitflags",
 ]
 
 [[package]]
 name = "regex"
-version = "1.8.2"
+version = "1.8.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "d1a59b5d8e97dee33696bf13c5ba8ab85341c002922fba050069326b9c498974"
+checksum = "81ca098a9821bd52d6b24fd8b10bd081f47d39c22778cafaa75a2857a62c6390"
 dependencies = [
  "aho-corasick",
  "memchr",
  "regex-syntax 0.7.2",
 ]
 
 [[package]]
@@ -1936,15 +1948,15 @@
 name = "serde_derive"
 version = "1.0.163"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "8c805777e3930c8883389c602315a24224bcc738b63905ef87cd1420353ea93e"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 2.0.16",
+ "syn 2.0.18",
 ]
 
 [[package]]
 name = "serde_json"
 version = "1.0.96"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "057d394a50403bcac12672b2b18fb387ab6d289d957dab67dd201875391e52f1"
@@ -1983,17 +1995,17 @@
 checksum = "d8229b473baa5980ac72ef434c4415e70c4b5e71b423043adb4ba059f89c99a1"
 dependencies = [
  "libc",
 ]
 
 [[package]]
 name = "simd-json"
-version = "0.10.2"
+version = "0.10.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5b001e6c10fcba79ac15990241d37c3f8c6ba4f9a14ee35fcebc0c067514b83a"
+checksum = "a3d0815e7ff0f1f05e09d4b029f86d8a330f0ab15b35b28736f3758325f59e14"
 dependencies = [
  "ahash",
  "halfbrown",
  "lexical-core",
  "once_cell",
  "serde",
  "serde_json",
@@ -2120,17 +2132,17 @@
  "proc-macro2",
  "quote",
  "unicode-ident",
 ]
 
 [[package]]
 name = "syn"
-version = "2.0.16"
+version = "2.0.18"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "a6f671d4b5ffdb8eadec19c0ae67fe2639df8684bd7bc4b83d986b8db549cf01"
+checksum = "32d41677bcbe24c20c52e7c70b0d8db04134c5d1066bf98662e2871ad200ea3e"
 dependencies = [
  "proc-macro2",
  "quote",
  "unicode-ident",
 ]
 
 [[package]]
@@ -2172,15 +2184,15 @@
 name = "thiserror-impl"
 version = "1.0.40"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "f9456a42c5b0d803c8cd86e73dd7cc9edd429499f37a3550d286d5e86720569f"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 2.0.16",
+ "syn 2.0.18",
 ]
 
 [[package]]
 name = "time"
 version = "0.1.45"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "1b797afad3f312d1c66a56d11d0316f916356d11bd158fbc6ca6389ff6bf805a"
@@ -2203,17 +2215,17 @@
 name = "tinyvec_macros"
 version = "0.1.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "1f3ccbac311fea05f86f61904b462b55fb3df8837a366dfc601a0161d0532f20"
 
 [[package]]
 name = "tokio"
-version = "1.28.1"
+version = "1.28.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "0aa32867d44e6f2ce3385e89dceb990188b8bb0fb25b0cf576647a6f98ac5105"
+checksum = "94d7b1cfd2aa4011f2de74c2c4c63665e27a71006b0a192dcd2710272e73dfa2"
 dependencies = [
  "autocfg",
  "libc",
  "mio",
  "pin-project-lite",
  "socket2",
  "windows-sys 0.48.0",
@@ -2232,17 +2244,17 @@
 name = "unicode-bidi"
 version = "0.3.13"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "92888ba5573ff080736b3648696b70cafad7d250551175acbaa4e0385b3e1460"
 
 [[package]]
 name = "unicode-ident"
-version = "1.0.8"
+version = "1.0.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e5464a87b239f13a63a501f2701565754bae92d243d4bb7eb12f6d57d2269bf4"
+checksum = "b15811caf2415fb889178633e7724bad2509101cde276048e013b9def5e51fa0"
 
 [[package]]
 name = "unicode-normalization"
 version = "0.1.22"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "5c5713f0fc4b5db668a2ac63cdb7bb4469d8c9fed047b1d0292cc7b0ce2ba921"
 dependencies = [
@@ -2325,15 +2337,15 @@
 checksum = "19b04bc93f9d6bdee709f6bd2118f57dd6679cf1176a1af464fca3ab0d66d8fb"
 dependencies = [
  "bumpalo",
  "log",
  "once_cell",
  "proc-macro2",
  "quote",
- "syn 2.0.16",
+ "syn 2.0.18",
  "wasm-bindgen-shared",
 ]
 
 [[package]]
 name = "wasm-bindgen-futures"
 version = "0.4.36"
 source = "registry+https://github.com/rust-lang/crates.io-index"
@@ -2359,15 +2371,15 @@
 name = "wasm-bindgen-macro-support"
 version = "0.2.86"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "e128beba882dd1eb6200e1dc92ae6c5dbaa4311aa7bb211ca035779e5efc39f8"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 2.0.16",
+ "syn 2.0.18",
  "wasm-bindgen-backend",
  "wasm-bindgen-shared",
 ]
 
 [[package]]
 name = "wasm-bindgen-shared"
 version = "0.2.86"
```

### Comparing `polars_lts_cpu-0.18.0/PKG-INFO` & `polars_lts_cpu-0.18.1/PKG-INFO`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: polars-lts-cpu
-Version: 0.18.0
+Version: 0.18.1
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Environment :: Console
 Classifier: Intended Audience :: Science/Research
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python
 Classifier: Programming Language :: Python :: 3
@@ -12,52 +12,52 @@
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: Rust
 Classifier: Topic :: Scientific/Engineering
-Requires-Dist: typing_extensions >= 4.0.1; python_version < '3.8'
-Requires-Dist: matplotlib; extra == 'matplotlib'
-Requires-Dist: deltalake >= 0.8.0; extra == 'deltalake'
-Requires-Dist: pyarrow>=7.0.0; extra == 'pandas'
-Requires-Dist: pandas; extra == 'pandas'
-Requires-Dist: numpy >= 1.16.0; extra == 'numpy'
-Requires-Dist: backports.zoneinfo; (python_version < '3.9') and extra == 'timezone'
-Requires-Dist: tzdata; (platform_system == 'Windows') and extra == 'timezone'
-Requires-Dist: pyarrow>=7.0.0; extra == 'pyarrow'
-Requires-Dist: fsspec; extra == 'fsspec'
-Requires-Dist: sqlalchemy; extra == 'sqlalchemy'
-Requires-Dist: pandas; extra == 'sqlalchemy'
-Requires-Dist: polars[pyarrow,pandas,numpy,fsspec,connectorx,xlsx2csv,deltalake,timezone,matplotlib,sqlalchemy,xlsxwriter]; extra == 'all'
-Requires-Dist: xlsx2csv >= 0.8.0; extra == 'xlsx2csv'
-Requires-Dist: connectorx; extra == 'connectorx'
-Requires-Dist: xlsxwriter; extra == 'xlsxwriter'
-Provides-Extra: matplotlib
-Provides-Extra: deltalake
+Requires-Dist: typing_extensions >=4.0.1 ; python_version < '3.8'
+Requires-Dist: pyarrow >=7.0.0 ; extra == 'pyarrow'
+Requires-Dist: pyarrow >=7.0.0 ; extra == 'pandas'
+Requires-Dist: pandas ; extra == 'pandas'
+Requires-Dist: numpy >=1.16.0 ; extra == 'numpy'
+Requires-Dist: fsspec ; extra == 'fsspec'
+Requires-Dist: connectorx ; extra == 'connectorx'
+Requires-Dist: xlsx2csv >=0.8.0 ; extra == 'xlsx2csv'
+Requires-Dist: deltalake >=0.8.0 ; extra == 'deltalake'
+Requires-Dist: backports.zoneinfo ; python_version < '3.9' and extra == 'timezone'
+Requires-Dist: tzdata ; platform_system == 'Windows' and extra == 'timezone'
+Requires-Dist: matplotlib ; extra == 'matplotlib'
+Requires-Dist: sqlalchemy ; extra == 'sqlalchemy'
+Requires-Dist: pandas ; extra == 'sqlalchemy'
+Requires-Dist: xlsxwriter ; extra == 'xlsxwriter'
+Requires-Dist: polars[pyarrow,pandas,numpy,fsspec,connectorx,xlsx2csv,deltalake,timezone,matplotlib,sqlalchemy,xlsxwriter] ; extra == 'all'
+Provides-Extra: pyarrow
 Provides-Extra: pandas
 Provides-Extra: numpy
-Provides-Extra: timezone
-Provides-Extra: pyarrow
 Provides-Extra: fsspec
-Provides-Extra: sqlalchemy
-Provides-Extra: all
-Provides-Extra: xlsx2csv
 Provides-Extra: connectorx
+Provides-Extra: xlsx2csv
+Provides-Extra: deltalake
+Provides-Extra: timezone
+Provides-Extra: matplotlib
+Provides-Extra: sqlalchemy
 Provides-Extra: xlsxwriter
+Provides-Extra: all
 License-File: LICENSE
 Summary: Blazingly fast DataFrame library
 Keywords: dataframe,arrow,out-of-core
 Author-email: Ritchie Vink <ritchie46@gmail.com>
 Requires-Python: >=3.7
 Description-Content-Type: text/markdown; charset=UTF-8; variant=GFM
+Project-URL: Homepage, https://www.pola.rs/
 Project-URL: Documentation, https://pola-rs.github.io/polars/py-polars/html/reference/index.html
-Project-URL: Changelog, https://github.com/pola-rs/polars/releases
 Project-URL: Repository, https://github.com/pola-rs/polars
-Project-URL: Homepage, https://www.pola.rs/
+Project-URL: Changelog, https://github.com/pola-rs/polars/releases
 
 <h1 align="center">
   <img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/polars_github_logo_rect_dark_name.svg">
   <br>
 </h1>
 
 <div align="center">
```

#### html2text {}

```diff
@@ -1,41 +1,41 @@
-Metadata-Version: 2.1 Name: polars-lts-cpu Version: 0.18.0 Classifier:
+Metadata-Version: 2.1 Name: polars-lts-cpu Version: 0.18.1 Classifier:
 Development Status :: 5 - Production/Stable Classifier: Environment :: Console
 Classifier: Intended Audience :: Science/Research Classifier: License :: OSI
 Approved :: MIT License Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python Classifier: Programming Language ::
 Python :: 3 Classifier: Programming Language :: Python :: 3 :: Only Classifier:
 Programming Language :: Python :: 3.7 Classifier: Programming Language ::
 Python :: 3.8 Classifier: Programming Language :: Python :: 3.9 Classifier:
 Programming Language :: Python :: 3.10 Classifier: Programming Language ::
 Python :: 3.11 Classifier: Programming Language :: Rust Classifier: Topic ::
-Scientific/Engineering Requires-Dist: typing_extensions >= 4.0.1;
-python_version < '3.8' Requires-Dist: matplotlib; extra == 'matplotlib'
-Requires-Dist: deltalake >= 0.8.0; extra == 'deltalake' Requires-Dist:
-pyarrow>=7.0.0; extra == 'pandas' Requires-Dist: pandas; extra == 'pandas'
-Requires-Dist: numpy >= 1.16.0; extra == 'numpy' Requires-Dist:
-backports.zoneinfo; (python_version < '3.9') and extra == 'timezone' Requires-
-Dist: tzdata; (platform_system == 'Windows') and extra == 'timezone' Requires-
-Dist: pyarrow>=7.0.0; extra == 'pyarrow' Requires-Dist: fsspec; extra ==
-'fsspec' Requires-Dist: sqlalchemy; extra == 'sqlalchemy' Requires-Dist:
-pandas; extra == 'sqlalchemy' Requires-Dist: polars
-[pyarrow,pandas,numpy,fsspec,connectorx,xlsx2csv,deltalake,timezone,matplotlib,sqlalchemy,xlsxwriter];
-extra == 'all' Requires-Dist: xlsx2csv >= 0.8.0; extra == 'xlsx2csv' Requires-
-Dist: connectorx; extra == 'connectorx' Requires-Dist: xlsxwriter; extra ==
-'xlsxwriter' Provides-Extra: matplotlib Provides-Extra: deltalake Provides-
-Extra: pandas Provides-Extra: numpy Provides-Extra: timezone Provides-Extra:
-pyarrow Provides-Extra: fsspec Provides-Extra: sqlalchemy Provides-Extra: all
-Provides-Extra: xlsx2csv Provides-Extra: connectorx Provides-Extra: xlsxwriter
-License-File: LICENSE Summary: Blazingly fast DataFrame library Keywords:
-dataframe,arrow,out-of-core Author-email: Ritchie Vink
+Scientific/Engineering Requires-Dist: typing_extensions >=4.0.1 ;
+python_version < '3.8' Requires-Dist: pyarrow >=7.0.0 ; extra == 'pyarrow'
+Requires-Dist: pyarrow >=7.0.0 ; extra == 'pandas' Requires-Dist: pandas ;
+extra == 'pandas' Requires-Dist: numpy >=1.16.0 ; extra == 'numpy' Requires-
+Dist: fsspec ; extra == 'fsspec' Requires-Dist: connectorx ; extra ==
+'connectorx' Requires-Dist: xlsx2csv >=0.8.0 ; extra == 'xlsx2csv' Requires-
+Dist: deltalake >=0.8.0 ; extra == 'deltalake' Requires-Dist:
+backports.zoneinfo ; python_version < '3.9' and extra == 'timezone' Requires-
+Dist: tzdata ; platform_system == 'Windows' and extra == 'timezone' Requires-
+Dist: matplotlib ; extra == 'matplotlib' Requires-Dist: sqlalchemy ; extra ==
+'sqlalchemy' Requires-Dist: pandas ; extra == 'sqlalchemy' Requires-Dist:
+xlsxwriter ; extra == 'xlsxwriter' Requires-Dist: polars
+[pyarrow,pandas,numpy,fsspec,connectorx,xlsx2csv,deltalake,timezone,matplotlib,sqlalchemy,xlsxwriter]
+; extra == 'all' Provides-Extra: pyarrow Provides-Extra: pandas Provides-Extra:
+numpy Provides-Extra: fsspec Provides-Extra: connectorx Provides-Extra:
+xlsx2csv Provides-Extra: deltalake Provides-Extra: timezone Provides-Extra:
+matplotlib Provides-Extra: sqlalchemy Provides-Extra: xlsxwriter Provides-
+Extra: all License-File: LICENSE Summary: Blazingly fast DataFrame library
+Keywords: dataframe,arrow,out-of-core Author-email: Ritchie Vink
 gmail.com> Requires-Python: >=3.7 Description-Content-Type: text/markdown;
-charset=UTF-8; variant=GFM Project-URL: Documentation, https://pola-
-rs.github.io/polars/py-polars/html/reference/index.html Project-URL: Changelog,
-https://github.com/pola-rs/polars/releases Project-URL: Repository, https://
-github.com/pola-rs/polars Project-URL: Homepage, https://www.pola.rs/
+charset=UTF-8; variant=GFM Project-URL: Homepage, https://www.pola.rs/ Project-
+URL: Documentation, https://pola-rs.github.io/polars/py-polars/html/reference/
+index.html Project-URL: Repository, https://github.com/pola-rs/polars Project-
+URL: Changelog, https://github.com/pola-rs/polars/releases
  ****** [https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/
                     polars_github_logo_rect_dark_name.svg]
                                      ******
 [rust_docs] [Build_and_test] [https://img.shields.io/crates/v/polars.svg] [PyPi
  Latest_Release] [NPM_Latest_Release] [R-universe_Latest_Release] [DOI_Latest
                                    Release]
   Documentation: Python - Rust - Node.js - R | StackOverflow: Python - Rust -
```

